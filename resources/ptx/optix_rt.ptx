//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26907403
// Cuda compilation tools, release 10.1, V10.1.243
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_61
.address_size 64

	// .globl	__intersection__cylinder
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0
)
;
.const .align 8 .b8 params[368];
.global .align 1 .b8 $str[36] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 83, 84, 65, 67, 75, 95, 79, 86, 69, 82, 70, 76, 79, 87, 0};
.global .align 1 .b8 $str1[42] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 67, 69, 95, 68, 69, 80, 84, 72, 95, 69, 88, 67, 69, 69, 68, 69, 68, 0};
.global .align 1 .b8 $str2[46] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 68, 69, 80, 84, 72, 95, 69, 88, 67, 69, 69, 68, 69, 68, 0};
.global .align 1 .b8 $str3[51] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 73, 78, 86, 65, 76, 73, 68, 95, 84, 82, 65, 86, 69, 82, 83, 65, 66, 76, 69, 0};
.global .align 1 .b8 $str4[48] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 73, 78, 86, 65, 76, 73, 68, 95, 77, 73, 83, 83, 95, 83, 66, 84, 0};
.global .align 1 .b8 $str5[47] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 73, 78, 86, 65, 76, 73, 68, 95, 72, 73, 84, 95, 83, 66, 84, 0};
.const .align 8 .u64 exceptions[12] = {4294967295, generic($str), 4294967294, generic($str1), 4294967293, generic($str2), 4294967291, generic($str3), 4294967290, generic($str4), 4294967289, generic($str5)};
.global .align 1 .b8 $str6[24] = {79, 112, 116, 105, 120, 32, 69, 120, 99, 101, 112, 116, 105, 111, 110, 32, 37, 117, 58, 32, 37, 115, 10, 0};

.visible .entry __intersection__cylinder(

)
{
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<14>;
	.reg .f32 	%f<965>;
	.reg .b32 	%r<320>;
	.reg .b64 	%rd<266>;


	// inline asm
	call (%rd19), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd1, [%rd19+8];
	// inline asm
	call (%f330), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f331), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f910), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r8), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p5, %r8, 0;
	@%p5 bra 	BB0_1;

	mov.u32 	%r318, 0;
	// inline asm
	call (%f333), _optix_get_ray_time, ();
	// inline asm

BB0_3:
	.pragma "nounroll";
	// inline asm
	call (%rd20), _optix_get_transform_list_handle, (%r318);
	// inline asm
	// inline asm
	call (%r11), _optix_get_transform_type_from_handle, (%rd20);
	// inline asm
	and.b32  	%r12, %r11, -2;
	setp.eq.s32	%p6, %r12, 2;
	@%p6 bra 	BB0_9;
	bra.uni 	BB0_4;

BB0_9:
	setp.eq.s32	%p9, %r11, 2;
	@%p9 bra 	BB0_13;
	bra.uni 	BB0_10;

BB0_13:
	// inline asm
	call (%rd94), _optix_get_matrix_motion_transform_from_handle, (%rd20);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd96, %rd94;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd96];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r102;
	add.s64 	%rd100, %rd94, 16;
	// inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd99];
	// inline asm
	add.s64 	%rd103, %rd94, 32;
	// inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd102];
	// inline asm
	add.s64 	%rd106, %rd94, 48;
	// inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd105];
	// inline asm
	add.s64 	%rd109, %rd94, 64;
	// inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd108];
	// inline asm
	add.s64 	%rd112, %rd94, 80;
	// inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd111];
	// inline asm
	add.s64 	%rd115, %rd94, 96;
	// inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd114];
	// inline asm
	add.s64 	%rd118, %rd94, 112;
	// inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd117];
	// inline asm
	mov.b32 	 %f460, %r103;
	mov.b32 	 %f461, %r104;
	cvt.u32.u16	%r144, %rs4;
	add.s32 	%r145, %r144, -1;
	cvt.rn.f32.s32	%f462, %r145;
	sub.f32 	%f463, %f333, %f460;
	mul.f32 	%f464, %f463, %f462;
	sub.f32 	%f465, %f461, %f460;
	div.rn.f32 	%f466, %f464, %f465;
	min.f32 	%f467, %f462, %f466;
	mov.f32 	%f468, 0f00000000;
	max.f32 	%f469, %f468, %f467;
	cvt.rmi.f32.f32	%f470, %f469;
	cvt.rzi.s32.f32	%r146, %f470;
	mul.wide.s32 	%rd129, %r146, 48;
	add.s64 	%rd121, %rd103, %rd129;
	// inline asm
	cvta.to.global.u64 %rd120, %rd121;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd120];
	// inline asm
	mov.b32 	 %f882, %r132;
	mov.b32 	 %f883, %r133;
	mov.b32 	 %f884, %r134;
	mov.b32 	 %f885, %r135;
	add.s64 	%rd124, %rd121, 16;
	// inline asm
	cvta.to.global.u64 %rd123, %rd124;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd123];
	// inline asm
	mov.b32 	 %f878, %r136;
	mov.b32 	 %f879, %r137;
	mov.b32 	 %f880, %r138;
	mov.b32 	 %f881, %r139;
	add.s64 	%rd127, %rd121, 32;
	// inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd126];
	// inline asm
	sub.f32 	%f98, %f469, %f470;
	mov.b32 	 %f874, %r140;
	mov.b32 	 %f875, %r141;
	mov.b32 	 %f876, %r142;
	mov.b32 	 %f877, %r143;
	setp.leu.f32	%p11, %f98, 0f00000000;
	@%p11 bra 	BB0_15;

	cvt.rmi.f32.f32	%f845, %f469;
	cvt.rzi.s32.f32	%r317, %f845;
	cvt.s64.s32	%rd263, %r317;
	mul.lo.s64 	%rd139, %rd263, 48;
	add.s64 	%rd140, %rd94, %rd139;
	add.s64 	%rd131, %rd140, 80;
	// inline asm
	cvta.to.global.u64 %rd130, %rd131;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd130];
	// inline asm
	mov.b32 	 %f471, %r147;
	mov.b32 	 %f472, %r148;
	mov.b32 	 %f473, %r149;
	mov.b32 	 %f474, %r150;
	add.s64 	%rd134, %rd140, 96;
	// inline asm
	cvta.to.global.u64 %rd133, %rd134;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd133];
	// inline asm
	mov.b32 	 %f475, %r151;
	mov.b32 	 %f476, %r152;
	mov.b32 	 %f477, %r153;
	mov.b32 	 %f478, %r154;
	add.s64 	%rd137, %rd140, 112;
	// inline asm
	cvta.to.global.u64 %rd136, %rd137;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd136];
	// inline asm
	mov.f32 	%f479, 0f3F800000;
	sub.f32 	%f480, %f479, %f98;
	mul.f32 	%f481, %f98, %f471;
	mul.f32 	%f482, %f98, %f472;
	mul.f32 	%f483, %f98, %f473;
	mul.f32 	%f484, %f98, %f474;
	fma.rn.f32 	%f882, %f480, %f882, %f481;
	fma.rn.f32 	%f883, %f480, %f883, %f482;
	fma.rn.f32 	%f884, %f480, %f884, %f483;
	fma.rn.f32 	%f885, %f480, %f885, %f484;
	mul.f32 	%f485, %f98, %f475;
	mul.f32 	%f486, %f98, %f476;
	mul.f32 	%f487, %f98, %f477;
	mul.f32 	%f488, %f98, %f478;
	fma.rn.f32 	%f878, %f480, %f878, %f485;
	fma.rn.f32 	%f879, %f480, %f879, %f486;
	fma.rn.f32 	%f880, %f480, %f880, %f487;
	fma.rn.f32 	%f881, %f480, %f881, %f488;
	mov.b32 	 %f489, %r155;
	mov.b32 	 %f490, %r156;
	mov.b32 	 %f491, %r157;
	mov.b32 	 %f492, %r158;
	mul.f32 	%f493, %f98, %f489;
	mul.f32 	%f494, %f98, %f490;
	mul.f32 	%f495, %f98, %f491;
	mul.f32 	%f496, %f98, %f492;
	fma.rn.f32 	%f874, %f480, %f874, %f493;
	fma.rn.f32 	%f875, %f480, %f875, %f494;
	fma.rn.f32 	%f876, %f480, %f876, %f495;
	fma.rn.f32 	%f877, %f480, %f877, %f496;
	bra.uni 	BB0_15;

BB0_4:
	mov.f32 	%f886, 0f00000000;
	mov.f32 	%f888, 0f3F800000;
	setp.eq.s32	%p7, %r11, 4;
	@%p7 bra 	BB0_7;
	bra.uni 	BB0_5;

BB0_7:
	// inline asm
	call (%rd264), _optix_get_instance_inverse_transform_from_handle, (%rd20);
	// inline asm
	bra.uni 	BB0_8;

BB0_10:
	// inline asm
	call (%rd35), _optix_get_srt_motion_transform_from_handle, (%rd20);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd37, %rd35;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r25,%r26,%r27,%r28}, [%rd37];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r27;
	add.s64 	%rd41, %rd35, 16;
	// inline asm
	cvta.to.global.u64 %rd40, %rd41;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r29,%r30,%r31,%r32}, [%rd40];
	// inline asm
	add.s64 	%rd44, %rd35, 32;
	// inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd43];
	// inline asm
	add.s64 	%rd47, %rd35, 48;
	// inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd46];
	// inline asm
	add.s64 	%rd50, %rd35, 64;
	// inline asm
	cvta.to.global.u64 %rd49, %rd50;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd49];
	// inline asm
	add.s64 	%rd53, %rd35, 80;
	// inline asm
	cvta.to.global.u64 %rd52, %rd53;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd52];
	// inline asm
	add.s64 	%rd56, %rd35, 96;
	// inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd55];
	// inline asm
	add.s64 	%rd59, %rd35, 112;
	// inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd58];
	// inline asm
	add.s64 	%rd62, %rd35, 128;
	// inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd61];
	// inline asm
	add.s64 	%rd65, %rd35, 144;
	// inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd64];
	// inline asm
	mov.b32 	 %f347, %r28;
	mov.b32 	 %f348, %r29;
	cvt.u32.u16	%r81, %rs2;
	add.s32 	%r82, %r81, -1;
	cvt.rn.f32.s32	%f349, %r82;
	sub.f32 	%f350, %f333, %f347;
	mul.f32 	%f351, %f350, %f349;
	sub.f32 	%f352, %f348, %f347;
	div.rn.f32 	%f353, %f351, %f352;
	min.f32 	%f354, %f349, %f353;
	mov.f32 	%f355, 0f00000000;
	max.f32 	%f356, %f355, %f354;
	cvt.rmi.f32.f32	%f357, %f356;
	cvt.rzi.s32.f32	%r83, %f357;
	mul.wide.s32 	%rd79, %r83, 64;
	add.s64 	%rd68, %rd44, %rd79;
	// inline asm
	cvta.to.global.u64 %rd67, %rd68;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd67];
	// inline asm
	mov.b32 	 %f858, %r65;
	mov.b32 	 %f859, %r66;
	mov.b32 	 %f860, %r67;
	mov.b32 	 %f861, %r68;
	add.s64 	%rd71, %rd68, 16;
	// inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd70];
	// inline asm
	mov.b32 	 %f862, %r69;
	mov.b32 	 %f863, %r70;
	mov.b32 	 %f864, %r71;
	mov.b32 	 %f865, %r72;
	add.s64 	%rd74, %rd68, 32;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd73];
	// inline asm
	sub.f32 	%f37, %f356, %f357;
	mov.b32 	 %f866, %r73;
	mov.b32 	 %f867, %r74;
	mov.b32 	 %f868, %r75;
	mov.b32 	 %f869, %r76;
	add.s64 	%rd77, %rd68, 48;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd76];
	// inline asm
	mov.b32 	 %f870, %r77;
	mov.b32 	 %f871, %r78;
	mov.b32 	 %f872, %r79;
	mov.b32 	 %f873, %r80;
	setp.leu.f32	%p10, %f37, 0f00000000;
	@%p10 bra 	BB0_12;

	cvt.rmi.f32.f32	%f844, %f356;
	cvt.rzi.s32.f32	%r316, %f844;
	cvt.s64.s32	%rd262, %r316;
	shl.b64 	%rd92, %rd262, 6;
	add.s64 	%rd93, %rd92, %rd35;
	add.s64 	%rd81, %rd93, 96;
	// inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd80];
	// inline asm
	mov.b32 	 %f358, %r84;
	mov.b32 	 %f359, %r85;
	mov.b32 	 %f360, %r86;
	mov.b32 	 %f361, %r87;
	add.s64 	%rd84, %rd93, 112;
	// inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd83];
	// inline asm
	mov.b32 	 %f362, %r88;
	mov.b32 	 %f363, %r89;
	mov.b32 	 %f364, %r90;
	mov.b32 	 %f365, %r91;
	add.s64 	%rd87, %rd93, 128;
	// inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd86];
	// inline asm
	mov.b32 	 %f366, %r92;
	mov.b32 	 %f367, %r93;
	mov.b32 	 %f368, %r94;
	mov.b32 	 %f369, %r95;
	add.s64 	%rd90, %rd93, 144;
	// inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd89];
	// inline asm
	mov.f32 	%f370, 0f3F800000;
	sub.f32 	%f371, %f370, %f37;
	mul.f32 	%f372, %f37, %f358;
	mul.f32 	%f373, %f37, %f359;
	mul.f32 	%f374, %f37, %f360;
	mul.f32 	%f375, %f37, %f361;
	fma.rn.f32 	%f858, %f371, %f858, %f372;
	fma.rn.f32 	%f859, %f371, %f859, %f373;
	fma.rn.f32 	%f860, %f371, %f860, %f374;
	fma.rn.f32 	%f861, %f371, %f861, %f375;
	mul.f32 	%f376, %f37, %f362;
	mul.f32 	%f377, %f37, %f363;
	mul.f32 	%f378, %f37, %f364;
	mul.f32 	%f379, %f37, %f365;
	fma.rn.f32 	%f862, %f371, %f862, %f376;
	fma.rn.f32 	%f863, %f371, %f863, %f377;
	fma.rn.f32 	%f864, %f371, %f864, %f378;
	fma.rn.f32 	%f865, %f371, %f865, %f379;
	mul.f32 	%f380, %f37, %f366;
	mul.f32 	%f381, %f37, %f367;
	mul.f32 	%f382, %f37, %f368;
	mul.f32 	%f383, %f37, %f369;
	fma.rn.f32 	%f866, %f371, %f866, %f380;
	fma.rn.f32 	%f384, %f371, %f867, %f381;
	fma.rn.f32 	%f385, %f371, %f868, %f382;
	fma.rn.f32 	%f386, %f371, %f869, %f383;
	mov.b32 	 %f387, %r96;
	mov.b32 	 %f388, %r97;
	mov.b32 	 %f389, %r98;
	mov.b32 	 %f390, %r99;
	mul.f32 	%f391, %f37, %f387;
	mul.f32 	%f392, %f37, %f388;
	mul.f32 	%f393, %f37, %f389;
	mul.f32 	%f394, %f37, %f390;
	fma.rn.f32 	%f395, %f371, %f870, %f391;
	fma.rn.f32 	%f871, %f371, %f871, %f392;
	fma.rn.f32 	%f872, %f371, %f872, %f393;
	fma.rn.f32 	%f873, %f371, %f873, %f394;
	mul.f32 	%f396, %f385, %f385;
	fma.rn.f32 	%f397, %f384, %f384, %f396;
	fma.rn.f32 	%f398, %f386, %f386, %f397;
	fma.rn.f32 	%f399, %f395, %f395, %f398;
	sqrt.rn.f32 	%f400, %f399;
	rcp.rn.f32 	%f401, %f400;
	mul.f32 	%f867, %f384, %f401;
	mul.f32 	%f868, %f385, %f401;
	mul.f32 	%f869, %f386, %f401;
	mul.f32 	%f870, %f395, %f401;

BB0_12:
	mul.f32 	%f402, %f868, %f868;
	fma.rn.f32 	%f403, %f867, %f867, %f402;
	fma.rn.f32 	%f404, %f869, %f869, %f403;
	fma.rn.f32 	%f405, %f870, %f870, %f404;
	rcp.rn.f32 	%f406, %f405;
	mul.f32 	%f407, %f867, %f406;
	mul.f32 	%f408, %f868, %f406;
	mul.f32 	%f409, %f869, %f406;
	mul.f32 	%f410, %f870, %f406;
	mul.f32 	%f411, %f867, %f407;
	mul.f32 	%f412, %f868, %f408;
	mul.f32 	%f413, %f869, %f409;
	mul.f32 	%f414, %f867, %f408;
	mul.f32 	%f415, %f869, %f410;
	mul.f32 	%f416, %f867, %f409;
	mul.f32 	%f417, %f868, %f410;
	mul.f32 	%f418, %f868, %f409;
	mul.f32 	%f419, %f867, %f410;
	sub.f32 	%f420, %f411, %f412;
	sub.f32 	%f421, %f420, %f413;
	fma.rn.f32 	%f422, %f870, %f410, %f421;
	sub.f32 	%f423, %f414, %f415;
	add.f32 	%f424, %f423, %f423;
	add.f32 	%f425, %f416, %f417;
	add.f32 	%f426, %f425, %f425;
	add.f32 	%f427, %f414, %f415;
	add.f32 	%f428, %f427, %f427;
	sub.f32 	%f429, %f412, %f411;
	sub.f32 	%f430, %f429, %f413;
	fma.rn.f32 	%f431, %f870, %f410, %f430;
	sub.f32 	%f432, %f418, %f419;
	add.f32 	%f433, %f432, %f432;
	sub.f32 	%f434, %f416, %f417;
	add.f32 	%f435, %f434, %f434;
	add.f32 	%f436, %f418, %f419;
	add.f32 	%f437, %f436, %f436;
	neg.f32 	%f438, %f411;
	sub.f32 	%f439, %f438, %f412;
	add.f32 	%f440, %f413, %f439;
	fma.rn.f32 	%f441, %f870, %f410, %f440;
	mul.f32 	%f442, %f861, %f422;
	fma.rn.f32 	%f443, %f864, %f424, %f442;
	fma.rn.f32 	%f444, %f866, %f426, %f443;
	sub.f32 	%f885, %f871, %f444;
	mul.f32 	%f445, %f864, %f431;
	fma.rn.f32 	%f446, %f861, %f428, %f445;
	fma.rn.f32 	%f447, %f866, %f433, %f446;
	sub.f32 	%f881, %f872, %f447;
	mul.f32 	%f448, %f864, %f437;
	fma.rn.f32 	%f449, %f861, %f435, %f448;
	fma.rn.f32 	%f450, %f866, %f441, %f449;
	sub.f32 	%f877, %f873, %f450;
	mul.f32 	%f451, %f860, %f422;
	fma.rn.f32 	%f452, %f863, %f424, %f451;
	fma.rn.f32 	%f884, %f865, %f426, %f452;
	mul.f32 	%f453, %f863, %f431;
	fma.rn.f32 	%f454, %f860, %f428, %f453;
	fma.rn.f32 	%f880, %f865, %f433, %f454;
	mul.f32 	%f455, %f863, %f437;
	fma.rn.f32 	%f456, %f860, %f435, %f455;
	fma.rn.f32 	%f876, %f865, %f441, %f456;
	mul.f32 	%f457, %f859, %f422;
	fma.rn.f32 	%f883, %f862, %f424, %f457;
	mul.f32 	%f458, %f862, %f431;
	fma.rn.f32 	%f879, %f859, %f428, %f458;
	mul.f32 	%f459, %f862, %f437;
	fma.rn.f32 	%f875, %f859, %f435, %f459;
	mul.f32 	%f882, %f858, %f422;
	mul.f32 	%f878, %f858, %f428;
	mul.f32 	%f874, %f858, %f435;

BB0_15:
	mul.f32 	%f497, %f875, %f880;
	mul.f32 	%f498, %f876, %f879;
	sub.f32 	%f499, %f498, %f497;
	mul.f32 	%f500, %f882, %f499;
	mul.f32 	%f501, %f874, %f880;
	mul.f32 	%f502, %f876, %f878;
	sub.f32 	%f503, %f502, %f501;
	mul.f32 	%f504, %f503, %f883;
	sub.f32 	%f505, %f500, %f504;
	mul.f32 	%f506, %f874, %f879;
	mul.f32 	%f507, %f875, %f878;
	sub.f32 	%f508, %f507, %f506;
	fma.rn.f32 	%f509, %f508, %f884, %f505;
	rcp.rn.f32 	%f510, %f509;
	mul.f32 	%f894, %f499, %f510;
	mul.f32 	%f511, %f876, %f883;
	mul.f32 	%f512, %f875, %f884;
	sub.f32 	%f513, %f512, %f511;
	mul.f32 	%f895, %f510, %f513;
	mul.f32 	%f514, %f879, %f884;
	mul.f32 	%f515, %f880, %f883;
	sub.f32 	%f516, %f515, %f514;
	mul.f32 	%f896, %f510, %f516;
	sub.f32 	%f517, %f501, %f502;
	mul.f32 	%f890, %f517, %f510;
	mul.f32 	%f518, %f874, %f884;
	mul.f32 	%f519, %f876, %f882;
	sub.f32 	%f520, %f519, %f518;
	mul.f32 	%f891, %f510, %f520;
	mul.f32 	%f521, %f880, %f882;
	mul.f32 	%f522, %f878, %f884;
	sub.f32 	%f523, %f522, %f521;
	mul.f32 	%f892, %f510, %f523;
	mul.f32 	%f886, %f508, %f510;
	mul.f32 	%f524, %f875, %f882;
	mul.f32 	%f525, %f874, %f883;
	sub.f32 	%f526, %f525, %f524;
	mul.f32 	%f887, %f526, %f510;
	mul.f32 	%f527, %f878, %f883;
	mul.f32 	%f528, %f879, %f882;
	sub.f32 	%f529, %f528, %f527;
	mul.f32 	%f888, %f529, %f510;
	mul.f32 	%f530, %f885, %f894;
	neg.f32 	%f531, %f530;
	mul.f32 	%f532, %f881, %f895;
	sub.f32 	%f533, %f531, %f532;
	mul.f32 	%f534, %f877, %f896;
	sub.f32 	%f897, %f533, %f534;
	mul.f32 	%f535, %f885, %f890;
	neg.f32 	%f536, %f535;
	mul.f32 	%f537, %f881, %f891;
	sub.f32 	%f538, %f536, %f537;
	mul.f32 	%f539, %f877, %f892;
	sub.f32 	%f893, %f538, %f539;
	mul.f32 	%f540, %f885, %f886;
	neg.f32 	%f541, %f540;
	mul.f32 	%f542, %f881, %f887;
	sub.f32 	%f543, %f541, %f542;
	mul.f32 	%f544, %f877, %f888;
	sub.f32 	%f889, %f543, %f544;
	bra.uni 	BB0_16;

BB0_5:
	setp.ne.s32	%p8, %r11, 1;
	mov.f32 	%f887, %f886;
	mov.f32 	%f889, %f886;
	mov.f32 	%f890, %f886;
	mov.f32 	%f891, %f888;
	mov.f32 	%f892, %f886;
	mov.f32 	%f893, %f886;
	mov.f32 	%f894, %f888;
	mov.f32 	%f895, %f886;
	mov.f32 	%f896, %f886;
	mov.f32 	%f897, %f886;
	@%p8 bra 	BB0_16;

	// inline asm
	call (%rd22), _optix_get_static_transform_from_handle, (%rd20);
	// inline asm
	add.s64 	%rd264, %rd22, 64;

BB0_8:
	// inline asm
	cvta.to.global.u64 %rd26, %rd264;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r13,%r14,%r15,%r16}, [%rd26];
	// inline asm
	mov.b32 	 %f894, %r13;
	mov.b32 	 %f895, %r14;
	mov.b32 	 %f896, %r15;
	mov.b32 	 %f897, %r16;
	add.s64 	%rd30, %rd264, 16;
	// inline asm
	cvta.to.global.u64 %rd29, %rd30;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r17,%r18,%r19,%r20}, [%rd29];
	// inline asm
	mov.b32 	 %f890, %r17;
	mov.b32 	 %f891, %r18;
	mov.b32 	 %f892, %r19;
	mov.b32 	 %f893, %r20;
	add.s64 	%rd33, %rd264, 32;
	// inline asm
	cvta.to.global.u64 %rd32, %rd33;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r21,%r22,%r23,%r24}, [%rd32];
	// inline asm
	mov.b32 	 %f886, %r21;
	mov.b32 	 %f887, %r22;
	mov.b32 	 %f888, %r23;
	mov.b32 	 %f889, %r24;

BB0_16:
	setp.eq.s32	%p12, %r318, 0;
	@%p12 bra 	BB0_17;
	bra.uni 	BB0_18;

BB0_17:
	mov.f32 	%f857, %f897;
	mov.f32 	%f856, %f896;
	mov.f32 	%f855, %f895;
	mov.f32 	%f854, %f894;
	mov.f32 	%f853, %f893;
	mov.f32 	%f852, %f892;
	mov.f32 	%f851, %f891;
	mov.f32 	%f850, %f890;
	mov.f32 	%f849, %f889;
	mov.f32 	%f848, %f888;
	mov.f32 	%f847, %f887;
	mov.f32 	%f846, %f886;
	bra.uni 	BB0_19;

BB0_18:
	mul.f32 	%f545, %f850, %f895;
	fma.rn.f32 	%f546, %f854, %f894, %f545;
	fma.rn.f32 	%f151, %f846, %f896, %f546;
	mul.f32 	%f547, %f851, %f895;
	fma.rn.f32 	%f548, %f855, %f894, %f547;
	fma.rn.f32 	%f152, %f847, %f896, %f548;
	mul.f32 	%f549, %f852, %f895;
	fma.rn.f32 	%f550, %f856, %f894, %f549;
	fma.rn.f32 	%f153, %f848, %f896, %f550;
	mul.f32 	%f551, %f853, %f895;
	fma.rn.f32 	%f552, %f857, %f894, %f551;
	fma.rn.f32 	%f553, %f849, %f896, %f552;
	add.f32 	%f154, %f897, %f553;
	mul.f32 	%f554, %f850, %f891;
	fma.rn.f32 	%f555, %f854, %f890, %f554;
	fma.rn.f32 	%f155, %f846, %f892, %f555;
	mul.f32 	%f556, %f851, %f891;
	fma.rn.f32 	%f557, %f855, %f890, %f556;
	fma.rn.f32 	%f156, %f847, %f892, %f557;
	mul.f32 	%f558, %f852, %f891;
	fma.rn.f32 	%f559, %f856, %f890, %f558;
	fma.rn.f32 	%f157, %f848, %f892, %f559;
	mul.f32 	%f560, %f853, %f891;
	fma.rn.f32 	%f561, %f857, %f890, %f560;
	fma.rn.f32 	%f562, %f849, %f892, %f561;
	add.f32 	%f158, %f893, %f562;
	mul.f32 	%f563, %f850, %f887;
	fma.rn.f32 	%f564, %f854, %f886, %f563;
	fma.rn.f32 	%f846, %f846, %f888, %f564;
	mul.f32 	%f565, %f851, %f887;
	fma.rn.f32 	%f566, %f855, %f886, %f565;
	fma.rn.f32 	%f847, %f847, %f888, %f566;
	mul.f32 	%f567, %f852, %f887;
	fma.rn.f32 	%f568, %f856, %f886, %f567;
	fma.rn.f32 	%f848, %f848, %f888, %f568;
	mul.f32 	%f569, %f853, %f887;
	fma.rn.f32 	%f570, %f857, %f886, %f569;
	fma.rn.f32 	%f571, %f849, %f888, %f570;
	add.f32 	%f849, %f889, %f571;
	mov.f32 	%f857, %f154;
	mov.f32 	%f856, %f153;
	mov.f32 	%f855, %f152;
	mov.f32 	%f854, %f151;
	mov.f32 	%f853, %f158;
	mov.f32 	%f852, %f157;
	mov.f32 	%f851, %f156;
	mov.f32 	%f850, %f155;

BB0_19:
	add.s32 	%r318, %r318, 1;
	setp.lt.u32	%p13, %r318, %r8;
	@%p13 bra 	BB0_3;

	mul.f32 	%f572, %f330, %f854;
	fma.rn.f32 	%f573, %f331, %f855, %f572;
	fma.rn.f32 	%f574, %f910, %f856, %f573;
	add.f32 	%f912, %f857, %f574;
	mul.f32 	%f575, %f330, %f850;
	fma.rn.f32 	%f576, %f331, %f851, %f575;
	fma.rn.f32 	%f577, %f910, %f852, %f576;
	add.f32 	%f911, %f853, %f577;
	mul.f32 	%f578, %f330, %f846;
	fma.rn.f32 	%f579, %f331, %f847, %f578;
	fma.rn.f32 	%f580, %f910, %f848, %f579;
	add.f32 	%f910, %f849, %f580;
	bra.uni 	BB0_21;

BB0_1:
	mov.f32 	%f911, %f331;
	mov.f32 	%f912, %f330;

BB0_21:
	setp.eq.s32	%p51, %r8, 0;
	// inline asm
	call (%f581), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f582), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f961), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f584), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r319, 0;
	@%p51 bra 	BB0_22;

BB0_23:
	.pragma "nounroll";
	// inline asm
	call (%rd141), _optix_get_transform_list_handle, (%r319);
	// inline asm
	// inline asm
	call (%r161), _optix_get_transform_type_from_handle, (%rd141);
	// inline asm
	and.b32  	%r162, %r161, -2;
	setp.eq.s32	%p15, %r162, 2;
	@%p15 bra 	BB0_29;
	bra.uni 	BB0_24;

BB0_29:
	setp.eq.s32	%p18, %r161, 2;
	@%p18 bra 	BB0_33;
	bra.uni 	BB0_30;

BB0_33:
	// inline asm
	call (%rd215), _optix_get_matrix_motion_transform_from_handle, (%rd141);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd217, %rd215;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd217];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r252;
	add.s64 	%rd221, %rd215, 16;
	// inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd220];
	// inline asm
	add.s64 	%rd224, %rd215, 32;
	// inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd223];
	// inline asm
	add.s64 	%rd227, %rd215, 48;
	// inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd226];
	// inline asm
	add.s64 	%rd230, %rd215, 64;
	// inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd229];
	// inline asm
	add.s64 	%rd233, %rd215, 80;
	// inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd232];
	// inline asm
	add.s64 	%rd236, %rd215, 96;
	// inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd235];
	// inline asm
	add.s64 	%rd239, %rd215, 112;
	// inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd238];
	// inline asm
	mov.b32 	 %f687, %r253;
	mov.b32 	 %f688, %r254;
	cvt.u32.u16	%r294, %rs8;
	add.s32 	%r295, %r294, -1;
	cvt.rn.f32.s32	%f689, %r295;
	sub.f32 	%f690, %f584, %f687;
	mul.f32 	%f691, %f690, %f689;
	sub.f32 	%f692, %f688, %f687;
	div.rn.f32 	%f693, %f691, %f692;
	min.f32 	%f694, %f689, %f693;
	mov.f32 	%f695, 0f00000000;
	max.f32 	%f696, %f695, %f694;
	cvt.rmi.f32.f32	%f697, %f696;
	cvt.rzi.s32.f32	%r296, %f697;
	cvt.s64.s32	%rd17, %r296;
	mul.wide.s32 	%rd250, %r296, 48;
	add.s64 	%rd242, %rd224, %rd250;
	// inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd241];
	// inline asm
	mov.b32 	 %f938, %r282;
	mov.b32 	 %f939, %r283;
	mov.b32 	 %f940, %r284;
	add.s64 	%rd245, %rd242, 16;
	// inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd244];
	// inline asm
	mov.b32 	 %f935, %r286;
	mov.b32 	 %f936, %r287;
	mov.b32 	 %f937, %r288;
	add.s64 	%rd248, %rd242, 32;
	// inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd247];
	// inline asm
	sub.f32 	%f249, %f696, %f697;
	mov.b32 	 %f932, %r290;
	mov.b32 	 %f933, %r291;
	mov.b32 	 %f934, %r292;
	setp.leu.f32	%p20, %f249, 0f00000000;
	@%p20 bra 	BB0_35;

	mul.lo.s64 	%rd260, %rd17, 48;
	add.s64 	%rd261, %rd215, %rd260;
	add.s64 	%rd252, %rd261, 80;
	// inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd251];
	// inline asm
	mov.b32 	 %f698, %r297;
	mov.b32 	 %f699, %r298;
	mov.b32 	 %f700, %r299;
	add.s64 	%rd255, %rd261, 96;
	// inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd254];
	// inline asm
	mov.b32 	 %f701, %r301;
	mov.b32 	 %f702, %r302;
	mov.b32 	 %f703, %r303;
	add.s64 	%rd258, %rd261, 112;
	// inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd257];
	// inline asm
	mov.f32 	%f704, 0f3F800000;
	sub.f32 	%f705, %f704, %f249;
	mul.f32 	%f706, %f249, %f698;
	mul.f32 	%f707, %f249, %f699;
	mul.f32 	%f708, %f249, %f700;
	fma.rn.f32 	%f938, %f705, %f938, %f706;
	fma.rn.f32 	%f939, %f705, %f939, %f707;
	fma.rn.f32 	%f940, %f705, %f940, %f708;
	mul.f32 	%f709, %f249, %f701;
	mul.f32 	%f710, %f249, %f702;
	mul.f32 	%f711, %f249, %f703;
	fma.rn.f32 	%f935, %f705, %f935, %f709;
	fma.rn.f32 	%f936, %f705, %f936, %f710;
	fma.rn.f32 	%f937, %f705, %f937, %f711;
	mov.b32 	 %f712, %r305;
	mov.b32 	 %f713, %r306;
	mov.b32 	 %f714, %r307;
	mul.f32 	%f715, %f249, %f712;
	mul.f32 	%f716, %f249, %f713;
	mul.f32 	%f717, %f249, %f714;
	fma.rn.f32 	%f932, %f705, %f932, %f715;
	fma.rn.f32 	%f933, %f705, %f933, %f716;
	fma.rn.f32 	%f934, %f705, %f934, %f717;
	bra.uni 	BB0_35;

BB0_24:
	mov.f32 	%f941, 0f00000000;
	mov.f32 	%f943, 0f3F800000;
	setp.eq.s32	%p16, %r161, 4;
	@%p16 bra 	BB0_27;
	bra.uni 	BB0_25;

BB0_27:
	// inline asm
	call (%rd265), _optix_get_instance_inverse_transform_from_handle, (%rd141);
	// inline asm
	bra.uni 	BB0_28;

BB0_30:
	// inline asm
	call (%rd156), _optix_get_srt_motion_transform_from_handle, (%rd141);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd158, %rd156;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd158];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r177;
	add.s64 	%rd162, %rd156, 16;
	// inline asm
	cvta.to.global.u64 %rd161, %rd162;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd161];
	// inline asm
	add.s64 	%rd165, %rd156, 32;
	// inline asm
	cvta.to.global.u64 %rd164, %rd165;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd164];
	// inline asm
	add.s64 	%rd168, %rd156, 48;
	// inline asm
	cvta.to.global.u64 %rd167, %rd168;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd167];
	// inline asm
	add.s64 	%rd171, %rd156, 64;
	// inline asm
	cvta.to.global.u64 %rd170, %rd171;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd170];
	// inline asm
	add.s64 	%rd174, %rd156, 80;
	// inline asm
	cvta.to.global.u64 %rd173, %rd174;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd173];
	// inline asm
	add.s64 	%rd177, %rd156, 96;
	// inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd176];
	// inline asm
	add.s64 	%rd180, %rd156, 112;
	// inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd179];
	// inline asm
	add.s64 	%rd183, %rd156, 128;
	// inline asm
	cvta.to.global.u64 %rd182, %rd183;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd182];
	// inline asm
	add.s64 	%rd186, %rd156, 144;
	// inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd185];
	// inline asm
	mov.b32 	 %f595, %r178;
	mov.b32 	 %f596, %r179;
	cvt.u32.u16	%r231, %rs6;
	add.s32 	%r232, %r231, -1;
	cvt.rn.f32.s32	%f597, %r232;
	sub.f32 	%f598, %f584, %f595;
	mul.f32 	%f599, %f598, %f597;
	sub.f32 	%f600, %f596, %f595;
	div.rn.f32 	%f601, %f599, %f600;
	min.f32 	%f602, %f597, %f601;
	mov.f32 	%f603, 0f00000000;
	max.f32 	%f604, %f603, %f602;
	cvt.rmi.f32.f32	%f605, %f604;
	cvt.rzi.s32.f32	%r233, %f605;
	cvt.s64.s32	%rd15, %r233;
	mul.wide.s32 	%rd200, %r233, 64;
	add.s64 	%rd189, %rd165, %rd200;
	// inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd188];
	// inline asm
	mov.b32 	 %f922, %r215;
	mov.b32 	 %f923, %r216;
	mov.b32 	 %f924, %r217;
	add.s64 	%rd192, %rd189, 16;
	// inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd191];
	// inline asm
	mov.b32 	 %f925, %r219;
	mov.b32 	 %f926, %r220;
	mov.b32 	 %f927, %r222;
	add.s64 	%rd195, %rd189, 32;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd194];
	// inline asm
	sub.f32 	%f209, %f604, %f605;
	mov.b32 	 %f928, %r224;
	mov.b32 	 %f929, %r225;
	mov.b32 	 %f930, %r226;
	add.s64 	%rd198, %rd189, 48;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd197];
	// inline asm
	mov.b32 	 %f931, %r227;
	setp.leu.f32	%p19, %f209, 0f00000000;
	@%p19 bra 	BB0_32;

	shl.b64 	%rd213, %rd15, 6;
	add.s64 	%rd214, %rd213, %rd156;
	add.s64 	%rd202, %rd214, 96;
	// inline asm
	cvta.to.global.u64 %rd201, %rd202;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd201];
	// inline asm
	mov.b32 	 %f606, %r234;
	mov.b32 	 %f607, %r235;
	mov.b32 	 %f608, %r236;
	add.s64 	%rd205, %rd214, 112;
	// inline asm
	cvta.to.global.u64 %rd204, %rd205;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd204];
	// inline asm
	mov.b32 	 %f609, %r238;
	mov.b32 	 %f610, %r239;
	mov.b32 	 %f611, %r241;
	add.s64 	%rd208, %rd214, 128;
	// inline asm
	cvta.to.global.u64 %rd207, %rd208;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd207];
	// inline asm
	mov.b32 	 %f612, %r243;
	mov.b32 	 %f613, %r244;
	mov.b32 	 %f614, %r245;
	add.s64 	%rd211, %rd214, 144;
	// inline asm
	cvta.to.global.u64 %rd210, %rd211;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd210];
	// inline asm
	mov.f32 	%f615, 0f3F800000;
	sub.f32 	%f616, %f615, %f209;
	mul.f32 	%f617, %f209, %f606;
	mul.f32 	%f618, %f209, %f607;
	mul.f32 	%f619, %f209, %f608;
	fma.rn.f32 	%f922, %f616, %f922, %f617;
	fma.rn.f32 	%f923, %f616, %f923, %f618;
	fma.rn.f32 	%f924, %f616, %f924, %f619;
	mul.f32 	%f620, %f209, %f609;
	mul.f32 	%f621, %f209, %f610;
	mul.f32 	%f622, %f209, %f611;
	fma.rn.f32 	%f925, %f616, %f925, %f620;
	fma.rn.f32 	%f926, %f616, %f926, %f621;
	fma.rn.f32 	%f927, %f616, %f927, %f622;
	mul.f32 	%f623, %f209, %f612;
	mul.f32 	%f624, %f209, %f613;
	mul.f32 	%f625, %f209, %f614;
	fma.rn.f32 	%f626, %f616, %f928, %f623;
	fma.rn.f32 	%f627, %f616, %f929, %f624;
	fma.rn.f32 	%f628, %f616, %f930, %f625;
	mov.b32 	 %f629, %r246;
	mul.f32 	%f630, %f209, %f629;
	fma.rn.f32 	%f631, %f616, %f931, %f630;
	mul.f32 	%f632, %f627, %f627;
	fma.rn.f32 	%f633, %f626, %f626, %f632;
	fma.rn.f32 	%f634, %f628, %f628, %f633;
	fma.rn.f32 	%f635, %f631, %f631, %f634;
	sqrt.rn.f32 	%f636, %f635;
	rcp.rn.f32 	%f637, %f636;
	mul.f32 	%f928, %f626, %f637;
	mul.f32 	%f929, %f627, %f637;
	mul.f32 	%f930, %f628, %f637;
	mul.f32 	%f931, %f631, %f637;

BB0_32:
	mul.f32 	%f638, %f929, %f929;
	fma.rn.f32 	%f639, %f928, %f928, %f638;
	fma.rn.f32 	%f640, %f930, %f930, %f639;
	fma.rn.f32 	%f641, %f931, %f931, %f640;
	rcp.rn.f32 	%f642, %f641;
	mul.f32 	%f643, %f928, %f642;
	mul.f32 	%f644, %f929, %f642;
	mul.f32 	%f645, %f930, %f642;
	mul.f32 	%f646, %f931, %f642;
	mul.f32 	%f647, %f928, %f643;
	mul.f32 	%f648, %f929, %f644;
	mul.f32 	%f649, %f930, %f645;
	mul.f32 	%f650, %f928, %f644;
	mul.f32 	%f651, %f930, %f646;
	mul.f32 	%f652, %f928, %f645;
	mul.f32 	%f653, %f929, %f646;
	mul.f32 	%f654, %f929, %f645;
	mul.f32 	%f655, %f928, %f646;
	sub.f32 	%f656, %f647, %f648;
	sub.f32 	%f657, %f656, %f649;
	fma.rn.f32 	%f658, %f931, %f646, %f657;
	sub.f32 	%f659, %f650, %f651;
	add.f32 	%f660, %f659, %f659;
	add.f32 	%f661, %f652, %f653;
	add.f32 	%f662, %f661, %f661;
	add.f32 	%f663, %f650, %f651;
	add.f32 	%f664, %f663, %f663;
	sub.f32 	%f665, %f648, %f647;
	sub.f32 	%f666, %f665, %f649;
	fma.rn.f32 	%f667, %f931, %f646, %f666;
	sub.f32 	%f668, %f654, %f655;
	add.f32 	%f669, %f668, %f668;
	sub.f32 	%f670, %f652, %f653;
	add.f32 	%f671, %f670, %f670;
	add.f32 	%f672, %f654, %f655;
	add.f32 	%f673, %f672, %f672;
	neg.f32 	%f674, %f647;
	sub.f32 	%f675, %f674, %f648;
	add.f32 	%f676, %f649, %f675;
	fma.rn.f32 	%f677, %f931, %f646, %f676;
	mul.f32 	%f678, %f924, %f658;
	fma.rn.f32 	%f679, %f926, %f660, %f678;
	fma.rn.f32 	%f940, %f927, %f662, %f679;
	mul.f32 	%f680, %f926, %f667;
	fma.rn.f32 	%f681, %f924, %f664, %f680;
	fma.rn.f32 	%f937, %f927, %f669, %f681;
	mul.f32 	%f682, %f926, %f673;
	fma.rn.f32 	%f683, %f924, %f671, %f682;
	fma.rn.f32 	%f934, %f927, %f677, %f683;
	mul.f32 	%f684, %f923, %f658;
	fma.rn.f32 	%f939, %f925, %f660, %f684;
	mul.f32 	%f685, %f925, %f667;
	fma.rn.f32 	%f936, %f923, %f664, %f685;
	mul.f32 	%f686, %f925, %f673;
	fma.rn.f32 	%f933, %f923, %f671, %f686;
	mul.f32 	%f938, %f922, %f658;
	mul.f32 	%f935, %f922, %f664;
	mul.f32 	%f932, %f922, %f671;

BB0_35:
	mul.f32 	%f718, %f933, %f937;
	mul.f32 	%f719, %f934, %f936;
	sub.f32 	%f720, %f719, %f718;
	mul.f32 	%f721, %f938, %f720;
	mul.f32 	%f722, %f932, %f937;
	mul.f32 	%f723, %f934, %f935;
	sub.f32 	%f724, %f723, %f722;
	mul.f32 	%f725, %f724, %f939;
	sub.f32 	%f726, %f721, %f725;
	mul.f32 	%f727, %f932, %f936;
	mul.f32 	%f728, %f933, %f935;
	sub.f32 	%f729, %f728, %f727;
	fma.rn.f32 	%f730, %f729, %f940, %f726;
	rcp.rn.f32 	%f731, %f730;
	mul.f32 	%f947, %f720, %f731;
	mul.f32 	%f732, %f934, %f939;
	mul.f32 	%f733, %f933, %f940;
	sub.f32 	%f734, %f733, %f732;
	mul.f32 	%f948, %f731, %f734;
	mul.f32 	%f735, %f936, %f940;
	mul.f32 	%f736, %f937, %f939;
	sub.f32 	%f737, %f736, %f735;
	mul.f32 	%f949, %f731, %f737;
	sub.f32 	%f738, %f722, %f723;
	mul.f32 	%f944, %f738, %f731;
	mul.f32 	%f739, %f932, %f940;
	mul.f32 	%f740, %f934, %f938;
	sub.f32 	%f741, %f740, %f739;
	mul.f32 	%f945, %f731, %f741;
	mul.f32 	%f742, %f937, %f938;
	mul.f32 	%f743, %f935, %f940;
	sub.f32 	%f744, %f743, %f742;
	mul.f32 	%f946, %f731, %f744;
	mul.f32 	%f941, %f729, %f731;
	mul.f32 	%f745, %f933, %f938;
	mul.f32 	%f746, %f932, %f939;
	sub.f32 	%f747, %f746, %f745;
	mul.f32 	%f942, %f747, %f731;
	mul.f32 	%f748, %f935, %f939;
	mul.f32 	%f749, %f936, %f938;
	sub.f32 	%f750, %f749, %f748;
	mul.f32 	%f943, %f750, %f731;
	bra.uni 	BB0_36;

BB0_25:
	setp.ne.s32	%p17, %r161, 1;
	mov.f32 	%f942, %f941;
	mov.f32 	%f944, %f941;
	mov.f32 	%f945, %f943;
	mov.f32 	%f946, %f941;
	mov.f32 	%f947, %f943;
	mov.f32 	%f948, %f941;
	mov.f32 	%f949, %f941;
	@%p17 bra 	BB0_36;

	// inline asm
	call (%rd143), _optix_get_static_transform_from_handle, (%rd141);
	// inline asm
	add.s64 	%rd265, %rd143, 64;

BB0_28:
	// inline asm
	cvta.to.global.u64 %rd147, %rd265;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd147];
	// inline asm
	mov.b32 	 %f947, %r163;
	mov.b32 	 %f948, %r164;
	mov.b32 	 %f949, %r165;
	add.s64 	%rd151, %rd265, 16;
	// inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd150];
	// inline asm
	mov.b32 	 %f944, %r167;
	mov.b32 	 %f945, %r168;
	mov.b32 	 %f946, %r169;
	add.s64 	%rd154, %rd265, 32;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd153];
	// inline asm
	mov.b32 	 %f941, %r171;
	mov.b32 	 %f942, %r172;
	mov.b32 	 %f943, %r173;

BB0_36:
	setp.eq.s32	%p21, %r319, 0;
	@%p21 bra 	BB0_37;
	bra.uni 	BB0_38;

BB0_37:
	mov.f32 	%f921, %f941;
	mov.f32 	%f920, %f942;
	mov.f32 	%f919, %f943;
	mov.f32 	%f918, %f944;
	mov.f32 	%f917, %f945;
	mov.f32 	%f916, %f946;
	mov.f32 	%f915, %f947;
	mov.f32 	%f914, %f948;
	mov.f32 	%f913, %f949;
	bra.uni 	BB0_39;

BB0_38:
	mul.f32 	%f751, %f918, %f948;
	fma.rn.f32 	%f752, %f915, %f947, %f751;
	fma.rn.f32 	%f289, %f921, %f949, %f752;
	mul.f32 	%f753, %f917, %f948;
	fma.rn.f32 	%f754, %f914, %f947, %f753;
	fma.rn.f32 	%f290, %f920, %f949, %f754;
	mul.f32 	%f755, %f916, %f948;
	fma.rn.f32 	%f756, %f913, %f947, %f755;
	fma.rn.f32 	%f291, %f919, %f949, %f756;
	mul.f32 	%f757, %f918, %f945;
	fma.rn.f32 	%f758, %f915, %f944, %f757;
	fma.rn.f32 	%f292, %f921, %f946, %f758;
	mul.f32 	%f759, %f917, %f945;
	fma.rn.f32 	%f760, %f914, %f944, %f759;
	fma.rn.f32 	%f293, %f920, %f946, %f760;
	mul.f32 	%f761, %f916, %f945;
	fma.rn.f32 	%f762, %f913, %f944, %f761;
	fma.rn.f32 	%f294, %f919, %f946, %f762;
	mul.f32 	%f763, %f918, %f942;
	fma.rn.f32 	%f764, %f915, %f941, %f763;
	fma.rn.f32 	%f921, %f921, %f943, %f764;
	mul.f32 	%f765, %f917, %f942;
	fma.rn.f32 	%f766, %f914, %f941, %f765;
	fma.rn.f32 	%f920, %f920, %f943, %f766;
	mul.f32 	%f767, %f916, %f942;
	fma.rn.f32 	%f768, %f913, %f941, %f767;
	fma.rn.f32 	%f919, %f919, %f943, %f768;
	mov.f32 	%f918, %f292;
	mov.f32 	%f917, %f293;
	mov.f32 	%f916, %f294;
	mov.f32 	%f915, %f289;
	mov.f32 	%f914, %f290;
	mov.f32 	%f913, %f291;

BB0_39:
	add.s32 	%r319, %r319, 1;
	setp.lt.u32	%p22, %r319, %r8;
	@%p22 bra 	BB0_23;

	mul.f32 	%f769, %f582, %f914;
	fma.rn.f32 	%f770, %f581, %f915, %f769;
	fma.rn.f32 	%f959, %f961, %f913, %f770;
	mul.f32 	%f771, %f582, %f917;
	fma.rn.f32 	%f772, %f581, %f918, %f771;
	fma.rn.f32 	%f960, %f961, %f916, %f772;
	mul.f32 	%f773, %f582, %f920;
	fma.rn.f32 	%f774, %f581, %f921, %f773;
	fma.rn.f32 	%f961, %f961, %f919, %f774;
	bra.uni 	BB0_41;

BB0_22:
	mov.f32 	%f959, %f581;
	mov.f32 	%f960, %f582;

BB0_41:
	// inline asm
	call (%f775), _optix_get_ray_tmin, ();
	// inline asm
	// inline asm
	call (%f776), _optix_get_ray_tmax, ();
	// inline asm
	ld.v4.f32 	{%f778, %f779, %f780, %f781}, [%rd1+208];
	ld.v4.f32 	{%f785, %f786, %f787, %f788}, [%rd1+160];
	fma.rn.f32 	%f790, %f912, %f785, %f778;
	fma.rn.f32 	%f792, %f912, %f786, %f779;
	fma.rn.f32 	%f794, %f912, %f787, %f780;
	ld.v4.f32 	{%f795, %f796, %f797, %f798}, [%rd1+176];
	fma.rn.f32 	%f800, %f911, %f795, %f790;
	fma.rn.f32 	%f802, %f911, %f796, %f792;
	fma.rn.f32 	%f804, %f911, %f797, %f794;
	ld.v4.f32 	{%f805, %f806, %f807, %f808}, [%rd1+192];
	fma.rn.f32 	%f810, %f910, %f805, %f800;
	fma.rn.f32 	%f812, %f910, %f806, %f802;
	fma.rn.f32 	%f315, %f910, %f807, %f804;
	mul.f32 	%f814, %f959, %f785;
	mul.f32 	%f815, %f959, %f786;
	mul.f32 	%f816, %f959, %f787;
	fma.rn.f32 	%f817, %f960, %f795, %f814;
	fma.rn.f32 	%f818, %f960, %f796, %f815;
	fma.rn.f32 	%f819, %f960, %f797, %f816;
	fma.rn.f32 	%f820, %f961, %f805, %f817;
	fma.rn.f32 	%f821, %f961, %f806, %f818;
	fma.rn.f32 	%f316, %f961, %f807, %f819;
	mul.f32 	%f822, %f821, %f821;
	fma.rn.f32 	%f317, %f820, %f820, %f822;
	mul.f32 	%f823, %f812, %f821;
	fma.rn.f32 	%f824, %f810, %f820, %f823;
	add.f32 	%f318, %f824, %f824;
	mul.f32 	%f825, %f812, %f812;
	fma.rn.f32 	%f826, %f810, %f810, %f825;
	ld.f32 	%f827, [%rd1+292];
	mul.f32 	%f828, %f827, %f827;
	sub.f32 	%f319, %f826, %f828;
	setp.eq.f32	%p23, %f317, 0f00000000;
	setp.eq.f32	%p24, %f318, 0f00000000;
	and.pred  	%p25, %p23, %p24;
	mov.u16 	%rs13, 0;
	@%p25 bra 	BB0_45;

	neg.f32 	%f829, %f319;
	div.rn.f32 	%f963, %f829, %f318;
	mul.f32 	%f830, %f317, 0fC0800000;
	mul.f32 	%f831, %f830, %f319;
	fma.rn.f32 	%f321, %f318, %f318, %f831;
	setp.lt.f32	%p26, %f321, 0f00000000;
	setp.neu.f32	%p27, %f317, 0f00000000;
	and.pred  	%p28, %p26, %p27;
	@%p28 bra 	BB0_43;
	bra.uni 	BB0_44;

BB0_43:
	mov.f32 	%f962, %f963;
	bra.uni 	BB0_45;

BB0_44:
	mov.b32 	 %r309, %f318;
	and.b32  	%r310, %r309, -2147483648;
	sqrt.rn.f32 	%f832, %f321;
	mov.b32 	 %r311, %f832;
	and.b32  	%r312, %r311, 2147483647;
	or.b32  	%r313, %r312, %r310;
	mov.b32 	 %f833, %r313;
	add.f32 	%f834, %f318, %f833;
	mul.f32 	%f835, %f834, 0fBF000000;
	div.rn.f32 	%f836, %f835, %f317;
	div.rn.f32 	%f837, %f319, %f835;
	min.f32 	%f838, %f836, %f837;
	max.f32 	%f839, %f836, %f837;
	selp.f32	%f962, %f963, %f838, %p23;
	selp.f32	%f963, %f963, %f839, %p23;
	mov.u16 	%rs13, 1;

BB0_45:
	setp.gtu.f32	%p31, %f962, %f776;
	mov.pred 	%p30, 0;
	mov.pred 	%p52, %p30;
	@%p31 bra 	BB0_47;

	setp.ge.f32	%p52, %f963, %f775;

BB0_47:
	fma.rn.f32 	%f326, %f316, %f962, %f315;
	fma.rn.f32 	%f327, %f316, %f963, %f315;
	setp.geu.f32	%p33, %f962, %f775;
	setp.leu.f32	%p34, %f963, %f776;
	or.pred  	%p35, %p33, %p34;
	setp.ne.s16	%p36, %rs13, 0;
	and.pred  	%p37, %p52, %p36;
	and.pred  	%p38, %p37, %p35;
	mov.pred 	%p53, %p30;
	@!%p38 bra 	BB0_54;
	bra.uni 	BB0_48;

BB0_48:
	setp.ltu.f32	%p39, %f326, 0f00000000;
	@%p39 bra 	BB0_50;

	ld.f32 	%f840, [%rd1+288];
	setp.le.f32	%p41, %f326, %f840;
	setp.ge.f32	%p42, %f962, %f775;
	mov.pred 	%p53, -1;
	and.pred  	%p43, %p41, %p42;
	@%p43 bra 	BB0_54;

BB0_50:
	setp.ltu.f32	%p45, %f327, 0f00000000;
	@%p45 bra 	BB0_51;
	bra.uni 	BB0_52;

BB0_51:
	mov.pred 	%p53, %p30;
	bra.uni 	BB0_54;

BB0_52:
	ld.f32 	%f841, [%rd1+288];
	setp.gtu.f32	%p47, %f327, %f841;
	mov.pred 	%p53, %p30;
	@%p47 bra 	BB0_54;

	setp.le.f32	%p53, %f963, %f776;

BB0_54:
	setp.ltu.f32	%p48, %f326, 0f00000000;
	@%p48 bra 	BB0_57;

	ld.f32 	%f842, [%rd1+288];
	setp.gtu.f32	%p49, %f326, %f842;
	@%p49 bra 	BB0_57;

	setp.ge.f32	%p50, %f962, %f775;
	selp.f32	%f963, %f962, %f963, %p50;

BB0_57:
	@!%p53 bra 	BB0_59;
	bra.uni 	BB0_58;

BB0_58:
	mov.u32 	%r315, 254;
	// inline asm
	call (%r314), _optix_report_intersection_0, (%f963, %r315);
	// inline asm

BB0_59:
	ret;
}

	// .globl	__closesthit__cylinder
.visible .entry __closesthit__cylinder(

)
{
	.reg .pred 	%p<65>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<2060>;
	.reg .b32 	%r<650>;
	.reg .b64 	%rd<665>;


	// inline asm
	call (%r23), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r24), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r26), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r27), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r28), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r29, %r28, %r24, %r27;
	mad.lo.s32 	%r1, %r29, %r23, %r26;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	@%p1 bra 	BB1_2;

	cvta.to.global.u64 	%rd48, %rd1;
	cvt.u64.u32	%rd49, %r1;
	add.s64 	%rd50, %rd48, %rd49;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd50], %rs1;
	bra.uni 	BB1_114;

BB1_2:
	// inline asm
	call (%rd51), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd3, [%rd51+8];
	// inline asm
	call (%f692), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f693), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f1849), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r30), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p2, %r30, 0;
	@%p2 bra 	BB1_3;

	mov.u32 	%r646, 0;
	// inline asm
	call (%f695), _optix_get_ray_time, ();
	// inline asm

BB1_5:
	.pragma "nounroll";
	// inline asm
	call (%rd52), _optix_get_transform_list_handle, (%r646);
	// inline asm
	// inline asm
	call (%r33), _optix_get_transform_type_from_handle, (%rd52);
	// inline asm
	and.b32  	%r34, %r33, -2;
	setp.eq.s32	%p3, %r34, 2;
	@%p3 bra 	BB1_11;
	bra.uni 	BB1_6;

BB1_11:
	setp.eq.s32	%p6, %r33, 2;
	@%p6 bra 	BB1_15;
	bra.uni 	BB1_12;

BB1_15:
	// inline asm
	call (%rd126), _optix_get_matrix_motion_transform_from_handle, (%rd52);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd128, %rd126;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd128];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r124;
	add.s64 	%rd132, %rd126, 16;
	// inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd131];
	// inline asm
	add.s64 	%rd135, %rd126, 32;
	// inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd134];
	// inline asm
	add.s64 	%rd138, %rd126, 48;
	// inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd137];
	// inline asm
	add.s64 	%rd141, %rd126, 64;
	// inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd140];
	// inline asm
	add.s64 	%rd144, %rd126, 80;
	// inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd143];
	// inline asm
	add.s64 	%rd147, %rd126, 96;
	// inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd146];
	// inline asm
	add.s64 	%rd150, %rd126, 112;
	// inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r150,%r151,%r152,%r153}, [%rd149];
	// inline asm
	mov.b32 	 %f822, %r125;
	mov.b32 	 %f823, %r126;
	cvt.u32.u16	%r166, %rs4;
	add.s32 	%r167, %r166, -1;
	cvt.rn.f32.s32	%f824, %r167;
	sub.f32 	%f825, %f695, %f822;
	mul.f32 	%f826, %f825, %f824;
	sub.f32 	%f827, %f823, %f822;
	div.rn.f32 	%f828, %f826, %f827;
	min.f32 	%f829, %f824, %f828;
	mov.f32 	%f830, 0f00000000;
	max.f32 	%f831, %f830, %f829;
	cvt.rmi.f32.f32	%f832, %f831;
	cvt.rzi.s32.f32	%r168, %f832;
	mul.wide.s32 	%rd161, %r168, 48;
	add.s64 	%rd153, %rd135, %rd161;
	// inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r154,%r155,%r156,%r157}, [%rd152];
	// inline asm
	mov.b32 	 %f1816, %r154;
	mov.b32 	 %f1815, %r155;
	mov.b32 	 %f1814, %r156;
	mov.b32 	 %f1813, %r157;
	add.s64 	%rd156, %rd153, 16;
	// inline asm
	cvta.to.global.u64 %rd155, %rd156;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r158,%r159,%r160,%r161}, [%rd155];
	// inline asm
	mov.b32 	 %f1820, %r158;
	mov.b32 	 %f1819, %r159;
	mov.b32 	 %f1818, %r160;
	mov.b32 	 %f1817, %r161;
	add.s64 	%rd159, %rd153, 32;
	// inline asm
	cvta.to.global.u64 %rd158, %rd159;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r162,%r163,%r164,%r165}, [%rd158];
	// inline asm
	sub.f32 	%f98, %f831, %f832;
	mov.b32 	 %f1824, %r162;
	mov.b32 	 %f1823, %r163;
	mov.b32 	 %f1822, %r164;
	mov.b32 	 %f1821, %r165;
	setp.leu.f32	%p8, %f98, 0f00000000;
	@%p8 bra 	BB1_17;

	cvt.rmi.f32.f32	%f1784, %f831;
	cvt.rzi.s32.f32	%r645, %f1784;
	cvt.s64.s32	%rd660, %r645;
	mul.lo.s64 	%rd171, %rd660, 48;
	add.s64 	%rd172, %rd126, %rd171;
	add.s64 	%rd163, %rd172, 80;
	// inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd162];
	// inline asm
	mov.b32 	 %f833, %r169;
	mov.b32 	 %f834, %r170;
	mov.b32 	 %f835, %r171;
	mov.b32 	 %f836, %r172;
	add.s64 	%rd166, %rd172, 96;
	// inline asm
	cvta.to.global.u64 %rd165, %rd166;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd165];
	// inline asm
	mov.b32 	 %f837, %r173;
	mov.b32 	 %f838, %r174;
	mov.b32 	 %f839, %r175;
	mov.b32 	 %f840, %r176;
	add.s64 	%rd169, %rd172, 112;
	// inline asm
	cvta.to.global.u64 %rd168, %rd169;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd168];
	// inline asm
	mov.f32 	%f841, 0f3F800000;
	sub.f32 	%f842, %f841, %f98;
	mul.f32 	%f843, %f98, %f833;
	mul.f32 	%f844, %f98, %f834;
	mul.f32 	%f845, %f98, %f835;
	mul.f32 	%f846, %f98, %f836;
	fma.rn.f32 	%f1816, %f842, %f1816, %f843;
	fma.rn.f32 	%f1815, %f842, %f1815, %f844;
	fma.rn.f32 	%f1814, %f842, %f1814, %f845;
	fma.rn.f32 	%f1813, %f842, %f1813, %f846;
	mul.f32 	%f847, %f98, %f837;
	mul.f32 	%f848, %f98, %f838;
	mul.f32 	%f849, %f98, %f839;
	mul.f32 	%f850, %f98, %f840;
	fma.rn.f32 	%f1820, %f842, %f1820, %f847;
	fma.rn.f32 	%f1819, %f842, %f1819, %f848;
	fma.rn.f32 	%f1818, %f842, %f1818, %f849;
	fma.rn.f32 	%f1817, %f842, %f1817, %f850;
	mov.b32 	 %f851, %r177;
	mov.b32 	 %f852, %r178;
	mov.b32 	 %f853, %r179;
	mov.b32 	 %f854, %r180;
	mul.f32 	%f855, %f98, %f851;
	mul.f32 	%f856, %f98, %f852;
	mul.f32 	%f857, %f98, %f853;
	mul.f32 	%f858, %f98, %f854;
	fma.rn.f32 	%f1824, %f842, %f1824, %f855;
	fma.rn.f32 	%f1823, %f842, %f1823, %f856;
	fma.rn.f32 	%f1822, %f842, %f1822, %f857;
	fma.rn.f32 	%f1821, %f842, %f1821, %f858;
	bra.uni 	BB1_17;

BB1_6:
	mov.f32 	%f1825, 0f00000000;
	mov.f32 	%f1828, 0f3F800000;
	setp.eq.s32	%p4, %r33, 4;
	@%p4 bra 	BB1_9;
	bra.uni 	BB1_7;

BB1_9:
	// inline asm
	call (%rd661), _optix_get_instance_inverse_transform_from_handle, (%rd52);
	// inline asm
	bra.uni 	BB1_10;

BB1_12:
	// inline asm
	call (%rd67), _optix_get_srt_motion_transform_from_handle, (%rd52);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd69, %rd67;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd69];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r49;
	add.s64 	%rd73, %rd67, 16;
	// inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd72];
	// inline asm
	add.s64 	%rd76, %rd67, 32;
	// inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd75];
	// inline asm
	add.s64 	%rd79, %rd67, 48;
	// inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd78];
	// inline asm
	add.s64 	%rd82, %rd67, 64;
	// inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd81];
	// inline asm
	add.s64 	%rd85, %rd67, 80;
	// inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd84];
	// inline asm
	add.s64 	%rd88, %rd67, 96;
	// inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd87];
	// inline asm
	add.s64 	%rd91, %rd67, 112;
	// inline asm
	cvta.to.global.u64 %rd90, %rd91;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd90];
	// inline asm
	add.s64 	%rd94, %rd67, 128;
	// inline asm
	cvta.to.global.u64 %rd93, %rd94;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd93];
	// inline asm
	add.s64 	%rd97, %rd67, 144;
	// inline asm
	cvta.to.global.u64 %rd96, %rd97;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd96];
	// inline asm
	mov.b32 	 %f709, %r50;
	mov.b32 	 %f710, %r51;
	cvt.u32.u16	%r103, %rs2;
	add.s32 	%r104, %r103, -1;
	cvt.rn.f32.s32	%f711, %r104;
	sub.f32 	%f712, %f695, %f709;
	mul.f32 	%f713, %f712, %f711;
	sub.f32 	%f714, %f710, %f709;
	div.rn.f32 	%f715, %f713, %f714;
	min.f32 	%f716, %f711, %f715;
	mov.f32 	%f717, 0f00000000;
	max.f32 	%f718, %f717, %f716;
	cvt.rmi.f32.f32	%f719, %f718;
	cvt.rzi.s32.f32	%r105, %f719;
	mul.wide.s32 	%rd111, %r105, 64;
	add.s64 	%rd100, %rd76, %rd111;
	// inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r87,%r88,%r89,%r90}, [%rd99];
	// inline asm
	mov.b32 	 %f1797, %r87;
	mov.b32 	 %f1798, %r88;
	mov.b32 	 %f1799, %r89;
	mov.b32 	 %f1800, %r90;
	add.s64 	%rd103, %rd100, 16;
	// inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r91,%r92,%r93,%r94}, [%rd102];
	// inline asm
	mov.b32 	 %f1801, %r91;
	mov.b32 	 %f1802, %r92;
	mov.b32 	 %f1803, %r93;
	mov.b32 	 %f1804, %r94;
	add.s64 	%rd106, %rd100, 32;
	// inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r95,%r96,%r97,%r98}, [%rd105];
	// inline asm
	sub.f32 	%f37, %f718, %f719;
	mov.b32 	 %f1805, %r95;
	mov.b32 	 %f1806, %r96;
	mov.b32 	 %f1807, %r97;
	mov.b32 	 %f1808, %r98;
	add.s64 	%rd109, %rd100, 48;
	// inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r99,%r100,%r101,%r102}, [%rd108];
	// inline asm
	mov.b32 	 %f1809, %r99;
	mov.b32 	 %f1810, %r100;
	mov.b32 	 %f1811, %r101;
	mov.b32 	 %f1812, %r102;
	setp.leu.f32	%p7, %f37, 0f00000000;
	@%p7 bra 	BB1_14;

	cvt.rmi.f32.f32	%f1783, %f718;
	cvt.rzi.s32.f32	%r644, %f1783;
	cvt.s64.s32	%rd659, %r644;
	shl.b64 	%rd124, %rd659, 6;
	add.s64 	%rd125, %rd124, %rd67;
	add.s64 	%rd113, %rd125, 96;
	// inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd112];
	// inline asm
	mov.b32 	 %f720, %r106;
	mov.b32 	 %f721, %r107;
	mov.b32 	 %f722, %r108;
	mov.b32 	 %f723, %r109;
	add.s64 	%rd116, %rd125, 112;
	// inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd115];
	// inline asm
	mov.b32 	 %f724, %r110;
	mov.b32 	 %f725, %r111;
	mov.b32 	 %f726, %r112;
	mov.b32 	 %f727, %r113;
	add.s64 	%rd119, %rd125, 128;
	// inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd118];
	// inline asm
	mov.b32 	 %f728, %r114;
	mov.b32 	 %f729, %r115;
	mov.b32 	 %f730, %r116;
	mov.b32 	 %f731, %r117;
	add.s64 	%rd122, %rd125, 144;
	// inline asm
	cvta.to.global.u64 %rd121, %rd122;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd121];
	// inline asm
	mov.f32 	%f732, 0f3F800000;
	sub.f32 	%f733, %f732, %f37;
	mul.f32 	%f734, %f37, %f720;
	mul.f32 	%f735, %f37, %f721;
	mul.f32 	%f736, %f37, %f722;
	mul.f32 	%f737, %f37, %f723;
	fma.rn.f32 	%f1797, %f733, %f1797, %f734;
	fma.rn.f32 	%f1798, %f733, %f1798, %f735;
	fma.rn.f32 	%f1799, %f733, %f1799, %f736;
	fma.rn.f32 	%f1800, %f733, %f1800, %f737;
	mul.f32 	%f738, %f37, %f724;
	mul.f32 	%f739, %f37, %f725;
	mul.f32 	%f740, %f37, %f726;
	mul.f32 	%f741, %f37, %f727;
	fma.rn.f32 	%f1801, %f733, %f1801, %f738;
	fma.rn.f32 	%f1802, %f733, %f1802, %f739;
	fma.rn.f32 	%f1803, %f733, %f1803, %f740;
	fma.rn.f32 	%f1804, %f733, %f1804, %f741;
	mul.f32 	%f742, %f37, %f728;
	mul.f32 	%f743, %f37, %f729;
	mul.f32 	%f744, %f37, %f730;
	mul.f32 	%f745, %f37, %f731;
	fma.rn.f32 	%f1805, %f733, %f1805, %f742;
	fma.rn.f32 	%f746, %f733, %f1806, %f743;
	fma.rn.f32 	%f747, %f733, %f1807, %f744;
	fma.rn.f32 	%f748, %f733, %f1808, %f745;
	mov.b32 	 %f749, %r118;
	mov.b32 	 %f750, %r119;
	mov.b32 	 %f751, %r120;
	mov.b32 	 %f752, %r121;
	mul.f32 	%f753, %f37, %f749;
	mul.f32 	%f754, %f37, %f750;
	mul.f32 	%f755, %f37, %f751;
	mul.f32 	%f756, %f37, %f752;
	fma.rn.f32 	%f757, %f733, %f1809, %f753;
	fma.rn.f32 	%f1810, %f733, %f1810, %f754;
	fma.rn.f32 	%f1811, %f733, %f1811, %f755;
	fma.rn.f32 	%f1812, %f733, %f1812, %f756;
	mul.f32 	%f758, %f747, %f747;
	fma.rn.f32 	%f759, %f746, %f746, %f758;
	fma.rn.f32 	%f760, %f748, %f748, %f759;
	fma.rn.f32 	%f761, %f757, %f757, %f760;
	sqrt.rn.f32 	%f762, %f761;
	rcp.rn.f32 	%f763, %f762;
	mul.f32 	%f1806, %f746, %f763;
	mul.f32 	%f1807, %f747, %f763;
	mul.f32 	%f1808, %f748, %f763;
	mul.f32 	%f1809, %f757, %f763;

BB1_14:
	mul.f32 	%f764, %f1807, %f1807;
	fma.rn.f32 	%f765, %f1806, %f1806, %f764;
	fma.rn.f32 	%f766, %f1808, %f1808, %f765;
	fma.rn.f32 	%f767, %f1809, %f1809, %f766;
	rcp.rn.f32 	%f768, %f767;
	mul.f32 	%f769, %f1806, %f768;
	mul.f32 	%f770, %f1807, %f768;
	mul.f32 	%f771, %f1808, %f768;
	mul.f32 	%f772, %f1809, %f768;
	mul.f32 	%f773, %f1806, %f769;
	mul.f32 	%f774, %f1807, %f770;
	mul.f32 	%f775, %f1808, %f771;
	mul.f32 	%f776, %f1806, %f770;
	mul.f32 	%f777, %f1808, %f772;
	mul.f32 	%f778, %f1806, %f771;
	mul.f32 	%f779, %f1807, %f772;
	mul.f32 	%f780, %f1807, %f771;
	mul.f32 	%f781, %f1806, %f772;
	sub.f32 	%f782, %f773, %f774;
	sub.f32 	%f783, %f782, %f775;
	fma.rn.f32 	%f784, %f1809, %f772, %f783;
	sub.f32 	%f785, %f776, %f777;
	add.f32 	%f786, %f785, %f785;
	add.f32 	%f787, %f778, %f779;
	add.f32 	%f788, %f787, %f787;
	add.f32 	%f789, %f776, %f777;
	add.f32 	%f790, %f789, %f789;
	sub.f32 	%f791, %f774, %f773;
	sub.f32 	%f792, %f791, %f775;
	fma.rn.f32 	%f793, %f1809, %f772, %f792;
	sub.f32 	%f794, %f780, %f781;
	add.f32 	%f795, %f794, %f794;
	sub.f32 	%f796, %f778, %f779;
	add.f32 	%f797, %f796, %f796;
	add.f32 	%f798, %f780, %f781;
	add.f32 	%f799, %f798, %f798;
	neg.f32 	%f800, %f773;
	sub.f32 	%f801, %f800, %f774;
	add.f32 	%f802, %f775, %f801;
	fma.rn.f32 	%f803, %f1809, %f772, %f802;
	mul.f32 	%f804, %f1800, %f784;
	fma.rn.f32 	%f805, %f1803, %f786, %f804;
	fma.rn.f32 	%f806, %f1805, %f788, %f805;
	sub.f32 	%f1813, %f1810, %f806;
	mul.f32 	%f807, %f1803, %f793;
	fma.rn.f32 	%f808, %f1800, %f790, %f807;
	fma.rn.f32 	%f809, %f1805, %f795, %f808;
	sub.f32 	%f1817, %f1811, %f809;
	mul.f32 	%f810, %f1803, %f799;
	fma.rn.f32 	%f811, %f1800, %f797, %f810;
	fma.rn.f32 	%f812, %f1805, %f803, %f811;
	sub.f32 	%f1821, %f1812, %f812;
	mul.f32 	%f813, %f1799, %f784;
	fma.rn.f32 	%f814, %f1802, %f786, %f813;
	fma.rn.f32 	%f1814, %f1804, %f788, %f814;
	mul.f32 	%f815, %f1802, %f793;
	fma.rn.f32 	%f816, %f1799, %f790, %f815;
	fma.rn.f32 	%f1818, %f1804, %f795, %f816;
	mul.f32 	%f817, %f1802, %f799;
	fma.rn.f32 	%f818, %f1799, %f797, %f817;
	fma.rn.f32 	%f1822, %f1804, %f803, %f818;
	mul.f32 	%f819, %f1798, %f784;
	fma.rn.f32 	%f1815, %f1801, %f786, %f819;
	mul.f32 	%f820, %f1801, %f793;
	fma.rn.f32 	%f1819, %f1798, %f790, %f820;
	mul.f32 	%f821, %f1801, %f799;
	fma.rn.f32 	%f1823, %f1798, %f797, %f821;
	mul.f32 	%f1816, %f1797, %f784;
	mul.f32 	%f1820, %f1797, %f790;
	mul.f32 	%f1824, %f1797, %f797;

BB1_17:
	mul.f32 	%f859, %f1818, %f1823;
	mul.f32 	%f860, %f1819, %f1822;
	sub.f32 	%f861, %f860, %f859;
	mul.f32 	%f862, %f1816, %f861;
	mul.f32 	%f863, %f1818, %f1824;
	mul.f32 	%f864, %f1820, %f1822;
	sub.f32 	%f865, %f864, %f863;
	mul.f32 	%f866, %f1815, %f865;
	sub.f32 	%f867, %f862, %f866;
	mul.f32 	%f868, %f1819, %f1824;
	mul.f32 	%f869, %f1820, %f1823;
	sub.f32 	%f870, %f869, %f868;
	fma.rn.f32 	%f871, %f1814, %f870, %f867;
	rcp.rn.f32 	%f872, %f871;
	mul.f32 	%f1828, %f872, %f861;
	mul.f32 	%f873, %f1815, %f1822;
	mul.f32 	%f874, %f1814, %f1823;
	sub.f32 	%f875, %f874, %f873;
	mul.f32 	%f1827, %f872, %f875;
	mul.f32 	%f876, %f1814, %f1819;
	mul.f32 	%f877, %f1815, %f1818;
	sub.f32 	%f878, %f877, %f876;
	mul.f32 	%f1826, %f878, %f872;
	sub.f32 	%f879, %f863, %f864;
	mul.f32 	%f1832, %f872, %f879;
	mul.f32 	%f880, %f1814, %f1824;
	mul.f32 	%f881, %f1816, %f1822;
	sub.f32 	%f882, %f881, %f880;
	mul.f32 	%f1831, %f872, %f882;
	mul.f32 	%f883, %f1816, %f1818;
	mul.f32 	%f884, %f1814, %f1820;
	sub.f32 	%f885, %f884, %f883;
	mul.f32 	%f1830, %f885, %f872;
	mul.f32 	%f1836, %f872, %f870;
	mul.f32 	%f886, %f1816, %f1823;
	mul.f32 	%f887, %f1815, %f1824;
	sub.f32 	%f888, %f887, %f886;
	mul.f32 	%f1835, %f872, %f888;
	mul.f32 	%f889, %f1815, %f1820;
	mul.f32 	%f890, %f1816, %f1819;
	sub.f32 	%f891, %f890, %f889;
	mul.f32 	%f1834, %f891, %f872;
	mul.f32 	%f892, %f1813, %f1828;
	neg.f32 	%f893, %f892;
	mul.f32 	%f894, %f1817, %f1827;
	sub.f32 	%f895, %f893, %f894;
	mul.f32 	%f896, %f1821, %f1826;
	sub.f32 	%f1825, %f895, %f896;
	mul.f32 	%f897, %f1813, %f1832;
	neg.f32 	%f898, %f897;
	mul.f32 	%f899, %f1817, %f1831;
	sub.f32 	%f900, %f898, %f899;
	mul.f32 	%f901, %f1821, %f1830;
	sub.f32 	%f1829, %f900, %f901;
	mul.f32 	%f902, %f1813, %f1836;
	neg.f32 	%f903, %f902;
	mul.f32 	%f904, %f1817, %f1835;
	sub.f32 	%f905, %f903, %f904;
	mul.f32 	%f906, %f1821, %f1834;
	sub.f32 	%f1833, %f905, %f906;
	bra.uni 	BB1_18;

BB1_7:
	setp.ne.s32	%p5, %r33, 1;
	mov.f32 	%f1826, %f1825;
	mov.f32 	%f1827, %f1825;
	mov.f32 	%f1829, %f1825;
	mov.f32 	%f1830, %f1825;
	mov.f32 	%f1831, %f1828;
	mov.f32 	%f1832, %f1825;
	mov.f32 	%f1833, %f1825;
	mov.f32 	%f1834, %f1828;
	mov.f32 	%f1835, %f1825;
	mov.f32 	%f1836, %f1825;
	@%p5 bra 	BB1_18;

	// inline asm
	call (%rd54), _optix_get_static_transform_from_handle, (%rd52);
	// inline asm
	add.s64 	%rd661, %rd54, 64;

BB1_10:
	// inline asm
	cvta.to.global.u64 %rd58, %rd661;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd58];
	// inline asm
	mov.b32 	 %f1828, %r35;
	mov.b32 	 %f1827, %r36;
	mov.b32 	 %f1826, %r37;
	mov.b32 	 %f1825, %r38;
	add.s64 	%rd62, %rd661, 16;
	// inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd61];
	// inline asm
	mov.b32 	 %f1832, %r39;
	mov.b32 	 %f1831, %r40;
	mov.b32 	 %f1830, %r41;
	mov.b32 	 %f1829, %r42;
	add.s64 	%rd65, %rd661, 32;
	// inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd64];
	// inline asm
	mov.b32 	 %f1836, %r43;
	mov.b32 	 %f1835, %r44;
	mov.b32 	 %f1834, %r45;
	mov.b32 	 %f1833, %r46;

BB1_18:
	setp.eq.s32	%p9, %r646, 0;
	@%p9 bra 	BB1_19;
	bra.uni 	BB1_20;

BB1_19:
	mov.f32 	%f1796, %f1825;
	mov.f32 	%f1795, %f1826;
	mov.f32 	%f1794, %f1827;
	mov.f32 	%f1793, %f1828;
	mov.f32 	%f1792, %f1829;
	mov.f32 	%f1791, %f1830;
	mov.f32 	%f1790, %f1831;
	mov.f32 	%f1789, %f1832;
	mov.f32 	%f1788, %f1833;
	mov.f32 	%f1787, %f1834;
	mov.f32 	%f1786, %f1835;
	mov.f32 	%f1785, %f1836;
	bra.uni 	BB1_21;

BB1_20:
	mul.f32 	%f907, %f1793, %f1828;
	fma.rn.f32 	%f908, %f1789, %f1827, %f907;
	fma.rn.f32 	%f151, %f1785, %f1826, %f908;
	mul.f32 	%f909, %f1794, %f1828;
	fma.rn.f32 	%f910, %f1790, %f1827, %f909;
	fma.rn.f32 	%f152, %f1786, %f1826, %f910;
	mul.f32 	%f911, %f1795, %f1828;
	fma.rn.f32 	%f912, %f1791, %f1827, %f911;
	fma.rn.f32 	%f153, %f1787, %f1826, %f912;
	mul.f32 	%f913, %f1796, %f1828;
	fma.rn.f32 	%f914, %f1792, %f1827, %f913;
	fma.rn.f32 	%f915, %f1788, %f1826, %f914;
	add.f32 	%f154, %f1825, %f915;
	mul.f32 	%f916, %f1793, %f1832;
	fma.rn.f32 	%f917, %f1789, %f1831, %f916;
	fma.rn.f32 	%f155, %f1785, %f1830, %f917;
	mul.f32 	%f918, %f1794, %f1832;
	fma.rn.f32 	%f919, %f1790, %f1831, %f918;
	fma.rn.f32 	%f156, %f1786, %f1830, %f919;
	mul.f32 	%f920, %f1795, %f1832;
	fma.rn.f32 	%f921, %f1791, %f1831, %f920;
	fma.rn.f32 	%f157, %f1787, %f1830, %f921;
	mul.f32 	%f922, %f1796, %f1832;
	fma.rn.f32 	%f923, %f1792, %f1831, %f922;
	fma.rn.f32 	%f924, %f1788, %f1830, %f923;
	add.f32 	%f158, %f1829, %f924;
	mul.f32 	%f925, %f1793, %f1836;
	fma.rn.f32 	%f926, %f1789, %f1835, %f925;
	fma.rn.f32 	%f1785, %f1785, %f1834, %f926;
	mul.f32 	%f927, %f1794, %f1836;
	fma.rn.f32 	%f928, %f1790, %f1835, %f927;
	fma.rn.f32 	%f1786, %f1786, %f1834, %f928;
	mul.f32 	%f929, %f1795, %f1836;
	fma.rn.f32 	%f930, %f1791, %f1835, %f929;
	fma.rn.f32 	%f1787, %f1787, %f1834, %f930;
	mul.f32 	%f931, %f1796, %f1836;
	fma.rn.f32 	%f932, %f1792, %f1835, %f931;
	fma.rn.f32 	%f933, %f1788, %f1834, %f932;
	add.f32 	%f1788, %f1833, %f933;
	mov.f32 	%f1796, %f154;
	mov.f32 	%f1795, %f153;
	mov.f32 	%f1794, %f152;
	mov.f32 	%f1793, %f151;
	mov.f32 	%f1792, %f158;
	mov.f32 	%f1791, %f157;
	mov.f32 	%f1790, %f156;
	mov.f32 	%f1789, %f155;

BB1_21:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32	%p10, %r646, %r30;
	@%p10 bra 	BB1_5;

	mul.f32 	%f934, %f692, %f1793;
	fma.rn.f32 	%f935, %f693, %f1794, %f934;
	fma.rn.f32 	%f936, %f1849, %f1795, %f935;
	add.f32 	%f1851, %f1796, %f936;
	mul.f32 	%f937, %f692, %f1789;
	fma.rn.f32 	%f938, %f693, %f1790, %f937;
	fma.rn.f32 	%f939, %f1849, %f1791, %f938;
	add.f32 	%f1850, %f1792, %f939;
	mul.f32 	%f940, %f692, %f1785;
	fma.rn.f32 	%f941, %f693, %f1786, %f940;
	fma.rn.f32 	%f942, %f1849, %f1787, %f941;
	add.f32 	%f1849, %f1788, %f942;
	bra.uni 	BB1_23;

BB1_3:
	mov.f32 	%f1850, %f693;
	mov.f32 	%f1851, %f692;

BB1_23:
	// inline asm
	call (%f943), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f944), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1900), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f946), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r647, 0;
	@%p2 bra 	BB1_24;

BB1_25:
	.pragma "nounroll";
	// inline asm
	call (%rd173), _optix_get_transform_list_handle, (%r647);
	// inline asm
	// inline asm
	call (%r183), _optix_get_transform_type_from_handle, (%rd173);
	// inline asm
	and.b32  	%r184, %r183, -2;
	setp.eq.s32	%p12, %r184, 2;
	@%p12 bra 	BB1_31;
	bra.uni 	BB1_26;

BB1_31:
	setp.eq.s32	%p15, %r183, 2;
	@%p15 bra 	BB1_35;
	bra.uni 	BB1_32;

BB1_35:
	// inline asm
	call (%rd247), _optix_get_matrix_motion_transform_from_handle, (%rd173);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd249, %rd247;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd249];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r274;
	add.s64 	%rd253, %rd247, 16;
	// inline asm
	cvta.to.global.u64 %rd252, %rd253;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd252];
	// inline asm
	add.s64 	%rd256, %rd247, 32;
	// inline asm
	cvta.to.global.u64 %rd255, %rd256;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd255];
	// inline asm
	add.s64 	%rd259, %rd247, 48;
	// inline asm
	cvta.to.global.u64 %rd258, %rd259;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd258];
	// inline asm
	add.s64 	%rd262, %rd247, 64;
	// inline asm
	cvta.to.global.u64 %rd261, %rd262;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd261];
	// inline asm
	add.s64 	%rd265, %rd247, 80;
	// inline asm
	cvta.to.global.u64 %rd264, %rd265;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd264];
	// inline asm
	add.s64 	%rd268, %rd247, 96;
	// inline asm
	cvta.to.global.u64 %rd267, %rd268;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd267];
	// inline asm
	add.s64 	%rd271, %rd247, 112;
	// inline asm
	cvta.to.global.u64 %rd270, %rd271;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r300,%r301,%r302,%r303}, [%rd270];
	// inline asm
	mov.b32 	 %f1049, %r275;
	mov.b32 	 %f1050, %r276;
	cvt.u32.u16	%r316, %rs8;
	add.s32 	%r317, %r316, -1;
	cvt.rn.f32.s32	%f1051, %r317;
	sub.f32 	%f1052, %f946, %f1049;
	mul.f32 	%f1053, %f1052, %f1051;
	sub.f32 	%f1054, %f1050, %f1049;
	div.rn.f32 	%f1055, %f1053, %f1054;
	min.f32 	%f1056, %f1051, %f1055;
	mov.f32 	%f1057, 0f00000000;
	max.f32 	%f1058, %f1057, %f1056;
	cvt.rmi.f32.f32	%f1059, %f1058;
	cvt.rzi.s32.f32	%r318, %f1059;
	cvt.s64.s32	%rd19, %r318;
	mul.wide.s32 	%rd282, %r318, 48;
	add.s64 	%rd274, %rd256, %rd282;
	// inline asm
	cvta.to.global.u64 %rd273, %rd274;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r304,%r305,%r306,%r307}, [%rd273];
	// inline asm
	mov.b32 	 %f1877, %r304;
	mov.b32 	 %f1878, %r305;
	mov.b32 	 %f1879, %r306;
	add.s64 	%rd277, %rd274, 16;
	// inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r308,%r309,%r310,%r311}, [%rd276];
	// inline asm
	mov.b32 	 %f1874, %r308;
	mov.b32 	 %f1875, %r309;
	mov.b32 	 %f1876, %r310;
	add.s64 	%rd280, %rd274, 32;
	// inline asm
	cvta.to.global.u64 %rd279, %rd280;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r312,%r313,%r314,%r315}, [%rd279];
	// inline asm
	sub.f32 	%f249, %f1058, %f1059;
	mov.b32 	 %f1871, %r312;
	mov.b32 	 %f1872, %r313;
	mov.b32 	 %f1873, %r314;
	setp.leu.f32	%p17, %f249, 0f00000000;
	@%p17 bra 	BB1_37;

	mul.lo.s64 	%rd292, %rd19, 48;
	add.s64 	%rd293, %rd247, %rd292;
	add.s64 	%rd284, %rd293, 80;
	// inline asm
	cvta.to.global.u64 %rd283, %rd284;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd283];
	// inline asm
	mov.b32 	 %f1060, %r319;
	mov.b32 	 %f1061, %r320;
	mov.b32 	 %f1062, %r321;
	add.s64 	%rd287, %rd293, 96;
	// inline asm
	cvta.to.global.u64 %rd286, %rd287;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r323,%r324,%r325,%r326}, [%rd286];
	// inline asm
	mov.b32 	 %f1063, %r323;
	mov.b32 	 %f1064, %r324;
	mov.b32 	 %f1065, %r325;
	add.s64 	%rd290, %rd293, 112;
	// inline asm
	cvta.to.global.u64 %rd289, %rd290;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r327,%r328,%r329,%r330}, [%rd289];
	// inline asm
	mov.f32 	%f1066, 0f3F800000;
	sub.f32 	%f1067, %f1066, %f249;
	mul.f32 	%f1068, %f249, %f1060;
	mul.f32 	%f1069, %f249, %f1061;
	mul.f32 	%f1070, %f249, %f1062;
	fma.rn.f32 	%f1877, %f1067, %f1877, %f1068;
	fma.rn.f32 	%f1878, %f1067, %f1878, %f1069;
	fma.rn.f32 	%f1879, %f1067, %f1879, %f1070;
	mul.f32 	%f1071, %f249, %f1063;
	mul.f32 	%f1072, %f249, %f1064;
	mul.f32 	%f1073, %f249, %f1065;
	fma.rn.f32 	%f1874, %f1067, %f1874, %f1071;
	fma.rn.f32 	%f1875, %f1067, %f1875, %f1072;
	fma.rn.f32 	%f1876, %f1067, %f1876, %f1073;
	mov.b32 	 %f1074, %r327;
	mov.b32 	 %f1075, %r328;
	mov.b32 	 %f1076, %r329;
	mul.f32 	%f1077, %f249, %f1074;
	mul.f32 	%f1078, %f249, %f1075;
	mul.f32 	%f1079, %f249, %f1076;
	fma.rn.f32 	%f1871, %f1067, %f1871, %f1077;
	fma.rn.f32 	%f1872, %f1067, %f1872, %f1078;
	fma.rn.f32 	%f1873, %f1067, %f1873, %f1079;
	bra.uni 	BB1_37;

BB1_26:
	mov.f32 	%f1880, 0f00000000;
	mov.f32 	%f1882, 0f3F800000;
	setp.eq.s32	%p13, %r183, 4;
	@%p13 bra 	BB1_29;
	bra.uni 	BB1_27;

BB1_29:
	// inline asm
	call (%rd662), _optix_get_instance_inverse_transform_from_handle, (%rd173);
	// inline asm
	bra.uni 	BB1_30;

BB1_32:
	// inline asm
	call (%rd188), _optix_get_srt_motion_transform_from_handle, (%rd173);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd190, %rd188;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd190];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r199;
	add.s64 	%rd194, %rd188, 16;
	// inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd193];
	// inline asm
	add.s64 	%rd197, %rd188, 32;
	// inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd196];
	// inline asm
	add.s64 	%rd200, %rd188, 48;
	// inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd199];
	// inline asm
	add.s64 	%rd203, %rd188, 64;
	// inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd202];
	// inline asm
	add.s64 	%rd206, %rd188, 80;
	// inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd205];
	// inline asm
	add.s64 	%rd209, %rd188, 96;
	// inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd208];
	// inline asm
	add.s64 	%rd212, %rd188, 112;
	// inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd211];
	// inline asm
	add.s64 	%rd215, %rd188, 128;
	// inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd214];
	// inline asm
	add.s64 	%rd218, %rd188, 144;
	// inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd217];
	// inline asm
	mov.b32 	 %f957, %r200;
	mov.b32 	 %f958, %r201;
	cvt.u32.u16	%r253, %rs6;
	add.s32 	%r254, %r253, -1;
	cvt.rn.f32.s32	%f959, %r254;
	sub.f32 	%f960, %f946, %f957;
	mul.f32 	%f961, %f960, %f959;
	sub.f32 	%f962, %f958, %f957;
	div.rn.f32 	%f963, %f961, %f962;
	min.f32 	%f964, %f959, %f963;
	mov.f32 	%f965, 0f00000000;
	max.f32 	%f966, %f965, %f964;
	cvt.rmi.f32.f32	%f967, %f966;
	cvt.rzi.s32.f32	%r255, %f967;
	cvt.s64.s32	%rd17, %r255;
	mul.wide.s32 	%rd232, %r255, 64;
	add.s64 	%rd221, %rd197, %rd232;
	// inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r237,%r238,%r239,%r240}, [%rd220];
	// inline asm
	mov.b32 	 %f1861, %r237;
	mov.b32 	 %f1862, %r238;
	mov.b32 	 %f1863, %r239;
	add.s64 	%rd224, %rd221, 16;
	// inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r241,%r242,%r243,%r244}, [%rd223];
	// inline asm
	mov.b32 	 %f1864, %r241;
	mov.b32 	 %f1865, %r242;
	mov.b32 	 %f1866, %r244;
	add.s64 	%rd227, %rd221, 32;
	// inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r245,%r246,%r247,%r248}, [%rd226];
	// inline asm
	sub.f32 	%f209, %f966, %f967;
	mov.b32 	 %f1867, %r246;
	mov.b32 	 %f1868, %r247;
	mov.b32 	 %f1869, %r248;
	add.s64 	%rd230, %rd221, 48;
	// inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r249,%r250,%r251,%r252}, [%rd229];
	// inline asm
	mov.b32 	 %f1870, %r249;
	setp.leu.f32	%p16, %f209, 0f00000000;
	@%p16 bra 	BB1_34;

	shl.b64 	%rd245, %rd17, 6;
	add.s64 	%rd246, %rd245, %rd188;
	add.s64 	%rd234, %rd246, 96;
	// inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd233];
	// inline asm
	mov.b32 	 %f968, %r256;
	mov.b32 	 %f969, %r257;
	mov.b32 	 %f970, %r258;
	add.s64 	%rd237, %rd246, 112;
	// inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd236];
	// inline asm
	mov.b32 	 %f971, %r260;
	mov.b32 	 %f972, %r261;
	mov.b32 	 %f973, %r263;
	add.s64 	%rd240, %rd246, 128;
	// inline asm
	cvta.to.global.u64 %rd239, %rd240;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd239];
	// inline asm
	mov.b32 	 %f974, %r265;
	mov.b32 	 %f975, %r266;
	mov.b32 	 %f976, %r267;
	add.s64 	%rd243, %rd246, 144;
	// inline asm
	cvta.to.global.u64 %rd242, %rd243;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd242];
	// inline asm
	mov.f32 	%f977, 0f3F800000;
	sub.f32 	%f978, %f977, %f209;
	mul.f32 	%f979, %f209, %f968;
	mul.f32 	%f980, %f209, %f969;
	mul.f32 	%f981, %f209, %f970;
	fma.rn.f32 	%f1861, %f978, %f1861, %f979;
	fma.rn.f32 	%f1862, %f978, %f1862, %f980;
	fma.rn.f32 	%f1863, %f978, %f1863, %f981;
	mul.f32 	%f982, %f209, %f971;
	mul.f32 	%f983, %f209, %f972;
	mul.f32 	%f984, %f209, %f973;
	fma.rn.f32 	%f1864, %f978, %f1864, %f982;
	fma.rn.f32 	%f1865, %f978, %f1865, %f983;
	fma.rn.f32 	%f1866, %f978, %f1866, %f984;
	mul.f32 	%f985, %f209, %f974;
	mul.f32 	%f986, %f209, %f975;
	mul.f32 	%f987, %f209, %f976;
	fma.rn.f32 	%f988, %f978, %f1867, %f985;
	fma.rn.f32 	%f989, %f978, %f1868, %f986;
	fma.rn.f32 	%f990, %f978, %f1869, %f987;
	mov.b32 	 %f991, %r268;
	mul.f32 	%f992, %f209, %f991;
	fma.rn.f32 	%f993, %f978, %f1870, %f992;
	mul.f32 	%f994, %f989, %f989;
	fma.rn.f32 	%f995, %f988, %f988, %f994;
	fma.rn.f32 	%f996, %f990, %f990, %f995;
	fma.rn.f32 	%f997, %f993, %f993, %f996;
	sqrt.rn.f32 	%f998, %f997;
	rcp.rn.f32 	%f999, %f998;
	mul.f32 	%f1867, %f988, %f999;
	mul.f32 	%f1868, %f989, %f999;
	mul.f32 	%f1869, %f990, %f999;
	mul.f32 	%f1870, %f993, %f999;

BB1_34:
	mul.f32 	%f1000, %f1868, %f1868;
	fma.rn.f32 	%f1001, %f1867, %f1867, %f1000;
	fma.rn.f32 	%f1002, %f1869, %f1869, %f1001;
	fma.rn.f32 	%f1003, %f1870, %f1870, %f1002;
	rcp.rn.f32 	%f1004, %f1003;
	mul.f32 	%f1005, %f1867, %f1004;
	mul.f32 	%f1006, %f1868, %f1004;
	mul.f32 	%f1007, %f1869, %f1004;
	mul.f32 	%f1008, %f1870, %f1004;
	mul.f32 	%f1009, %f1867, %f1005;
	mul.f32 	%f1010, %f1868, %f1006;
	mul.f32 	%f1011, %f1869, %f1007;
	mul.f32 	%f1012, %f1867, %f1006;
	mul.f32 	%f1013, %f1869, %f1008;
	mul.f32 	%f1014, %f1867, %f1007;
	mul.f32 	%f1015, %f1868, %f1008;
	mul.f32 	%f1016, %f1868, %f1007;
	mul.f32 	%f1017, %f1867, %f1008;
	sub.f32 	%f1018, %f1009, %f1010;
	sub.f32 	%f1019, %f1018, %f1011;
	fma.rn.f32 	%f1020, %f1870, %f1008, %f1019;
	sub.f32 	%f1021, %f1012, %f1013;
	add.f32 	%f1022, %f1021, %f1021;
	add.f32 	%f1023, %f1014, %f1015;
	add.f32 	%f1024, %f1023, %f1023;
	add.f32 	%f1025, %f1012, %f1013;
	add.f32 	%f1026, %f1025, %f1025;
	sub.f32 	%f1027, %f1010, %f1009;
	sub.f32 	%f1028, %f1027, %f1011;
	fma.rn.f32 	%f1029, %f1870, %f1008, %f1028;
	sub.f32 	%f1030, %f1016, %f1017;
	add.f32 	%f1031, %f1030, %f1030;
	sub.f32 	%f1032, %f1014, %f1015;
	add.f32 	%f1033, %f1032, %f1032;
	add.f32 	%f1034, %f1016, %f1017;
	add.f32 	%f1035, %f1034, %f1034;
	neg.f32 	%f1036, %f1009;
	sub.f32 	%f1037, %f1036, %f1010;
	add.f32 	%f1038, %f1011, %f1037;
	fma.rn.f32 	%f1039, %f1870, %f1008, %f1038;
	mul.f32 	%f1040, %f1863, %f1020;
	fma.rn.f32 	%f1041, %f1865, %f1022, %f1040;
	fma.rn.f32 	%f1879, %f1866, %f1024, %f1041;
	mul.f32 	%f1042, %f1865, %f1029;
	fma.rn.f32 	%f1043, %f1863, %f1026, %f1042;
	fma.rn.f32 	%f1876, %f1866, %f1031, %f1043;
	mul.f32 	%f1044, %f1865, %f1035;
	fma.rn.f32 	%f1045, %f1863, %f1033, %f1044;
	fma.rn.f32 	%f1873, %f1866, %f1039, %f1045;
	mul.f32 	%f1046, %f1862, %f1020;
	fma.rn.f32 	%f1878, %f1864, %f1022, %f1046;
	mul.f32 	%f1047, %f1864, %f1029;
	fma.rn.f32 	%f1875, %f1862, %f1026, %f1047;
	mul.f32 	%f1048, %f1864, %f1035;
	fma.rn.f32 	%f1872, %f1862, %f1033, %f1048;
	mul.f32 	%f1877, %f1861, %f1020;
	mul.f32 	%f1874, %f1861, %f1026;
	mul.f32 	%f1871, %f1861, %f1033;

BB1_37:
	mul.f32 	%f1080, %f1872, %f1876;
	mul.f32 	%f1081, %f1873, %f1875;
	sub.f32 	%f1082, %f1081, %f1080;
	mul.f32 	%f1083, %f1877, %f1082;
	mul.f32 	%f1084, %f1871, %f1876;
	mul.f32 	%f1085, %f1873, %f1874;
	sub.f32 	%f1086, %f1085, %f1084;
	mul.f32 	%f1087, %f1086, %f1878;
	sub.f32 	%f1088, %f1083, %f1087;
	mul.f32 	%f1089, %f1871, %f1875;
	mul.f32 	%f1090, %f1872, %f1874;
	sub.f32 	%f1091, %f1090, %f1089;
	fma.rn.f32 	%f1092, %f1091, %f1879, %f1088;
	rcp.rn.f32 	%f1093, %f1092;
	mul.f32 	%f1886, %f1082, %f1093;
	mul.f32 	%f1094, %f1873, %f1878;
	mul.f32 	%f1095, %f1872, %f1879;
	sub.f32 	%f1096, %f1095, %f1094;
	mul.f32 	%f1887, %f1093, %f1096;
	mul.f32 	%f1097, %f1875, %f1879;
	mul.f32 	%f1098, %f1876, %f1878;
	sub.f32 	%f1099, %f1098, %f1097;
	mul.f32 	%f1888, %f1093, %f1099;
	sub.f32 	%f1100, %f1084, %f1085;
	mul.f32 	%f1883, %f1100, %f1093;
	mul.f32 	%f1101, %f1871, %f1879;
	mul.f32 	%f1102, %f1873, %f1877;
	sub.f32 	%f1103, %f1102, %f1101;
	mul.f32 	%f1884, %f1093, %f1103;
	mul.f32 	%f1104, %f1876, %f1877;
	mul.f32 	%f1105, %f1874, %f1879;
	sub.f32 	%f1106, %f1105, %f1104;
	mul.f32 	%f1885, %f1093, %f1106;
	mul.f32 	%f1880, %f1091, %f1093;
	mul.f32 	%f1107, %f1872, %f1877;
	mul.f32 	%f1108, %f1871, %f1878;
	sub.f32 	%f1109, %f1108, %f1107;
	mul.f32 	%f1881, %f1109, %f1093;
	mul.f32 	%f1110, %f1874, %f1878;
	mul.f32 	%f1111, %f1875, %f1877;
	sub.f32 	%f1112, %f1111, %f1110;
	mul.f32 	%f1882, %f1112, %f1093;
	bra.uni 	BB1_38;

BB1_27:
	setp.ne.s32	%p14, %r183, 1;
	mov.f32 	%f1881, %f1880;
	mov.f32 	%f1883, %f1880;
	mov.f32 	%f1884, %f1882;
	mov.f32 	%f1885, %f1880;
	mov.f32 	%f1886, %f1882;
	mov.f32 	%f1887, %f1880;
	mov.f32 	%f1888, %f1880;
	@%p14 bra 	BB1_38;

	// inline asm
	call (%rd175), _optix_get_static_transform_from_handle, (%rd173);
	// inline asm
	add.s64 	%rd662, %rd175, 64;

BB1_30:
	// inline asm
	cvta.to.global.u64 %rd179, %rd662;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd179];
	// inline asm
	mov.b32 	 %f1886, %r185;
	mov.b32 	 %f1887, %r186;
	mov.b32 	 %f1888, %r187;
	add.s64 	%rd183, %rd662, 16;
	// inline asm
	cvta.to.global.u64 %rd182, %rd183;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd182];
	// inline asm
	mov.b32 	 %f1883, %r189;
	mov.b32 	 %f1884, %r190;
	mov.b32 	 %f1885, %r191;
	add.s64 	%rd186, %rd662, 32;
	// inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd185];
	// inline asm
	mov.b32 	 %f1880, %r193;
	mov.b32 	 %f1881, %r194;
	mov.b32 	 %f1882, %r195;

BB1_38:
	setp.eq.s32	%p18, %r647, 0;
	@%p18 bra 	BB1_39;
	bra.uni 	BB1_40;

BB1_39:
	mov.f32 	%f1860, %f1880;
	mov.f32 	%f1859, %f1881;
	mov.f32 	%f1858, %f1882;
	mov.f32 	%f1857, %f1883;
	mov.f32 	%f1856, %f1884;
	mov.f32 	%f1855, %f1885;
	mov.f32 	%f1854, %f1886;
	mov.f32 	%f1853, %f1887;
	mov.f32 	%f1852, %f1888;
	bra.uni 	BB1_41;

BB1_40:
	mul.f32 	%f1113, %f1857, %f1887;
	fma.rn.f32 	%f1114, %f1854, %f1886, %f1113;
	fma.rn.f32 	%f289, %f1860, %f1888, %f1114;
	mul.f32 	%f1115, %f1856, %f1887;
	fma.rn.f32 	%f1116, %f1853, %f1886, %f1115;
	fma.rn.f32 	%f290, %f1859, %f1888, %f1116;
	mul.f32 	%f1117, %f1855, %f1887;
	fma.rn.f32 	%f1118, %f1852, %f1886, %f1117;
	fma.rn.f32 	%f291, %f1858, %f1888, %f1118;
	mul.f32 	%f1119, %f1857, %f1884;
	fma.rn.f32 	%f1120, %f1854, %f1883, %f1119;
	fma.rn.f32 	%f292, %f1860, %f1885, %f1120;
	mul.f32 	%f1121, %f1856, %f1884;
	fma.rn.f32 	%f1122, %f1853, %f1883, %f1121;
	fma.rn.f32 	%f293, %f1859, %f1885, %f1122;
	mul.f32 	%f1123, %f1855, %f1884;
	fma.rn.f32 	%f1124, %f1852, %f1883, %f1123;
	fma.rn.f32 	%f294, %f1858, %f1885, %f1124;
	mul.f32 	%f1125, %f1857, %f1881;
	fma.rn.f32 	%f1126, %f1854, %f1880, %f1125;
	fma.rn.f32 	%f1860, %f1860, %f1882, %f1126;
	mul.f32 	%f1127, %f1856, %f1881;
	fma.rn.f32 	%f1128, %f1853, %f1880, %f1127;
	fma.rn.f32 	%f1859, %f1859, %f1882, %f1128;
	mul.f32 	%f1129, %f1855, %f1881;
	fma.rn.f32 	%f1130, %f1852, %f1880, %f1129;
	fma.rn.f32 	%f1858, %f1858, %f1882, %f1130;
	mov.f32 	%f1857, %f292;
	mov.f32 	%f1856, %f293;
	mov.f32 	%f1855, %f294;
	mov.f32 	%f1854, %f289;
	mov.f32 	%f1853, %f290;
	mov.f32 	%f1852, %f291;

BB1_41:
	add.s32 	%r647, %r647, 1;
	setp.lt.u32	%p19, %r647, %r30;
	@%p19 bra 	BB1_25;

	mul.f32 	%f1131, %f944, %f1853;
	fma.rn.f32 	%f1132, %f943, %f1854, %f1131;
	fma.rn.f32 	%f1898, %f1900, %f1852, %f1132;
	mul.f32 	%f1133, %f944, %f1856;
	fma.rn.f32 	%f1134, %f943, %f1857, %f1133;
	fma.rn.f32 	%f1899, %f1900, %f1855, %f1134;
	mul.f32 	%f1135, %f944, %f1859;
	fma.rn.f32 	%f1136, %f943, %f1860, %f1135;
	fma.rn.f32 	%f1900, %f1900, %f1858, %f1136;
	bra.uni 	BB1_43;

BB1_24:
	mov.f32 	%f1898, %f943;
	mov.f32 	%f1899, %f944;

BB1_43:
	// inline asm
	call (%f1138), _optix_get_ray_tmax, ();
	// inline asm
	ld.const.u64 	%rd294, [params+80];
	setp.eq.s64	%p20, %rd294, 0;
	@%p20 bra 	BB1_48;

	ld.u64 	%rd295, [%rd51];
	ld.const.u64 	%rd296, [params+328];
	cvta.to.global.u64 	%rd297, %rd296;
	cvt.u64.u32	%rd20, %r1;
	mul.wide.u32 	%rd298, %r1, 8;
	add.s64 	%rd299, %rd297, %rd298;
	st.global.u64 	[%rd299], %rd295;
	ld.const.u64 	%rd300, [params+336];
	cvta.to.global.u64 	%rd301, %rd300;
	mul.wide.u32 	%rd302, %r1, 4;
	add.s64 	%rd303, %rd301, %rd302;
	mov.u32 	%r331, 0;
	st.global.u32 	[%rd303], %r331;
	ld.const.u64 	%rd304, [params+344];
	cvta.to.global.u64 	%rd305, %rd304;
	add.s64 	%rd21, %rd305, %rd302;
	ld.global.u32 	%r9, [%rd21];
	setp.eq.s32	%p21, %r9, 0;
	@%p21 bra 	BB1_47;

	// inline asm
	call (%r332), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p22, %r332, %r9;
	@%p22 bra 	BB1_47;

	st.global.u32 	[%rd21], %r332;

BB1_47:
	ld.const.u64 	%rd306, [params+72];
	cvta.to.global.u64 	%rd307, %rd306;
	shl.b64 	%rd308, %rd20, 2;
	add.s64 	%rd309, %rd307, %rd308;
	st.global.f32 	[%rd309], %f1138;
	bra.uni 	BB1_114;

BB1_48:
	fma.rn.f32 	%f314, %f1138, %f1898, %f1851;
	ld.v4.f32 	{%f1139, %f1140, %f1141, %f1142}, [%rd3+208];
	ld.v4.f32 	{%f1146, %f1147, %f1148, %f1149}, [%rd3+160];
	fma.rn.f32 	%f1151, %f314, %f1146, %f1139;
	fma.rn.f32 	%f1153, %f314, %f1147, %f1140;
	fma.rn.f32 	%f1155, %f314, %f1148, %f1141;
	fma.rn.f32 	%f315, %f1138, %f1899, %f1850;
	ld.v4.f32 	{%f1156, %f1157, %f1158, %f1159}, [%rd3+176];
	fma.rn.f32 	%f1161, %f315, %f1156, %f1151;
	fma.rn.f32 	%f1163, %f315, %f1157, %f1153;
	fma.rn.f32 	%f1165, %f315, %f1158, %f1155;
	fma.rn.f32 	%f316, %f1138, %f1900, %f1849;
	ld.v4.f32 	{%f1166, %f1167, %f1168, %f1169}, [%rd3+192];
	fma.rn.f32 	%f317, %f316, %f1166, %f1161;
	fma.rn.f32 	%f318, %f316, %f1167, %f1163;
	fma.rn.f32 	%f319, %f316, %f1168, %f1165;
	abs.f32 	%f320, %f317;
	abs.f32 	%f321, %f318;
	setp.eq.f32	%p23, %f320, 0f00000000;
	setp.eq.f32	%p24, %f321, 0f00000000;
	and.pred  	%p25, %p23, %p24;
	mov.b32 	 %r11, %f317;
	mov.b32 	 %r333, %f318;
	and.b32  	%r12, %r333, -2147483648;
	@%p25 bra 	BB1_52;
	bra.uni 	BB1_49;

BB1_52:
	shr.s32 	%r340, %r11, 31;
	and.b32  	%r341, %r340, 1078530011;
	or.b32  	%r342, %r341, %r12;
	mov.b32 	 %f1901, %r342;
	bra.uni 	BB1_53;

BB1_49:
	setp.eq.f32	%p26, %f320, 0f7F800000;
	setp.eq.f32	%p27, %f321, 0f7F800000;
	and.pred  	%p28, %p26, %p27;
	@%p28 bra 	BB1_51;
	bra.uni 	BB1_50;

BB1_51:
	shr.s32 	%r336, %r11, 31;
	and.b32  	%r337, %r336, 13483017;
	add.s32 	%r338, %r337, 1061752795;
	or.b32  	%r339, %r338, %r12;
	mov.b32 	 %f1901, %r339;
	bra.uni 	BB1_53;

BB1_50:
	max.f32 	%f1173, %f321, %f320;
	min.f32 	%f1174, %f321, %f320;
	div.rn.f32 	%f1175, %f1174, %f1173;
	mul.rn.f32 	%f1176, %f1175, %f1175;
	mov.f32 	%f1177, 0fC0B59883;
	mov.f32 	%f1178, 0fBF52C7EA;
	fma.rn.f32 	%f1179, %f1176, %f1178, %f1177;
	mov.f32 	%f1180, 0fC0D21907;
	fma.rn.f32 	%f1181, %f1179, %f1176, %f1180;
	mul.f32 	%f1182, %f1176, %f1181;
	mul.f32 	%f1183, %f1175, %f1182;
	add.f32 	%f1184, %f1176, 0f41355DC0;
	mov.f32 	%f1185, 0f41E6BD60;
	fma.rn.f32 	%f1186, %f1184, %f1176, %f1185;
	mov.f32 	%f1187, 0f419D92C8;
	fma.rn.f32 	%f1188, %f1186, %f1176, %f1187;
	rcp.rn.f32 	%f1189, %f1188;
	fma.rn.f32 	%f1190, %f1183, %f1189, %f1175;
	mov.f32 	%f1191, 0f3FC90FDB;
	sub.f32 	%f1192, %f1191, %f1190;
	setp.gt.f32	%p29, %f321, %f320;
	selp.f32	%f1193, %f1192, %f1190, %p29;
	mov.f32 	%f1194, 0f40490FDB;
	sub.f32 	%f1195, %f1194, %f1193;
	setp.lt.s32	%p30, %r11, 0;
	selp.f32	%f1196, %f1195, %f1193, %p30;
	mov.b32 	 %r334, %f1196;
	or.b32  	%r335, %r334, %r12;
	mov.b32 	 %f1197, %r335;
	add.f32 	%f1198, %f320, %f321;
	setp.gtu.f32	%p31, %f1198, 0f7F800000;
	selp.f32	%f1901, %f1198, %f1197, %p31;

BB1_53:
	add.f32 	%f1202, %f1901, 0f40C90FDB;
	setp.lt.f32	%p32, %f1901, 0f00000000;
	selp.f32	%f326, %f1202, %f1901, %p32;
	ld.v2.f32 	{%f1203, %f1204}, [%rd3+288];
	div.rn.f32 	%f327, %f319, %f1203;
	ld.v4.f32 	{%f1207, %f1208, %f1209, %f1210}, [%rd3+32];
	mul.f32 	%f1214, %f318, 0fC0C90FDB;
	mul.f32 	%f1215, %f1214, %f1207;
	mul.f32 	%f1216, %f1214, %f1208;
	mul.f32 	%f1217, %f1214, %f1209;
	ld.v4.f32 	{%f1218, %f1219, %f1220, %f1221}, [%rd3+48];
	mul.f32 	%f1225, %f317, 0f40C90FDB;
	fma.rn.f32 	%f1226, %f1225, %f1218, %f1215;
	fma.rn.f32 	%f1227, %f1225, %f1219, %f1216;
	fma.rn.f32 	%f1228, %f1225, %f1220, %f1217;
	ld.v4.f32 	{%f1229, %f1230, %f1231, %f1232}, [%rd3+64];
	mov.f32 	%f2039, 0f00000000;
	fma.rn.f32 	%f2048, %f2039, %f1229, %f1226;
	fma.rn.f32 	%f2049, %f2039, %f1230, %f1227;
	fma.rn.f32 	%f2050, %f2039, %f1231, %f1228;
	mul.f32 	%f1236, %f1207, 0f00000000;
	mul.f32 	%f1237, %f1208, 0f00000000;
	mul.f32 	%f1238, %f1209, 0f00000000;
	fma.rn.f32 	%f1239, %f2039, %f1218, %f1236;
	fma.rn.f32 	%f1240, %f2039, %f1219, %f1237;
	fma.rn.f32 	%f1241, %f2039, %f1220, %f1238;
	fma.rn.f32 	%f2045, %f1203, %f1229, %f1239;
	fma.rn.f32 	%f2046, %f1203, %f1230, %f1240;
	fma.rn.f32 	%f2047, %f1203, %f1231, %f1241;
	mul.f32 	%f1242, %f2049, %f2047;
	mul.f32 	%f1243, %f2050, %f2046;
	sub.f32 	%f1244, %f1242, %f1243;
	mul.f32 	%f1245, %f2050, %f2045;
	mul.f32 	%f1246, %f2048, %f2047;
	sub.f32 	%f1247, %f1245, %f1246;
	mul.f32 	%f1248, %f2048, %f2046;
	mul.f32 	%f1249, %f2049, %f2045;
	sub.f32 	%f1250, %f1248, %f1249;
	mul.f32 	%f1251, %f1244, %f1244;
	fma.rn.f32 	%f1252, %f1247, %f1247, %f1251;
	fma.rn.f32 	%f1253, %f1250, %f1250, %f1252;
	sqrt.rn.f32 	%f1254, %f1253;
	div.rn.f32 	%f1255, %f1244, %f1254;
	div.rn.f32 	%f1256, %f1247, %f1254;
	div.rn.f32 	%f1257, %f1250, %f1254;
	mul.f32 	%f1258, %f317, %f317;
	fma.rn.f32 	%f1259, %f318, %f318, %f1258;
	sqrt.rn.f32 	%f1260, %f1259;
	sub.f32 	%f1261, %f1204, %f1260;
	fma.rn.f32 	%f2057, %f1255, %f1261, %f314;
	fma.rn.f32 	%f2058, %f1256, %f1261, %f315;
	fma.rn.f32 	%f2059, %f1257, %f1261, %f316;
	ld.u8 	%rs10, [%rd3+296];
	setp.eq.s16	%p33, %rs10, 0;
	neg.f32 	%f1262, %f1255;
	neg.f32 	%f1263, %f1256;
	neg.f32 	%f1264, %f1257;
	selp.f32	%f2056, %f1257, %f1264, %p33;
	selp.f32	%f2055, %f1256, %f1263, %p33;
	selp.f32	%f2054, %f1255, %f1262, %p33;
	selp.f32	%f1265, 0f3F800000, 0fBF800000, %p33;
	mul.f32 	%f1266, %f1204, %f1265;
	div.rn.f32 	%f2042, %f2048, %f1266;
	div.rn.f32 	%f2043, %f2049, %f1266;
	div.rn.f32 	%f2044, %f2050, %f1266;
	ld.u64 	%rd23, [%rd51];
	ld.const.u64 	%rd310, [params+344];
	cvta.to.global.u64 	%rd311, %rd310;
	cvt.u64.u32	%rd24, %r1;
	mul.wide.u32 	%rd312, %r1, 4;
	add.s64 	%rd25, %rd311, %rd312;
	ld.global.u32 	%r13, [%rd25];
	setp.eq.s32	%p34, %r13, 0;
	@%p34 bra 	BB1_54;

	// inline asm
	call (%r343), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p35, %r343, %r13;
	@%p35 bra 	BB1_54;

	mov.f32 	%f1967, 0f00000000;
	mov.f32 	%f1968, 0f3F800000;
	mov.f32 	%f1905, %f1968;
	mov.f32 	%f1904, %f1967;
	mov.f32 	%f1903, %f1967;
	mov.f32 	%f1902, %f1967;
	mov.f32 	%f1909, %f1967;
	mov.f32 	%f1908, %f1968;
	mov.f32 	%f1907, %f1967;
	mov.f32 	%f1906, %f1967;
	mov.f32 	%f1913, %f1967;
	mov.f32 	%f1912, %f1967;
	mov.f32 	%f1911, %f1968;
	mov.f32 	%f1910, %f1967;
	@%p2 bra 	BB1_74;

	add.s32 	%r648, %r30, -1;
	setp.lt.s32	%p37, %r648, 0;
	@%p37 bra 	BB1_74;

BB1_58:
	.pragma "nounroll";
	// inline asm
	call (%rd313), _optix_get_transform_list_handle, (%r648);
	// inline asm
	// inline asm
	call (%r345), _optix_get_transform_type_from_handle, (%rd313);
	// inline asm
	and.b32  	%r346, %r345, -2;
	setp.eq.s32	%p38, %r346, 2;
	@%p38 bra 	BB1_64;
	bra.uni 	BB1_59;

BB1_64:
	setp.eq.s32	%p41, %r345, 2;
	@%p41 bra 	BB1_68;
	bra.uni 	BB1_65;

BB1_68:
	// inline asm
	call (%rd387), _optix_get_matrix_motion_transform_from_handle, (%rd313);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd389, %rd387;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd389];
	// inline asm
	mov.b32	{%rs13, %rs14}, %r436;
	add.s64 	%rd393, %rd387, 16;
	// inline asm
	cvta.to.global.u64 %rd392, %rd393;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd392];
	// inline asm
	add.s64 	%rd396, %rd387, 32;
	// inline asm
	cvta.to.global.u64 %rd395, %rd396;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd395];
	// inline asm
	add.s64 	%rd399, %rd387, 48;
	// inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd398];
	// inline asm
	add.s64 	%rd402, %rd387, 64;
	// inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd401];
	// inline asm
	add.s64 	%rd405, %rd387, 80;
	// inline asm
	cvta.to.global.u64 %rd404, %rd405;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd404];
	// inline asm
	add.s64 	%rd408, %rd387, 96;
	// inline asm
	cvta.to.global.u64 %rd407, %rd408;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd407];
	// inline asm
	add.s64 	%rd411, %rd387, 112;
	// inline asm
	cvta.to.global.u64 %rd410, %rd411;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd410];
	// inline asm
	mov.b32 	 %f1408, %r437;
	mov.b32 	 %f1409, %r438;
	cvt.u32.u16	%r478, %rs13;
	add.s32 	%r479, %r478, -1;
	cvt.rn.f32.s32	%f1410, %r479;
	sub.f32 	%f1411, %f946, %f1408;
	mul.f32 	%f1412, %f1411, %f1410;
	sub.f32 	%f1413, %f1409, %f1408;
	div.rn.f32 	%f1414, %f1412, %f1413;
	min.f32 	%f1415, %f1410, %f1414;
	mov.f32 	%f1416, 0f00000000;
	max.f32 	%f1417, %f1416, %f1415;
	cvt.rmi.f32.f32	%f1418, %f1417;
	cvt.rzi.s32.f32	%r480, %f1418;
	cvt.s64.s32	%rd33, %r480;
	mul.wide.s32 	%rd422, %r480, 48;
	add.s64 	%rd414, %rd396, %rd422;
	// inline asm
	cvta.to.global.u64 %rd413, %rd414;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd413];
	// inline asm
	mov.b32 	 %f1938, %r466;
	mov.b32 	 %f1939, %r467;
	mov.b32 	 %f1940, %r468;
	mov.b32 	 %f1941, %r469;
	add.s64 	%rd417, %rd414, 16;
	// inline asm
	cvta.to.global.u64 %rd416, %rd417;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd416];
	// inline asm
	mov.b32 	 %f1934, %r470;
	mov.b32 	 %f1935, %r471;
	mov.b32 	 %f1936, %r472;
	mov.b32 	 %f1937, %r473;
	add.s64 	%rd420, %rd414, 32;
	// inline asm
	cvta.to.global.u64 %rd419, %rd420;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd419];
	// inline asm
	sub.f32 	%f436, %f1417, %f1418;
	mov.b32 	 %f1930, %r474;
	mov.b32 	 %f1931, %r475;
	mov.b32 	 %f1932, %r476;
	mov.b32 	 %f1933, %r477;
	setp.leu.f32	%p43, %f436, 0f00000000;
	@%p43 bra 	BB1_70;

	mul.lo.s64 	%rd432, %rd33, 48;
	add.s64 	%rd433, %rd387, %rd432;
	add.s64 	%rd424, %rd433, 80;
	// inline asm
	cvta.to.global.u64 %rd423, %rd424;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r481,%r482,%r483,%r484}, [%rd423];
	// inline asm
	mov.b32 	 %f1419, %r481;
	mov.b32 	 %f1420, %r482;
	mov.b32 	 %f1421, %r483;
	mov.b32 	 %f1422, %r484;
	add.s64 	%rd427, %rd433, 96;
	// inline asm
	cvta.to.global.u64 %rd426, %rd427;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r485,%r486,%r487,%r488}, [%rd426];
	// inline asm
	mov.b32 	 %f1423, %r485;
	mov.b32 	 %f1424, %r486;
	mov.b32 	 %f1425, %r487;
	mov.b32 	 %f1426, %r488;
	add.s64 	%rd430, %rd433, 112;
	// inline asm
	cvta.to.global.u64 %rd429, %rd430;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd429];
	// inline asm
	mov.f32 	%f1427, 0f3F800000;
	sub.f32 	%f1428, %f1427, %f436;
	mul.f32 	%f1429, %f436, %f1419;
	mul.f32 	%f1430, %f436, %f1420;
	mul.f32 	%f1431, %f436, %f1421;
	mul.f32 	%f1432, %f436, %f1422;
	fma.rn.f32 	%f1938, %f1428, %f1938, %f1429;
	fma.rn.f32 	%f1939, %f1428, %f1939, %f1430;
	fma.rn.f32 	%f1940, %f1428, %f1940, %f1431;
	fma.rn.f32 	%f1941, %f1428, %f1941, %f1432;
	mul.f32 	%f1433, %f436, %f1423;
	mul.f32 	%f1434, %f436, %f1424;
	mul.f32 	%f1435, %f436, %f1425;
	mul.f32 	%f1436, %f436, %f1426;
	fma.rn.f32 	%f1934, %f1428, %f1934, %f1433;
	fma.rn.f32 	%f1935, %f1428, %f1935, %f1434;
	fma.rn.f32 	%f1936, %f1428, %f1936, %f1435;
	fma.rn.f32 	%f1937, %f1428, %f1937, %f1436;
	mov.b32 	 %f1437, %r489;
	mov.b32 	 %f1438, %r490;
	mov.b32 	 %f1439, %r491;
	mov.b32 	 %f1440, %r492;
	mul.f32 	%f1441, %f436, %f1437;
	mul.f32 	%f1442, %f436, %f1438;
	mul.f32 	%f1443, %f436, %f1439;
	mul.f32 	%f1444, %f436, %f1440;
	fma.rn.f32 	%f1930, %f1428, %f1930, %f1441;
	fma.rn.f32 	%f1931, %f1428, %f1931, %f1442;
	fma.rn.f32 	%f1932, %f1428, %f1932, %f1443;
	fma.rn.f32 	%f1933, %f1428, %f1933, %f1444;
	bra.uni 	BB1_70;

BB1_59:
	mov.f32 	%f1930, 0f00000000;
	mov.f32 	%f1932, 0f3F800000;
	setp.eq.s32	%p39, %r345, 4;
	@%p39 bra 	BB1_62;
	bra.uni 	BB1_60;

BB1_62:
	// inline asm
	call (%rd663), _optix_get_instance_transform_from_handle, (%rd313);
	// inline asm
	bra.uni 	BB1_63;

BB1_65:
	// inline asm
	call (%rd328), _optix_get_srt_motion_transform_from_handle, (%rd313);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd330, %rd328;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd330];
	// inline asm
	mov.b32	{%rs11, %rs12}, %r361;
	add.s64 	%rd334, %rd328, 16;
	// inline asm
	cvta.to.global.u64 %rd333, %rd334;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd333];
	// inline asm
	add.s64 	%rd337, %rd328, 32;
	// inline asm
	cvta.to.global.u64 %rd336, %rd337;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd336];
	// inline asm
	add.s64 	%rd340, %rd328, 48;
	// inline asm
	cvta.to.global.u64 %rd339, %rd340;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd339];
	// inline asm
	add.s64 	%rd343, %rd328, 64;
	// inline asm
	cvta.to.global.u64 %rd342, %rd343;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd342];
	// inline asm
	add.s64 	%rd346, %rd328, 80;
	// inline asm
	cvta.to.global.u64 %rd345, %rd346;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd345];
	// inline asm
	add.s64 	%rd349, %rd328, 96;
	// inline asm
	cvta.to.global.u64 %rd348, %rd349;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd348];
	// inline asm
	add.s64 	%rd352, %rd328, 112;
	// inline asm
	cvta.to.global.u64 %rd351, %rd352;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd351];
	// inline asm
	add.s64 	%rd355, %rd328, 128;
	// inline asm
	cvta.to.global.u64 %rd354, %rd355;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd354];
	// inline asm
	add.s64 	%rd358, %rd328, 144;
	// inline asm
	cvta.to.global.u64 %rd357, %rd358;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd357];
	// inline asm
	mov.b32 	 %f1295, %r362;
	mov.b32 	 %f1296, %r363;
	cvt.u32.u16	%r415, %rs11;
	add.s32 	%r416, %r415, -1;
	cvt.rn.f32.s32	%f1297, %r416;
	sub.f32 	%f1298, %f946, %f1295;
	mul.f32 	%f1299, %f1298, %f1297;
	sub.f32 	%f1300, %f1296, %f1295;
	div.rn.f32 	%f1301, %f1299, %f1300;
	min.f32 	%f1302, %f1297, %f1301;
	mov.f32 	%f1303, 0f00000000;
	max.f32 	%f1304, %f1303, %f1302;
	cvt.rmi.f32.f32	%f1305, %f1304;
	cvt.rzi.s32.f32	%r417, %f1305;
	cvt.s64.s32	%rd31, %r417;
	mul.wide.s32 	%rd372, %r417, 64;
	add.s64 	%rd361, %rd337, %rd372;
	// inline asm
	cvta.to.global.u64 %rd360, %rd361;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd360];
	// inline asm
	mov.b32 	 %f1914, %r399;
	mov.b32 	 %f1915, %r400;
	mov.b32 	 %f1916, %r401;
	mov.b32 	 %f1917, %r402;
	add.s64 	%rd364, %rd361, 16;
	// inline asm
	cvta.to.global.u64 %rd363, %rd364;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd363];
	// inline asm
	mov.b32 	 %f1918, %r403;
	mov.b32 	 %f1919, %r404;
	mov.b32 	 %f1920, %r405;
	mov.b32 	 %f1921, %r406;
	add.s64 	%rd367, %rd361, 32;
	// inline asm
	cvta.to.global.u64 %rd366, %rd367;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd366];
	// inline asm
	sub.f32 	%f375, %f1304, %f1305;
	mov.b32 	 %f1922, %r407;
	mov.b32 	 %f1923, %r408;
	mov.b32 	 %f1924, %r409;
	mov.b32 	 %f1925, %r410;
	add.s64 	%rd370, %rd361, 48;
	// inline asm
	cvta.to.global.u64 %rd369, %rd370;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd369];
	// inline asm
	mov.b32 	 %f1926, %r411;
	mov.b32 	 %f1927, %r412;
	mov.b32 	 %f1928, %r413;
	mov.b32 	 %f1929, %r414;
	setp.leu.f32	%p42, %f375, 0f00000000;
	@%p42 bra 	BB1_67;

	shl.b64 	%rd385, %rd31, 6;
	add.s64 	%rd386, %rd385, %rd328;
	add.s64 	%rd374, %rd386, 96;
	// inline asm
	cvta.to.global.u64 %rd373, %rd374;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r418,%r419,%r420,%r421}, [%rd373];
	// inline asm
	mov.b32 	 %f1306, %r418;
	mov.b32 	 %f1307, %r419;
	mov.b32 	 %f1308, %r420;
	mov.b32 	 %f1309, %r421;
	add.s64 	%rd377, %rd386, 112;
	// inline asm
	cvta.to.global.u64 %rd376, %rd377;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r422,%r423,%r424,%r425}, [%rd376];
	// inline asm
	mov.b32 	 %f1310, %r422;
	mov.b32 	 %f1311, %r423;
	mov.b32 	 %f1312, %r424;
	mov.b32 	 %f1313, %r425;
	add.s64 	%rd380, %rd386, 128;
	// inline asm
	cvta.to.global.u64 %rd379, %rd380;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd379];
	// inline asm
	mov.b32 	 %f1314, %r426;
	mov.b32 	 %f1315, %r427;
	mov.b32 	 %f1316, %r428;
	mov.b32 	 %f1317, %r429;
	add.s64 	%rd383, %rd386, 144;
	// inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd382];
	// inline asm
	mov.f32 	%f1318, 0f3F800000;
	sub.f32 	%f1319, %f1318, %f375;
	mul.f32 	%f1320, %f375, %f1306;
	mul.f32 	%f1321, %f375, %f1307;
	mul.f32 	%f1322, %f375, %f1308;
	mul.f32 	%f1323, %f375, %f1309;
	fma.rn.f32 	%f1914, %f1319, %f1914, %f1320;
	fma.rn.f32 	%f1915, %f1319, %f1915, %f1321;
	fma.rn.f32 	%f1916, %f1319, %f1916, %f1322;
	fma.rn.f32 	%f1917, %f1319, %f1917, %f1323;
	mul.f32 	%f1324, %f375, %f1310;
	mul.f32 	%f1325, %f375, %f1311;
	mul.f32 	%f1326, %f375, %f1312;
	mul.f32 	%f1327, %f375, %f1313;
	fma.rn.f32 	%f1918, %f1319, %f1918, %f1324;
	fma.rn.f32 	%f1919, %f1319, %f1919, %f1325;
	fma.rn.f32 	%f1920, %f1319, %f1920, %f1326;
	fma.rn.f32 	%f1921, %f1319, %f1921, %f1327;
	mul.f32 	%f1328, %f375, %f1314;
	mul.f32 	%f1329, %f375, %f1315;
	mul.f32 	%f1330, %f375, %f1316;
	mul.f32 	%f1331, %f375, %f1317;
	fma.rn.f32 	%f1922, %f1319, %f1922, %f1328;
	fma.rn.f32 	%f1332, %f1319, %f1923, %f1329;
	fma.rn.f32 	%f1333, %f1319, %f1924, %f1330;
	fma.rn.f32 	%f1334, %f1319, %f1925, %f1331;
	mov.b32 	 %f1335, %r430;
	mov.b32 	 %f1336, %r431;
	mov.b32 	 %f1337, %r432;
	mov.b32 	 %f1338, %r433;
	mul.f32 	%f1339, %f375, %f1335;
	mul.f32 	%f1340, %f375, %f1336;
	mul.f32 	%f1341, %f375, %f1337;
	mul.f32 	%f1342, %f375, %f1338;
	fma.rn.f32 	%f1343, %f1319, %f1926, %f1339;
	fma.rn.f32 	%f1927, %f1319, %f1927, %f1340;
	fma.rn.f32 	%f1928, %f1319, %f1928, %f1341;
	fma.rn.f32 	%f1929, %f1319, %f1929, %f1342;
	mul.f32 	%f1344, %f1333, %f1333;
	fma.rn.f32 	%f1345, %f1332, %f1332, %f1344;
	fma.rn.f32 	%f1346, %f1334, %f1334, %f1345;
	fma.rn.f32 	%f1347, %f1343, %f1343, %f1346;
	sqrt.rn.f32 	%f1348, %f1347;
	rcp.rn.f32 	%f1349, %f1348;
	mul.f32 	%f1923, %f1332, %f1349;
	mul.f32 	%f1924, %f1333, %f1349;
	mul.f32 	%f1925, %f1334, %f1349;
	mul.f32 	%f1926, %f1343, %f1349;

BB1_67:
	mul.f32 	%f1350, %f1924, %f1924;
	fma.rn.f32 	%f1351, %f1923, %f1923, %f1350;
	fma.rn.f32 	%f1352, %f1925, %f1925, %f1351;
	fma.rn.f32 	%f1353, %f1926, %f1926, %f1352;
	rcp.rn.f32 	%f1354, %f1353;
	mul.f32 	%f1355, %f1923, %f1354;
	mul.f32 	%f1356, %f1924, %f1354;
	mul.f32 	%f1357, %f1925, %f1354;
	mul.f32 	%f1358, %f1926, %f1354;
	mul.f32 	%f1359, %f1923, %f1355;
	mul.f32 	%f1360, %f1924, %f1356;
	mul.f32 	%f1361, %f1925, %f1357;
	mul.f32 	%f1362, %f1923, %f1356;
	mul.f32 	%f1363, %f1925, %f1358;
	mul.f32 	%f1364, %f1923, %f1357;
	mul.f32 	%f1365, %f1924, %f1358;
	mul.f32 	%f1366, %f1924, %f1357;
	mul.f32 	%f1367, %f1923, %f1358;
	sub.f32 	%f1368, %f1359, %f1360;
	sub.f32 	%f1369, %f1368, %f1361;
	fma.rn.f32 	%f1370, %f1926, %f1358, %f1369;
	sub.f32 	%f1371, %f1362, %f1363;
	add.f32 	%f1372, %f1371, %f1371;
	add.f32 	%f1373, %f1364, %f1365;
	add.f32 	%f1374, %f1373, %f1373;
	add.f32 	%f1375, %f1362, %f1363;
	add.f32 	%f1376, %f1375, %f1375;
	sub.f32 	%f1377, %f1360, %f1359;
	sub.f32 	%f1378, %f1377, %f1361;
	fma.rn.f32 	%f1379, %f1926, %f1358, %f1378;
	sub.f32 	%f1380, %f1366, %f1367;
	add.f32 	%f1381, %f1380, %f1380;
	sub.f32 	%f1382, %f1364, %f1365;
	add.f32 	%f1383, %f1382, %f1382;
	add.f32 	%f1384, %f1366, %f1367;
	add.f32 	%f1385, %f1384, %f1384;
	neg.f32 	%f1386, %f1359;
	sub.f32 	%f1387, %f1386, %f1360;
	add.f32 	%f1388, %f1361, %f1387;
	fma.rn.f32 	%f1389, %f1926, %f1358, %f1388;
	mul.f32 	%f1390, %f1917, %f1370;
	fma.rn.f32 	%f1391, %f1920, %f1372, %f1390;
	fma.rn.f32 	%f1392, %f1922, %f1374, %f1391;
	sub.f32 	%f1941, %f1927, %f1392;
	mul.f32 	%f1393, %f1920, %f1379;
	fma.rn.f32 	%f1394, %f1917, %f1376, %f1393;
	fma.rn.f32 	%f1395, %f1922, %f1381, %f1394;
	sub.f32 	%f1937, %f1928, %f1395;
	mul.f32 	%f1396, %f1920, %f1385;
	fma.rn.f32 	%f1397, %f1917, %f1383, %f1396;
	fma.rn.f32 	%f1398, %f1922, %f1389, %f1397;
	sub.f32 	%f1933, %f1929, %f1398;
	mul.f32 	%f1399, %f1916, %f1370;
	fma.rn.f32 	%f1400, %f1919, %f1372, %f1399;
	fma.rn.f32 	%f1940, %f1921, %f1374, %f1400;
	mul.f32 	%f1401, %f1919, %f1379;
	fma.rn.f32 	%f1402, %f1916, %f1376, %f1401;
	fma.rn.f32 	%f1936, %f1921, %f1381, %f1402;
	mul.f32 	%f1403, %f1919, %f1385;
	fma.rn.f32 	%f1404, %f1916, %f1383, %f1403;
	fma.rn.f32 	%f1932, %f1921, %f1389, %f1404;
	mul.f32 	%f1405, %f1915, %f1370;
	fma.rn.f32 	%f1939, %f1918, %f1372, %f1405;
	mul.f32 	%f1406, %f1918, %f1379;
	fma.rn.f32 	%f1935, %f1915, %f1376, %f1406;
	mul.f32 	%f1407, %f1918, %f1385;
	fma.rn.f32 	%f1931, %f1915, %f1383, %f1407;
	mul.f32 	%f1938, %f1914, %f1370;
	mul.f32 	%f1934, %f1914, %f1376;
	mul.f32 	%f1930, %f1914, %f1383;
	bra.uni 	BB1_70;

BB1_60:
	setp.ne.s32	%p40, %r345, 1;
	mov.f32 	%f1931, %f1930;
	mov.f32 	%f1933, %f1930;
	mov.f32 	%f1934, %f1930;
	mov.f32 	%f1935, %f1932;
	mov.f32 	%f1936, %f1930;
	mov.f32 	%f1937, %f1930;
	mov.f32 	%f1938, %f1932;
	mov.f32 	%f1939, %f1930;
	mov.f32 	%f1940, %f1930;
	mov.f32 	%f1941, %f1930;
	@%p40 bra 	BB1_70;

	// inline asm
	call (%rd315), _optix_get_static_transform_from_handle, (%rd313);
	// inline asm
	add.s64 	%rd663, %rd315, 16;

BB1_63:
	// inline asm
	cvta.to.global.u64 %rd319, %rd663;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r347,%r348,%r349,%r350}, [%rd319];
	// inline asm
	mov.b32 	 %f1938, %r347;
	mov.b32 	 %f1939, %r348;
	mov.b32 	 %f1940, %r349;
	mov.b32 	 %f1941, %r350;
	add.s64 	%rd323, %rd663, 16;
	// inline asm
	cvta.to.global.u64 %rd322, %rd323;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r351,%r352,%r353,%r354}, [%rd322];
	// inline asm
	mov.b32 	 %f1934, %r351;
	mov.b32 	 %f1935, %r352;
	mov.b32 	 %f1936, %r353;
	mov.b32 	 %f1937, %r354;
	add.s64 	%rd326, %rd663, 32;
	// inline asm
	cvta.to.global.u64 %rd325, %rd326;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd325];
	// inline asm
	mov.b32 	 %f1930, %r355;
	mov.b32 	 %f1931, %r356;
	mov.b32 	 %f1932, %r357;
	mov.b32 	 %f1933, %r358;

BB1_70:
	add.s32 	%r18, %r648, 1;
	setp.eq.s32	%p44, %r18, %r30;
	@%p44 bra 	BB1_71;
	bra.uni 	BB1_72;

BB1_71:
	mov.f32 	%f1913, %f1930;
	mov.f32 	%f1912, %f1931;
	mov.f32 	%f1911, %f1932;
	mov.f32 	%f1910, %f1933;
	mov.f32 	%f1909, %f1934;
	mov.f32 	%f1908, %f1935;
	mov.f32 	%f1907, %f1936;
	mov.f32 	%f1906, %f1937;
	mov.f32 	%f1905, %f1938;
	mov.f32 	%f1904, %f1939;
	mov.f32 	%f1903, %f1940;
	mov.f32 	%f1902, %f1941;
	bra.uni 	BB1_73;

BB1_72:
	mul.f32 	%f1445, %f1909, %f1939;
	fma.rn.f32 	%f1446, %f1905, %f1938, %f1445;
	fma.rn.f32 	%f465, %f1913, %f1940, %f1446;
	mul.f32 	%f1447, %f1908, %f1939;
	fma.rn.f32 	%f1448, %f1904, %f1938, %f1447;
	fma.rn.f32 	%f466, %f1912, %f1940, %f1448;
	mul.f32 	%f1449, %f1907, %f1939;
	fma.rn.f32 	%f1450, %f1903, %f1938, %f1449;
	fma.rn.f32 	%f467, %f1911, %f1940, %f1450;
	mul.f32 	%f1451, %f1906, %f1939;
	fma.rn.f32 	%f1452, %f1902, %f1938, %f1451;
	fma.rn.f32 	%f1453, %f1910, %f1940, %f1452;
	add.f32 	%f468, %f1941, %f1453;
	mul.f32 	%f1454, %f1909, %f1935;
	fma.rn.f32 	%f1455, %f1905, %f1934, %f1454;
	fma.rn.f32 	%f469, %f1913, %f1936, %f1455;
	mul.f32 	%f1456, %f1908, %f1935;
	fma.rn.f32 	%f1457, %f1904, %f1934, %f1456;
	fma.rn.f32 	%f470, %f1912, %f1936, %f1457;
	mul.f32 	%f1458, %f1907, %f1935;
	fma.rn.f32 	%f1459, %f1903, %f1934, %f1458;
	fma.rn.f32 	%f471, %f1911, %f1936, %f1459;
	mul.f32 	%f1460, %f1906, %f1935;
	fma.rn.f32 	%f1461, %f1902, %f1934, %f1460;
	fma.rn.f32 	%f1462, %f1910, %f1936, %f1461;
	add.f32 	%f472, %f1937, %f1462;
	mul.f32 	%f1463, %f1909, %f1931;
	fma.rn.f32 	%f1464, %f1905, %f1930, %f1463;
	fma.rn.f32 	%f1913, %f1913, %f1932, %f1464;
	mul.f32 	%f1465, %f1908, %f1931;
	fma.rn.f32 	%f1466, %f1904, %f1930, %f1465;
	fma.rn.f32 	%f1912, %f1912, %f1932, %f1466;
	mul.f32 	%f1467, %f1907, %f1931;
	fma.rn.f32 	%f1468, %f1903, %f1930, %f1467;
	fma.rn.f32 	%f1911, %f1911, %f1932, %f1468;
	mul.f32 	%f1469, %f1906, %f1931;
	fma.rn.f32 	%f1470, %f1902, %f1930, %f1469;
	fma.rn.f32 	%f1471, %f1910, %f1932, %f1470;
	add.f32 	%f1910, %f1933, %f1471;
	mov.f32 	%f1909, %f469;
	mov.f32 	%f1908, %f470;
	mov.f32 	%f1907, %f471;
	mov.f32 	%f1906, %f472;
	mov.f32 	%f1905, %f465;
	mov.f32 	%f1904, %f466;
	mov.f32 	%f1903, %f467;
	mov.f32 	%f1902, %f468;

BB1_73:
	add.s32 	%r648, %r18, -2;
	setp.gt.s32	%p45, %r648, -1;
	@%p45 bra 	BB1_58;

BB1_74:
	mov.u32 	%r649, 0;
	mov.f32 	%f1966, %f1967;
	mov.f32 	%f1971, %f1967;
	mov.f32 	%f1970, %f1968;
	mov.f32 	%f1969, %f1967;
	mov.f32 	%f1974, %f1967;
	mov.f32 	%f1973, %f1967;
	mov.f32 	%f1972, %f1968;
	@%p2 bra 	BB1_92;

BB1_75:
	.pragma "nounroll";
	// inline asm
	call (%rd434), _optix_get_transform_list_handle, (%r649);
	// inline asm
	// inline asm
	call (%r495), _optix_get_transform_type_from_handle, (%rd434);
	// inline asm
	and.b32  	%r496, %r495, -2;
	setp.eq.s32	%p47, %r496, 2;
	@%p47 bra 	BB1_81;
	bra.uni 	BB1_76;

BB1_81:
	setp.eq.s32	%p50, %r495, 2;
	@%p50 bra 	BB1_85;
	bra.uni 	BB1_82;

BB1_85:
	// inline asm
	call (%rd508), _optix_get_matrix_motion_transform_from_handle, (%rd434);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd510, %rd508;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd510];
	// inline asm
	mov.b32	{%rs17, %rs18}, %r586;
	add.s64 	%rd514, %rd508, 16;
	// inline asm
	cvta.to.global.u64 %rd513, %rd514;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd513];
	// inline asm
	add.s64 	%rd517, %rd508, 32;
	// inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd516];
	// inline asm
	add.s64 	%rd520, %rd508, 48;
	// inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd519];
	// inline asm
	add.s64 	%rd523, %rd508, 64;
	// inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd522];
	// inline asm
	add.s64 	%rd526, %rd508, 80;
	// inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd525];
	// inline asm
	add.s64 	%rd529, %rd508, 96;
	// inline asm
	cvta.to.global.u64 %rd528, %rd529;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd528];
	// inline asm
	add.s64 	%rd532, %rd508, 112;
	// inline asm
	cvta.to.global.u64 %rd531, %rd532;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd531];
	// inline asm
	mov.b32 	 %f1583, %r587;
	mov.b32 	 %f1584, %r588;
	cvt.u32.u16	%r628, %rs17;
	add.s32 	%r629, %r628, -1;
	cvt.rn.f32.s32	%f1585, %r629;
	sub.f32 	%f1586, %f946, %f1583;
	mul.f32 	%f1587, %f1586, %f1585;
	sub.f32 	%f1588, %f1584, %f1583;
	div.rn.f32 	%f1589, %f1587, %f1588;
	min.f32 	%f1590, %f1585, %f1589;
	mov.f32 	%f1591, 0f00000000;
	max.f32 	%f1592, %f1591, %f1590;
	cvt.rmi.f32.f32	%f1593, %f1592;
	cvt.rzi.s32.f32	%r630, %f1593;
	cvt.s64.s32	%rd41, %r630;
	mul.wide.s32 	%rd543, %r630, 48;
	add.s64 	%rd535, %rd517, %rd543;
	// inline asm
	cvta.to.global.u64 %rd534, %rd535;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd534];
	// inline asm
	mov.b32 	 %f1991, %r616;
	mov.b32 	 %f1992, %r617;
	mov.b32 	 %f1993, %r618;
	add.s64 	%rd538, %rd535, 16;
	// inline asm
	cvta.to.global.u64 %rd537, %rd538;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd537];
	// inline asm
	mov.b32 	 %f1988, %r620;
	mov.b32 	 %f1989, %r621;
	mov.b32 	 %f1990, %r622;
	add.s64 	%rd541, %rd535, 32;
	// inline asm
	cvta.to.global.u64 %rd540, %rd541;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd540];
	// inline asm
	sub.f32 	%f565, %f1592, %f1593;
	mov.b32 	 %f1985, %r624;
	mov.b32 	 %f1986, %r625;
	mov.b32 	 %f1987, %r626;
	setp.leu.f32	%p52, %f565, 0f00000000;
	@%p52 bra 	BB1_87;

	mul.lo.s64 	%rd553, %rd41, 48;
	add.s64 	%rd554, %rd508, %rd553;
	add.s64 	%rd545, %rd554, 80;
	// inline asm
	cvta.to.global.u64 %rd544, %rd545;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd544];
	// inline asm
	mov.b32 	 %f1594, %r631;
	mov.b32 	 %f1595, %r632;
	mov.b32 	 %f1596, %r633;
	add.s64 	%rd548, %rd554, 96;
	// inline asm
	cvta.to.global.u64 %rd547, %rd548;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd547];
	// inline asm
	mov.b32 	 %f1597, %r635;
	mov.b32 	 %f1598, %r636;
	mov.b32 	 %f1599, %r637;
	add.s64 	%rd551, %rd554, 112;
	// inline asm
	cvta.to.global.u64 %rd550, %rd551;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd550];
	// inline asm
	mov.f32 	%f1600, 0f3F800000;
	sub.f32 	%f1601, %f1600, %f565;
	mul.f32 	%f1602, %f565, %f1594;
	mul.f32 	%f1603, %f565, %f1595;
	mul.f32 	%f1604, %f565, %f1596;
	fma.rn.f32 	%f1991, %f1601, %f1991, %f1602;
	fma.rn.f32 	%f1992, %f1601, %f1992, %f1603;
	fma.rn.f32 	%f1993, %f1601, %f1993, %f1604;
	mul.f32 	%f1605, %f565, %f1597;
	mul.f32 	%f1606, %f565, %f1598;
	mul.f32 	%f1607, %f565, %f1599;
	fma.rn.f32 	%f1988, %f1601, %f1988, %f1605;
	fma.rn.f32 	%f1989, %f1601, %f1989, %f1606;
	fma.rn.f32 	%f1990, %f1601, %f1990, %f1607;
	mov.b32 	 %f1608, %r639;
	mov.b32 	 %f1609, %r640;
	mov.b32 	 %f1610, %r641;
	mul.f32 	%f1611, %f565, %f1608;
	mul.f32 	%f1612, %f565, %f1609;
	mul.f32 	%f1613, %f565, %f1610;
	fma.rn.f32 	%f1985, %f1601, %f1985, %f1611;
	fma.rn.f32 	%f1986, %f1601, %f1986, %f1612;
	fma.rn.f32 	%f1987, %f1601, %f1987, %f1613;
	bra.uni 	BB1_87;

BB1_76:
	mov.f32 	%f1994, 0f00000000;
	mov.f32 	%f1996, 0f3F800000;
	setp.eq.s32	%p48, %r495, 4;
	@%p48 bra 	BB1_79;
	bra.uni 	BB1_77;

BB1_79:
	// inline asm
	call (%rd664), _optix_get_instance_inverse_transform_from_handle, (%rd434);
	// inline asm
	bra.uni 	BB1_80;

BB1_82:
	// inline asm
	call (%rd449), _optix_get_srt_motion_transform_from_handle, (%rd434);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd451, %rd449;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd451];
	// inline asm
	mov.b32	{%rs15, %rs16}, %r511;
	add.s64 	%rd455, %rd449, 16;
	// inline asm
	cvta.to.global.u64 %rd454, %rd455;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd454];
	// inline asm
	add.s64 	%rd458, %rd449, 32;
	// inline asm
	cvta.to.global.u64 %rd457, %rd458;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd457];
	// inline asm
	add.s64 	%rd461, %rd449, 48;
	// inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd460];
	// inline asm
	add.s64 	%rd464, %rd449, 64;
	// inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd463];
	// inline asm
	add.s64 	%rd467, %rd449, 80;
	// inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd466];
	// inline asm
	add.s64 	%rd470, %rd449, 96;
	// inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd469];
	// inline asm
	add.s64 	%rd473, %rd449, 112;
	// inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd472];
	// inline asm
	add.s64 	%rd476, %rd449, 128;
	// inline asm
	cvta.to.global.u64 %rd475, %rd476;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd475];
	// inline asm
	add.s64 	%rd479, %rd449, 144;
	// inline asm
	cvta.to.global.u64 %rd478, %rd479;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd478];
	// inline asm
	mov.b32 	 %f1491, %r512;
	mov.b32 	 %f1492, %r513;
	cvt.u32.u16	%r565, %rs15;
	add.s32 	%r566, %r565, -1;
	cvt.rn.f32.s32	%f1493, %r566;
	sub.f32 	%f1494, %f946, %f1491;
	mul.f32 	%f1495, %f1494, %f1493;
	sub.f32 	%f1496, %f1492, %f1491;
	div.rn.f32 	%f1497, %f1495, %f1496;
	min.f32 	%f1498, %f1493, %f1497;
	mov.f32 	%f1499, 0f00000000;
	max.f32 	%f1500, %f1499, %f1498;
	cvt.rmi.f32.f32	%f1501, %f1500;
	cvt.rzi.s32.f32	%r567, %f1501;
	cvt.s64.s32	%rd39, %r567;
	mul.wide.s32 	%rd493, %r567, 64;
	add.s64 	%rd482, %rd458, %rd493;
	// inline asm
	cvta.to.global.u64 %rd481, %rd482;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd481];
	// inline asm
	mov.b32 	 %f1975, %r549;
	mov.b32 	 %f1976, %r550;
	mov.b32 	 %f1977, %r551;
	add.s64 	%rd485, %rd482, 16;
	// inline asm
	cvta.to.global.u64 %rd484, %rd485;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd484];
	// inline asm
	mov.b32 	 %f1978, %r553;
	mov.b32 	 %f1979, %r554;
	mov.b32 	 %f1980, %r556;
	add.s64 	%rd488, %rd482, 32;
	// inline asm
	cvta.to.global.u64 %rd487, %rd488;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd487];
	// inline asm
	sub.f32 	%f525, %f1500, %f1501;
	mov.b32 	 %f1981, %r558;
	mov.b32 	 %f1982, %r559;
	mov.b32 	 %f1983, %r560;
	add.s64 	%rd491, %rd482, 48;
	// inline asm
	cvta.to.global.u64 %rd490, %rd491;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r561,%r562,%r563,%r564}, [%rd490];
	// inline asm
	mov.b32 	 %f1984, %r561;
	setp.leu.f32	%p51, %f525, 0f00000000;
	@%p51 bra 	BB1_84;

	shl.b64 	%rd506, %rd39, 6;
	add.s64 	%rd507, %rd506, %rd449;
	add.s64 	%rd495, %rd507, 96;
	// inline asm
	cvta.to.global.u64 %rd494, %rd495;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd494];
	// inline asm
	mov.b32 	 %f1502, %r568;
	mov.b32 	 %f1503, %r569;
	mov.b32 	 %f1504, %r570;
	add.s64 	%rd498, %rd507, 112;
	// inline asm
	cvta.to.global.u64 %rd497, %rd498;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd497];
	// inline asm
	mov.b32 	 %f1505, %r572;
	mov.b32 	 %f1506, %r573;
	mov.b32 	 %f1507, %r575;
	add.s64 	%rd501, %rd507, 128;
	// inline asm
	cvta.to.global.u64 %rd500, %rd501;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd500];
	// inline asm
	mov.b32 	 %f1508, %r577;
	mov.b32 	 %f1509, %r578;
	mov.b32 	 %f1510, %r579;
	add.s64 	%rd504, %rd507, 144;
	// inline asm
	cvta.to.global.u64 %rd503, %rd504;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd503];
	// inline asm
	mov.f32 	%f1511, 0f3F800000;
	sub.f32 	%f1512, %f1511, %f525;
	mul.f32 	%f1513, %f525, %f1502;
	mul.f32 	%f1514, %f525, %f1503;
	mul.f32 	%f1515, %f525, %f1504;
	fma.rn.f32 	%f1975, %f1512, %f1975, %f1513;
	fma.rn.f32 	%f1976, %f1512, %f1976, %f1514;
	fma.rn.f32 	%f1977, %f1512, %f1977, %f1515;
	mul.f32 	%f1516, %f525, %f1505;
	mul.f32 	%f1517, %f525, %f1506;
	mul.f32 	%f1518, %f525, %f1507;
	fma.rn.f32 	%f1978, %f1512, %f1978, %f1516;
	fma.rn.f32 	%f1979, %f1512, %f1979, %f1517;
	fma.rn.f32 	%f1980, %f1512, %f1980, %f1518;
	mul.f32 	%f1519, %f525, %f1508;
	mul.f32 	%f1520, %f525, %f1509;
	mul.f32 	%f1521, %f525, %f1510;
	fma.rn.f32 	%f1522, %f1512, %f1981, %f1519;
	fma.rn.f32 	%f1523, %f1512, %f1982, %f1520;
	fma.rn.f32 	%f1524, %f1512, %f1983, %f1521;
	mov.b32 	 %f1525, %r580;
	mul.f32 	%f1526, %f525, %f1525;
	fma.rn.f32 	%f1527, %f1512, %f1984, %f1526;
	mul.f32 	%f1528, %f1523, %f1523;
	fma.rn.f32 	%f1529, %f1522, %f1522, %f1528;
	fma.rn.f32 	%f1530, %f1524, %f1524, %f1529;
	fma.rn.f32 	%f1531, %f1527, %f1527, %f1530;
	sqrt.rn.f32 	%f1532, %f1531;
	rcp.rn.f32 	%f1533, %f1532;
	mul.f32 	%f1981, %f1522, %f1533;
	mul.f32 	%f1982, %f1523, %f1533;
	mul.f32 	%f1983, %f1524, %f1533;
	mul.f32 	%f1984, %f1527, %f1533;

BB1_84:
	mul.f32 	%f1534, %f1982, %f1982;
	fma.rn.f32 	%f1535, %f1981, %f1981, %f1534;
	fma.rn.f32 	%f1536, %f1983, %f1983, %f1535;
	fma.rn.f32 	%f1537, %f1984, %f1984, %f1536;
	rcp.rn.f32 	%f1538, %f1537;
	mul.f32 	%f1539, %f1981, %f1538;
	mul.f32 	%f1540, %f1982, %f1538;
	mul.f32 	%f1541, %f1983, %f1538;
	mul.f32 	%f1542, %f1984, %f1538;
	mul.f32 	%f1543, %f1981, %f1539;
	mul.f32 	%f1544, %f1982, %f1540;
	mul.f32 	%f1545, %f1983, %f1541;
	mul.f32 	%f1546, %f1981, %f1540;
	mul.f32 	%f1547, %f1983, %f1542;
	mul.f32 	%f1548, %f1981, %f1541;
	mul.f32 	%f1549, %f1982, %f1542;
	mul.f32 	%f1550, %f1982, %f1541;
	mul.f32 	%f1551, %f1981, %f1542;
	sub.f32 	%f1552, %f1543, %f1544;
	sub.f32 	%f1553, %f1552, %f1545;
	fma.rn.f32 	%f1554, %f1984, %f1542, %f1553;
	sub.f32 	%f1555, %f1546, %f1547;
	add.f32 	%f1556, %f1555, %f1555;
	add.f32 	%f1557, %f1548, %f1549;
	add.f32 	%f1558, %f1557, %f1557;
	add.f32 	%f1559, %f1546, %f1547;
	add.f32 	%f1560, %f1559, %f1559;
	sub.f32 	%f1561, %f1544, %f1543;
	sub.f32 	%f1562, %f1561, %f1545;
	fma.rn.f32 	%f1563, %f1984, %f1542, %f1562;
	sub.f32 	%f1564, %f1550, %f1551;
	add.f32 	%f1565, %f1564, %f1564;
	sub.f32 	%f1566, %f1548, %f1549;
	add.f32 	%f1567, %f1566, %f1566;
	add.f32 	%f1568, %f1550, %f1551;
	add.f32 	%f1569, %f1568, %f1568;
	neg.f32 	%f1570, %f1543;
	sub.f32 	%f1571, %f1570, %f1544;
	add.f32 	%f1572, %f1545, %f1571;
	fma.rn.f32 	%f1573, %f1984, %f1542, %f1572;
	mul.f32 	%f1574, %f1977, %f1554;
	fma.rn.f32 	%f1575, %f1979, %f1556, %f1574;
	fma.rn.f32 	%f1993, %f1980, %f1558, %f1575;
	mul.f32 	%f1576, %f1979, %f1563;
	fma.rn.f32 	%f1577, %f1977, %f1560, %f1576;
	fma.rn.f32 	%f1990, %f1980, %f1565, %f1577;
	mul.f32 	%f1578, %f1979, %f1569;
	fma.rn.f32 	%f1579, %f1977, %f1567, %f1578;
	fma.rn.f32 	%f1987, %f1980, %f1573, %f1579;
	mul.f32 	%f1580, %f1976, %f1554;
	fma.rn.f32 	%f1992, %f1978, %f1556, %f1580;
	mul.f32 	%f1581, %f1978, %f1563;
	fma.rn.f32 	%f1989, %f1976, %f1560, %f1581;
	mul.f32 	%f1582, %f1978, %f1569;
	fma.rn.f32 	%f1986, %f1976, %f1567, %f1582;
	mul.f32 	%f1991, %f1975, %f1554;
	mul.f32 	%f1988, %f1975, %f1560;
	mul.f32 	%f1985, %f1975, %f1567;

BB1_87:
	mul.f32 	%f1614, %f1986, %f1990;
	mul.f32 	%f1615, %f1987, %f1989;
	sub.f32 	%f1616, %f1615, %f1614;
	mul.f32 	%f1617, %f1991, %f1616;
	mul.f32 	%f1618, %f1985, %f1990;
	mul.f32 	%f1619, %f1987, %f1988;
	sub.f32 	%f1620, %f1619, %f1618;
	mul.f32 	%f1621, %f1620, %f1992;
	sub.f32 	%f1622, %f1617, %f1621;
	mul.f32 	%f1623, %f1985, %f1989;
	mul.f32 	%f1624, %f1986, %f1988;
	sub.f32 	%f1625, %f1624, %f1623;
	fma.rn.f32 	%f1626, %f1625, %f1993, %f1622;
	rcp.rn.f32 	%f1627, %f1626;
	mul.f32 	%f2000, %f1616, %f1627;
	mul.f32 	%f1628, %f1987, %f1992;
	mul.f32 	%f1629, %f1986, %f1993;
	sub.f32 	%f1630, %f1629, %f1628;
	mul.f32 	%f2001, %f1627, %f1630;
	mul.f32 	%f1631, %f1989, %f1993;
	mul.f32 	%f1632, %f1990, %f1992;
	sub.f32 	%f1633, %f1632, %f1631;
	mul.f32 	%f2002, %f1627, %f1633;
	sub.f32 	%f1634, %f1618, %f1619;
	mul.f32 	%f1997, %f1634, %f1627;
	mul.f32 	%f1635, %f1985, %f1993;
	mul.f32 	%f1636, %f1987, %f1991;
	sub.f32 	%f1637, %f1636, %f1635;
	mul.f32 	%f1998, %f1627, %f1637;
	mul.f32 	%f1638, %f1990, %f1991;
	mul.f32 	%f1639, %f1988, %f1993;
	sub.f32 	%f1640, %f1639, %f1638;
	mul.f32 	%f1999, %f1627, %f1640;
	mul.f32 	%f1994, %f1625, %f1627;
	mul.f32 	%f1641, %f1986, %f1991;
	mul.f32 	%f1642, %f1985, %f1992;
	sub.f32 	%f1643, %f1642, %f1641;
	mul.f32 	%f1995, %f1643, %f1627;
	mul.f32 	%f1644, %f1988, %f1992;
	mul.f32 	%f1645, %f1989, %f1991;
	sub.f32 	%f1646, %f1645, %f1644;
	mul.f32 	%f1996, %f1646, %f1627;
	bra.uni 	BB1_88;

BB1_77:
	setp.ne.s32	%p49, %r495, 1;
	mov.f32 	%f1995, %f1994;
	mov.f32 	%f1997, %f1994;
	mov.f32 	%f1998, %f1996;
	mov.f32 	%f1999, %f1994;
	mov.f32 	%f2000, %f1996;
	mov.f32 	%f2001, %f1994;
	mov.f32 	%f2002, %f1994;
	@%p49 bra 	BB1_88;

	// inline asm
	call (%rd436), _optix_get_static_transform_from_handle, (%rd434);
	// inline asm
	add.s64 	%rd664, %rd436, 64;

BB1_80:
	// inline asm
	cvta.to.global.u64 %rd440, %rd664;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd440];
	// inline asm
	mov.b32 	 %f2000, %r497;
	mov.b32 	 %f2001, %r498;
	mov.b32 	 %f2002, %r499;
	add.s64 	%rd444, %rd664, 16;
	// inline asm
	cvta.to.global.u64 %rd443, %rd444;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd443];
	// inline asm
	mov.b32 	 %f1997, %r501;
	mov.b32 	 %f1998, %r502;
	mov.b32 	 %f1999, %r503;
	add.s64 	%rd447, %rd664, 32;
	// inline asm
	cvta.to.global.u64 %rd446, %rd447;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd446];
	// inline asm
	mov.b32 	 %f1994, %r505;
	mov.b32 	 %f1995, %r506;
	mov.b32 	 %f1996, %r507;

BB1_88:
	setp.eq.s32	%p53, %r649, 0;
	@%p53 bra 	BB1_89;
	bra.uni 	BB1_90;

BB1_89:
	mov.f32 	%f1974, %f1994;
	mov.f32 	%f1973, %f1995;
	mov.f32 	%f1972, %f1996;
	mov.f32 	%f1971, %f1997;
	mov.f32 	%f1970, %f1998;
	mov.f32 	%f1969, %f1999;
	mov.f32 	%f1968, %f2000;
	mov.f32 	%f1967, %f2001;
	mov.f32 	%f1966, %f2002;
	bra.uni 	BB1_91;

BB1_90:
	mul.f32 	%f1647, %f1971, %f2001;
	fma.rn.f32 	%f1648, %f1968, %f2000, %f1647;
	fma.rn.f32 	%f605, %f1974, %f2002, %f1648;
	mul.f32 	%f1649, %f1970, %f2001;
	fma.rn.f32 	%f1650, %f1967, %f2000, %f1649;
	fma.rn.f32 	%f606, %f1973, %f2002, %f1650;
	mul.f32 	%f1651, %f1969, %f2001;
	fma.rn.f32 	%f1652, %f1966, %f2000, %f1651;
	fma.rn.f32 	%f607, %f1972, %f2002, %f1652;
	mul.f32 	%f1653, %f1971, %f1998;
	fma.rn.f32 	%f1654, %f1968, %f1997, %f1653;
	fma.rn.f32 	%f608, %f1974, %f1999, %f1654;
	mul.f32 	%f1655, %f1970, %f1998;
	fma.rn.f32 	%f1656, %f1967, %f1997, %f1655;
	fma.rn.f32 	%f609, %f1973, %f1999, %f1656;
	mul.f32 	%f1657, %f1969, %f1998;
	fma.rn.f32 	%f1658, %f1966, %f1997, %f1657;
	fma.rn.f32 	%f610, %f1972, %f1999, %f1658;
	mul.f32 	%f1659, %f1971, %f1995;
	fma.rn.f32 	%f1660, %f1968, %f1994, %f1659;
	fma.rn.f32 	%f1974, %f1974, %f1996, %f1660;
	mul.f32 	%f1661, %f1970, %f1995;
	fma.rn.f32 	%f1662, %f1967, %f1994, %f1661;
	fma.rn.f32 	%f1973, %f1973, %f1996, %f1662;
	mul.f32 	%f1663, %f1969, %f1995;
	fma.rn.f32 	%f1664, %f1966, %f1994, %f1663;
	fma.rn.f32 	%f1972, %f1972, %f1996, %f1664;
	mov.f32 	%f1971, %f608;
	mov.f32 	%f1970, %f609;
	mov.f32 	%f1969, %f610;
	mov.f32 	%f1968, %f605;
	mov.f32 	%f1967, %f606;
	mov.f32 	%f1966, %f607;

BB1_91:
	add.s32 	%r649, %r649, 1;
	setp.lt.u32	%p54, %r649, %r30;
	@%p54 bra 	BB1_75;

BB1_92:
	fma.rn.f32 	%f1665, %f2057, %f1905, %f1902;
	fma.rn.f32 	%f1666, %f2058, %f1904, %f1665;
	fma.rn.f32 	%f1667, %f2057, %f1909, %f1906;
	fma.rn.f32 	%f1668, %f2058, %f1908, %f1667;
	fma.rn.f32 	%f1669, %f2057, %f1913, %f1910;
	fma.rn.f32 	%f1670, %f2058, %f1912, %f1669;
	fma.rn.f32 	%f2057, %f2059, %f1903, %f1666;
	fma.rn.f32 	%f2058, %f2059, %f1907, %f1668;
	fma.rn.f32 	%f2059, %f2059, %f1911, %f1670;
	ld.const.u64 	%rd555, [params+112];
	setp.eq.s64	%p55, %rd555, 0;
	mov.f32 	%f2051, %f2054;
	mov.f32 	%f2052, %f2055;
	mov.f32 	%f2053, %f2056;
	@%p55 bra 	BB1_94;

	mul.f32 	%f1671, %f2054, %f1968;
	fma.rn.f32 	%f1672, %f2055, %f1971, %f1671;
	mul.f32 	%f1673, %f2054, %f1967;
	fma.rn.f32 	%f1674, %f2055, %f1970, %f1673;
	mul.f32 	%f1675, %f2054, %f1966;
	fma.rn.f32 	%f1676, %f2055, %f1969, %f1675;
	fma.rn.f32 	%f1677, %f2056, %f1974, %f1672;
	fma.rn.f32 	%f1678, %f2056, %f1973, %f1674;
	fma.rn.f32 	%f1679, %f2056, %f1972, %f1676;
	mul.f32 	%f1680, %f1677, %f1677;
	fma.rn.f32 	%f1681, %f1678, %f1678, %f1680;
	fma.rn.f32 	%f1682, %f1679, %f1679, %f1681;
	sqrt.rn.f32 	%f1683, %f1682;
	div.rn.f32 	%f2051, %f1677, %f1683;
	div.rn.f32 	%f2052, %f1678, %f1683;
	div.rn.f32 	%f2053, %f1679, %f1683;

BB1_94:
	ld.const.u64 	%rd556, [params+136];
	setp.eq.s64	%p56, %rd556, 0;
	@%p56 bra 	BB1_96;

	mul.f32 	%f1684, %f2054, %f1968;
	fma.rn.f32 	%f1685, %f2055, %f1971, %f1684;
	mul.f32 	%f1686, %f2054, %f1967;
	fma.rn.f32 	%f1687, %f2055, %f1970, %f1686;
	mul.f32 	%f1688, %f2054, %f1966;
	fma.rn.f32 	%f1689, %f2055, %f1969, %f1688;
	fma.rn.f32 	%f1690, %f2056, %f1974, %f1685;
	fma.rn.f32 	%f1691, %f2056, %f1973, %f1687;
	fma.rn.f32 	%f1692, %f2056, %f1972, %f1689;
	mul.f32 	%f1693, %f1690, %f1690;
	fma.rn.f32 	%f1694, %f1691, %f1691, %f1693;
	fma.rn.f32 	%f1695, %f1692, %f1692, %f1694;
	sqrt.rn.f32 	%f1696, %f1695;
	div.rn.f32 	%f2054, %f1690, %f1696;
	div.rn.f32 	%f2055, %f1691, %f1696;
	div.rn.f32 	%f2056, %f1692, %f1696;

BB1_96:
	ld.const.u64 	%rd557, [params+184];
	setp.eq.s64	%p57, %rd557, 0;
	@%p57 bra 	BB1_98;

	mul.f32 	%f1697, %f2048, %f1905;
	fma.rn.f32 	%f1698, %f2049, %f1904, %f1697;
	mul.f32 	%f1699, %f2048, %f1909;
	fma.rn.f32 	%f1700, %f2049, %f1908, %f1699;
	mul.f32 	%f1701, %f2048, %f1913;
	fma.rn.f32 	%f1702, %f2049, %f1912, %f1701;
	fma.rn.f32 	%f2048, %f2050, %f1903, %f1698;
	fma.rn.f32 	%f2049, %f2050, %f1907, %f1700;
	fma.rn.f32 	%f2050, %f2050, %f1911, %f1702;
	mul.f32 	%f1703, %f2045, %f1905;
	fma.rn.f32 	%f1704, %f2046, %f1904, %f1703;
	mul.f32 	%f1705, %f2045, %f1909;
	fma.rn.f32 	%f1706, %f2046, %f1908, %f1705;
	mul.f32 	%f1707, %f2045, %f1913;
	fma.rn.f32 	%f1708, %f2046, %f1912, %f1707;
	fma.rn.f32 	%f2045, %f2047, %f1903, %f1704;
	fma.rn.f32 	%f2046, %f2047, %f1907, %f1706;
	fma.rn.f32 	%f2047, %f2047, %f1911, %f1708;

BB1_98:
	ld.const.u64 	%rd558, [params+280];
	ld.const.u64 	%rd559, [params+232];
	mov.f32 	%f2039, 0f00000000;
	or.b64  	%rd560, %rd558, %rd559;
	setp.eq.s64	%p58, %rd560, 0;
	@%p58 bra 	BB1_99;

	mul.f32 	%f1712, %f2054, %f1905;
	fma.rn.f32 	%f1713, %f2055, %f1909, %f1712;
	mul.f32 	%f1714, %f2054, %f1904;
	fma.rn.f32 	%f1715, %f2055, %f1908, %f1714;
	mul.f32 	%f1716, %f2054, %f1903;
	fma.rn.f32 	%f1717, %f2055, %f1907, %f1716;
	fma.rn.f32 	%f1718, %f2056, %f1913, %f1713;
	fma.rn.f32 	%f1719, %f2056, %f1912, %f1715;
	fma.rn.f32 	%f1720, %f2056, %f1911, %f1717;
	mul.f32 	%f1721, %f1718, %f1718;
	fma.rn.f32 	%f1722, %f1719, %f1719, %f1721;
	fma.rn.f32 	%f1723, %f1720, %f1720, %f1722;
	sqrt.rn.f32 	%f1724, %f1723;
	div.rn.f32 	%f1725, %f1718, %f1724;
	div.rn.f32 	%f1726, %f1719, %f1724;
	div.rn.f32 	%f1727, %f1720, %f1724;
	mul.f32 	%f1728, %f1725, %f1968;
	mul.f32 	%f1729, %f1725, %f1967;
	mul.f32 	%f1730, %f1725, %f1966;
	fma.rn.f32 	%f1731, %f1726, %f1971, %f1728;
	fma.rn.f32 	%f1732, %f1726, %f1970, %f1729;
	fma.rn.f32 	%f1733, %f1726, %f1969, %f1730;
	fma.rn.f32 	%f1734, %f1727, %f1974, %f1731;
	fma.rn.f32 	%f1735, %f1727, %f1973, %f1732;
	fma.rn.f32 	%f1736, %f1727, %f1972, %f1733;
	mul.f32 	%f1737, %f1734, %f1734;
	fma.rn.f32 	%f1738, %f1735, %f1735, %f1737;
	fma.rn.f32 	%f1739, %f1736, %f1736, %f1738;
	sqrt.rn.f32 	%f1740, %f1739;
	rcp.rn.f32 	%f1741, %f1740;
	mul.f32 	%f1742, %f1741, %f1734;
	mul.f32 	%f1743, %f1741, %f1735;
	mul.f32 	%f1744, %f1741, %f1736;
	mul.f32 	%f1745, %f2042, %f1968;
	fma.rn.f32 	%f1746, %f2043, %f1971, %f1745;
	mul.f32 	%f1747, %f2042, %f1967;
	fma.rn.f32 	%f1748, %f2043, %f1970, %f1747;
	mul.f32 	%f1749, %f2042, %f1966;
	fma.rn.f32 	%f1750, %f2043, %f1969, %f1749;
	fma.rn.f32 	%f1751, %f2044, %f1974, %f1746;
	fma.rn.f32 	%f1752, %f2044, %f1973, %f1748;
	fma.rn.f32 	%f1753, %f2044, %f1972, %f1750;
	mul.f32 	%f1754, %f1751, %f1741;
	mul.f32 	%f1755, %f1752, %f1741;
	mul.f32 	%f1756, %f1753, %f1741;
	mul.f32 	%f1757, %f1968, 0f00000000;
	mov.f32 	%f1758, 0f00000000;
	fma.rn.f32 	%f1759, %f1758, %f1971, %f1757;
	mul.f32 	%f1760, %f1967, 0f00000000;
	fma.rn.f32 	%f1761, %f1758, %f1970, %f1760;
	mul.f32 	%f1762, %f1966, 0f00000000;
	fma.rn.f32 	%f1763, %f1758, %f1969, %f1762;
	fma.rn.f32 	%f1764, %f1758, %f1974, %f1759;
	fma.rn.f32 	%f1765, %f1758, %f1973, %f1761;
	fma.rn.f32 	%f1766, %f1758, %f1972, %f1763;
	mul.f32 	%f1767, %f1764, %f1741;
	mul.f32 	%f1768, %f1765, %f1741;
	mul.f32 	%f1769, %f1766, %f1741;
	mul.f32 	%f1770, %f1742, %f1754;
	fma.rn.f32 	%f1771, %f1743, %f1755, %f1770;
	fma.rn.f32 	%f1772, %f1744, %f1756, %f1771;
	mul.f32 	%f1773, %f1742, %f1772;
	mul.f32 	%f1774, %f1743, %f1772;
	mul.f32 	%f1775, %f1744, %f1772;
	sub.f32 	%f2042, %f1754, %f1773;
	sub.f32 	%f2043, %f1755, %f1774;
	sub.f32 	%f2044, %f1756, %f1775;
	mul.f32 	%f1776, %f1742, %f1767;
	fma.rn.f32 	%f1777, %f1743, %f1768, %f1776;
	fma.rn.f32 	%f1778, %f1744, %f1769, %f1777;
	mul.f32 	%f1779, %f1742, %f1778;
	mul.f32 	%f1780, %f1743, %f1778;
	mul.f32 	%f1781, %f1744, %f1778;
	sub.f32 	%f2039, %f1767, %f1779;
	sub.f32 	%f2040, %f1768, %f1780;
	sub.f32 	%f2041, %f1769, %f1781;
	bra.uni 	BB1_101;

BB1_54:
	mov.f32 	%f2040, %f2039;
	mov.f32 	%f2041, %f2039;
	mov.f32 	%f2051, %f2054;
	mov.f32 	%f2052, %f2055;
	mov.f32 	%f2053, %f2056;
	bra.uni 	BB1_102;

BB1_99:
	mov.f32 	%f2040, %f2039;
	mov.f32 	%f2041, %f2039;

BB1_101:
	st.global.u32 	[%rd25], %r343;

BB1_102:
	ld.const.u64 	%rd561, [params+328];
	cvta.to.global.u64 	%rd562, %rd561;
	shl.b64 	%rd563, %rd24, 3;
	add.s64 	%rd564, %rd562, %rd563;
	st.global.u64 	[%rd564], %rd23;
	ld.const.u64 	%rd565, [params+336];
	cvta.to.global.u64 	%rd566, %rd565;
	shl.b64 	%rd567, %rd24, 2;
	add.s64 	%rd568, %rd566, %rd567;
	mov.u32 	%r643, 0;
	st.global.u32 	[%rd568], %r643;
	ld.const.u64 	%rd569, [params+160];
	cvta.to.global.u64 	%rd570, %rd569;
	add.s64 	%rd571, %rd570, %rd567;
	st.global.f32 	[%rd571], %f2057;
	ld.const.u64 	%rd572, [params+168];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd567;
	st.global.f32 	[%rd574], %f2058;
	ld.const.u64 	%rd575, [params+176];
	cvta.to.global.u64 	%rd576, %rd575;
	add.s64 	%rd577, %rd576, %rd567;
	st.global.f32 	[%rd577], %f2059;
	ld.const.u64 	%rd578, [params+72];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd567;
	st.global.f32 	[%rd580], %f1138;
	ld.const.u64 	%rd42, [params+96];
	setp.eq.s64	%p59, %rd42, 0;
	@%p59 bra 	BB1_104;

	cvta.to.global.u64 	%rd581, %rd42;
	add.s64 	%rd583, %rd581, %rd567;
	mul.f32 	%f1782, %f326, 0f3E22F983;
	st.global.f32 	[%rd583], %f1782;
	ld.const.u64 	%rd584, [params+104];
	cvta.to.global.u64 	%rd585, %rd584;
	add.s64 	%rd586, %rd585, %rd567;
	st.global.f32 	[%rd586], %f327;

BB1_104:
	ld.const.u64 	%rd43, [params+112];
	setp.eq.s64	%p60, %rd43, 0;
	@%p60 bra 	BB1_106;

	cvta.to.global.u64 	%rd587, %rd43;
	add.s64 	%rd589, %rd587, %rd567;
	st.global.f32 	[%rd589], %f2051;
	ld.const.u64 	%rd590, [params+120];
	cvta.to.global.u64 	%rd591, %rd590;
	add.s64 	%rd592, %rd591, %rd567;
	st.global.f32 	[%rd592], %f2052;
	ld.const.u64 	%rd593, [params+128];
	cvta.to.global.u64 	%rd594, %rd593;
	add.s64 	%rd595, %rd594, %rd567;
	st.global.f32 	[%rd595], %f2053;

BB1_106:
	ld.const.u64 	%rd44, [params+136];
	setp.eq.s64	%p61, %rd44, 0;
	@%p61 bra 	BB1_108;

	cvta.to.global.u64 	%rd596, %rd44;
	add.s64 	%rd598, %rd596, %rd567;
	st.global.f32 	[%rd598], %f2054;
	ld.const.u64 	%rd599, [params+144];
	cvta.to.global.u64 	%rd600, %rd599;
	add.s64 	%rd601, %rd600, %rd567;
	st.global.f32 	[%rd601], %f2055;
	ld.const.u64 	%rd602, [params+152];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd567;
	st.global.f32 	[%rd604], %f2056;

BB1_108:
	ld.const.u64 	%rd45, [params+184];
	setp.eq.s64	%p62, %rd45, 0;
	@%p62 bra 	BB1_110;

	cvta.to.global.u64 	%rd605, %rd45;
	add.s64 	%rd607, %rd605, %rd567;
	st.global.f32 	[%rd607], %f2048;
	ld.const.u64 	%rd608, [params+192];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd567;
	st.global.f32 	[%rd610], %f2049;
	ld.const.u64 	%rd611, [params+200];
	cvta.to.global.u64 	%rd612, %rd611;
	add.s64 	%rd613, %rd612, %rd567;
	st.global.f32 	[%rd613], %f2050;
	ld.const.u64 	%rd614, [params+208];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd567;
	st.global.f32 	[%rd616], %f2045;
	ld.const.u64 	%rd617, [params+216];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd567;
	st.global.f32 	[%rd619], %f2046;
	ld.const.u64 	%rd620, [params+224];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd567;
	st.global.f32 	[%rd622], %f2047;

BB1_110:
	ld.const.u64 	%rd46, [params+232];
	setp.eq.s64	%p63, %rd46, 0;
	@%p63 bra 	BB1_112;

	cvta.to.global.u64 	%rd623, %rd46;
	add.s64 	%rd625, %rd623, %rd567;
	st.global.f32 	[%rd625], %f2042;
	ld.const.u64 	%rd626, [params+240];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd567;
	st.global.f32 	[%rd628], %f2043;
	ld.const.u64 	%rd629, [params+248];
	cvta.to.global.u64 	%rd630, %rd629;
	add.s64 	%rd631, %rd630, %rd567;
	st.global.f32 	[%rd631], %f2044;
	ld.const.u64 	%rd632, [params+256];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd567;
	st.global.f32 	[%rd634], %f2039;
	ld.const.u64 	%rd635, [params+264];
	cvta.to.global.u64 	%rd636, %rd635;
	add.s64 	%rd637, %rd636, %rd567;
	st.global.f32 	[%rd637], %f2040;
	ld.const.u64 	%rd638, [params+272];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd567;
	st.global.f32 	[%rd640], %f2041;

BB1_112:
	ld.const.u64 	%rd47, [params+280];
	setp.eq.s64	%p64, %rd47, 0;
	@%p64 bra 	BB1_114;

	cvta.to.global.u64 	%rd641, %rd47;
	add.s64 	%rd643, %rd641, %rd567;
	st.global.f32 	[%rd643], %f2042;
	ld.const.u64 	%rd644, [params+288];
	cvta.to.global.u64 	%rd645, %rd644;
	add.s64 	%rd646, %rd645, %rd567;
	st.global.f32 	[%rd646], %f2043;
	ld.const.u64 	%rd647, [params+296];
	cvta.to.global.u64 	%rd648, %rd647;
	add.s64 	%rd649, %rd648, %rd567;
	st.global.f32 	[%rd649], %f2044;
	ld.const.u64 	%rd650, [params+304];
	cvta.to.global.u64 	%rd651, %rd650;
	add.s64 	%rd652, %rd651, %rd567;
	st.global.f32 	[%rd652], %f2039;
	ld.const.u64 	%rd653, [params+312];
	cvta.to.global.u64 	%rd654, %rd653;
	add.s64 	%rd655, %rd654, %rd567;
	st.global.f32 	[%rd655], %f2040;
	ld.const.u64 	%rd656, [params+320];
	cvta.to.global.u64 	%rd657, %rd656;
	add.s64 	%rd658, %rd657, %rd567;
	st.global.f32 	[%rd658], %f2041;

BB1_114:
	ret;
}

	// .globl	__intersection__disk
.visible .entry __intersection__disk(

)
{
	.reg .pred 	%p<21>;
	.reg .b16 	%rs<9>;
	.reg .f32 	%f<932>;
	.reg .b32 	%r<315>;
	.reg .b64 	%rd<265>;


	// inline asm
	call (%rd18), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd1, [%rd18+8];
	// inline asm
	call (%f314), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f315), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f880), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r8), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p1, %r8, 0;
	@%p1 bra 	BB2_1;

	mov.u32 	%r313, 0;
	// inline asm
	call (%f317), _optix_get_ray_time, ();
	// inline asm

BB2_3:
	.pragma "nounroll";
	// inline asm
	call (%rd19), _optix_get_transform_list_handle, (%r313);
	// inline asm
	// inline asm
	call (%r11), _optix_get_transform_type_from_handle, (%rd19);
	// inline asm
	and.b32  	%r12, %r11, -2;
	setp.eq.s32	%p2, %r12, 2;
	@%p2 bra 	BB2_9;
	bra.uni 	BB2_4;

BB2_9:
	setp.eq.s32	%p5, %r11, 2;
	@%p5 bra 	BB2_13;
	bra.uni 	BB2_10;

BB2_13:
	// inline asm
	call (%rd93), _optix_get_matrix_motion_transform_from_handle, (%rd19);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd95, %rd93;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd95];
	// inline asm
	mov.b32	{%rs3, %rs4}, %r102;
	add.s64 	%rd99, %rd93, 16;
	// inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd98];
	// inline asm
	add.s64 	%rd102, %rd93, 32;
	// inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd101];
	// inline asm
	add.s64 	%rd105, %rd93, 48;
	// inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd104];
	// inline asm
	add.s64 	%rd108, %rd93, 64;
	// inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd107];
	// inline asm
	add.s64 	%rd111, %rd93, 80;
	// inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd110];
	// inline asm
	add.s64 	%rd114, %rd93, 96;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd113];
	// inline asm
	add.s64 	%rd117, %rd93, 112;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd116];
	// inline asm
	mov.b32 	 %f444, %r103;
	mov.b32 	 %f445, %r104;
	cvt.u32.u16	%r144, %rs3;
	add.s32 	%r145, %r144, -1;
	cvt.rn.f32.s32	%f446, %r145;
	sub.f32 	%f447, %f317, %f444;
	mul.f32 	%f448, %f447, %f446;
	sub.f32 	%f449, %f445, %f444;
	div.rn.f32 	%f450, %f448, %f449;
	min.f32 	%f451, %f446, %f450;
	mov.f32 	%f452, 0f00000000;
	max.f32 	%f453, %f452, %f451;
	cvt.rmi.f32.f32	%f454, %f453;
	cvt.rzi.s32.f32	%r146, %f454;
	mul.wide.s32 	%rd128, %r146, 48;
	add.s64 	%rd120, %rd102, %rd128;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd119];
	// inline asm
	mov.b32 	 %f852, %r132;
	mov.b32 	 %f853, %r133;
	mov.b32 	 %f854, %r134;
	mov.b32 	 %f855, %r135;
	add.s64 	%rd123, %rd120, 16;
	// inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd122];
	// inline asm
	mov.b32 	 %f848, %r136;
	mov.b32 	 %f849, %r137;
	mov.b32 	 %f850, %r138;
	mov.b32 	 %f851, %r139;
	add.s64 	%rd126, %rd120, 32;
	// inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd125];
	// inline asm
	sub.f32 	%f98, %f453, %f454;
	mov.b32 	 %f844, %r140;
	mov.b32 	 %f845, %r141;
	mov.b32 	 %f846, %r142;
	mov.b32 	 %f847, %r143;
	setp.leu.f32	%p7, %f98, 0f00000000;
	@%p7 bra 	BB2_15;

	cvt.rmi.f32.f32	%f815, %f453;
	cvt.rzi.s32.f32	%r312, %f815;
	cvt.s64.s32	%rd262, %r312;
	mul.lo.s64 	%rd138, %rd262, 48;
	add.s64 	%rd139, %rd93, %rd138;
	add.s64 	%rd130, %rd139, 80;
	// inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd129];
	// inline asm
	mov.b32 	 %f455, %r147;
	mov.b32 	 %f456, %r148;
	mov.b32 	 %f457, %r149;
	mov.b32 	 %f458, %r150;
	add.s64 	%rd133, %rd139, 96;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd132];
	// inline asm
	mov.b32 	 %f459, %r151;
	mov.b32 	 %f460, %r152;
	mov.b32 	 %f461, %r153;
	mov.b32 	 %f462, %r154;
	add.s64 	%rd136, %rd139, 112;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd135];
	// inline asm
	mov.f32 	%f463, 0f3F800000;
	sub.f32 	%f464, %f463, %f98;
	mul.f32 	%f465, %f98, %f455;
	mul.f32 	%f466, %f98, %f456;
	mul.f32 	%f467, %f98, %f457;
	mul.f32 	%f468, %f98, %f458;
	fma.rn.f32 	%f852, %f464, %f852, %f465;
	fma.rn.f32 	%f853, %f464, %f853, %f466;
	fma.rn.f32 	%f854, %f464, %f854, %f467;
	fma.rn.f32 	%f855, %f464, %f855, %f468;
	mul.f32 	%f469, %f98, %f459;
	mul.f32 	%f470, %f98, %f460;
	mul.f32 	%f471, %f98, %f461;
	mul.f32 	%f472, %f98, %f462;
	fma.rn.f32 	%f848, %f464, %f848, %f469;
	fma.rn.f32 	%f849, %f464, %f849, %f470;
	fma.rn.f32 	%f850, %f464, %f850, %f471;
	fma.rn.f32 	%f851, %f464, %f851, %f472;
	mov.b32 	 %f473, %r155;
	mov.b32 	 %f474, %r156;
	mov.b32 	 %f475, %r157;
	mov.b32 	 %f476, %r158;
	mul.f32 	%f477, %f98, %f473;
	mul.f32 	%f478, %f98, %f474;
	mul.f32 	%f479, %f98, %f475;
	mul.f32 	%f480, %f98, %f476;
	fma.rn.f32 	%f844, %f464, %f844, %f477;
	fma.rn.f32 	%f845, %f464, %f845, %f478;
	fma.rn.f32 	%f846, %f464, %f846, %f479;
	fma.rn.f32 	%f847, %f464, %f847, %f480;
	bra.uni 	BB2_15;

BB2_4:
	mov.f32 	%f856, 0f00000000;
	mov.f32 	%f858, 0f3F800000;
	setp.eq.s32	%p3, %r11, 4;
	@%p3 bra 	BB2_7;
	bra.uni 	BB2_5;

BB2_7:
	// inline asm
	call (%rd263), _optix_get_instance_inverse_transform_from_handle, (%rd19);
	// inline asm
	bra.uni 	BB2_8;

BB2_10:
	// inline asm
	call (%rd34), _optix_get_srt_motion_transform_from_handle, (%rd19);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd36, %rd34;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r25,%r26,%r27,%r28}, [%rd36];
	// inline asm
	mov.b32	{%rs1, %rs2}, %r27;
	add.s64 	%rd40, %rd34, 16;
	// inline asm
	cvta.to.global.u64 %rd39, %rd40;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r29,%r30,%r31,%r32}, [%rd39];
	// inline asm
	add.s64 	%rd43, %rd34, 32;
	// inline asm
	cvta.to.global.u64 %rd42, %rd43;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd42];
	// inline asm
	add.s64 	%rd46, %rd34, 48;
	// inline asm
	cvta.to.global.u64 %rd45, %rd46;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd45];
	// inline asm
	add.s64 	%rd49, %rd34, 64;
	// inline asm
	cvta.to.global.u64 %rd48, %rd49;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd48];
	// inline asm
	add.s64 	%rd52, %rd34, 80;
	// inline asm
	cvta.to.global.u64 %rd51, %rd52;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd51];
	// inline asm
	add.s64 	%rd55, %rd34, 96;
	// inline asm
	cvta.to.global.u64 %rd54, %rd55;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd54];
	// inline asm
	add.s64 	%rd58, %rd34, 112;
	// inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd57];
	// inline asm
	add.s64 	%rd61, %rd34, 128;
	// inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd60];
	// inline asm
	add.s64 	%rd64, %rd34, 144;
	// inline asm
	cvta.to.global.u64 %rd63, %rd64;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd63];
	// inline asm
	mov.b32 	 %f331, %r28;
	mov.b32 	 %f332, %r29;
	cvt.u32.u16	%r81, %rs1;
	add.s32 	%r82, %r81, -1;
	cvt.rn.f32.s32	%f333, %r82;
	sub.f32 	%f334, %f317, %f331;
	mul.f32 	%f335, %f334, %f333;
	sub.f32 	%f336, %f332, %f331;
	div.rn.f32 	%f337, %f335, %f336;
	min.f32 	%f338, %f333, %f337;
	mov.f32 	%f339, 0f00000000;
	max.f32 	%f340, %f339, %f338;
	cvt.rmi.f32.f32	%f341, %f340;
	cvt.rzi.s32.f32	%r83, %f341;
	mul.wide.s32 	%rd78, %r83, 64;
	add.s64 	%rd67, %rd43, %rd78;
	// inline asm
	cvta.to.global.u64 %rd66, %rd67;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd66];
	// inline asm
	mov.b32 	 %f828, %r65;
	mov.b32 	 %f829, %r66;
	mov.b32 	 %f830, %r67;
	mov.b32 	 %f831, %r68;
	add.s64 	%rd70, %rd67, 16;
	// inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd69];
	// inline asm
	mov.b32 	 %f832, %r69;
	mov.b32 	 %f833, %r70;
	mov.b32 	 %f834, %r71;
	mov.b32 	 %f835, %r72;
	add.s64 	%rd73, %rd67, 32;
	// inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd72];
	// inline asm
	sub.f32 	%f37, %f340, %f341;
	mov.b32 	 %f836, %r73;
	mov.b32 	 %f837, %r74;
	mov.b32 	 %f838, %r75;
	mov.b32 	 %f839, %r76;
	add.s64 	%rd76, %rd67, 48;
	// inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd75];
	// inline asm
	mov.b32 	 %f840, %r77;
	mov.b32 	 %f841, %r78;
	mov.b32 	 %f842, %r79;
	mov.b32 	 %f843, %r80;
	setp.leu.f32	%p6, %f37, 0f00000000;
	@%p6 bra 	BB2_12;

	cvt.rmi.f32.f32	%f814, %f340;
	cvt.rzi.s32.f32	%r311, %f814;
	cvt.s64.s32	%rd261, %r311;
	shl.b64 	%rd91, %rd261, 6;
	add.s64 	%rd92, %rd91, %rd34;
	add.s64 	%rd80, %rd92, 96;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd79];
	// inline asm
	mov.b32 	 %f342, %r84;
	mov.b32 	 %f343, %r85;
	mov.b32 	 %f344, %r86;
	mov.b32 	 %f345, %r87;
	add.s64 	%rd83, %rd92, 112;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd82];
	// inline asm
	mov.b32 	 %f346, %r88;
	mov.b32 	 %f347, %r89;
	mov.b32 	 %f348, %r90;
	mov.b32 	 %f349, %r91;
	add.s64 	%rd86, %rd92, 128;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd85];
	// inline asm
	mov.b32 	 %f350, %r92;
	mov.b32 	 %f351, %r93;
	mov.b32 	 %f352, %r94;
	mov.b32 	 %f353, %r95;
	add.s64 	%rd89, %rd92, 144;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd88];
	// inline asm
	mov.f32 	%f354, 0f3F800000;
	sub.f32 	%f355, %f354, %f37;
	mul.f32 	%f356, %f37, %f342;
	mul.f32 	%f357, %f37, %f343;
	mul.f32 	%f358, %f37, %f344;
	mul.f32 	%f359, %f37, %f345;
	fma.rn.f32 	%f828, %f355, %f828, %f356;
	fma.rn.f32 	%f829, %f355, %f829, %f357;
	fma.rn.f32 	%f830, %f355, %f830, %f358;
	fma.rn.f32 	%f831, %f355, %f831, %f359;
	mul.f32 	%f360, %f37, %f346;
	mul.f32 	%f361, %f37, %f347;
	mul.f32 	%f362, %f37, %f348;
	mul.f32 	%f363, %f37, %f349;
	fma.rn.f32 	%f832, %f355, %f832, %f360;
	fma.rn.f32 	%f833, %f355, %f833, %f361;
	fma.rn.f32 	%f834, %f355, %f834, %f362;
	fma.rn.f32 	%f835, %f355, %f835, %f363;
	mul.f32 	%f364, %f37, %f350;
	mul.f32 	%f365, %f37, %f351;
	mul.f32 	%f366, %f37, %f352;
	mul.f32 	%f367, %f37, %f353;
	fma.rn.f32 	%f836, %f355, %f836, %f364;
	fma.rn.f32 	%f368, %f355, %f837, %f365;
	fma.rn.f32 	%f369, %f355, %f838, %f366;
	fma.rn.f32 	%f370, %f355, %f839, %f367;
	mov.b32 	 %f371, %r96;
	mov.b32 	 %f372, %r97;
	mov.b32 	 %f373, %r98;
	mov.b32 	 %f374, %r99;
	mul.f32 	%f375, %f37, %f371;
	mul.f32 	%f376, %f37, %f372;
	mul.f32 	%f377, %f37, %f373;
	mul.f32 	%f378, %f37, %f374;
	fma.rn.f32 	%f379, %f355, %f840, %f375;
	fma.rn.f32 	%f841, %f355, %f841, %f376;
	fma.rn.f32 	%f842, %f355, %f842, %f377;
	fma.rn.f32 	%f843, %f355, %f843, %f378;
	mul.f32 	%f380, %f369, %f369;
	fma.rn.f32 	%f381, %f368, %f368, %f380;
	fma.rn.f32 	%f382, %f370, %f370, %f381;
	fma.rn.f32 	%f383, %f379, %f379, %f382;
	sqrt.rn.f32 	%f384, %f383;
	rcp.rn.f32 	%f385, %f384;
	mul.f32 	%f837, %f368, %f385;
	mul.f32 	%f838, %f369, %f385;
	mul.f32 	%f839, %f370, %f385;
	mul.f32 	%f840, %f379, %f385;

BB2_12:
	mul.f32 	%f386, %f838, %f838;
	fma.rn.f32 	%f387, %f837, %f837, %f386;
	fma.rn.f32 	%f388, %f839, %f839, %f387;
	fma.rn.f32 	%f389, %f840, %f840, %f388;
	rcp.rn.f32 	%f390, %f389;
	mul.f32 	%f391, %f837, %f390;
	mul.f32 	%f392, %f838, %f390;
	mul.f32 	%f393, %f839, %f390;
	mul.f32 	%f394, %f840, %f390;
	mul.f32 	%f395, %f837, %f391;
	mul.f32 	%f396, %f838, %f392;
	mul.f32 	%f397, %f839, %f393;
	mul.f32 	%f398, %f837, %f392;
	mul.f32 	%f399, %f839, %f394;
	mul.f32 	%f400, %f837, %f393;
	mul.f32 	%f401, %f838, %f394;
	mul.f32 	%f402, %f838, %f393;
	mul.f32 	%f403, %f837, %f394;
	sub.f32 	%f404, %f395, %f396;
	sub.f32 	%f405, %f404, %f397;
	fma.rn.f32 	%f406, %f840, %f394, %f405;
	sub.f32 	%f407, %f398, %f399;
	add.f32 	%f408, %f407, %f407;
	add.f32 	%f409, %f400, %f401;
	add.f32 	%f410, %f409, %f409;
	add.f32 	%f411, %f398, %f399;
	add.f32 	%f412, %f411, %f411;
	sub.f32 	%f413, %f396, %f395;
	sub.f32 	%f414, %f413, %f397;
	fma.rn.f32 	%f415, %f840, %f394, %f414;
	sub.f32 	%f416, %f402, %f403;
	add.f32 	%f417, %f416, %f416;
	sub.f32 	%f418, %f400, %f401;
	add.f32 	%f419, %f418, %f418;
	add.f32 	%f420, %f402, %f403;
	add.f32 	%f421, %f420, %f420;
	neg.f32 	%f422, %f395;
	sub.f32 	%f423, %f422, %f396;
	add.f32 	%f424, %f397, %f423;
	fma.rn.f32 	%f425, %f840, %f394, %f424;
	mul.f32 	%f426, %f831, %f406;
	fma.rn.f32 	%f427, %f834, %f408, %f426;
	fma.rn.f32 	%f428, %f836, %f410, %f427;
	sub.f32 	%f855, %f841, %f428;
	mul.f32 	%f429, %f834, %f415;
	fma.rn.f32 	%f430, %f831, %f412, %f429;
	fma.rn.f32 	%f431, %f836, %f417, %f430;
	sub.f32 	%f851, %f842, %f431;
	mul.f32 	%f432, %f834, %f421;
	fma.rn.f32 	%f433, %f831, %f419, %f432;
	fma.rn.f32 	%f434, %f836, %f425, %f433;
	sub.f32 	%f847, %f843, %f434;
	mul.f32 	%f435, %f830, %f406;
	fma.rn.f32 	%f436, %f833, %f408, %f435;
	fma.rn.f32 	%f854, %f835, %f410, %f436;
	mul.f32 	%f437, %f833, %f415;
	fma.rn.f32 	%f438, %f830, %f412, %f437;
	fma.rn.f32 	%f850, %f835, %f417, %f438;
	mul.f32 	%f439, %f833, %f421;
	fma.rn.f32 	%f440, %f830, %f419, %f439;
	fma.rn.f32 	%f846, %f835, %f425, %f440;
	mul.f32 	%f441, %f829, %f406;
	fma.rn.f32 	%f853, %f832, %f408, %f441;
	mul.f32 	%f442, %f832, %f415;
	fma.rn.f32 	%f849, %f829, %f412, %f442;
	mul.f32 	%f443, %f832, %f421;
	fma.rn.f32 	%f845, %f829, %f419, %f443;
	mul.f32 	%f852, %f828, %f406;
	mul.f32 	%f848, %f828, %f412;
	mul.f32 	%f844, %f828, %f419;

BB2_15:
	mul.f32 	%f481, %f845, %f850;
	mul.f32 	%f482, %f846, %f849;
	sub.f32 	%f483, %f482, %f481;
	mul.f32 	%f484, %f852, %f483;
	mul.f32 	%f485, %f844, %f850;
	mul.f32 	%f486, %f846, %f848;
	sub.f32 	%f487, %f486, %f485;
	mul.f32 	%f488, %f487, %f853;
	sub.f32 	%f489, %f484, %f488;
	mul.f32 	%f490, %f844, %f849;
	mul.f32 	%f491, %f845, %f848;
	sub.f32 	%f492, %f491, %f490;
	fma.rn.f32 	%f493, %f492, %f854, %f489;
	rcp.rn.f32 	%f494, %f493;
	mul.f32 	%f864, %f483, %f494;
	mul.f32 	%f495, %f846, %f853;
	mul.f32 	%f496, %f845, %f854;
	sub.f32 	%f497, %f496, %f495;
	mul.f32 	%f865, %f494, %f497;
	mul.f32 	%f498, %f849, %f854;
	mul.f32 	%f499, %f850, %f853;
	sub.f32 	%f500, %f499, %f498;
	mul.f32 	%f866, %f494, %f500;
	sub.f32 	%f501, %f485, %f486;
	mul.f32 	%f860, %f501, %f494;
	mul.f32 	%f502, %f844, %f854;
	mul.f32 	%f503, %f846, %f852;
	sub.f32 	%f504, %f503, %f502;
	mul.f32 	%f861, %f494, %f504;
	mul.f32 	%f505, %f850, %f852;
	mul.f32 	%f506, %f848, %f854;
	sub.f32 	%f507, %f506, %f505;
	mul.f32 	%f862, %f494, %f507;
	mul.f32 	%f856, %f492, %f494;
	mul.f32 	%f508, %f845, %f852;
	mul.f32 	%f509, %f844, %f853;
	sub.f32 	%f510, %f509, %f508;
	mul.f32 	%f857, %f510, %f494;
	mul.f32 	%f511, %f848, %f853;
	mul.f32 	%f512, %f849, %f852;
	sub.f32 	%f513, %f512, %f511;
	mul.f32 	%f858, %f513, %f494;
	mul.f32 	%f514, %f855, %f864;
	neg.f32 	%f515, %f514;
	mul.f32 	%f516, %f851, %f865;
	sub.f32 	%f517, %f515, %f516;
	mul.f32 	%f518, %f847, %f866;
	sub.f32 	%f867, %f517, %f518;
	mul.f32 	%f519, %f855, %f860;
	neg.f32 	%f520, %f519;
	mul.f32 	%f521, %f851, %f861;
	sub.f32 	%f522, %f520, %f521;
	mul.f32 	%f523, %f847, %f862;
	sub.f32 	%f863, %f522, %f523;
	mul.f32 	%f524, %f855, %f856;
	neg.f32 	%f525, %f524;
	mul.f32 	%f526, %f851, %f857;
	sub.f32 	%f527, %f525, %f526;
	mul.f32 	%f528, %f847, %f858;
	sub.f32 	%f859, %f527, %f528;
	bra.uni 	BB2_16;

BB2_5:
	setp.ne.s32	%p4, %r11, 1;
	mov.f32 	%f857, %f856;
	mov.f32 	%f859, %f856;
	mov.f32 	%f860, %f856;
	mov.f32 	%f861, %f858;
	mov.f32 	%f862, %f856;
	mov.f32 	%f863, %f856;
	mov.f32 	%f864, %f858;
	mov.f32 	%f865, %f856;
	mov.f32 	%f866, %f856;
	mov.f32 	%f867, %f856;
	@%p4 bra 	BB2_16;

	// inline asm
	call (%rd21), _optix_get_static_transform_from_handle, (%rd19);
	// inline asm
	add.s64 	%rd263, %rd21, 64;

BB2_8:
	// inline asm
	cvta.to.global.u64 %rd25, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r13,%r14,%r15,%r16}, [%rd25];
	// inline asm
	mov.b32 	 %f864, %r13;
	mov.b32 	 %f865, %r14;
	mov.b32 	 %f866, %r15;
	mov.b32 	 %f867, %r16;
	add.s64 	%rd29, %rd263, 16;
	// inline asm
	cvta.to.global.u64 %rd28, %rd29;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r17,%r18,%r19,%r20}, [%rd28];
	// inline asm
	mov.b32 	 %f860, %r17;
	mov.b32 	 %f861, %r18;
	mov.b32 	 %f862, %r19;
	mov.b32 	 %f863, %r20;
	add.s64 	%rd32, %rd263, 32;
	// inline asm
	cvta.to.global.u64 %rd31, %rd32;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r21,%r22,%r23,%r24}, [%rd31];
	// inline asm
	mov.b32 	 %f856, %r21;
	mov.b32 	 %f857, %r22;
	mov.b32 	 %f858, %r23;
	mov.b32 	 %f859, %r24;

BB2_16:
	setp.eq.s32	%p8, %r313, 0;
	@%p8 bra 	BB2_17;
	bra.uni 	BB2_18;

BB2_17:
	mov.f32 	%f827, %f867;
	mov.f32 	%f826, %f866;
	mov.f32 	%f825, %f865;
	mov.f32 	%f824, %f864;
	mov.f32 	%f823, %f863;
	mov.f32 	%f822, %f862;
	mov.f32 	%f821, %f861;
	mov.f32 	%f820, %f860;
	mov.f32 	%f819, %f859;
	mov.f32 	%f818, %f858;
	mov.f32 	%f817, %f857;
	mov.f32 	%f816, %f856;
	bra.uni 	BB2_19;

BB2_18:
	mul.f32 	%f529, %f820, %f865;
	fma.rn.f32 	%f530, %f824, %f864, %f529;
	fma.rn.f32 	%f151, %f816, %f866, %f530;
	mul.f32 	%f531, %f821, %f865;
	fma.rn.f32 	%f532, %f825, %f864, %f531;
	fma.rn.f32 	%f152, %f817, %f866, %f532;
	mul.f32 	%f533, %f822, %f865;
	fma.rn.f32 	%f534, %f826, %f864, %f533;
	fma.rn.f32 	%f153, %f818, %f866, %f534;
	mul.f32 	%f535, %f823, %f865;
	fma.rn.f32 	%f536, %f827, %f864, %f535;
	fma.rn.f32 	%f537, %f819, %f866, %f536;
	add.f32 	%f154, %f867, %f537;
	mul.f32 	%f538, %f820, %f861;
	fma.rn.f32 	%f539, %f824, %f860, %f538;
	fma.rn.f32 	%f155, %f816, %f862, %f539;
	mul.f32 	%f540, %f821, %f861;
	fma.rn.f32 	%f541, %f825, %f860, %f540;
	fma.rn.f32 	%f156, %f817, %f862, %f541;
	mul.f32 	%f542, %f822, %f861;
	fma.rn.f32 	%f543, %f826, %f860, %f542;
	fma.rn.f32 	%f157, %f818, %f862, %f543;
	mul.f32 	%f544, %f823, %f861;
	fma.rn.f32 	%f545, %f827, %f860, %f544;
	fma.rn.f32 	%f546, %f819, %f862, %f545;
	add.f32 	%f158, %f863, %f546;
	mul.f32 	%f547, %f820, %f857;
	fma.rn.f32 	%f548, %f824, %f856, %f547;
	fma.rn.f32 	%f816, %f816, %f858, %f548;
	mul.f32 	%f549, %f821, %f857;
	fma.rn.f32 	%f550, %f825, %f856, %f549;
	fma.rn.f32 	%f817, %f817, %f858, %f550;
	mul.f32 	%f551, %f822, %f857;
	fma.rn.f32 	%f552, %f826, %f856, %f551;
	fma.rn.f32 	%f818, %f818, %f858, %f552;
	mul.f32 	%f553, %f823, %f857;
	fma.rn.f32 	%f554, %f827, %f856, %f553;
	fma.rn.f32 	%f555, %f819, %f858, %f554;
	add.f32 	%f819, %f859, %f555;
	mov.f32 	%f827, %f154;
	mov.f32 	%f826, %f153;
	mov.f32 	%f825, %f152;
	mov.f32 	%f824, %f151;
	mov.f32 	%f823, %f158;
	mov.f32 	%f822, %f157;
	mov.f32 	%f821, %f156;
	mov.f32 	%f820, %f155;

BB2_19:
	add.s32 	%r313, %r313, 1;
	setp.lt.u32	%p9, %r313, %r8;
	@%p9 bra 	BB2_3;

	mul.f32 	%f556, %f314, %f824;
	fma.rn.f32 	%f557, %f315, %f825, %f556;
	fma.rn.f32 	%f558, %f880, %f826, %f557;
	add.f32 	%f882, %f827, %f558;
	mul.f32 	%f559, %f314, %f820;
	fma.rn.f32 	%f560, %f315, %f821, %f559;
	fma.rn.f32 	%f561, %f880, %f822, %f560;
	add.f32 	%f881, %f823, %f561;
	mul.f32 	%f562, %f314, %f816;
	fma.rn.f32 	%f563, %f315, %f817, %f562;
	fma.rn.f32 	%f564, %f880, %f818, %f563;
	add.f32 	%f880, %f819, %f564;
	bra.uni 	BB2_21;

BB2_1:
	mov.f32 	%f881, %f315;
	mov.f32 	%f882, %f314;

BB2_21:
	setp.eq.s32	%p20, %r8, 0;
	// inline asm
	call (%f565), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f566), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f931), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f568), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r314, 0;
	@%p20 bra 	BB2_22;

BB2_23:
	.pragma "nounroll";
	// inline asm
	call (%rd140), _optix_get_transform_list_handle, (%r314);
	// inline asm
	// inline asm
	call (%r161), _optix_get_transform_type_from_handle, (%rd140);
	// inline asm
	and.b32  	%r162, %r161, -2;
	setp.eq.s32	%p11, %r162, 2;
	@%p11 bra 	BB2_29;
	bra.uni 	BB2_24;

BB2_29:
	setp.eq.s32	%p14, %r161, 2;
	@%p14 bra 	BB2_33;
	bra.uni 	BB2_30;

BB2_33:
	// inline asm
	call (%rd214), _optix_get_matrix_motion_transform_from_handle, (%rd140);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd216, %rd214;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd216];
	// inline asm
	mov.b32	{%rs7, %rs8}, %r252;
	add.s64 	%rd220, %rd214, 16;
	// inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd219];
	// inline asm
	add.s64 	%rd223, %rd214, 32;
	// inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd222];
	// inline asm
	add.s64 	%rd226, %rd214, 48;
	// inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd225];
	// inline asm
	add.s64 	%rd229, %rd214, 64;
	// inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd228];
	// inline asm
	add.s64 	%rd232, %rd214, 80;
	// inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd231];
	// inline asm
	add.s64 	%rd235, %rd214, 96;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd234];
	// inline asm
	add.s64 	%rd238, %rd214, 112;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd237];
	// inline asm
	mov.b32 	 %f671, %r253;
	mov.b32 	 %f672, %r254;
	cvt.u32.u16	%r294, %rs7;
	add.s32 	%r295, %r294, -1;
	cvt.rn.f32.s32	%f673, %r295;
	sub.f32 	%f674, %f568, %f671;
	mul.f32 	%f675, %f674, %f673;
	sub.f32 	%f676, %f672, %f671;
	div.rn.f32 	%f677, %f675, %f676;
	min.f32 	%f678, %f673, %f677;
	mov.f32 	%f679, 0f00000000;
	max.f32 	%f680, %f679, %f678;
	cvt.rmi.f32.f32	%f681, %f680;
	cvt.rzi.s32.f32	%r296, %f681;
	cvt.s64.s32	%rd17, %r296;
	mul.wide.s32 	%rd249, %r296, 48;
	add.s64 	%rd241, %rd223, %rd249;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd240];
	// inline asm
	mov.b32 	 %f908, %r282;
	mov.b32 	 %f909, %r283;
	mov.b32 	 %f910, %r284;
	add.s64 	%rd244, %rd241, 16;
	// inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd243];
	// inline asm
	mov.b32 	 %f905, %r286;
	mov.b32 	 %f906, %r287;
	mov.b32 	 %f907, %r288;
	add.s64 	%rd247, %rd241, 32;
	// inline asm
	cvta.to.global.u64 %rd246, %rd247;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd246];
	// inline asm
	sub.f32 	%f249, %f680, %f681;
	mov.b32 	 %f902, %r290;
	mov.b32 	 %f903, %r291;
	mov.b32 	 %f904, %r292;
	setp.leu.f32	%p16, %f249, 0f00000000;
	@%p16 bra 	BB2_35;

	mul.lo.s64 	%rd259, %rd17, 48;
	add.s64 	%rd260, %rd214, %rd259;
	add.s64 	%rd251, %rd260, 80;
	// inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd250];
	// inline asm
	mov.b32 	 %f682, %r297;
	mov.b32 	 %f683, %r298;
	mov.b32 	 %f684, %r299;
	add.s64 	%rd254, %rd260, 96;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd253];
	// inline asm
	mov.b32 	 %f685, %r301;
	mov.b32 	 %f686, %r302;
	mov.b32 	 %f687, %r303;
	add.s64 	%rd257, %rd260, 112;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd256];
	// inline asm
	mov.f32 	%f688, 0f3F800000;
	sub.f32 	%f689, %f688, %f249;
	mul.f32 	%f690, %f249, %f682;
	mul.f32 	%f691, %f249, %f683;
	mul.f32 	%f692, %f249, %f684;
	fma.rn.f32 	%f908, %f689, %f908, %f690;
	fma.rn.f32 	%f909, %f689, %f909, %f691;
	fma.rn.f32 	%f910, %f689, %f910, %f692;
	mul.f32 	%f693, %f249, %f685;
	mul.f32 	%f694, %f249, %f686;
	mul.f32 	%f695, %f249, %f687;
	fma.rn.f32 	%f905, %f689, %f905, %f693;
	fma.rn.f32 	%f906, %f689, %f906, %f694;
	fma.rn.f32 	%f907, %f689, %f907, %f695;
	mov.b32 	 %f696, %r305;
	mov.b32 	 %f697, %r306;
	mov.b32 	 %f698, %r307;
	mul.f32 	%f699, %f249, %f696;
	mul.f32 	%f700, %f249, %f697;
	mul.f32 	%f701, %f249, %f698;
	fma.rn.f32 	%f902, %f689, %f902, %f699;
	fma.rn.f32 	%f903, %f689, %f903, %f700;
	fma.rn.f32 	%f904, %f689, %f904, %f701;
	bra.uni 	BB2_35;

BB2_24:
	mov.f32 	%f911, 0f00000000;
	mov.f32 	%f913, 0f3F800000;
	setp.eq.s32	%p12, %r161, 4;
	@%p12 bra 	BB2_27;
	bra.uni 	BB2_25;

BB2_27:
	// inline asm
	call (%rd264), _optix_get_instance_inverse_transform_from_handle, (%rd140);
	// inline asm
	bra.uni 	BB2_28;

BB2_30:
	// inline asm
	call (%rd155), _optix_get_srt_motion_transform_from_handle, (%rd140);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd157, %rd155;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd157];
	// inline asm
	mov.b32	{%rs5, %rs6}, %r177;
	add.s64 	%rd161, %rd155, 16;
	// inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd160];
	// inline asm
	add.s64 	%rd164, %rd155, 32;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd163];
	// inline asm
	add.s64 	%rd167, %rd155, 48;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd166];
	// inline asm
	add.s64 	%rd170, %rd155, 64;
	// inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd169];
	// inline asm
	add.s64 	%rd173, %rd155, 80;
	// inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd172];
	// inline asm
	add.s64 	%rd176, %rd155, 96;
	// inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd175];
	// inline asm
	add.s64 	%rd179, %rd155, 112;
	// inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd178];
	// inline asm
	add.s64 	%rd182, %rd155, 128;
	// inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd181];
	// inline asm
	add.s64 	%rd185, %rd155, 144;
	// inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd184];
	// inline asm
	mov.b32 	 %f579, %r178;
	mov.b32 	 %f580, %r179;
	cvt.u32.u16	%r231, %rs5;
	add.s32 	%r232, %r231, -1;
	cvt.rn.f32.s32	%f581, %r232;
	sub.f32 	%f582, %f568, %f579;
	mul.f32 	%f583, %f582, %f581;
	sub.f32 	%f584, %f580, %f579;
	div.rn.f32 	%f585, %f583, %f584;
	min.f32 	%f586, %f581, %f585;
	mov.f32 	%f587, 0f00000000;
	max.f32 	%f588, %f587, %f586;
	cvt.rmi.f32.f32	%f589, %f588;
	cvt.rzi.s32.f32	%r233, %f589;
	cvt.s64.s32	%rd15, %r233;
	mul.wide.s32 	%rd199, %r233, 64;
	add.s64 	%rd188, %rd164, %rd199;
	// inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd187];
	// inline asm
	mov.b32 	 %f892, %r215;
	mov.b32 	 %f893, %r216;
	mov.b32 	 %f894, %r217;
	add.s64 	%rd191, %rd188, 16;
	// inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd190];
	// inline asm
	mov.b32 	 %f895, %r219;
	mov.b32 	 %f896, %r220;
	mov.b32 	 %f897, %r222;
	add.s64 	%rd194, %rd188, 32;
	// inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd193];
	// inline asm
	sub.f32 	%f209, %f588, %f589;
	mov.b32 	 %f898, %r224;
	mov.b32 	 %f899, %r225;
	mov.b32 	 %f900, %r226;
	add.s64 	%rd197, %rd188, 48;
	// inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd196];
	// inline asm
	mov.b32 	 %f901, %r227;
	setp.leu.f32	%p15, %f209, 0f00000000;
	@%p15 bra 	BB2_32;

	shl.b64 	%rd212, %rd15, 6;
	add.s64 	%rd213, %rd212, %rd155;
	add.s64 	%rd201, %rd213, 96;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd200];
	// inline asm
	mov.b32 	 %f590, %r234;
	mov.b32 	 %f591, %r235;
	mov.b32 	 %f592, %r236;
	add.s64 	%rd204, %rd213, 112;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd203];
	// inline asm
	mov.b32 	 %f593, %r238;
	mov.b32 	 %f594, %r239;
	mov.b32 	 %f595, %r241;
	add.s64 	%rd207, %rd213, 128;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd206];
	// inline asm
	mov.b32 	 %f596, %r243;
	mov.b32 	 %f597, %r244;
	mov.b32 	 %f598, %r245;
	add.s64 	%rd210, %rd213, 144;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd209];
	// inline asm
	mov.f32 	%f599, 0f3F800000;
	sub.f32 	%f600, %f599, %f209;
	mul.f32 	%f601, %f209, %f590;
	mul.f32 	%f602, %f209, %f591;
	mul.f32 	%f603, %f209, %f592;
	fma.rn.f32 	%f892, %f600, %f892, %f601;
	fma.rn.f32 	%f893, %f600, %f893, %f602;
	fma.rn.f32 	%f894, %f600, %f894, %f603;
	mul.f32 	%f604, %f209, %f593;
	mul.f32 	%f605, %f209, %f594;
	mul.f32 	%f606, %f209, %f595;
	fma.rn.f32 	%f895, %f600, %f895, %f604;
	fma.rn.f32 	%f896, %f600, %f896, %f605;
	fma.rn.f32 	%f897, %f600, %f897, %f606;
	mul.f32 	%f607, %f209, %f596;
	mul.f32 	%f608, %f209, %f597;
	mul.f32 	%f609, %f209, %f598;
	fma.rn.f32 	%f610, %f600, %f898, %f607;
	fma.rn.f32 	%f611, %f600, %f899, %f608;
	fma.rn.f32 	%f612, %f600, %f900, %f609;
	mov.b32 	 %f613, %r246;
	mul.f32 	%f614, %f209, %f613;
	fma.rn.f32 	%f615, %f600, %f901, %f614;
	mul.f32 	%f616, %f611, %f611;
	fma.rn.f32 	%f617, %f610, %f610, %f616;
	fma.rn.f32 	%f618, %f612, %f612, %f617;
	fma.rn.f32 	%f619, %f615, %f615, %f618;
	sqrt.rn.f32 	%f620, %f619;
	rcp.rn.f32 	%f621, %f620;
	mul.f32 	%f898, %f610, %f621;
	mul.f32 	%f899, %f611, %f621;
	mul.f32 	%f900, %f612, %f621;
	mul.f32 	%f901, %f615, %f621;

BB2_32:
	mul.f32 	%f622, %f899, %f899;
	fma.rn.f32 	%f623, %f898, %f898, %f622;
	fma.rn.f32 	%f624, %f900, %f900, %f623;
	fma.rn.f32 	%f625, %f901, %f901, %f624;
	rcp.rn.f32 	%f626, %f625;
	mul.f32 	%f627, %f898, %f626;
	mul.f32 	%f628, %f899, %f626;
	mul.f32 	%f629, %f900, %f626;
	mul.f32 	%f630, %f901, %f626;
	mul.f32 	%f631, %f898, %f627;
	mul.f32 	%f632, %f899, %f628;
	mul.f32 	%f633, %f900, %f629;
	mul.f32 	%f634, %f898, %f628;
	mul.f32 	%f635, %f900, %f630;
	mul.f32 	%f636, %f898, %f629;
	mul.f32 	%f637, %f899, %f630;
	mul.f32 	%f638, %f899, %f629;
	mul.f32 	%f639, %f898, %f630;
	sub.f32 	%f640, %f631, %f632;
	sub.f32 	%f641, %f640, %f633;
	fma.rn.f32 	%f642, %f901, %f630, %f641;
	sub.f32 	%f643, %f634, %f635;
	add.f32 	%f644, %f643, %f643;
	add.f32 	%f645, %f636, %f637;
	add.f32 	%f646, %f645, %f645;
	add.f32 	%f647, %f634, %f635;
	add.f32 	%f648, %f647, %f647;
	sub.f32 	%f649, %f632, %f631;
	sub.f32 	%f650, %f649, %f633;
	fma.rn.f32 	%f651, %f901, %f630, %f650;
	sub.f32 	%f652, %f638, %f639;
	add.f32 	%f653, %f652, %f652;
	sub.f32 	%f654, %f636, %f637;
	add.f32 	%f655, %f654, %f654;
	add.f32 	%f656, %f638, %f639;
	add.f32 	%f657, %f656, %f656;
	neg.f32 	%f658, %f631;
	sub.f32 	%f659, %f658, %f632;
	add.f32 	%f660, %f633, %f659;
	fma.rn.f32 	%f661, %f901, %f630, %f660;
	mul.f32 	%f662, %f894, %f642;
	fma.rn.f32 	%f663, %f896, %f644, %f662;
	fma.rn.f32 	%f910, %f897, %f646, %f663;
	mul.f32 	%f664, %f896, %f651;
	fma.rn.f32 	%f665, %f894, %f648, %f664;
	fma.rn.f32 	%f907, %f897, %f653, %f665;
	mul.f32 	%f666, %f896, %f657;
	fma.rn.f32 	%f667, %f894, %f655, %f666;
	fma.rn.f32 	%f904, %f897, %f661, %f667;
	mul.f32 	%f668, %f893, %f642;
	fma.rn.f32 	%f909, %f895, %f644, %f668;
	mul.f32 	%f669, %f895, %f651;
	fma.rn.f32 	%f906, %f893, %f648, %f669;
	mul.f32 	%f670, %f895, %f657;
	fma.rn.f32 	%f903, %f893, %f655, %f670;
	mul.f32 	%f908, %f892, %f642;
	mul.f32 	%f905, %f892, %f648;
	mul.f32 	%f902, %f892, %f655;

BB2_35:
	mul.f32 	%f702, %f903, %f907;
	mul.f32 	%f703, %f904, %f906;
	sub.f32 	%f704, %f703, %f702;
	mul.f32 	%f705, %f908, %f704;
	mul.f32 	%f706, %f902, %f907;
	mul.f32 	%f707, %f904, %f905;
	sub.f32 	%f708, %f707, %f706;
	mul.f32 	%f709, %f708, %f909;
	sub.f32 	%f710, %f705, %f709;
	mul.f32 	%f711, %f902, %f906;
	mul.f32 	%f712, %f903, %f905;
	sub.f32 	%f713, %f712, %f711;
	fma.rn.f32 	%f714, %f713, %f910, %f710;
	rcp.rn.f32 	%f715, %f714;
	mul.f32 	%f917, %f704, %f715;
	mul.f32 	%f716, %f904, %f909;
	mul.f32 	%f717, %f903, %f910;
	sub.f32 	%f718, %f717, %f716;
	mul.f32 	%f918, %f715, %f718;
	mul.f32 	%f719, %f906, %f910;
	mul.f32 	%f720, %f907, %f909;
	sub.f32 	%f721, %f720, %f719;
	mul.f32 	%f919, %f715, %f721;
	sub.f32 	%f722, %f706, %f707;
	mul.f32 	%f914, %f722, %f715;
	mul.f32 	%f723, %f902, %f910;
	mul.f32 	%f724, %f904, %f908;
	sub.f32 	%f725, %f724, %f723;
	mul.f32 	%f915, %f715, %f725;
	mul.f32 	%f726, %f907, %f908;
	mul.f32 	%f727, %f905, %f910;
	sub.f32 	%f728, %f727, %f726;
	mul.f32 	%f916, %f715, %f728;
	mul.f32 	%f911, %f713, %f715;
	mul.f32 	%f729, %f903, %f908;
	mul.f32 	%f730, %f902, %f909;
	sub.f32 	%f731, %f730, %f729;
	mul.f32 	%f912, %f731, %f715;
	mul.f32 	%f732, %f905, %f909;
	mul.f32 	%f733, %f906, %f908;
	sub.f32 	%f734, %f733, %f732;
	mul.f32 	%f913, %f734, %f715;
	bra.uni 	BB2_36;

BB2_25:
	setp.ne.s32	%p13, %r161, 1;
	mov.f32 	%f912, %f911;
	mov.f32 	%f914, %f911;
	mov.f32 	%f915, %f913;
	mov.f32 	%f916, %f911;
	mov.f32 	%f917, %f913;
	mov.f32 	%f918, %f911;
	mov.f32 	%f919, %f911;
	@%p13 bra 	BB2_36;

	// inline asm
	call (%rd142), _optix_get_static_transform_from_handle, (%rd140);
	// inline asm
	add.s64 	%rd264, %rd142, 64;

BB2_28:
	// inline asm
	cvta.to.global.u64 %rd146, %rd264;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd146];
	// inline asm
	mov.b32 	 %f917, %r163;
	mov.b32 	 %f918, %r164;
	mov.b32 	 %f919, %r165;
	add.s64 	%rd150, %rd264, 16;
	// inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd149];
	// inline asm
	mov.b32 	 %f914, %r167;
	mov.b32 	 %f915, %r168;
	mov.b32 	 %f916, %r169;
	add.s64 	%rd153, %rd264, 32;
	// inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd152];
	// inline asm
	mov.b32 	 %f911, %r171;
	mov.b32 	 %f912, %r172;
	mov.b32 	 %f913, %r173;

BB2_36:
	setp.eq.s32	%p17, %r314, 0;
	@%p17 bra 	BB2_37;
	bra.uni 	BB2_38;

BB2_37:
	mov.f32 	%f891, %f911;
	mov.f32 	%f890, %f912;
	mov.f32 	%f889, %f913;
	mov.f32 	%f888, %f914;
	mov.f32 	%f887, %f915;
	mov.f32 	%f886, %f916;
	mov.f32 	%f885, %f917;
	mov.f32 	%f884, %f918;
	mov.f32 	%f883, %f919;
	bra.uni 	BB2_39;

BB2_38:
	mul.f32 	%f735, %f888, %f918;
	fma.rn.f32 	%f736, %f885, %f917, %f735;
	fma.rn.f32 	%f289, %f891, %f919, %f736;
	mul.f32 	%f737, %f887, %f918;
	fma.rn.f32 	%f738, %f884, %f917, %f737;
	fma.rn.f32 	%f290, %f890, %f919, %f738;
	mul.f32 	%f739, %f886, %f918;
	fma.rn.f32 	%f740, %f883, %f917, %f739;
	fma.rn.f32 	%f291, %f889, %f919, %f740;
	mul.f32 	%f741, %f888, %f915;
	fma.rn.f32 	%f742, %f885, %f914, %f741;
	fma.rn.f32 	%f292, %f891, %f916, %f742;
	mul.f32 	%f743, %f887, %f915;
	fma.rn.f32 	%f744, %f884, %f914, %f743;
	fma.rn.f32 	%f293, %f890, %f916, %f744;
	mul.f32 	%f745, %f886, %f915;
	fma.rn.f32 	%f746, %f883, %f914, %f745;
	fma.rn.f32 	%f294, %f889, %f916, %f746;
	mul.f32 	%f747, %f888, %f912;
	fma.rn.f32 	%f748, %f885, %f911, %f747;
	fma.rn.f32 	%f891, %f891, %f913, %f748;
	mul.f32 	%f749, %f887, %f912;
	fma.rn.f32 	%f750, %f884, %f911, %f749;
	fma.rn.f32 	%f890, %f890, %f913, %f750;
	mul.f32 	%f751, %f886, %f912;
	fma.rn.f32 	%f752, %f883, %f911, %f751;
	fma.rn.f32 	%f889, %f889, %f913, %f752;
	mov.f32 	%f888, %f292;
	mov.f32 	%f887, %f293;
	mov.f32 	%f886, %f294;
	mov.f32 	%f885, %f289;
	mov.f32 	%f884, %f290;
	mov.f32 	%f883, %f291;

BB2_39:
	add.s32 	%r314, %r314, 1;
	setp.lt.u32	%p18, %r314, %r8;
	@%p18 bra 	BB2_23;

	mul.f32 	%f753, %f566, %f884;
	fma.rn.f32 	%f754, %f565, %f885, %f753;
	fma.rn.f32 	%f929, %f931, %f883, %f754;
	mul.f32 	%f755, %f566, %f887;
	fma.rn.f32 	%f756, %f565, %f888, %f755;
	fma.rn.f32 	%f930, %f931, %f886, %f756;
	mul.f32 	%f757, %f566, %f890;
	fma.rn.f32 	%f758, %f565, %f891, %f757;
	fma.rn.f32 	%f931, %f931, %f889, %f758;
	bra.uni 	BB2_41;

BB2_22:
	mov.f32 	%f929, %f565;
	mov.f32 	%f930, %f566;

BB2_41:
	ld.v4.f32 	{%f761, %f762, %f763, %f764}, [%rd1+208];
	ld.v4.f32 	{%f768, %f769, %f770, %f771}, [%rd1+160];
	fma.rn.f32 	%f773, %f882, %f768, %f761;
	fma.rn.f32 	%f775, %f882, %f769, %f762;
	fma.rn.f32 	%f777, %f882, %f770, %f763;
	ld.v4.f32 	{%f778, %f779, %f780, %f781}, [%rd1+176];
	fma.rn.f32 	%f783, %f881, %f778, %f773;
	fma.rn.f32 	%f785, %f881, %f779, %f775;
	fma.rn.f32 	%f787, %f881, %f780, %f777;
	ld.v4.f32 	{%f788, %f789, %f790, %f791}, [%rd1+192];
	fma.rn.f32 	%f793, %f880, %f788, %f783;
	fma.rn.f32 	%f795, %f880, %f789, %f785;
	fma.rn.f32 	%f797, %f880, %f790, %f787;
	mul.f32 	%f798, %f929, %f768;
	mul.f32 	%f799, %f929, %f769;
	mul.f32 	%f800, %f929, %f770;
	fma.rn.f32 	%f801, %f930, %f778, %f798;
	fma.rn.f32 	%f802, %f930, %f779, %f799;
	fma.rn.f32 	%f803, %f930, %f780, %f800;
	fma.rn.f32 	%f804, %f931, %f788, %f801;
	fma.rn.f32 	%f805, %f931, %f789, %f802;
	fma.rn.f32 	%f806, %f931, %f790, %f803;
	rcp.rn.f32 	%f807, %f806;
	mul.f32 	%f808, %f797, %f807;
	neg.f32 	%f313, %f808;
	fma.rn.f32 	%f809, %f313, %f804, %f793;
	fma.rn.f32 	%f810, %f313, %f805, %f795;
	mul.f32 	%f811, %f810, %f810;
	fma.rn.f32 	%f812, %f809, %f809, %f811;
	setp.gtu.f32	%p19, %f812, 0f3F800000;
	@%p19 bra 	BB2_43;

	mov.u32 	%r310, 254;
	// inline asm
	call (%r309), _optix_report_intersection_0, (%f313, %r310);
	// inline asm

BB2_43:
	ret;
}

	// .globl	__closesthit__disk
.visible .entry __closesthit__disk(

)
{
	.reg .pred 	%p<67>;
	.reg .b16 	%rs<18>;
	.reg .f32 	%f<2066>;
	.reg .b32 	%r<650>;
	.reg .b64 	%rd<671>;


	// inline asm
	call (%r23), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r24), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r26), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r27), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r28), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r29, %r28, %r24, %r27;
	mad.lo.s32 	%r1, %r29, %r23, %r26;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	@%p1 bra 	BB3_2;

	cvta.to.global.u64 	%rd49, %rd1;
	cvt.u64.u32	%rd50, %r1;
	add.s64 	%rd51, %rd49, %rd50;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd51], %rs1;
	bra.uni 	BB3_116;

BB3_2:
	// inline asm
	call (%rd52), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd3, [%rd52+8];
	// inline asm
	call (%f684), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f685), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f1853), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r30), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p2, %r30, 0;
	@%p2 bra 	BB3_3;

	mov.u32 	%r646, 0;
	// inline asm
	call (%f687), _optix_get_ray_time, ();
	// inline asm

BB3_5:
	.pragma "nounroll";
	// inline asm
	call (%rd53), _optix_get_transform_list_handle, (%r646);
	// inline asm
	// inline asm
	call (%r33), _optix_get_transform_type_from_handle, (%rd53);
	// inline asm
	and.b32  	%r34, %r33, -2;
	setp.eq.s32	%p3, %r34, 2;
	@%p3 bra 	BB3_11;
	bra.uni 	BB3_6;

BB3_11:
	setp.eq.s32	%p6, %r33, 2;
	@%p6 bra 	BB3_15;
	bra.uni 	BB3_12;

BB3_15:
	// inline asm
	call (%rd127), _optix_get_matrix_motion_transform_from_handle, (%rd53);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd129, %rd127;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd129];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r124;
	add.s64 	%rd133, %rd127, 16;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd132];
	// inline asm
	add.s64 	%rd136, %rd127, 32;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd135];
	// inline asm
	add.s64 	%rd139, %rd127, 48;
	// inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd138];
	// inline asm
	add.s64 	%rd142, %rd127, 64;
	// inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd141];
	// inline asm
	add.s64 	%rd145, %rd127, 80;
	// inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd144];
	// inline asm
	add.s64 	%rd148, %rd127, 96;
	// inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd147];
	// inline asm
	add.s64 	%rd151, %rd127, 112;
	// inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r150,%r151,%r152,%r153}, [%rd150];
	// inline asm
	mov.b32 	 %f814, %r125;
	mov.b32 	 %f815, %r126;
	cvt.u32.u16	%r166, %rs4;
	add.s32 	%r167, %r166, -1;
	cvt.rn.f32.s32	%f816, %r167;
	sub.f32 	%f817, %f687, %f814;
	mul.f32 	%f818, %f817, %f816;
	sub.f32 	%f819, %f815, %f814;
	div.rn.f32 	%f820, %f818, %f819;
	min.f32 	%f821, %f816, %f820;
	mov.f32 	%f822, 0f00000000;
	max.f32 	%f823, %f822, %f821;
	cvt.rmi.f32.f32	%f824, %f823;
	cvt.rzi.s32.f32	%r168, %f824;
	mul.wide.s32 	%rd162, %r168, 48;
	add.s64 	%rd154, %rd136, %rd162;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r154,%r155,%r156,%r157}, [%rd153];
	// inline asm
	mov.b32 	 %f1820, %r154;
	mov.b32 	 %f1819, %r155;
	mov.b32 	 %f1818, %r156;
	mov.b32 	 %f1817, %r157;
	add.s64 	%rd157, %rd154, 16;
	// inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r158,%r159,%r160,%r161}, [%rd156];
	// inline asm
	mov.b32 	 %f1824, %r158;
	mov.b32 	 %f1823, %r159;
	mov.b32 	 %f1822, %r160;
	mov.b32 	 %f1821, %r161;
	add.s64 	%rd160, %rd154, 32;
	// inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r162,%r163,%r164,%r165}, [%rd159];
	// inline asm
	sub.f32 	%f98, %f823, %f824;
	mov.b32 	 %f1828, %r162;
	mov.b32 	 %f1827, %r163;
	mov.b32 	 %f1826, %r164;
	mov.b32 	 %f1825, %r165;
	setp.leu.f32	%p8, %f98, 0f00000000;
	@%p8 bra 	BB3_17;

	cvt.rmi.f32.f32	%f1788, %f823;
	cvt.rzi.s32.f32	%r645, %f1788;
	cvt.s64.s32	%rd666, %r645;
	mul.lo.s64 	%rd172, %rd666, 48;
	add.s64 	%rd173, %rd127, %rd172;
	add.s64 	%rd164, %rd173, 80;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd163];
	// inline asm
	mov.b32 	 %f825, %r169;
	mov.b32 	 %f826, %r170;
	mov.b32 	 %f827, %r171;
	mov.b32 	 %f828, %r172;
	add.s64 	%rd167, %rd173, 96;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd166];
	// inline asm
	mov.b32 	 %f829, %r173;
	mov.b32 	 %f830, %r174;
	mov.b32 	 %f831, %r175;
	mov.b32 	 %f832, %r176;
	add.s64 	%rd170, %rd173, 112;
	// inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd169];
	// inline asm
	mov.f32 	%f833, 0f3F800000;
	sub.f32 	%f834, %f833, %f98;
	mul.f32 	%f835, %f98, %f825;
	mul.f32 	%f836, %f98, %f826;
	mul.f32 	%f837, %f98, %f827;
	mul.f32 	%f838, %f98, %f828;
	fma.rn.f32 	%f1820, %f834, %f1820, %f835;
	fma.rn.f32 	%f1819, %f834, %f1819, %f836;
	fma.rn.f32 	%f1818, %f834, %f1818, %f837;
	fma.rn.f32 	%f1817, %f834, %f1817, %f838;
	mul.f32 	%f839, %f98, %f829;
	mul.f32 	%f840, %f98, %f830;
	mul.f32 	%f841, %f98, %f831;
	mul.f32 	%f842, %f98, %f832;
	fma.rn.f32 	%f1824, %f834, %f1824, %f839;
	fma.rn.f32 	%f1823, %f834, %f1823, %f840;
	fma.rn.f32 	%f1822, %f834, %f1822, %f841;
	fma.rn.f32 	%f1821, %f834, %f1821, %f842;
	mov.b32 	 %f843, %r177;
	mov.b32 	 %f844, %r178;
	mov.b32 	 %f845, %r179;
	mov.b32 	 %f846, %r180;
	mul.f32 	%f847, %f98, %f843;
	mul.f32 	%f848, %f98, %f844;
	mul.f32 	%f849, %f98, %f845;
	mul.f32 	%f850, %f98, %f846;
	fma.rn.f32 	%f1828, %f834, %f1828, %f847;
	fma.rn.f32 	%f1827, %f834, %f1827, %f848;
	fma.rn.f32 	%f1826, %f834, %f1826, %f849;
	fma.rn.f32 	%f1825, %f834, %f1825, %f850;
	bra.uni 	BB3_17;

BB3_6:
	mov.f32 	%f1829, 0f00000000;
	mov.f32 	%f1832, 0f3F800000;
	setp.eq.s32	%p4, %r33, 4;
	@%p4 bra 	BB3_9;
	bra.uni 	BB3_7;

BB3_9:
	// inline asm
	call (%rd667), _optix_get_instance_inverse_transform_from_handle, (%rd53);
	// inline asm
	bra.uni 	BB3_10;

BB3_12:
	// inline asm
	call (%rd68), _optix_get_srt_motion_transform_from_handle, (%rd53);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd70, %rd68;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd70];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r49;
	add.s64 	%rd74, %rd68, 16;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd73];
	// inline asm
	add.s64 	%rd77, %rd68, 32;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd76];
	// inline asm
	add.s64 	%rd80, %rd68, 48;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd79];
	// inline asm
	add.s64 	%rd83, %rd68, 64;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd82];
	// inline asm
	add.s64 	%rd86, %rd68, 80;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd85];
	// inline asm
	add.s64 	%rd89, %rd68, 96;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd88];
	// inline asm
	add.s64 	%rd92, %rd68, 112;
	// inline asm
	cvta.to.global.u64 %rd91, %rd92;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd91];
	// inline asm
	add.s64 	%rd95, %rd68, 128;
	// inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd94];
	// inline asm
	add.s64 	%rd98, %rd68, 144;
	// inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd97];
	// inline asm
	mov.b32 	 %f701, %r50;
	mov.b32 	 %f702, %r51;
	cvt.u32.u16	%r103, %rs2;
	add.s32 	%r104, %r103, -1;
	cvt.rn.f32.s32	%f703, %r104;
	sub.f32 	%f704, %f687, %f701;
	mul.f32 	%f705, %f704, %f703;
	sub.f32 	%f706, %f702, %f701;
	div.rn.f32 	%f707, %f705, %f706;
	min.f32 	%f708, %f703, %f707;
	mov.f32 	%f709, 0f00000000;
	max.f32 	%f710, %f709, %f708;
	cvt.rmi.f32.f32	%f711, %f710;
	cvt.rzi.s32.f32	%r105, %f711;
	mul.wide.s32 	%rd112, %r105, 64;
	add.s64 	%rd101, %rd77, %rd112;
	// inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r87,%r88,%r89,%r90}, [%rd100];
	// inline asm
	mov.b32 	 %f1801, %r87;
	mov.b32 	 %f1802, %r88;
	mov.b32 	 %f1803, %r89;
	mov.b32 	 %f1804, %r90;
	add.s64 	%rd104, %rd101, 16;
	// inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r91,%r92,%r93,%r94}, [%rd103];
	// inline asm
	mov.b32 	 %f1805, %r91;
	mov.b32 	 %f1806, %r92;
	mov.b32 	 %f1807, %r93;
	mov.b32 	 %f1808, %r94;
	add.s64 	%rd107, %rd101, 32;
	// inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r95,%r96,%r97,%r98}, [%rd106];
	// inline asm
	sub.f32 	%f37, %f710, %f711;
	mov.b32 	 %f1809, %r95;
	mov.b32 	 %f1810, %r96;
	mov.b32 	 %f1811, %r97;
	mov.b32 	 %f1812, %r98;
	add.s64 	%rd110, %rd101, 48;
	// inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r99,%r100,%r101,%r102}, [%rd109];
	// inline asm
	mov.b32 	 %f1813, %r99;
	mov.b32 	 %f1814, %r100;
	mov.b32 	 %f1815, %r101;
	mov.b32 	 %f1816, %r102;
	setp.leu.f32	%p7, %f37, 0f00000000;
	@%p7 bra 	BB3_14;

	cvt.rmi.f32.f32	%f1787, %f710;
	cvt.rzi.s32.f32	%r644, %f1787;
	cvt.s64.s32	%rd665, %r644;
	shl.b64 	%rd125, %rd665, 6;
	add.s64 	%rd126, %rd125, %rd68;
	add.s64 	%rd114, %rd126, 96;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd113];
	// inline asm
	mov.b32 	 %f712, %r106;
	mov.b32 	 %f713, %r107;
	mov.b32 	 %f714, %r108;
	mov.b32 	 %f715, %r109;
	add.s64 	%rd117, %rd126, 112;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd116];
	// inline asm
	mov.b32 	 %f716, %r110;
	mov.b32 	 %f717, %r111;
	mov.b32 	 %f718, %r112;
	mov.b32 	 %f719, %r113;
	add.s64 	%rd120, %rd126, 128;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd119];
	// inline asm
	mov.b32 	 %f720, %r114;
	mov.b32 	 %f721, %r115;
	mov.b32 	 %f722, %r116;
	mov.b32 	 %f723, %r117;
	add.s64 	%rd123, %rd126, 144;
	// inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd122];
	// inline asm
	mov.f32 	%f724, 0f3F800000;
	sub.f32 	%f725, %f724, %f37;
	mul.f32 	%f726, %f37, %f712;
	mul.f32 	%f727, %f37, %f713;
	mul.f32 	%f728, %f37, %f714;
	mul.f32 	%f729, %f37, %f715;
	fma.rn.f32 	%f1801, %f725, %f1801, %f726;
	fma.rn.f32 	%f1802, %f725, %f1802, %f727;
	fma.rn.f32 	%f1803, %f725, %f1803, %f728;
	fma.rn.f32 	%f1804, %f725, %f1804, %f729;
	mul.f32 	%f730, %f37, %f716;
	mul.f32 	%f731, %f37, %f717;
	mul.f32 	%f732, %f37, %f718;
	mul.f32 	%f733, %f37, %f719;
	fma.rn.f32 	%f1805, %f725, %f1805, %f730;
	fma.rn.f32 	%f1806, %f725, %f1806, %f731;
	fma.rn.f32 	%f1807, %f725, %f1807, %f732;
	fma.rn.f32 	%f1808, %f725, %f1808, %f733;
	mul.f32 	%f734, %f37, %f720;
	mul.f32 	%f735, %f37, %f721;
	mul.f32 	%f736, %f37, %f722;
	mul.f32 	%f737, %f37, %f723;
	fma.rn.f32 	%f1809, %f725, %f1809, %f734;
	fma.rn.f32 	%f738, %f725, %f1810, %f735;
	fma.rn.f32 	%f739, %f725, %f1811, %f736;
	fma.rn.f32 	%f740, %f725, %f1812, %f737;
	mov.b32 	 %f741, %r118;
	mov.b32 	 %f742, %r119;
	mov.b32 	 %f743, %r120;
	mov.b32 	 %f744, %r121;
	mul.f32 	%f745, %f37, %f741;
	mul.f32 	%f746, %f37, %f742;
	mul.f32 	%f747, %f37, %f743;
	mul.f32 	%f748, %f37, %f744;
	fma.rn.f32 	%f749, %f725, %f1813, %f745;
	fma.rn.f32 	%f1814, %f725, %f1814, %f746;
	fma.rn.f32 	%f1815, %f725, %f1815, %f747;
	fma.rn.f32 	%f1816, %f725, %f1816, %f748;
	mul.f32 	%f750, %f739, %f739;
	fma.rn.f32 	%f751, %f738, %f738, %f750;
	fma.rn.f32 	%f752, %f740, %f740, %f751;
	fma.rn.f32 	%f753, %f749, %f749, %f752;
	sqrt.rn.f32 	%f754, %f753;
	rcp.rn.f32 	%f755, %f754;
	mul.f32 	%f1810, %f738, %f755;
	mul.f32 	%f1811, %f739, %f755;
	mul.f32 	%f1812, %f740, %f755;
	mul.f32 	%f1813, %f749, %f755;

BB3_14:
	mul.f32 	%f756, %f1811, %f1811;
	fma.rn.f32 	%f757, %f1810, %f1810, %f756;
	fma.rn.f32 	%f758, %f1812, %f1812, %f757;
	fma.rn.f32 	%f759, %f1813, %f1813, %f758;
	rcp.rn.f32 	%f760, %f759;
	mul.f32 	%f761, %f1810, %f760;
	mul.f32 	%f762, %f1811, %f760;
	mul.f32 	%f763, %f1812, %f760;
	mul.f32 	%f764, %f1813, %f760;
	mul.f32 	%f765, %f1810, %f761;
	mul.f32 	%f766, %f1811, %f762;
	mul.f32 	%f767, %f1812, %f763;
	mul.f32 	%f768, %f1810, %f762;
	mul.f32 	%f769, %f1812, %f764;
	mul.f32 	%f770, %f1810, %f763;
	mul.f32 	%f771, %f1811, %f764;
	mul.f32 	%f772, %f1811, %f763;
	mul.f32 	%f773, %f1810, %f764;
	sub.f32 	%f774, %f765, %f766;
	sub.f32 	%f775, %f774, %f767;
	fma.rn.f32 	%f776, %f1813, %f764, %f775;
	sub.f32 	%f777, %f768, %f769;
	add.f32 	%f778, %f777, %f777;
	add.f32 	%f779, %f770, %f771;
	add.f32 	%f780, %f779, %f779;
	add.f32 	%f781, %f768, %f769;
	add.f32 	%f782, %f781, %f781;
	sub.f32 	%f783, %f766, %f765;
	sub.f32 	%f784, %f783, %f767;
	fma.rn.f32 	%f785, %f1813, %f764, %f784;
	sub.f32 	%f786, %f772, %f773;
	add.f32 	%f787, %f786, %f786;
	sub.f32 	%f788, %f770, %f771;
	add.f32 	%f789, %f788, %f788;
	add.f32 	%f790, %f772, %f773;
	add.f32 	%f791, %f790, %f790;
	neg.f32 	%f792, %f765;
	sub.f32 	%f793, %f792, %f766;
	add.f32 	%f794, %f767, %f793;
	fma.rn.f32 	%f795, %f1813, %f764, %f794;
	mul.f32 	%f796, %f1804, %f776;
	fma.rn.f32 	%f797, %f1807, %f778, %f796;
	fma.rn.f32 	%f798, %f1809, %f780, %f797;
	sub.f32 	%f1817, %f1814, %f798;
	mul.f32 	%f799, %f1807, %f785;
	fma.rn.f32 	%f800, %f1804, %f782, %f799;
	fma.rn.f32 	%f801, %f1809, %f787, %f800;
	sub.f32 	%f1821, %f1815, %f801;
	mul.f32 	%f802, %f1807, %f791;
	fma.rn.f32 	%f803, %f1804, %f789, %f802;
	fma.rn.f32 	%f804, %f1809, %f795, %f803;
	sub.f32 	%f1825, %f1816, %f804;
	mul.f32 	%f805, %f1803, %f776;
	fma.rn.f32 	%f806, %f1806, %f778, %f805;
	fma.rn.f32 	%f1818, %f1808, %f780, %f806;
	mul.f32 	%f807, %f1806, %f785;
	fma.rn.f32 	%f808, %f1803, %f782, %f807;
	fma.rn.f32 	%f1822, %f1808, %f787, %f808;
	mul.f32 	%f809, %f1806, %f791;
	fma.rn.f32 	%f810, %f1803, %f789, %f809;
	fma.rn.f32 	%f1826, %f1808, %f795, %f810;
	mul.f32 	%f811, %f1802, %f776;
	fma.rn.f32 	%f1819, %f1805, %f778, %f811;
	mul.f32 	%f812, %f1805, %f785;
	fma.rn.f32 	%f1823, %f1802, %f782, %f812;
	mul.f32 	%f813, %f1805, %f791;
	fma.rn.f32 	%f1827, %f1802, %f789, %f813;
	mul.f32 	%f1820, %f1801, %f776;
	mul.f32 	%f1824, %f1801, %f782;
	mul.f32 	%f1828, %f1801, %f789;

BB3_17:
	mul.f32 	%f851, %f1822, %f1827;
	mul.f32 	%f852, %f1823, %f1826;
	sub.f32 	%f853, %f852, %f851;
	mul.f32 	%f854, %f1820, %f853;
	mul.f32 	%f855, %f1822, %f1828;
	mul.f32 	%f856, %f1824, %f1826;
	sub.f32 	%f857, %f856, %f855;
	mul.f32 	%f858, %f1819, %f857;
	sub.f32 	%f859, %f854, %f858;
	mul.f32 	%f860, %f1823, %f1828;
	mul.f32 	%f861, %f1824, %f1827;
	sub.f32 	%f862, %f861, %f860;
	fma.rn.f32 	%f863, %f1818, %f862, %f859;
	rcp.rn.f32 	%f864, %f863;
	mul.f32 	%f1832, %f864, %f853;
	mul.f32 	%f865, %f1819, %f1826;
	mul.f32 	%f866, %f1818, %f1827;
	sub.f32 	%f867, %f866, %f865;
	mul.f32 	%f1831, %f864, %f867;
	mul.f32 	%f868, %f1818, %f1823;
	mul.f32 	%f869, %f1819, %f1822;
	sub.f32 	%f870, %f869, %f868;
	mul.f32 	%f1830, %f870, %f864;
	sub.f32 	%f871, %f855, %f856;
	mul.f32 	%f1836, %f864, %f871;
	mul.f32 	%f872, %f1818, %f1828;
	mul.f32 	%f873, %f1820, %f1826;
	sub.f32 	%f874, %f873, %f872;
	mul.f32 	%f1835, %f864, %f874;
	mul.f32 	%f875, %f1820, %f1822;
	mul.f32 	%f876, %f1818, %f1824;
	sub.f32 	%f877, %f876, %f875;
	mul.f32 	%f1834, %f877, %f864;
	mul.f32 	%f1840, %f864, %f862;
	mul.f32 	%f878, %f1820, %f1827;
	mul.f32 	%f879, %f1819, %f1828;
	sub.f32 	%f880, %f879, %f878;
	mul.f32 	%f1839, %f864, %f880;
	mul.f32 	%f881, %f1819, %f1824;
	mul.f32 	%f882, %f1820, %f1823;
	sub.f32 	%f883, %f882, %f881;
	mul.f32 	%f1838, %f883, %f864;
	mul.f32 	%f884, %f1817, %f1832;
	neg.f32 	%f885, %f884;
	mul.f32 	%f886, %f1821, %f1831;
	sub.f32 	%f887, %f885, %f886;
	mul.f32 	%f888, %f1825, %f1830;
	sub.f32 	%f1829, %f887, %f888;
	mul.f32 	%f889, %f1817, %f1836;
	neg.f32 	%f890, %f889;
	mul.f32 	%f891, %f1821, %f1835;
	sub.f32 	%f892, %f890, %f891;
	mul.f32 	%f893, %f1825, %f1834;
	sub.f32 	%f1833, %f892, %f893;
	mul.f32 	%f894, %f1817, %f1840;
	neg.f32 	%f895, %f894;
	mul.f32 	%f896, %f1821, %f1839;
	sub.f32 	%f897, %f895, %f896;
	mul.f32 	%f898, %f1825, %f1838;
	sub.f32 	%f1837, %f897, %f898;
	bra.uni 	BB3_18;

BB3_7:
	setp.ne.s32	%p5, %r33, 1;
	mov.f32 	%f1830, %f1829;
	mov.f32 	%f1831, %f1829;
	mov.f32 	%f1833, %f1829;
	mov.f32 	%f1834, %f1829;
	mov.f32 	%f1835, %f1832;
	mov.f32 	%f1836, %f1829;
	mov.f32 	%f1837, %f1829;
	mov.f32 	%f1838, %f1832;
	mov.f32 	%f1839, %f1829;
	mov.f32 	%f1840, %f1829;
	@%p5 bra 	BB3_18;

	// inline asm
	call (%rd55), _optix_get_static_transform_from_handle, (%rd53);
	// inline asm
	add.s64 	%rd667, %rd55, 64;

BB3_10:
	// inline asm
	cvta.to.global.u64 %rd59, %rd667;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd59];
	// inline asm
	mov.b32 	 %f1832, %r35;
	mov.b32 	 %f1831, %r36;
	mov.b32 	 %f1830, %r37;
	mov.b32 	 %f1829, %r38;
	add.s64 	%rd63, %rd667, 16;
	// inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd62];
	// inline asm
	mov.b32 	 %f1836, %r39;
	mov.b32 	 %f1835, %r40;
	mov.b32 	 %f1834, %r41;
	mov.b32 	 %f1833, %r42;
	add.s64 	%rd66, %rd667, 32;
	// inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd65];
	// inline asm
	mov.b32 	 %f1840, %r43;
	mov.b32 	 %f1839, %r44;
	mov.b32 	 %f1838, %r45;
	mov.b32 	 %f1837, %r46;

BB3_18:
	setp.eq.s32	%p9, %r646, 0;
	@%p9 bra 	BB3_19;
	bra.uni 	BB3_20;

BB3_19:
	mov.f32 	%f1800, %f1829;
	mov.f32 	%f1799, %f1830;
	mov.f32 	%f1798, %f1831;
	mov.f32 	%f1797, %f1832;
	mov.f32 	%f1796, %f1833;
	mov.f32 	%f1795, %f1834;
	mov.f32 	%f1794, %f1835;
	mov.f32 	%f1793, %f1836;
	mov.f32 	%f1792, %f1837;
	mov.f32 	%f1791, %f1838;
	mov.f32 	%f1790, %f1839;
	mov.f32 	%f1789, %f1840;
	bra.uni 	BB3_21;

BB3_20:
	mul.f32 	%f899, %f1797, %f1832;
	fma.rn.f32 	%f900, %f1793, %f1831, %f899;
	fma.rn.f32 	%f151, %f1789, %f1830, %f900;
	mul.f32 	%f901, %f1798, %f1832;
	fma.rn.f32 	%f902, %f1794, %f1831, %f901;
	fma.rn.f32 	%f152, %f1790, %f1830, %f902;
	mul.f32 	%f903, %f1799, %f1832;
	fma.rn.f32 	%f904, %f1795, %f1831, %f903;
	fma.rn.f32 	%f153, %f1791, %f1830, %f904;
	mul.f32 	%f905, %f1800, %f1832;
	fma.rn.f32 	%f906, %f1796, %f1831, %f905;
	fma.rn.f32 	%f907, %f1792, %f1830, %f906;
	add.f32 	%f154, %f1829, %f907;
	mul.f32 	%f908, %f1797, %f1836;
	fma.rn.f32 	%f909, %f1793, %f1835, %f908;
	fma.rn.f32 	%f155, %f1789, %f1834, %f909;
	mul.f32 	%f910, %f1798, %f1836;
	fma.rn.f32 	%f911, %f1794, %f1835, %f910;
	fma.rn.f32 	%f156, %f1790, %f1834, %f911;
	mul.f32 	%f912, %f1799, %f1836;
	fma.rn.f32 	%f913, %f1795, %f1835, %f912;
	fma.rn.f32 	%f157, %f1791, %f1834, %f913;
	mul.f32 	%f914, %f1800, %f1836;
	fma.rn.f32 	%f915, %f1796, %f1835, %f914;
	fma.rn.f32 	%f916, %f1792, %f1834, %f915;
	add.f32 	%f158, %f1833, %f916;
	mul.f32 	%f917, %f1797, %f1840;
	fma.rn.f32 	%f918, %f1793, %f1839, %f917;
	fma.rn.f32 	%f1789, %f1789, %f1838, %f918;
	mul.f32 	%f919, %f1798, %f1840;
	fma.rn.f32 	%f920, %f1794, %f1839, %f919;
	fma.rn.f32 	%f1790, %f1790, %f1838, %f920;
	mul.f32 	%f921, %f1799, %f1840;
	fma.rn.f32 	%f922, %f1795, %f1839, %f921;
	fma.rn.f32 	%f1791, %f1791, %f1838, %f922;
	mul.f32 	%f923, %f1800, %f1840;
	fma.rn.f32 	%f924, %f1796, %f1839, %f923;
	fma.rn.f32 	%f925, %f1792, %f1838, %f924;
	add.f32 	%f1792, %f1837, %f925;
	mov.f32 	%f1800, %f154;
	mov.f32 	%f1799, %f153;
	mov.f32 	%f1798, %f152;
	mov.f32 	%f1797, %f151;
	mov.f32 	%f1796, %f158;
	mov.f32 	%f1795, %f157;
	mov.f32 	%f1794, %f156;
	mov.f32 	%f1793, %f155;

BB3_21:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32	%p10, %r646, %r30;
	@%p10 bra 	BB3_5;

	mul.f32 	%f926, %f684, %f1797;
	fma.rn.f32 	%f927, %f685, %f1798, %f926;
	fma.rn.f32 	%f928, %f1853, %f1799, %f927;
	add.f32 	%f1855, %f1800, %f928;
	mul.f32 	%f929, %f684, %f1793;
	fma.rn.f32 	%f930, %f685, %f1794, %f929;
	fma.rn.f32 	%f931, %f1853, %f1795, %f930;
	add.f32 	%f1854, %f1796, %f931;
	mul.f32 	%f932, %f684, %f1789;
	fma.rn.f32 	%f933, %f685, %f1790, %f932;
	fma.rn.f32 	%f934, %f1853, %f1791, %f933;
	add.f32 	%f1853, %f1792, %f934;
	bra.uni 	BB3_23;

BB3_3:
	mov.f32 	%f1854, %f685;
	mov.f32 	%f1855, %f684;

BB3_23:
	// inline asm
	call (%f935), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f936), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1904), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f938), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r647, 0;
	@%p2 bra 	BB3_24;

BB3_25:
	.pragma "nounroll";
	// inline asm
	call (%rd174), _optix_get_transform_list_handle, (%r647);
	// inline asm
	// inline asm
	call (%r183), _optix_get_transform_type_from_handle, (%rd174);
	// inline asm
	and.b32  	%r184, %r183, -2;
	setp.eq.s32	%p12, %r184, 2;
	@%p12 bra 	BB3_31;
	bra.uni 	BB3_26;

BB3_31:
	setp.eq.s32	%p15, %r183, 2;
	@%p15 bra 	BB3_35;
	bra.uni 	BB3_32;

BB3_35:
	// inline asm
	call (%rd248), _optix_get_matrix_motion_transform_from_handle, (%rd174);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd250, %rd248;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd250];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r274;
	add.s64 	%rd254, %rd248, 16;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd253];
	// inline asm
	add.s64 	%rd257, %rd248, 32;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd256];
	// inline asm
	add.s64 	%rd260, %rd248, 48;
	// inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd259];
	// inline asm
	add.s64 	%rd263, %rd248, 64;
	// inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd262];
	// inline asm
	add.s64 	%rd266, %rd248, 80;
	// inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd265];
	// inline asm
	add.s64 	%rd269, %rd248, 96;
	// inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd268];
	// inline asm
	add.s64 	%rd272, %rd248, 112;
	// inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r300,%r301,%r302,%r303}, [%rd271];
	// inline asm
	mov.b32 	 %f1041, %r275;
	mov.b32 	 %f1042, %r276;
	cvt.u32.u16	%r316, %rs8;
	add.s32 	%r317, %r316, -1;
	cvt.rn.f32.s32	%f1043, %r317;
	sub.f32 	%f1044, %f938, %f1041;
	mul.f32 	%f1045, %f1044, %f1043;
	sub.f32 	%f1046, %f1042, %f1041;
	div.rn.f32 	%f1047, %f1045, %f1046;
	min.f32 	%f1048, %f1043, %f1047;
	mov.f32 	%f1049, 0f00000000;
	max.f32 	%f1050, %f1049, %f1048;
	cvt.rmi.f32.f32	%f1051, %f1050;
	cvt.rzi.s32.f32	%r318, %f1051;
	cvt.s64.s32	%rd19, %r318;
	mul.wide.s32 	%rd283, %r318, 48;
	add.s64 	%rd275, %rd257, %rd283;
	// inline asm
	cvta.to.global.u64 %rd274, %rd275;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r304,%r305,%r306,%r307}, [%rd274];
	// inline asm
	mov.b32 	 %f1881, %r304;
	mov.b32 	 %f1882, %r305;
	mov.b32 	 %f1883, %r306;
	add.s64 	%rd278, %rd275, 16;
	// inline asm
	cvta.to.global.u64 %rd277, %rd278;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r308,%r309,%r310,%r311}, [%rd277];
	// inline asm
	mov.b32 	 %f1878, %r308;
	mov.b32 	 %f1879, %r309;
	mov.b32 	 %f1880, %r310;
	add.s64 	%rd281, %rd275, 32;
	// inline asm
	cvta.to.global.u64 %rd280, %rd281;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r312,%r313,%r314,%r315}, [%rd280];
	// inline asm
	sub.f32 	%f249, %f1050, %f1051;
	mov.b32 	 %f1875, %r312;
	mov.b32 	 %f1876, %r313;
	mov.b32 	 %f1877, %r314;
	setp.leu.f32	%p17, %f249, 0f00000000;
	@%p17 bra 	BB3_37;

	mul.lo.s64 	%rd293, %rd19, 48;
	add.s64 	%rd294, %rd248, %rd293;
	add.s64 	%rd285, %rd294, 80;
	// inline asm
	cvta.to.global.u64 %rd284, %rd285;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd284];
	// inline asm
	mov.b32 	 %f1052, %r319;
	mov.b32 	 %f1053, %r320;
	mov.b32 	 %f1054, %r321;
	add.s64 	%rd288, %rd294, 96;
	// inline asm
	cvta.to.global.u64 %rd287, %rd288;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r323,%r324,%r325,%r326}, [%rd287];
	// inline asm
	mov.b32 	 %f1055, %r323;
	mov.b32 	 %f1056, %r324;
	mov.b32 	 %f1057, %r325;
	add.s64 	%rd291, %rd294, 112;
	// inline asm
	cvta.to.global.u64 %rd290, %rd291;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r327,%r328,%r329,%r330}, [%rd290];
	// inline asm
	mov.f32 	%f1058, 0f3F800000;
	sub.f32 	%f1059, %f1058, %f249;
	mul.f32 	%f1060, %f249, %f1052;
	mul.f32 	%f1061, %f249, %f1053;
	mul.f32 	%f1062, %f249, %f1054;
	fma.rn.f32 	%f1881, %f1059, %f1881, %f1060;
	fma.rn.f32 	%f1882, %f1059, %f1882, %f1061;
	fma.rn.f32 	%f1883, %f1059, %f1883, %f1062;
	mul.f32 	%f1063, %f249, %f1055;
	mul.f32 	%f1064, %f249, %f1056;
	mul.f32 	%f1065, %f249, %f1057;
	fma.rn.f32 	%f1878, %f1059, %f1878, %f1063;
	fma.rn.f32 	%f1879, %f1059, %f1879, %f1064;
	fma.rn.f32 	%f1880, %f1059, %f1880, %f1065;
	mov.b32 	 %f1066, %r327;
	mov.b32 	 %f1067, %r328;
	mov.b32 	 %f1068, %r329;
	mul.f32 	%f1069, %f249, %f1066;
	mul.f32 	%f1070, %f249, %f1067;
	mul.f32 	%f1071, %f249, %f1068;
	fma.rn.f32 	%f1875, %f1059, %f1875, %f1069;
	fma.rn.f32 	%f1876, %f1059, %f1876, %f1070;
	fma.rn.f32 	%f1877, %f1059, %f1877, %f1071;
	bra.uni 	BB3_37;

BB3_26:
	mov.f32 	%f1884, 0f00000000;
	mov.f32 	%f1886, 0f3F800000;
	setp.eq.s32	%p13, %r183, 4;
	@%p13 bra 	BB3_29;
	bra.uni 	BB3_27;

BB3_29:
	// inline asm
	call (%rd668), _optix_get_instance_inverse_transform_from_handle, (%rd174);
	// inline asm
	bra.uni 	BB3_30;

BB3_32:
	// inline asm
	call (%rd189), _optix_get_srt_motion_transform_from_handle, (%rd174);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd191, %rd189;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd191];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r199;
	add.s64 	%rd195, %rd189, 16;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd194];
	// inline asm
	add.s64 	%rd198, %rd189, 32;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd197];
	// inline asm
	add.s64 	%rd201, %rd189, 48;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd200];
	// inline asm
	add.s64 	%rd204, %rd189, 64;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd203];
	// inline asm
	add.s64 	%rd207, %rd189, 80;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd206];
	// inline asm
	add.s64 	%rd210, %rd189, 96;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd209];
	// inline asm
	add.s64 	%rd213, %rd189, 112;
	// inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd212];
	// inline asm
	add.s64 	%rd216, %rd189, 128;
	// inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd215];
	// inline asm
	add.s64 	%rd219, %rd189, 144;
	// inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd218];
	// inline asm
	mov.b32 	 %f949, %r200;
	mov.b32 	 %f950, %r201;
	cvt.u32.u16	%r253, %rs6;
	add.s32 	%r254, %r253, -1;
	cvt.rn.f32.s32	%f951, %r254;
	sub.f32 	%f952, %f938, %f949;
	mul.f32 	%f953, %f952, %f951;
	sub.f32 	%f954, %f950, %f949;
	div.rn.f32 	%f955, %f953, %f954;
	min.f32 	%f956, %f951, %f955;
	mov.f32 	%f957, 0f00000000;
	max.f32 	%f958, %f957, %f956;
	cvt.rmi.f32.f32	%f959, %f958;
	cvt.rzi.s32.f32	%r255, %f959;
	cvt.s64.s32	%rd17, %r255;
	mul.wide.s32 	%rd233, %r255, 64;
	add.s64 	%rd222, %rd198, %rd233;
	// inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r237,%r238,%r239,%r240}, [%rd221];
	// inline asm
	mov.b32 	 %f1865, %r237;
	mov.b32 	 %f1866, %r238;
	mov.b32 	 %f1867, %r239;
	add.s64 	%rd225, %rd222, 16;
	// inline asm
	cvta.to.global.u64 %rd224, %rd225;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r241,%r242,%r243,%r244}, [%rd224];
	// inline asm
	mov.b32 	 %f1868, %r241;
	mov.b32 	 %f1869, %r242;
	mov.b32 	 %f1870, %r244;
	add.s64 	%rd228, %rd222, 32;
	// inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r245,%r246,%r247,%r248}, [%rd227];
	// inline asm
	sub.f32 	%f209, %f958, %f959;
	mov.b32 	 %f1871, %r246;
	mov.b32 	 %f1872, %r247;
	mov.b32 	 %f1873, %r248;
	add.s64 	%rd231, %rd222, 48;
	// inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r249,%r250,%r251,%r252}, [%rd230];
	// inline asm
	mov.b32 	 %f1874, %r249;
	setp.leu.f32	%p16, %f209, 0f00000000;
	@%p16 bra 	BB3_34;

	shl.b64 	%rd246, %rd17, 6;
	add.s64 	%rd247, %rd246, %rd189;
	add.s64 	%rd235, %rd247, 96;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd234];
	// inline asm
	mov.b32 	 %f960, %r256;
	mov.b32 	 %f961, %r257;
	mov.b32 	 %f962, %r258;
	add.s64 	%rd238, %rd247, 112;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd237];
	// inline asm
	mov.b32 	 %f963, %r260;
	mov.b32 	 %f964, %r261;
	mov.b32 	 %f965, %r263;
	add.s64 	%rd241, %rd247, 128;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd240];
	// inline asm
	mov.b32 	 %f966, %r265;
	mov.b32 	 %f967, %r266;
	mov.b32 	 %f968, %r267;
	add.s64 	%rd244, %rd247, 144;
	// inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd243];
	// inline asm
	mov.f32 	%f969, 0f3F800000;
	sub.f32 	%f970, %f969, %f209;
	mul.f32 	%f971, %f209, %f960;
	mul.f32 	%f972, %f209, %f961;
	mul.f32 	%f973, %f209, %f962;
	fma.rn.f32 	%f1865, %f970, %f1865, %f971;
	fma.rn.f32 	%f1866, %f970, %f1866, %f972;
	fma.rn.f32 	%f1867, %f970, %f1867, %f973;
	mul.f32 	%f974, %f209, %f963;
	mul.f32 	%f975, %f209, %f964;
	mul.f32 	%f976, %f209, %f965;
	fma.rn.f32 	%f1868, %f970, %f1868, %f974;
	fma.rn.f32 	%f1869, %f970, %f1869, %f975;
	fma.rn.f32 	%f1870, %f970, %f1870, %f976;
	mul.f32 	%f977, %f209, %f966;
	mul.f32 	%f978, %f209, %f967;
	mul.f32 	%f979, %f209, %f968;
	fma.rn.f32 	%f980, %f970, %f1871, %f977;
	fma.rn.f32 	%f981, %f970, %f1872, %f978;
	fma.rn.f32 	%f982, %f970, %f1873, %f979;
	mov.b32 	 %f983, %r268;
	mul.f32 	%f984, %f209, %f983;
	fma.rn.f32 	%f985, %f970, %f1874, %f984;
	mul.f32 	%f986, %f981, %f981;
	fma.rn.f32 	%f987, %f980, %f980, %f986;
	fma.rn.f32 	%f988, %f982, %f982, %f987;
	fma.rn.f32 	%f989, %f985, %f985, %f988;
	sqrt.rn.f32 	%f990, %f989;
	rcp.rn.f32 	%f991, %f990;
	mul.f32 	%f1871, %f980, %f991;
	mul.f32 	%f1872, %f981, %f991;
	mul.f32 	%f1873, %f982, %f991;
	mul.f32 	%f1874, %f985, %f991;

BB3_34:
	mul.f32 	%f992, %f1872, %f1872;
	fma.rn.f32 	%f993, %f1871, %f1871, %f992;
	fma.rn.f32 	%f994, %f1873, %f1873, %f993;
	fma.rn.f32 	%f995, %f1874, %f1874, %f994;
	rcp.rn.f32 	%f996, %f995;
	mul.f32 	%f997, %f1871, %f996;
	mul.f32 	%f998, %f1872, %f996;
	mul.f32 	%f999, %f1873, %f996;
	mul.f32 	%f1000, %f1874, %f996;
	mul.f32 	%f1001, %f1871, %f997;
	mul.f32 	%f1002, %f1872, %f998;
	mul.f32 	%f1003, %f1873, %f999;
	mul.f32 	%f1004, %f1871, %f998;
	mul.f32 	%f1005, %f1873, %f1000;
	mul.f32 	%f1006, %f1871, %f999;
	mul.f32 	%f1007, %f1872, %f1000;
	mul.f32 	%f1008, %f1872, %f999;
	mul.f32 	%f1009, %f1871, %f1000;
	sub.f32 	%f1010, %f1001, %f1002;
	sub.f32 	%f1011, %f1010, %f1003;
	fma.rn.f32 	%f1012, %f1874, %f1000, %f1011;
	sub.f32 	%f1013, %f1004, %f1005;
	add.f32 	%f1014, %f1013, %f1013;
	add.f32 	%f1015, %f1006, %f1007;
	add.f32 	%f1016, %f1015, %f1015;
	add.f32 	%f1017, %f1004, %f1005;
	add.f32 	%f1018, %f1017, %f1017;
	sub.f32 	%f1019, %f1002, %f1001;
	sub.f32 	%f1020, %f1019, %f1003;
	fma.rn.f32 	%f1021, %f1874, %f1000, %f1020;
	sub.f32 	%f1022, %f1008, %f1009;
	add.f32 	%f1023, %f1022, %f1022;
	sub.f32 	%f1024, %f1006, %f1007;
	add.f32 	%f1025, %f1024, %f1024;
	add.f32 	%f1026, %f1008, %f1009;
	add.f32 	%f1027, %f1026, %f1026;
	neg.f32 	%f1028, %f1001;
	sub.f32 	%f1029, %f1028, %f1002;
	add.f32 	%f1030, %f1003, %f1029;
	fma.rn.f32 	%f1031, %f1874, %f1000, %f1030;
	mul.f32 	%f1032, %f1867, %f1012;
	fma.rn.f32 	%f1033, %f1869, %f1014, %f1032;
	fma.rn.f32 	%f1883, %f1870, %f1016, %f1033;
	mul.f32 	%f1034, %f1869, %f1021;
	fma.rn.f32 	%f1035, %f1867, %f1018, %f1034;
	fma.rn.f32 	%f1880, %f1870, %f1023, %f1035;
	mul.f32 	%f1036, %f1869, %f1027;
	fma.rn.f32 	%f1037, %f1867, %f1025, %f1036;
	fma.rn.f32 	%f1877, %f1870, %f1031, %f1037;
	mul.f32 	%f1038, %f1866, %f1012;
	fma.rn.f32 	%f1882, %f1868, %f1014, %f1038;
	mul.f32 	%f1039, %f1868, %f1021;
	fma.rn.f32 	%f1879, %f1866, %f1018, %f1039;
	mul.f32 	%f1040, %f1868, %f1027;
	fma.rn.f32 	%f1876, %f1866, %f1025, %f1040;
	mul.f32 	%f1881, %f1865, %f1012;
	mul.f32 	%f1878, %f1865, %f1018;
	mul.f32 	%f1875, %f1865, %f1025;

BB3_37:
	mul.f32 	%f1072, %f1876, %f1880;
	mul.f32 	%f1073, %f1877, %f1879;
	sub.f32 	%f1074, %f1073, %f1072;
	mul.f32 	%f1075, %f1881, %f1074;
	mul.f32 	%f1076, %f1875, %f1880;
	mul.f32 	%f1077, %f1877, %f1878;
	sub.f32 	%f1078, %f1077, %f1076;
	mul.f32 	%f1079, %f1078, %f1882;
	sub.f32 	%f1080, %f1075, %f1079;
	mul.f32 	%f1081, %f1875, %f1879;
	mul.f32 	%f1082, %f1876, %f1878;
	sub.f32 	%f1083, %f1082, %f1081;
	fma.rn.f32 	%f1084, %f1083, %f1883, %f1080;
	rcp.rn.f32 	%f1085, %f1084;
	mul.f32 	%f1890, %f1074, %f1085;
	mul.f32 	%f1086, %f1877, %f1882;
	mul.f32 	%f1087, %f1876, %f1883;
	sub.f32 	%f1088, %f1087, %f1086;
	mul.f32 	%f1891, %f1085, %f1088;
	mul.f32 	%f1089, %f1879, %f1883;
	mul.f32 	%f1090, %f1880, %f1882;
	sub.f32 	%f1091, %f1090, %f1089;
	mul.f32 	%f1892, %f1085, %f1091;
	sub.f32 	%f1092, %f1076, %f1077;
	mul.f32 	%f1887, %f1092, %f1085;
	mul.f32 	%f1093, %f1875, %f1883;
	mul.f32 	%f1094, %f1877, %f1881;
	sub.f32 	%f1095, %f1094, %f1093;
	mul.f32 	%f1888, %f1085, %f1095;
	mul.f32 	%f1096, %f1880, %f1881;
	mul.f32 	%f1097, %f1878, %f1883;
	sub.f32 	%f1098, %f1097, %f1096;
	mul.f32 	%f1889, %f1085, %f1098;
	mul.f32 	%f1884, %f1083, %f1085;
	mul.f32 	%f1099, %f1876, %f1881;
	mul.f32 	%f1100, %f1875, %f1882;
	sub.f32 	%f1101, %f1100, %f1099;
	mul.f32 	%f1885, %f1101, %f1085;
	mul.f32 	%f1102, %f1878, %f1882;
	mul.f32 	%f1103, %f1879, %f1881;
	sub.f32 	%f1104, %f1103, %f1102;
	mul.f32 	%f1886, %f1104, %f1085;
	bra.uni 	BB3_38;

BB3_27:
	setp.ne.s32	%p14, %r183, 1;
	mov.f32 	%f1885, %f1884;
	mov.f32 	%f1887, %f1884;
	mov.f32 	%f1888, %f1886;
	mov.f32 	%f1889, %f1884;
	mov.f32 	%f1890, %f1886;
	mov.f32 	%f1891, %f1884;
	mov.f32 	%f1892, %f1884;
	@%p14 bra 	BB3_38;

	// inline asm
	call (%rd176), _optix_get_static_transform_from_handle, (%rd174);
	// inline asm
	add.s64 	%rd668, %rd176, 64;

BB3_30:
	// inline asm
	cvta.to.global.u64 %rd180, %rd668;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd180];
	// inline asm
	mov.b32 	 %f1890, %r185;
	mov.b32 	 %f1891, %r186;
	mov.b32 	 %f1892, %r187;
	add.s64 	%rd184, %rd668, 16;
	// inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd183];
	// inline asm
	mov.b32 	 %f1887, %r189;
	mov.b32 	 %f1888, %r190;
	mov.b32 	 %f1889, %r191;
	add.s64 	%rd187, %rd668, 32;
	// inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd186];
	// inline asm
	mov.b32 	 %f1884, %r193;
	mov.b32 	 %f1885, %r194;
	mov.b32 	 %f1886, %r195;

BB3_38:
	setp.eq.s32	%p18, %r647, 0;
	@%p18 bra 	BB3_39;
	bra.uni 	BB3_40;

BB3_39:
	mov.f32 	%f1864, %f1884;
	mov.f32 	%f1863, %f1885;
	mov.f32 	%f1862, %f1886;
	mov.f32 	%f1861, %f1887;
	mov.f32 	%f1860, %f1888;
	mov.f32 	%f1859, %f1889;
	mov.f32 	%f1858, %f1890;
	mov.f32 	%f1857, %f1891;
	mov.f32 	%f1856, %f1892;
	bra.uni 	BB3_41;

BB3_40:
	mul.f32 	%f1105, %f1861, %f1891;
	fma.rn.f32 	%f1106, %f1858, %f1890, %f1105;
	fma.rn.f32 	%f289, %f1864, %f1892, %f1106;
	mul.f32 	%f1107, %f1860, %f1891;
	fma.rn.f32 	%f1108, %f1857, %f1890, %f1107;
	fma.rn.f32 	%f290, %f1863, %f1892, %f1108;
	mul.f32 	%f1109, %f1859, %f1891;
	fma.rn.f32 	%f1110, %f1856, %f1890, %f1109;
	fma.rn.f32 	%f291, %f1862, %f1892, %f1110;
	mul.f32 	%f1111, %f1861, %f1888;
	fma.rn.f32 	%f1112, %f1858, %f1887, %f1111;
	fma.rn.f32 	%f292, %f1864, %f1889, %f1112;
	mul.f32 	%f1113, %f1860, %f1888;
	fma.rn.f32 	%f1114, %f1857, %f1887, %f1113;
	fma.rn.f32 	%f293, %f1863, %f1889, %f1114;
	mul.f32 	%f1115, %f1859, %f1888;
	fma.rn.f32 	%f1116, %f1856, %f1887, %f1115;
	fma.rn.f32 	%f294, %f1862, %f1889, %f1116;
	mul.f32 	%f1117, %f1861, %f1885;
	fma.rn.f32 	%f1118, %f1858, %f1884, %f1117;
	fma.rn.f32 	%f1864, %f1864, %f1886, %f1118;
	mul.f32 	%f1119, %f1860, %f1885;
	fma.rn.f32 	%f1120, %f1857, %f1884, %f1119;
	fma.rn.f32 	%f1863, %f1863, %f1886, %f1120;
	mul.f32 	%f1121, %f1859, %f1885;
	fma.rn.f32 	%f1122, %f1856, %f1884, %f1121;
	fma.rn.f32 	%f1862, %f1862, %f1886, %f1122;
	mov.f32 	%f1861, %f292;
	mov.f32 	%f1860, %f293;
	mov.f32 	%f1859, %f294;
	mov.f32 	%f1858, %f289;
	mov.f32 	%f1857, %f290;
	mov.f32 	%f1856, %f291;

BB3_41:
	add.s32 	%r647, %r647, 1;
	setp.lt.u32	%p19, %r647, %r30;
	@%p19 bra 	BB3_25;

	mul.f32 	%f1123, %f936, %f1857;
	fma.rn.f32 	%f1124, %f935, %f1858, %f1123;
	fma.rn.f32 	%f1902, %f1904, %f1856, %f1124;
	mul.f32 	%f1125, %f936, %f1860;
	fma.rn.f32 	%f1126, %f935, %f1861, %f1125;
	fma.rn.f32 	%f1903, %f1904, %f1859, %f1126;
	mul.f32 	%f1127, %f936, %f1863;
	fma.rn.f32 	%f1128, %f935, %f1864, %f1127;
	fma.rn.f32 	%f1904, %f1904, %f1862, %f1128;
	bra.uni 	BB3_43;

BB3_24:
	mov.f32 	%f1902, %f935;
	mov.f32 	%f1903, %f936;

BB3_43:
	ld.v4.f32 	{%f1131, %f1132, %f1133, %f1134}, [%rd3+208];
	ld.v4.f32 	{%f1138, %f1139, %f1140, %f1141}, [%rd3+160];
	fma.rn.f32 	%f1143, %f1855, %f1138, %f1131;
	fma.rn.f32 	%f1145, %f1855, %f1139, %f1132;
	fma.rn.f32 	%f1147, %f1855, %f1140, %f1133;
	ld.v4.f32 	{%f1148, %f1149, %f1150, %f1151}, [%rd3+176];
	fma.rn.f32 	%f1153, %f1854, %f1148, %f1143;
	fma.rn.f32 	%f1155, %f1854, %f1149, %f1145;
	fma.rn.f32 	%f1157, %f1854, %f1150, %f1147;
	ld.v4.f32 	{%f1158, %f1159, %f1160, %f1161}, [%rd3+192];
	fma.rn.f32 	%f1163, %f1853, %f1158, %f1153;
	fma.rn.f32 	%f1165, %f1853, %f1159, %f1155;
	fma.rn.f32 	%f1167, %f1853, %f1160, %f1157;
	mul.f32 	%f1168, %f1902, %f1138;
	mul.f32 	%f1169, %f1902, %f1139;
	mul.f32 	%f1170, %f1902, %f1140;
	fma.rn.f32 	%f1171, %f1903, %f1148, %f1168;
	fma.rn.f32 	%f1172, %f1903, %f1149, %f1169;
	fma.rn.f32 	%f1173, %f1903, %f1150, %f1170;
	fma.rn.f32 	%f1174, %f1904, %f1158, %f1171;
	fma.rn.f32 	%f1175, %f1904, %f1159, %f1172;
	fma.rn.f32 	%f1176, %f1904, %f1160, %f1173;
	rcp.rn.f32 	%f1177, %f1176;
	mul.f32 	%f1178, %f1167, %f1177;
	neg.f32 	%f313, %f1178;
	fma.rn.f32 	%f314, %f313, %f1174, %f1163;
	fma.rn.f32 	%f315, %f313, %f1175, %f1165;
	ld.const.u64 	%rd21, [params+80];
	setp.eq.s64	%p20, %rd21, 0;
	@%p20 bra 	BB3_48;

	ld.u64 	%rd295, [%rd52];
	ld.const.u64 	%rd296, [params+328];
	cvta.to.global.u64 	%rd297, %rd296;
	cvt.u64.u32	%rd22, %r1;
	mul.wide.u32 	%rd298, %r1, 8;
	add.s64 	%rd299, %rd297, %rd298;
	st.global.u64 	[%rd299], %rd295;
	ld.const.u64 	%rd300, [params+336];
	cvta.to.global.u64 	%rd301, %rd300;
	mul.wide.u32 	%rd302, %r1, 4;
	add.s64 	%rd303, %rd301, %rd302;
	mov.u32 	%r331, 0;
	st.global.u32 	[%rd303], %r331;
	ld.const.u64 	%rd304, [params+344];
	cvta.to.global.u64 	%rd305, %rd304;
	add.s64 	%rd23, %rd305, %rd302;
	ld.global.u32 	%r9, [%rd23];
	setp.eq.s32	%p21, %r9, 0;
	@%p21 bra 	BB3_47;

	// inline asm
	call (%r332), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p22, %r332, %r9;
	@%p22 bra 	BB3_47;

	st.global.u32 	[%rd23], %r332;

BB3_47:
	cvta.to.global.u64 	%rd306, %rd21;
	shl.b64 	%rd307, %rd22, 2;
	add.s64 	%rd308, %rd306, %rd307;
	st.global.f32 	[%rd308], %f314;
	ld.const.u64 	%rd309, [params+88];
	cvta.to.global.u64 	%rd310, %rd309;
	add.s64 	%rd311, %rd310, %rd307;
	st.global.f32 	[%rd311], %f315;
	ld.const.u64 	%rd312, [params+72];
	cvta.to.global.u64 	%rd313, %rd312;
	add.s64 	%rd314, %rd313, %rd307;
	st.global.f32 	[%rd314], %f313;
	bra.uni 	BB3_116;

BB3_48:
	fma.rn.f32 	%f2063, %f313, %f1902, %f1855;
	fma.rn.f32 	%f2064, %f313, %f1903, %f1854;
	fma.rn.f32 	%f2065, %f313, %f1904, %f1853;
	ld.v4.f32 	{%f1180, %f1181, %f1182, %f1183}, [%rd3+96];
	mul.f32 	%f1187, %f1180, 0f00000000;
	mul.f32 	%f1188, %f1181, 0f00000000;
	mul.f32 	%f1189, %f1182, 0f00000000;
	ld.v4.f32 	{%f1190, %f1191, %f1192, %f1193}, [%rd3+112];
	mov.f32 	%f2048, 0f00000000;
	fma.rn.f32 	%f1198, %f2048, %f1190, %f1187;
	fma.rn.f32 	%f1199, %f2048, %f1191, %f1188;
	fma.rn.f32 	%f1200, %f2048, %f1192, %f1189;
	ld.v4.f32 	{%f1201, %f1202, %f1203, %f1204}, [%rd3+128];
	mov.f32 	%f1980, 0f3F800000;
	fma.rn.f32 	%f1207, %f1980, %f1201, %f1198;
	fma.rn.f32 	%f1209, %f1980, %f1202, %f1199;
	fma.rn.f32 	%f1211, %f1980, %f1203, %f1200;
	mul.f32 	%f1212, %f1207, %f1207;
	fma.rn.f32 	%f1213, %f1209, %f1209, %f1212;
	fma.rn.f32 	%f1214, %f1211, %f1211, %f1213;
	sqrt.rn.f32 	%f1215, %f1214;
	div.rn.f32 	%f2060, %f1207, %f1215;
	div.rn.f32 	%f2061, %f1209, %f1215;
	div.rn.f32 	%f2062, %f1211, %f1215;
	ld.const.u64 	%rd24, [params+96];
	setp.eq.s64	%p23, %rd24, 0;
	@%p23 bra 	BB3_56;

	mul.f32 	%f1216, %f314, %f314;
	fma.rn.f32 	%f1217, %f315, %f315, %f1216;
	sqrt.rn.f32 	%f1907, %f1217;
	abs.f32 	%f323, %f314;
	setp.eq.f32	%p24, %f323, 0f00000000;
	abs.f32 	%f324, %f315;
	setp.eq.f32	%p25, %f324, 0f00000000;
	and.pred  	%p26, %p24, %p25;
	mov.b32 	 %r11, %f314;
	mov.b32 	 %r333, %f315;
	and.b32  	%r12, %r333, -2147483648;
	@%p26 bra 	BB3_53;
	bra.uni 	BB3_50;

BB3_53:
	shr.s32 	%r340, %r11, 31;
	and.b32  	%r341, %r340, 1078530011;
	or.b32  	%r342, %r341, %r12;
	mov.b32 	 %f1905, %r342;
	bra.uni 	BB3_54;

BB3_50:
	setp.eq.f32	%p27, %f323, 0f7F800000;
	setp.eq.f32	%p28, %f324, 0f7F800000;
	and.pred  	%p29, %p27, %p28;
	@%p29 bra 	BB3_52;
	bra.uni 	BB3_51;

BB3_52:
	shr.s32 	%r336, %r11, 31;
	and.b32  	%r337, %r336, 13483017;
	add.s32 	%r338, %r337, 1061752795;
	or.b32  	%r339, %r338, %r12;
	mov.b32 	 %f1905, %r339;
	bra.uni 	BB3_54;

BB3_51:
	max.f32 	%f1218, %f324, %f323;
	min.f32 	%f1219, %f324, %f323;
	div.rn.f32 	%f1220, %f1219, %f1218;
	mul.rn.f32 	%f1221, %f1220, %f1220;
	mov.f32 	%f1222, 0fC0B59883;
	mov.f32 	%f1223, 0fBF52C7EA;
	fma.rn.f32 	%f1224, %f1221, %f1223, %f1222;
	mov.f32 	%f1225, 0fC0D21907;
	fma.rn.f32 	%f1226, %f1224, %f1221, %f1225;
	mul.f32 	%f1227, %f1221, %f1226;
	mul.f32 	%f1228, %f1220, %f1227;
	add.f32 	%f1229, %f1221, 0f41355DC0;
	mov.f32 	%f1230, 0f41E6BD60;
	fma.rn.f32 	%f1231, %f1229, %f1221, %f1230;
	mov.f32 	%f1232, 0f419D92C8;
	fma.rn.f32 	%f1233, %f1231, %f1221, %f1232;
	rcp.rn.f32 	%f1234, %f1233;
	fma.rn.f32 	%f1235, %f1228, %f1234, %f1220;
	mov.f32 	%f1236, 0f3FC90FDB;
	sub.f32 	%f1237, %f1236, %f1235;
	setp.gt.f32	%p30, %f324, %f323;
	selp.f32	%f1238, %f1237, %f1235, %p30;
	mov.f32 	%f1239, 0f40490FDB;
	sub.f32 	%f1240, %f1239, %f1238;
	setp.lt.s32	%p31, %r11, 0;
	selp.f32	%f1241, %f1240, %f1238, %p31;
	mov.b32 	 %r334, %f1241;
	or.b32  	%r335, %r334, %r12;
	mov.b32 	 %f1242, %r335;
	add.f32 	%f1243, %f323, %f324;
	setp.gtu.f32	%p32, %f1243, 0f7F800000;
	selp.f32	%f1905, %f1243, %f1242, %p32;

BB3_54:
	mul.f32 	%f1245, %f1905, 0f3E22F983;
	setp.lt.f32	%p33, %f1245, 0f00000000;
	add.f32 	%f1246, %f1245, 0f3F800000;
	selp.f32	%f1906, %f1246, %f1245, %p33;
	ld.const.u64 	%rd315, [params+184];
	setp.eq.s64	%p34, %rd315, 0;
	@%p34 bra 	BB3_56;

	rcp.rn.f32 	%f1247, %f1907;
	setp.neu.f32	%p35, %f1907, 0f00000000;
	mul.f32 	%f1248, %f314, %f1247;
	selp.f32	%f1249, %f1248, 0f3F800000, %p35;
	mul.f32 	%f1250, %f315, %f1247;
	selp.f32	%f1251, %f1250, 0f00000000, %p35;
	ld.v4.f32 	{%f1252, %f1253, %f1254, %f1255}, [%rd3+32];
	mul.f32 	%f1259, %f1249, %f1252;
	mul.f32 	%f1260, %f1249, %f1253;
	mul.f32 	%f1261, %f1249, %f1254;
	ld.v4.f32 	{%f1262, %f1263, %f1264, %f1265}, [%rd3+48];
	fma.rn.f32 	%f1269, %f1251, %f1262, %f1259;
	fma.rn.f32 	%f1270, %f1251, %f1263, %f1260;
	fma.rn.f32 	%f1271, %f1251, %f1264, %f1261;
	ld.v4.f32 	{%f1272, %f1273, %f1274, %f1275}, [%rd3+64];
	fma.rn.f32 	%f340, %f2048, %f1272, %f1269;
	fma.rn.f32 	%f339, %f2048, %f1273, %f1270;
	fma.rn.f32 	%f338, %f2048, %f1274, %f1271;
	neg.f32 	%f1280, %f1251;
	mul.f32 	%f1281, %f1252, %f1280;
	mul.f32 	%f1282, %f1253, %f1280;
	mul.f32 	%f1283, %f1254, %f1280;
	fma.rn.f32 	%f1284, %f1249, %f1262, %f1281;
	fma.rn.f32 	%f1285, %f1249, %f1263, %f1282;
	fma.rn.f32 	%f1286, %f1249, %f1264, %f1283;
	fma.rn.f32 	%f343, %f2048, %f1272, %f1284;
	fma.rn.f32 	%f342, %f2048, %f1273, %f1285;
	fma.rn.f32 	%f341, %f2048, %f1274, %f1286;

BB3_56:
	ld.u64 	%rd25, [%rd52];
	ld.const.u64 	%rd316, [params+344];
	cvta.to.global.u64 	%rd317, %rd316;
	cvt.u64.u32	%rd26, %r1;
	mul.wide.u32 	%rd318, %r1, 4;
	add.s64 	%rd27, %rd317, %rd318;
	ld.global.u32 	%r13, [%rd27];
	setp.eq.s32	%p36, %r13, 0;
	@%p36 bra 	BB3_57;

	// inline asm
	call (%r343), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p37, %r343, %r13;
	@%p37 bra 	BB3_57;

	mov.f32 	%f1979, 0f00000000;
	mov.f32 	%f1917, %f1980;
	mov.f32 	%f1916, %f1979;
	mov.f32 	%f1915, %f1979;
	mov.f32 	%f1914, %f1979;
	mov.f32 	%f1921, %f1979;
	mov.f32 	%f1920, %f1980;
	mov.f32 	%f1919, %f1979;
	mov.f32 	%f1918, %f1979;
	mov.f32 	%f1925, %f1979;
	mov.f32 	%f1924, %f1979;
	mov.f32 	%f1923, %f1980;
	mov.f32 	%f1922, %f1979;
	@%p2 bra 	BB3_77;

	add.s32 	%r648, %r30, -1;
	setp.lt.s32	%p39, %r648, 0;
	@%p39 bra 	BB3_77;

BB3_61:
	.pragma "nounroll";
	// inline asm
	call (%rd319), _optix_get_transform_list_handle, (%r648);
	// inline asm
	// inline asm
	call (%r345), _optix_get_transform_type_from_handle, (%rd319);
	// inline asm
	and.b32  	%r346, %r345, -2;
	setp.eq.s32	%p40, %r346, 2;
	@%p40 bra 	BB3_67;
	bra.uni 	BB3_62;

BB3_67:
	setp.eq.s32	%p43, %r345, 2;
	@%p43 bra 	BB3_71;
	bra.uni 	BB3_68;

BB3_71:
	// inline asm
	call (%rd393), _optix_get_matrix_motion_transform_from_handle, (%rd319);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd395, %rd393;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd395];
	// inline asm
	mov.b32	{%rs12, %rs13}, %r436;
	add.s64 	%rd399, %rd393, 16;
	// inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd398];
	// inline asm
	add.s64 	%rd402, %rd393, 32;
	// inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd401];
	// inline asm
	add.s64 	%rd405, %rd393, 48;
	// inline asm
	cvta.to.global.u64 %rd404, %rd405;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd404];
	// inline asm
	add.s64 	%rd408, %rd393, 64;
	// inline asm
	cvta.to.global.u64 %rd407, %rd408;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd407];
	// inline asm
	add.s64 	%rd411, %rd393, 80;
	// inline asm
	cvta.to.global.u64 %rd410, %rd411;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd410];
	// inline asm
	add.s64 	%rd414, %rd393, 96;
	// inline asm
	cvta.to.global.u64 %rd413, %rd414;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd413];
	// inline asm
	add.s64 	%rd417, %rd393, 112;
	// inline asm
	cvta.to.global.u64 %rd416, %rd417;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd416];
	// inline asm
	mov.b32 	 %f1431, %r437;
	mov.b32 	 %f1432, %r438;
	cvt.u32.u16	%r478, %rs12;
	add.s32 	%r479, %r478, -1;
	cvt.rn.f32.s32	%f1433, %r479;
	sub.f32 	%f1434, %f938, %f1431;
	mul.f32 	%f1435, %f1434, %f1433;
	sub.f32 	%f1436, %f1432, %f1431;
	div.rn.f32 	%f1437, %f1435, %f1436;
	min.f32 	%f1438, %f1433, %f1437;
	mov.f32 	%f1439, 0f00000000;
	max.f32 	%f1440, %f1439, %f1438;
	cvt.rmi.f32.f32	%f1441, %f1440;
	cvt.rzi.s32.f32	%r480, %f1441;
	cvt.s64.s32	%rd35, %r480;
	mul.wide.s32 	%rd428, %r480, 48;
	add.s64 	%rd420, %rd402, %rd428;
	// inline asm
	cvta.to.global.u64 %rd419, %rd420;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd419];
	// inline asm
	mov.b32 	 %f1950, %r466;
	mov.b32 	 %f1951, %r467;
	mov.b32 	 %f1952, %r468;
	mov.b32 	 %f1953, %r469;
	add.s64 	%rd423, %rd420, 16;
	// inline asm
	cvta.to.global.u64 %rd422, %rd423;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd422];
	// inline asm
	mov.b32 	 %f1946, %r470;
	mov.b32 	 %f1947, %r471;
	mov.b32 	 %f1948, %r472;
	mov.b32 	 %f1949, %r473;
	add.s64 	%rd426, %rd420, 32;
	// inline asm
	cvta.to.global.u64 %rd425, %rd426;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd425];
	// inline asm
	sub.f32 	%f437, %f1440, %f1441;
	mov.b32 	 %f1942, %r474;
	mov.b32 	 %f1943, %r475;
	mov.b32 	 %f1944, %r476;
	mov.b32 	 %f1945, %r477;
	setp.leu.f32	%p45, %f437, 0f00000000;
	@%p45 bra 	BB3_73;

	mul.lo.s64 	%rd438, %rd35, 48;
	add.s64 	%rd439, %rd393, %rd438;
	add.s64 	%rd430, %rd439, 80;
	// inline asm
	cvta.to.global.u64 %rd429, %rd430;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r481,%r482,%r483,%r484}, [%rd429];
	// inline asm
	mov.b32 	 %f1442, %r481;
	mov.b32 	 %f1443, %r482;
	mov.b32 	 %f1444, %r483;
	mov.b32 	 %f1445, %r484;
	add.s64 	%rd433, %rd439, 96;
	// inline asm
	cvta.to.global.u64 %rd432, %rd433;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r485,%r486,%r487,%r488}, [%rd432];
	// inline asm
	mov.b32 	 %f1446, %r485;
	mov.b32 	 %f1447, %r486;
	mov.b32 	 %f1448, %r487;
	mov.b32 	 %f1449, %r488;
	add.s64 	%rd436, %rd439, 112;
	// inline asm
	cvta.to.global.u64 %rd435, %rd436;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd435];
	// inline asm
	mov.f32 	%f1450, 0f3F800000;
	sub.f32 	%f1451, %f1450, %f437;
	mul.f32 	%f1452, %f437, %f1442;
	mul.f32 	%f1453, %f437, %f1443;
	mul.f32 	%f1454, %f437, %f1444;
	mul.f32 	%f1455, %f437, %f1445;
	fma.rn.f32 	%f1950, %f1451, %f1950, %f1452;
	fma.rn.f32 	%f1951, %f1451, %f1951, %f1453;
	fma.rn.f32 	%f1952, %f1451, %f1952, %f1454;
	fma.rn.f32 	%f1953, %f1451, %f1953, %f1455;
	mul.f32 	%f1456, %f437, %f1446;
	mul.f32 	%f1457, %f437, %f1447;
	mul.f32 	%f1458, %f437, %f1448;
	mul.f32 	%f1459, %f437, %f1449;
	fma.rn.f32 	%f1946, %f1451, %f1946, %f1456;
	fma.rn.f32 	%f1947, %f1451, %f1947, %f1457;
	fma.rn.f32 	%f1948, %f1451, %f1948, %f1458;
	fma.rn.f32 	%f1949, %f1451, %f1949, %f1459;
	mov.b32 	 %f1460, %r489;
	mov.b32 	 %f1461, %r490;
	mov.b32 	 %f1462, %r491;
	mov.b32 	 %f1463, %r492;
	mul.f32 	%f1464, %f437, %f1460;
	mul.f32 	%f1465, %f437, %f1461;
	mul.f32 	%f1466, %f437, %f1462;
	mul.f32 	%f1467, %f437, %f1463;
	fma.rn.f32 	%f1942, %f1451, %f1942, %f1464;
	fma.rn.f32 	%f1943, %f1451, %f1943, %f1465;
	fma.rn.f32 	%f1944, %f1451, %f1944, %f1466;
	fma.rn.f32 	%f1945, %f1451, %f1945, %f1467;
	bra.uni 	BB3_73;

BB3_62:
	mov.f32 	%f1942, 0f00000000;
	mov.f32 	%f1944, 0f3F800000;
	setp.eq.s32	%p41, %r345, 4;
	@%p41 bra 	BB3_65;
	bra.uni 	BB3_63;

BB3_65:
	// inline asm
	call (%rd669), _optix_get_instance_transform_from_handle, (%rd319);
	// inline asm
	bra.uni 	BB3_66;

BB3_68:
	// inline asm
	call (%rd334), _optix_get_srt_motion_transform_from_handle, (%rd319);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd336, %rd334;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd336];
	// inline asm
	mov.b32	{%rs10, %rs11}, %r361;
	add.s64 	%rd340, %rd334, 16;
	// inline asm
	cvta.to.global.u64 %rd339, %rd340;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd339];
	// inline asm
	add.s64 	%rd343, %rd334, 32;
	// inline asm
	cvta.to.global.u64 %rd342, %rd343;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd342];
	// inline asm
	add.s64 	%rd346, %rd334, 48;
	// inline asm
	cvta.to.global.u64 %rd345, %rd346;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd345];
	// inline asm
	add.s64 	%rd349, %rd334, 64;
	// inline asm
	cvta.to.global.u64 %rd348, %rd349;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd348];
	// inline asm
	add.s64 	%rd352, %rd334, 80;
	// inline asm
	cvta.to.global.u64 %rd351, %rd352;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd351];
	// inline asm
	add.s64 	%rd355, %rd334, 96;
	// inline asm
	cvta.to.global.u64 %rd354, %rd355;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd354];
	// inline asm
	add.s64 	%rd358, %rd334, 112;
	// inline asm
	cvta.to.global.u64 %rd357, %rd358;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd357];
	// inline asm
	add.s64 	%rd361, %rd334, 128;
	// inline asm
	cvta.to.global.u64 %rd360, %rd361;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd360];
	// inline asm
	add.s64 	%rd364, %rd334, 144;
	// inline asm
	cvta.to.global.u64 %rd363, %rd364;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd363];
	// inline asm
	mov.b32 	 %f1318, %r362;
	mov.b32 	 %f1319, %r363;
	cvt.u32.u16	%r415, %rs10;
	add.s32 	%r416, %r415, -1;
	cvt.rn.f32.s32	%f1320, %r416;
	sub.f32 	%f1321, %f938, %f1318;
	mul.f32 	%f1322, %f1321, %f1320;
	sub.f32 	%f1323, %f1319, %f1318;
	div.rn.f32 	%f1324, %f1322, %f1323;
	min.f32 	%f1325, %f1320, %f1324;
	mov.f32 	%f1326, 0f00000000;
	max.f32 	%f1327, %f1326, %f1325;
	cvt.rmi.f32.f32	%f1328, %f1327;
	cvt.rzi.s32.f32	%r417, %f1328;
	cvt.s64.s32	%rd33, %r417;
	mul.wide.s32 	%rd378, %r417, 64;
	add.s64 	%rd367, %rd343, %rd378;
	// inline asm
	cvta.to.global.u64 %rd366, %rd367;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd366];
	// inline asm
	mov.b32 	 %f1926, %r399;
	mov.b32 	 %f1927, %r400;
	mov.b32 	 %f1928, %r401;
	mov.b32 	 %f1929, %r402;
	add.s64 	%rd370, %rd367, 16;
	// inline asm
	cvta.to.global.u64 %rd369, %rd370;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd369];
	// inline asm
	mov.b32 	 %f1930, %r403;
	mov.b32 	 %f1931, %r404;
	mov.b32 	 %f1932, %r405;
	mov.b32 	 %f1933, %r406;
	add.s64 	%rd373, %rd367, 32;
	// inline asm
	cvta.to.global.u64 %rd372, %rd373;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd372];
	// inline asm
	sub.f32 	%f376, %f1327, %f1328;
	mov.b32 	 %f1934, %r407;
	mov.b32 	 %f1935, %r408;
	mov.b32 	 %f1936, %r409;
	mov.b32 	 %f1937, %r410;
	add.s64 	%rd376, %rd367, 48;
	// inline asm
	cvta.to.global.u64 %rd375, %rd376;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd375];
	// inline asm
	mov.b32 	 %f1938, %r411;
	mov.b32 	 %f1939, %r412;
	mov.b32 	 %f1940, %r413;
	mov.b32 	 %f1941, %r414;
	setp.leu.f32	%p44, %f376, 0f00000000;
	@%p44 bra 	BB3_70;

	shl.b64 	%rd391, %rd33, 6;
	add.s64 	%rd392, %rd391, %rd334;
	add.s64 	%rd380, %rd392, 96;
	// inline asm
	cvta.to.global.u64 %rd379, %rd380;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r418,%r419,%r420,%r421}, [%rd379];
	// inline asm
	mov.b32 	 %f1329, %r418;
	mov.b32 	 %f1330, %r419;
	mov.b32 	 %f1331, %r420;
	mov.b32 	 %f1332, %r421;
	add.s64 	%rd383, %rd392, 112;
	// inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r422,%r423,%r424,%r425}, [%rd382];
	// inline asm
	mov.b32 	 %f1333, %r422;
	mov.b32 	 %f1334, %r423;
	mov.b32 	 %f1335, %r424;
	mov.b32 	 %f1336, %r425;
	add.s64 	%rd386, %rd392, 128;
	// inline asm
	cvta.to.global.u64 %rd385, %rd386;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd385];
	// inline asm
	mov.b32 	 %f1337, %r426;
	mov.b32 	 %f1338, %r427;
	mov.b32 	 %f1339, %r428;
	mov.b32 	 %f1340, %r429;
	add.s64 	%rd389, %rd392, 144;
	// inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd388];
	// inline asm
	mov.f32 	%f1341, 0f3F800000;
	sub.f32 	%f1342, %f1341, %f376;
	mul.f32 	%f1343, %f376, %f1329;
	mul.f32 	%f1344, %f376, %f1330;
	mul.f32 	%f1345, %f376, %f1331;
	mul.f32 	%f1346, %f376, %f1332;
	fma.rn.f32 	%f1926, %f1342, %f1926, %f1343;
	fma.rn.f32 	%f1927, %f1342, %f1927, %f1344;
	fma.rn.f32 	%f1928, %f1342, %f1928, %f1345;
	fma.rn.f32 	%f1929, %f1342, %f1929, %f1346;
	mul.f32 	%f1347, %f376, %f1333;
	mul.f32 	%f1348, %f376, %f1334;
	mul.f32 	%f1349, %f376, %f1335;
	mul.f32 	%f1350, %f376, %f1336;
	fma.rn.f32 	%f1930, %f1342, %f1930, %f1347;
	fma.rn.f32 	%f1931, %f1342, %f1931, %f1348;
	fma.rn.f32 	%f1932, %f1342, %f1932, %f1349;
	fma.rn.f32 	%f1933, %f1342, %f1933, %f1350;
	mul.f32 	%f1351, %f376, %f1337;
	mul.f32 	%f1352, %f376, %f1338;
	mul.f32 	%f1353, %f376, %f1339;
	mul.f32 	%f1354, %f376, %f1340;
	fma.rn.f32 	%f1934, %f1342, %f1934, %f1351;
	fma.rn.f32 	%f1355, %f1342, %f1935, %f1352;
	fma.rn.f32 	%f1356, %f1342, %f1936, %f1353;
	fma.rn.f32 	%f1357, %f1342, %f1937, %f1354;
	mov.b32 	 %f1358, %r430;
	mov.b32 	 %f1359, %r431;
	mov.b32 	 %f1360, %r432;
	mov.b32 	 %f1361, %r433;
	mul.f32 	%f1362, %f376, %f1358;
	mul.f32 	%f1363, %f376, %f1359;
	mul.f32 	%f1364, %f376, %f1360;
	mul.f32 	%f1365, %f376, %f1361;
	fma.rn.f32 	%f1366, %f1342, %f1938, %f1362;
	fma.rn.f32 	%f1939, %f1342, %f1939, %f1363;
	fma.rn.f32 	%f1940, %f1342, %f1940, %f1364;
	fma.rn.f32 	%f1941, %f1342, %f1941, %f1365;
	mul.f32 	%f1367, %f1356, %f1356;
	fma.rn.f32 	%f1368, %f1355, %f1355, %f1367;
	fma.rn.f32 	%f1369, %f1357, %f1357, %f1368;
	fma.rn.f32 	%f1370, %f1366, %f1366, %f1369;
	sqrt.rn.f32 	%f1371, %f1370;
	rcp.rn.f32 	%f1372, %f1371;
	mul.f32 	%f1935, %f1355, %f1372;
	mul.f32 	%f1936, %f1356, %f1372;
	mul.f32 	%f1937, %f1357, %f1372;
	mul.f32 	%f1938, %f1366, %f1372;

BB3_70:
	mul.f32 	%f1373, %f1936, %f1936;
	fma.rn.f32 	%f1374, %f1935, %f1935, %f1373;
	fma.rn.f32 	%f1375, %f1937, %f1937, %f1374;
	fma.rn.f32 	%f1376, %f1938, %f1938, %f1375;
	rcp.rn.f32 	%f1377, %f1376;
	mul.f32 	%f1378, %f1935, %f1377;
	mul.f32 	%f1379, %f1936, %f1377;
	mul.f32 	%f1380, %f1937, %f1377;
	mul.f32 	%f1381, %f1938, %f1377;
	mul.f32 	%f1382, %f1935, %f1378;
	mul.f32 	%f1383, %f1936, %f1379;
	mul.f32 	%f1384, %f1937, %f1380;
	mul.f32 	%f1385, %f1935, %f1379;
	mul.f32 	%f1386, %f1937, %f1381;
	mul.f32 	%f1387, %f1935, %f1380;
	mul.f32 	%f1388, %f1936, %f1381;
	mul.f32 	%f1389, %f1936, %f1380;
	mul.f32 	%f1390, %f1935, %f1381;
	sub.f32 	%f1391, %f1382, %f1383;
	sub.f32 	%f1392, %f1391, %f1384;
	fma.rn.f32 	%f1393, %f1938, %f1381, %f1392;
	sub.f32 	%f1394, %f1385, %f1386;
	add.f32 	%f1395, %f1394, %f1394;
	add.f32 	%f1396, %f1387, %f1388;
	add.f32 	%f1397, %f1396, %f1396;
	add.f32 	%f1398, %f1385, %f1386;
	add.f32 	%f1399, %f1398, %f1398;
	sub.f32 	%f1400, %f1383, %f1382;
	sub.f32 	%f1401, %f1400, %f1384;
	fma.rn.f32 	%f1402, %f1938, %f1381, %f1401;
	sub.f32 	%f1403, %f1389, %f1390;
	add.f32 	%f1404, %f1403, %f1403;
	sub.f32 	%f1405, %f1387, %f1388;
	add.f32 	%f1406, %f1405, %f1405;
	add.f32 	%f1407, %f1389, %f1390;
	add.f32 	%f1408, %f1407, %f1407;
	neg.f32 	%f1409, %f1382;
	sub.f32 	%f1410, %f1409, %f1383;
	add.f32 	%f1411, %f1384, %f1410;
	fma.rn.f32 	%f1412, %f1938, %f1381, %f1411;
	mul.f32 	%f1413, %f1929, %f1393;
	fma.rn.f32 	%f1414, %f1932, %f1395, %f1413;
	fma.rn.f32 	%f1415, %f1934, %f1397, %f1414;
	sub.f32 	%f1953, %f1939, %f1415;
	mul.f32 	%f1416, %f1932, %f1402;
	fma.rn.f32 	%f1417, %f1929, %f1399, %f1416;
	fma.rn.f32 	%f1418, %f1934, %f1404, %f1417;
	sub.f32 	%f1949, %f1940, %f1418;
	mul.f32 	%f1419, %f1932, %f1408;
	fma.rn.f32 	%f1420, %f1929, %f1406, %f1419;
	fma.rn.f32 	%f1421, %f1934, %f1412, %f1420;
	sub.f32 	%f1945, %f1941, %f1421;
	mul.f32 	%f1422, %f1928, %f1393;
	fma.rn.f32 	%f1423, %f1931, %f1395, %f1422;
	fma.rn.f32 	%f1952, %f1933, %f1397, %f1423;
	mul.f32 	%f1424, %f1931, %f1402;
	fma.rn.f32 	%f1425, %f1928, %f1399, %f1424;
	fma.rn.f32 	%f1948, %f1933, %f1404, %f1425;
	mul.f32 	%f1426, %f1931, %f1408;
	fma.rn.f32 	%f1427, %f1928, %f1406, %f1426;
	fma.rn.f32 	%f1944, %f1933, %f1412, %f1427;
	mul.f32 	%f1428, %f1927, %f1393;
	fma.rn.f32 	%f1951, %f1930, %f1395, %f1428;
	mul.f32 	%f1429, %f1930, %f1402;
	fma.rn.f32 	%f1947, %f1927, %f1399, %f1429;
	mul.f32 	%f1430, %f1930, %f1408;
	fma.rn.f32 	%f1943, %f1927, %f1406, %f1430;
	mul.f32 	%f1950, %f1926, %f1393;
	mul.f32 	%f1946, %f1926, %f1399;
	mul.f32 	%f1942, %f1926, %f1406;
	bra.uni 	BB3_73;

BB3_63:
	setp.ne.s32	%p42, %r345, 1;
	mov.f32 	%f1943, %f1942;
	mov.f32 	%f1945, %f1942;
	mov.f32 	%f1946, %f1942;
	mov.f32 	%f1947, %f1944;
	mov.f32 	%f1948, %f1942;
	mov.f32 	%f1949, %f1942;
	mov.f32 	%f1950, %f1944;
	mov.f32 	%f1951, %f1942;
	mov.f32 	%f1952, %f1942;
	mov.f32 	%f1953, %f1942;
	@%p42 bra 	BB3_73;

	// inline asm
	call (%rd321), _optix_get_static_transform_from_handle, (%rd319);
	// inline asm
	add.s64 	%rd669, %rd321, 16;

BB3_66:
	// inline asm
	cvta.to.global.u64 %rd325, %rd669;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r347,%r348,%r349,%r350}, [%rd325];
	// inline asm
	mov.b32 	 %f1950, %r347;
	mov.b32 	 %f1951, %r348;
	mov.b32 	 %f1952, %r349;
	mov.b32 	 %f1953, %r350;
	add.s64 	%rd329, %rd669, 16;
	// inline asm
	cvta.to.global.u64 %rd328, %rd329;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r351,%r352,%r353,%r354}, [%rd328];
	// inline asm
	mov.b32 	 %f1946, %r351;
	mov.b32 	 %f1947, %r352;
	mov.b32 	 %f1948, %r353;
	mov.b32 	 %f1949, %r354;
	add.s64 	%rd332, %rd669, 32;
	// inline asm
	cvta.to.global.u64 %rd331, %rd332;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd331];
	// inline asm
	mov.b32 	 %f1942, %r355;
	mov.b32 	 %f1943, %r356;
	mov.b32 	 %f1944, %r357;
	mov.b32 	 %f1945, %r358;

BB3_73:
	add.s32 	%r18, %r648, 1;
	setp.eq.s32	%p46, %r18, %r30;
	@%p46 bra 	BB3_74;
	bra.uni 	BB3_75;

BB3_74:
	mov.f32 	%f1925, %f1942;
	mov.f32 	%f1924, %f1943;
	mov.f32 	%f1923, %f1944;
	mov.f32 	%f1922, %f1945;
	mov.f32 	%f1921, %f1946;
	mov.f32 	%f1920, %f1947;
	mov.f32 	%f1919, %f1948;
	mov.f32 	%f1918, %f1949;
	mov.f32 	%f1917, %f1950;
	mov.f32 	%f1916, %f1951;
	mov.f32 	%f1915, %f1952;
	mov.f32 	%f1914, %f1953;
	bra.uni 	BB3_76;

BB3_75:
	mul.f32 	%f1468, %f1921, %f1951;
	fma.rn.f32 	%f1469, %f1917, %f1950, %f1468;
	fma.rn.f32 	%f466, %f1925, %f1952, %f1469;
	mul.f32 	%f1470, %f1920, %f1951;
	fma.rn.f32 	%f1471, %f1916, %f1950, %f1470;
	fma.rn.f32 	%f467, %f1924, %f1952, %f1471;
	mul.f32 	%f1472, %f1919, %f1951;
	fma.rn.f32 	%f1473, %f1915, %f1950, %f1472;
	fma.rn.f32 	%f468, %f1923, %f1952, %f1473;
	mul.f32 	%f1474, %f1918, %f1951;
	fma.rn.f32 	%f1475, %f1914, %f1950, %f1474;
	fma.rn.f32 	%f1476, %f1922, %f1952, %f1475;
	add.f32 	%f469, %f1953, %f1476;
	mul.f32 	%f1477, %f1921, %f1947;
	fma.rn.f32 	%f1478, %f1917, %f1946, %f1477;
	fma.rn.f32 	%f470, %f1925, %f1948, %f1478;
	mul.f32 	%f1479, %f1920, %f1947;
	fma.rn.f32 	%f1480, %f1916, %f1946, %f1479;
	fma.rn.f32 	%f471, %f1924, %f1948, %f1480;
	mul.f32 	%f1481, %f1919, %f1947;
	fma.rn.f32 	%f1482, %f1915, %f1946, %f1481;
	fma.rn.f32 	%f472, %f1923, %f1948, %f1482;
	mul.f32 	%f1483, %f1918, %f1947;
	fma.rn.f32 	%f1484, %f1914, %f1946, %f1483;
	fma.rn.f32 	%f1485, %f1922, %f1948, %f1484;
	add.f32 	%f473, %f1949, %f1485;
	mul.f32 	%f1486, %f1921, %f1943;
	fma.rn.f32 	%f1487, %f1917, %f1942, %f1486;
	fma.rn.f32 	%f1925, %f1925, %f1944, %f1487;
	mul.f32 	%f1488, %f1920, %f1943;
	fma.rn.f32 	%f1489, %f1916, %f1942, %f1488;
	fma.rn.f32 	%f1924, %f1924, %f1944, %f1489;
	mul.f32 	%f1490, %f1919, %f1943;
	fma.rn.f32 	%f1491, %f1915, %f1942, %f1490;
	fma.rn.f32 	%f1923, %f1923, %f1944, %f1491;
	mul.f32 	%f1492, %f1918, %f1943;
	fma.rn.f32 	%f1493, %f1914, %f1942, %f1492;
	fma.rn.f32 	%f1494, %f1922, %f1944, %f1493;
	add.f32 	%f1922, %f1945, %f1494;
	mov.f32 	%f1921, %f470;
	mov.f32 	%f1920, %f471;
	mov.f32 	%f1919, %f472;
	mov.f32 	%f1918, %f473;
	mov.f32 	%f1917, %f466;
	mov.f32 	%f1916, %f467;
	mov.f32 	%f1915, %f468;
	mov.f32 	%f1914, %f469;

BB3_76:
	add.s32 	%r648, %r18, -2;
	setp.gt.s32	%p47, %r648, -1;
	@%p47 bra 	BB3_61;

BB3_77:
	mov.u32 	%r649, 0;
	mov.f32 	%f1978, %f1979;
	mov.f32 	%f1983, %f1979;
	mov.f32 	%f1982, %f1980;
	mov.f32 	%f1981, %f1979;
	mov.f32 	%f1986, %f1979;
	mov.f32 	%f1985, %f1979;
	mov.f32 	%f1984, %f1980;
	@%p2 bra 	BB3_95;

BB3_78:
	.pragma "nounroll";
	// inline asm
	call (%rd440), _optix_get_transform_list_handle, (%r649);
	// inline asm
	// inline asm
	call (%r495), _optix_get_transform_type_from_handle, (%rd440);
	// inline asm
	and.b32  	%r496, %r495, -2;
	setp.eq.s32	%p49, %r496, 2;
	@%p49 bra 	BB3_84;
	bra.uni 	BB3_79;

BB3_84:
	setp.eq.s32	%p52, %r495, 2;
	@%p52 bra 	BB3_88;
	bra.uni 	BB3_85;

BB3_88:
	// inline asm
	call (%rd514), _optix_get_matrix_motion_transform_from_handle, (%rd440);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd516, %rd514;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd516];
	// inline asm
	mov.b32	{%rs16, %rs17}, %r586;
	add.s64 	%rd520, %rd514, 16;
	// inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd519];
	// inline asm
	add.s64 	%rd523, %rd514, 32;
	// inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd522];
	// inline asm
	add.s64 	%rd526, %rd514, 48;
	// inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd525];
	// inline asm
	add.s64 	%rd529, %rd514, 64;
	// inline asm
	cvta.to.global.u64 %rd528, %rd529;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd528];
	// inline asm
	add.s64 	%rd532, %rd514, 80;
	// inline asm
	cvta.to.global.u64 %rd531, %rd532;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd531];
	// inline asm
	add.s64 	%rd535, %rd514, 96;
	// inline asm
	cvta.to.global.u64 %rd534, %rd535;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd534];
	// inline asm
	add.s64 	%rd538, %rd514, 112;
	// inline asm
	cvta.to.global.u64 %rd537, %rd538;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd537];
	// inline asm
	mov.b32 	 %f1606, %r587;
	mov.b32 	 %f1607, %r588;
	cvt.u32.u16	%r628, %rs16;
	add.s32 	%r629, %r628, -1;
	cvt.rn.f32.s32	%f1608, %r629;
	sub.f32 	%f1609, %f938, %f1606;
	mul.f32 	%f1610, %f1609, %f1608;
	sub.f32 	%f1611, %f1607, %f1606;
	div.rn.f32 	%f1612, %f1610, %f1611;
	min.f32 	%f1613, %f1608, %f1612;
	mov.f32 	%f1614, 0f00000000;
	max.f32 	%f1615, %f1614, %f1613;
	cvt.rmi.f32.f32	%f1616, %f1615;
	cvt.rzi.s32.f32	%r630, %f1616;
	cvt.s64.s32	%rd43, %r630;
	mul.wide.s32 	%rd549, %r630, 48;
	add.s64 	%rd541, %rd523, %rd549;
	// inline asm
	cvta.to.global.u64 %rd540, %rd541;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd540];
	// inline asm
	mov.b32 	 %f2003, %r616;
	mov.b32 	 %f2004, %r617;
	mov.b32 	 %f2005, %r618;
	add.s64 	%rd544, %rd541, 16;
	// inline asm
	cvta.to.global.u64 %rd543, %rd544;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd543];
	// inline asm
	mov.b32 	 %f2000, %r620;
	mov.b32 	 %f2001, %r621;
	mov.b32 	 %f2002, %r622;
	add.s64 	%rd547, %rd541, 32;
	// inline asm
	cvta.to.global.u64 %rd546, %rd547;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd546];
	// inline asm
	sub.f32 	%f566, %f1615, %f1616;
	mov.b32 	 %f1997, %r624;
	mov.b32 	 %f1998, %r625;
	mov.b32 	 %f1999, %r626;
	setp.leu.f32	%p54, %f566, 0f00000000;
	@%p54 bra 	BB3_90;

	mul.lo.s64 	%rd559, %rd43, 48;
	add.s64 	%rd560, %rd514, %rd559;
	add.s64 	%rd551, %rd560, 80;
	// inline asm
	cvta.to.global.u64 %rd550, %rd551;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd550];
	// inline asm
	mov.b32 	 %f1617, %r631;
	mov.b32 	 %f1618, %r632;
	mov.b32 	 %f1619, %r633;
	add.s64 	%rd554, %rd560, 96;
	// inline asm
	cvta.to.global.u64 %rd553, %rd554;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd553];
	// inline asm
	mov.b32 	 %f1620, %r635;
	mov.b32 	 %f1621, %r636;
	mov.b32 	 %f1622, %r637;
	add.s64 	%rd557, %rd560, 112;
	// inline asm
	cvta.to.global.u64 %rd556, %rd557;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd556];
	// inline asm
	mov.f32 	%f1623, 0f3F800000;
	sub.f32 	%f1624, %f1623, %f566;
	mul.f32 	%f1625, %f566, %f1617;
	mul.f32 	%f1626, %f566, %f1618;
	mul.f32 	%f1627, %f566, %f1619;
	fma.rn.f32 	%f2003, %f1624, %f2003, %f1625;
	fma.rn.f32 	%f2004, %f1624, %f2004, %f1626;
	fma.rn.f32 	%f2005, %f1624, %f2005, %f1627;
	mul.f32 	%f1628, %f566, %f1620;
	mul.f32 	%f1629, %f566, %f1621;
	mul.f32 	%f1630, %f566, %f1622;
	fma.rn.f32 	%f2000, %f1624, %f2000, %f1628;
	fma.rn.f32 	%f2001, %f1624, %f2001, %f1629;
	fma.rn.f32 	%f2002, %f1624, %f2002, %f1630;
	mov.b32 	 %f1631, %r639;
	mov.b32 	 %f1632, %r640;
	mov.b32 	 %f1633, %r641;
	mul.f32 	%f1634, %f566, %f1631;
	mul.f32 	%f1635, %f566, %f1632;
	mul.f32 	%f1636, %f566, %f1633;
	fma.rn.f32 	%f1997, %f1624, %f1997, %f1634;
	fma.rn.f32 	%f1998, %f1624, %f1998, %f1635;
	fma.rn.f32 	%f1999, %f1624, %f1999, %f1636;
	bra.uni 	BB3_90;

BB3_79:
	mov.f32 	%f2006, 0f00000000;
	mov.f32 	%f2008, 0f3F800000;
	setp.eq.s32	%p50, %r495, 4;
	@%p50 bra 	BB3_82;
	bra.uni 	BB3_80;

BB3_82:
	// inline asm
	call (%rd670), _optix_get_instance_inverse_transform_from_handle, (%rd440);
	// inline asm
	bra.uni 	BB3_83;

BB3_85:
	// inline asm
	call (%rd455), _optix_get_srt_motion_transform_from_handle, (%rd440);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd457, %rd455;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd457];
	// inline asm
	mov.b32	{%rs14, %rs15}, %r511;
	add.s64 	%rd461, %rd455, 16;
	// inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd460];
	// inline asm
	add.s64 	%rd464, %rd455, 32;
	// inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd463];
	// inline asm
	add.s64 	%rd467, %rd455, 48;
	// inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd466];
	// inline asm
	add.s64 	%rd470, %rd455, 64;
	// inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd469];
	// inline asm
	add.s64 	%rd473, %rd455, 80;
	// inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd472];
	// inline asm
	add.s64 	%rd476, %rd455, 96;
	// inline asm
	cvta.to.global.u64 %rd475, %rd476;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd475];
	// inline asm
	add.s64 	%rd479, %rd455, 112;
	// inline asm
	cvta.to.global.u64 %rd478, %rd479;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd478];
	// inline asm
	add.s64 	%rd482, %rd455, 128;
	// inline asm
	cvta.to.global.u64 %rd481, %rd482;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd481];
	// inline asm
	add.s64 	%rd485, %rd455, 144;
	// inline asm
	cvta.to.global.u64 %rd484, %rd485;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd484];
	// inline asm
	mov.b32 	 %f1514, %r512;
	mov.b32 	 %f1515, %r513;
	cvt.u32.u16	%r565, %rs14;
	add.s32 	%r566, %r565, -1;
	cvt.rn.f32.s32	%f1516, %r566;
	sub.f32 	%f1517, %f938, %f1514;
	mul.f32 	%f1518, %f1517, %f1516;
	sub.f32 	%f1519, %f1515, %f1514;
	div.rn.f32 	%f1520, %f1518, %f1519;
	min.f32 	%f1521, %f1516, %f1520;
	mov.f32 	%f1522, 0f00000000;
	max.f32 	%f1523, %f1522, %f1521;
	cvt.rmi.f32.f32	%f1524, %f1523;
	cvt.rzi.s32.f32	%r567, %f1524;
	cvt.s64.s32	%rd41, %r567;
	mul.wide.s32 	%rd499, %r567, 64;
	add.s64 	%rd488, %rd464, %rd499;
	// inline asm
	cvta.to.global.u64 %rd487, %rd488;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd487];
	// inline asm
	mov.b32 	 %f1987, %r549;
	mov.b32 	 %f1988, %r550;
	mov.b32 	 %f1989, %r551;
	add.s64 	%rd491, %rd488, 16;
	// inline asm
	cvta.to.global.u64 %rd490, %rd491;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd490];
	// inline asm
	mov.b32 	 %f1990, %r553;
	mov.b32 	 %f1991, %r554;
	mov.b32 	 %f1992, %r556;
	add.s64 	%rd494, %rd488, 32;
	// inline asm
	cvta.to.global.u64 %rd493, %rd494;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd493];
	// inline asm
	sub.f32 	%f526, %f1523, %f1524;
	mov.b32 	 %f1993, %r558;
	mov.b32 	 %f1994, %r559;
	mov.b32 	 %f1995, %r560;
	add.s64 	%rd497, %rd488, 48;
	// inline asm
	cvta.to.global.u64 %rd496, %rd497;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r561,%r562,%r563,%r564}, [%rd496];
	// inline asm
	mov.b32 	 %f1996, %r561;
	setp.leu.f32	%p53, %f526, 0f00000000;
	@%p53 bra 	BB3_87;

	shl.b64 	%rd512, %rd41, 6;
	add.s64 	%rd513, %rd512, %rd455;
	add.s64 	%rd501, %rd513, 96;
	// inline asm
	cvta.to.global.u64 %rd500, %rd501;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd500];
	// inline asm
	mov.b32 	 %f1525, %r568;
	mov.b32 	 %f1526, %r569;
	mov.b32 	 %f1527, %r570;
	add.s64 	%rd504, %rd513, 112;
	// inline asm
	cvta.to.global.u64 %rd503, %rd504;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd503];
	// inline asm
	mov.b32 	 %f1528, %r572;
	mov.b32 	 %f1529, %r573;
	mov.b32 	 %f1530, %r575;
	add.s64 	%rd507, %rd513, 128;
	// inline asm
	cvta.to.global.u64 %rd506, %rd507;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd506];
	// inline asm
	mov.b32 	 %f1531, %r577;
	mov.b32 	 %f1532, %r578;
	mov.b32 	 %f1533, %r579;
	add.s64 	%rd510, %rd513, 144;
	// inline asm
	cvta.to.global.u64 %rd509, %rd510;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd509];
	// inline asm
	mov.f32 	%f1534, 0f3F800000;
	sub.f32 	%f1535, %f1534, %f526;
	mul.f32 	%f1536, %f526, %f1525;
	mul.f32 	%f1537, %f526, %f1526;
	mul.f32 	%f1538, %f526, %f1527;
	fma.rn.f32 	%f1987, %f1535, %f1987, %f1536;
	fma.rn.f32 	%f1988, %f1535, %f1988, %f1537;
	fma.rn.f32 	%f1989, %f1535, %f1989, %f1538;
	mul.f32 	%f1539, %f526, %f1528;
	mul.f32 	%f1540, %f526, %f1529;
	mul.f32 	%f1541, %f526, %f1530;
	fma.rn.f32 	%f1990, %f1535, %f1990, %f1539;
	fma.rn.f32 	%f1991, %f1535, %f1991, %f1540;
	fma.rn.f32 	%f1992, %f1535, %f1992, %f1541;
	mul.f32 	%f1542, %f526, %f1531;
	mul.f32 	%f1543, %f526, %f1532;
	mul.f32 	%f1544, %f526, %f1533;
	fma.rn.f32 	%f1545, %f1535, %f1993, %f1542;
	fma.rn.f32 	%f1546, %f1535, %f1994, %f1543;
	fma.rn.f32 	%f1547, %f1535, %f1995, %f1544;
	mov.b32 	 %f1548, %r580;
	mul.f32 	%f1549, %f526, %f1548;
	fma.rn.f32 	%f1550, %f1535, %f1996, %f1549;
	mul.f32 	%f1551, %f1546, %f1546;
	fma.rn.f32 	%f1552, %f1545, %f1545, %f1551;
	fma.rn.f32 	%f1553, %f1547, %f1547, %f1552;
	fma.rn.f32 	%f1554, %f1550, %f1550, %f1553;
	sqrt.rn.f32 	%f1555, %f1554;
	rcp.rn.f32 	%f1556, %f1555;
	mul.f32 	%f1993, %f1545, %f1556;
	mul.f32 	%f1994, %f1546, %f1556;
	mul.f32 	%f1995, %f1547, %f1556;
	mul.f32 	%f1996, %f1550, %f1556;

BB3_87:
	mul.f32 	%f1557, %f1994, %f1994;
	fma.rn.f32 	%f1558, %f1993, %f1993, %f1557;
	fma.rn.f32 	%f1559, %f1995, %f1995, %f1558;
	fma.rn.f32 	%f1560, %f1996, %f1996, %f1559;
	rcp.rn.f32 	%f1561, %f1560;
	mul.f32 	%f1562, %f1993, %f1561;
	mul.f32 	%f1563, %f1994, %f1561;
	mul.f32 	%f1564, %f1995, %f1561;
	mul.f32 	%f1565, %f1996, %f1561;
	mul.f32 	%f1566, %f1993, %f1562;
	mul.f32 	%f1567, %f1994, %f1563;
	mul.f32 	%f1568, %f1995, %f1564;
	mul.f32 	%f1569, %f1993, %f1563;
	mul.f32 	%f1570, %f1995, %f1565;
	mul.f32 	%f1571, %f1993, %f1564;
	mul.f32 	%f1572, %f1994, %f1565;
	mul.f32 	%f1573, %f1994, %f1564;
	mul.f32 	%f1574, %f1993, %f1565;
	sub.f32 	%f1575, %f1566, %f1567;
	sub.f32 	%f1576, %f1575, %f1568;
	fma.rn.f32 	%f1577, %f1996, %f1565, %f1576;
	sub.f32 	%f1578, %f1569, %f1570;
	add.f32 	%f1579, %f1578, %f1578;
	add.f32 	%f1580, %f1571, %f1572;
	add.f32 	%f1581, %f1580, %f1580;
	add.f32 	%f1582, %f1569, %f1570;
	add.f32 	%f1583, %f1582, %f1582;
	sub.f32 	%f1584, %f1567, %f1566;
	sub.f32 	%f1585, %f1584, %f1568;
	fma.rn.f32 	%f1586, %f1996, %f1565, %f1585;
	sub.f32 	%f1587, %f1573, %f1574;
	add.f32 	%f1588, %f1587, %f1587;
	sub.f32 	%f1589, %f1571, %f1572;
	add.f32 	%f1590, %f1589, %f1589;
	add.f32 	%f1591, %f1573, %f1574;
	add.f32 	%f1592, %f1591, %f1591;
	neg.f32 	%f1593, %f1566;
	sub.f32 	%f1594, %f1593, %f1567;
	add.f32 	%f1595, %f1568, %f1594;
	fma.rn.f32 	%f1596, %f1996, %f1565, %f1595;
	mul.f32 	%f1597, %f1989, %f1577;
	fma.rn.f32 	%f1598, %f1991, %f1579, %f1597;
	fma.rn.f32 	%f2005, %f1992, %f1581, %f1598;
	mul.f32 	%f1599, %f1991, %f1586;
	fma.rn.f32 	%f1600, %f1989, %f1583, %f1599;
	fma.rn.f32 	%f2002, %f1992, %f1588, %f1600;
	mul.f32 	%f1601, %f1991, %f1592;
	fma.rn.f32 	%f1602, %f1989, %f1590, %f1601;
	fma.rn.f32 	%f1999, %f1992, %f1596, %f1602;
	mul.f32 	%f1603, %f1988, %f1577;
	fma.rn.f32 	%f2004, %f1990, %f1579, %f1603;
	mul.f32 	%f1604, %f1990, %f1586;
	fma.rn.f32 	%f2001, %f1988, %f1583, %f1604;
	mul.f32 	%f1605, %f1990, %f1592;
	fma.rn.f32 	%f1998, %f1988, %f1590, %f1605;
	mul.f32 	%f2003, %f1987, %f1577;
	mul.f32 	%f2000, %f1987, %f1583;
	mul.f32 	%f1997, %f1987, %f1590;

BB3_90:
	mul.f32 	%f1637, %f1998, %f2002;
	mul.f32 	%f1638, %f1999, %f2001;
	sub.f32 	%f1639, %f1638, %f1637;
	mul.f32 	%f1640, %f2003, %f1639;
	mul.f32 	%f1641, %f1997, %f2002;
	mul.f32 	%f1642, %f1999, %f2000;
	sub.f32 	%f1643, %f1642, %f1641;
	mul.f32 	%f1644, %f1643, %f2004;
	sub.f32 	%f1645, %f1640, %f1644;
	mul.f32 	%f1646, %f1997, %f2001;
	mul.f32 	%f1647, %f1998, %f2000;
	sub.f32 	%f1648, %f1647, %f1646;
	fma.rn.f32 	%f1649, %f1648, %f2005, %f1645;
	rcp.rn.f32 	%f1650, %f1649;
	mul.f32 	%f2012, %f1639, %f1650;
	mul.f32 	%f1651, %f1999, %f2004;
	mul.f32 	%f1652, %f1998, %f2005;
	sub.f32 	%f1653, %f1652, %f1651;
	mul.f32 	%f2013, %f1650, %f1653;
	mul.f32 	%f1654, %f2001, %f2005;
	mul.f32 	%f1655, %f2002, %f2004;
	sub.f32 	%f1656, %f1655, %f1654;
	mul.f32 	%f2014, %f1650, %f1656;
	sub.f32 	%f1657, %f1641, %f1642;
	mul.f32 	%f2009, %f1657, %f1650;
	mul.f32 	%f1658, %f1997, %f2005;
	mul.f32 	%f1659, %f1999, %f2003;
	sub.f32 	%f1660, %f1659, %f1658;
	mul.f32 	%f2010, %f1650, %f1660;
	mul.f32 	%f1661, %f2002, %f2003;
	mul.f32 	%f1662, %f2000, %f2005;
	sub.f32 	%f1663, %f1662, %f1661;
	mul.f32 	%f2011, %f1650, %f1663;
	mul.f32 	%f2006, %f1648, %f1650;
	mul.f32 	%f1664, %f1998, %f2003;
	mul.f32 	%f1665, %f1997, %f2004;
	sub.f32 	%f1666, %f1665, %f1664;
	mul.f32 	%f2007, %f1666, %f1650;
	mul.f32 	%f1667, %f2000, %f2004;
	mul.f32 	%f1668, %f2001, %f2003;
	sub.f32 	%f1669, %f1668, %f1667;
	mul.f32 	%f2008, %f1669, %f1650;
	bra.uni 	BB3_91;

BB3_80:
	setp.ne.s32	%p51, %r495, 1;
	mov.f32 	%f2007, %f2006;
	mov.f32 	%f2009, %f2006;
	mov.f32 	%f2010, %f2008;
	mov.f32 	%f2011, %f2006;
	mov.f32 	%f2012, %f2008;
	mov.f32 	%f2013, %f2006;
	mov.f32 	%f2014, %f2006;
	@%p51 bra 	BB3_91;

	// inline asm
	call (%rd442), _optix_get_static_transform_from_handle, (%rd440);
	// inline asm
	add.s64 	%rd670, %rd442, 64;

BB3_83:
	// inline asm
	cvta.to.global.u64 %rd446, %rd670;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd446];
	// inline asm
	mov.b32 	 %f2012, %r497;
	mov.b32 	 %f2013, %r498;
	mov.b32 	 %f2014, %r499;
	add.s64 	%rd450, %rd670, 16;
	// inline asm
	cvta.to.global.u64 %rd449, %rd450;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd449];
	// inline asm
	mov.b32 	 %f2009, %r501;
	mov.b32 	 %f2010, %r502;
	mov.b32 	 %f2011, %r503;
	add.s64 	%rd453, %rd670, 32;
	// inline asm
	cvta.to.global.u64 %rd452, %rd453;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd452];
	// inline asm
	mov.b32 	 %f2006, %r505;
	mov.b32 	 %f2007, %r506;
	mov.b32 	 %f2008, %r507;

BB3_91:
	setp.eq.s32	%p55, %r649, 0;
	@%p55 bra 	BB3_92;
	bra.uni 	BB3_93;

BB3_92:
	mov.f32 	%f1986, %f2006;
	mov.f32 	%f1985, %f2007;
	mov.f32 	%f1984, %f2008;
	mov.f32 	%f1983, %f2009;
	mov.f32 	%f1982, %f2010;
	mov.f32 	%f1981, %f2011;
	mov.f32 	%f1980, %f2012;
	mov.f32 	%f1979, %f2013;
	mov.f32 	%f1978, %f2014;
	bra.uni 	BB3_94;

BB3_93:
	mul.f32 	%f1670, %f1983, %f2013;
	fma.rn.f32 	%f1671, %f1980, %f2012, %f1670;
	fma.rn.f32 	%f606, %f1986, %f2014, %f1671;
	mul.f32 	%f1672, %f1982, %f2013;
	fma.rn.f32 	%f1673, %f1979, %f2012, %f1672;
	fma.rn.f32 	%f607, %f1985, %f2014, %f1673;
	mul.f32 	%f1674, %f1981, %f2013;
	fma.rn.f32 	%f1675, %f1978, %f2012, %f1674;
	fma.rn.f32 	%f608, %f1984, %f2014, %f1675;
	mul.f32 	%f1676, %f1983, %f2010;
	fma.rn.f32 	%f1677, %f1980, %f2009, %f1676;
	fma.rn.f32 	%f609, %f1986, %f2011, %f1677;
	mul.f32 	%f1678, %f1982, %f2010;
	fma.rn.f32 	%f1679, %f1979, %f2009, %f1678;
	fma.rn.f32 	%f610, %f1985, %f2011, %f1679;
	mul.f32 	%f1680, %f1981, %f2010;
	fma.rn.f32 	%f1681, %f1978, %f2009, %f1680;
	fma.rn.f32 	%f611, %f1984, %f2011, %f1681;
	mul.f32 	%f1682, %f1983, %f2007;
	fma.rn.f32 	%f1683, %f1980, %f2006, %f1682;
	fma.rn.f32 	%f1986, %f1986, %f2008, %f1683;
	mul.f32 	%f1684, %f1982, %f2007;
	fma.rn.f32 	%f1685, %f1979, %f2006, %f1684;
	fma.rn.f32 	%f1985, %f1985, %f2008, %f1685;
	mul.f32 	%f1686, %f1981, %f2007;
	fma.rn.f32 	%f1687, %f1978, %f2006, %f1686;
	fma.rn.f32 	%f1984, %f1984, %f2008, %f1687;
	mov.f32 	%f1983, %f609;
	mov.f32 	%f1982, %f610;
	mov.f32 	%f1981, %f611;
	mov.f32 	%f1980, %f606;
	mov.f32 	%f1979, %f607;
	mov.f32 	%f1978, %f608;

BB3_94:
	add.s32 	%r649, %r649, 1;
	setp.lt.u32	%p56, %r649, %r30;
	@%p56 bra 	BB3_78;

BB3_95:
	fma.rn.f32 	%f1688, %f2063, %f1917, %f1914;
	fma.rn.f32 	%f1689, %f2064, %f1916, %f1688;
	fma.rn.f32 	%f1690, %f2063, %f1921, %f1918;
	fma.rn.f32 	%f1691, %f2064, %f1920, %f1690;
	fma.rn.f32 	%f1692, %f2063, %f1925, %f1922;
	fma.rn.f32 	%f1693, %f2064, %f1924, %f1692;
	fma.rn.f32 	%f2063, %f2065, %f1915, %f1689;
	fma.rn.f32 	%f2064, %f2065, %f1919, %f1691;
	fma.rn.f32 	%f2065, %f2065, %f1923, %f1693;
	ld.const.u64 	%rd561, [params+112];
	setp.eq.s64	%p57, %rd561, 0;
	mov.f32 	%f2057, %f2060;
	mov.f32 	%f2058, %f2061;
	mov.f32 	%f2059, %f2062;
	@%p57 bra 	BB3_97;

	mul.f32 	%f1694, %f2060, %f1980;
	fma.rn.f32 	%f1695, %f2061, %f1983, %f1694;
	mul.f32 	%f1696, %f2060, %f1979;
	fma.rn.f32 	%f1697, %f2061, %f1982, %f1696;
	mul.f32 	%f1698, %f2060, %f1978;
	fma.rn.f32 	%f1699, %f2061, %f1981, %f1698;
	fma.rn.f32 	%f1700, %f2062, %f1986, %f1695;
	fma.rn.f32 	%f1701, %f2062, %f1985, %f1697;
	fma.rn.f32 	%f1702, %f2062, %f1984, %f1699;
	mul.f32 	%f1703, %f1700, %f1700;
	fma.rn.f32 	%f1704, %f1701, %f1701, %f1703;
	fma.rn.f32 	%f1705, %f1702, %f1702, %f1704;
	sqrt.rn.f32 	%f1706, %f1705;
	div.rn.f32 	%f2057, %f1700, %f1706;
	div.rn.f32 	%f2058, %f1701, %f1706;
	div.rn.f32 	%f2059, %f1702, %f1706;

BB3_97:
	ld.const.u64 	%rd562, [params+136];
	setp.eq.s64	%p58, %rd562, 0;
	@%p58 bra 	BB3_99;

	mul.f32 	%f1707, %f2060, %f1980;
	fma.rn.f32 	%f1708, %f2061, %f1983, %f1707;
	mul.f32 	%f1709, %f2060, %f1979;
	fma.rn.f32 	%f1710, %f2061, %f1982, %f1709;
	mul.f32 	%f1711, %f2060, %f1978;
	fma.rn.f32 	%f1712, %f2061, %f1981, %f1711;
	fma.rn.f32 	%f1713, %f2062, %f1986, %f1708;
	fma.rn.f32 	%f1714, %f2062, %f1985, %f1710;
	fma.rn.f32 	%f1715, %f2062, %f1984, %f1712;
	mul.f32 	%f1716, %f1713, %f1713;
	fma.rn.f32 	%f1717, %f1714, %f1714, %f1716;
	fma.rn.f32 	%f1718, %f1715, %f1715, %f1717;
	sqrt.rn.f32 	%f1719, %f1718;
	div.rn.f32 	%f2060, %f1713, %f1719;
	div.rn.f32 	%f2061, %f1714, %f1719;
	div.rn.f32 	%f2062, %f1715, %f1719;

BB3_99:
	ld.const.u64 	%rd563, [params+184];
	setp.eq.s64	%p59, %rd563, 0;
	@%p59 bra 	BB3_101;

	mul.f32 	%f1720, %f340, %f1917;
	fma.rn.f32 	%f1721, %f339, %f1916, %f1720;
	mul.f32 	%f1722, %f340, %f1921;
	fma.rn.f32 	%f1723, %f339, %f1920, %f1722;
	mul.f32 	%f1724, %f340, %f1925;
	fma.rn.f32 	%f1725, %f339, %f1924, %f1724;
	fma.rn.f32 	%f340, %f338, %f1915, %f1721;
	fma.rn.f32 	%f339, %f338, %f1919, %f1723;
	fma.rn.f32 	%f338, %f338, %f1923, %f1725;
	mul.f32 	%f1726, %f343, %f1917;
	fma.rn.f32 	%f1727, %f342, %f1916, %f1726;
	mul.f32 	%f1728, %f343, %f1921;
	fma.rn.f32 	%f1729, %f342, %f1920, %f1728;
	mul.f32 	%f1730, %f343, %f1925;
	fma.rn.f32 	%f1731, %f342, %f1924, %f1730;
	fma.rn.f32 	%f343, %f341, %f1915, %f1727;
	fma.rn.f32 	%f342, %f341, %f1919, %f1729;
	fma.rn.f32 	%f341, %f341, %f1923, %f1731;

BB3_101:
	ld.const.u64 	%rd564, [params+280];
	ld.const.u64 	%rd565, [params+232];
	mov.f32 	%f2048, 0f00000000;
	or.b64  	%rd566, %rd564, %rd565;
	setp.eq.s64	%p60, %rd566, 0;
	mov.f32 	%f2049, %f2048;
	mov.f32 	%f2050, %f2048;
	@%p60 bra 	BB3_103;

	mul.f32 	%f1735, %f2060, %f1917;
	fma.rn.f32 	%f1736, %f2061, %f1921, %f1735;
	mul.f32 	%f1737, %f2060, %f1916;
	fma.rn.f32 	%f1738, %f2061, %f1920, %f1737;
	mul.f32 	%f1739, %f2060, %f1915;
	fma.rn.f32 	%f1740, %f2061, %f1919, %f1739;
	fma.rn.f32 	%f1741, %f2062, %f1925, %f1736;
	fma.rn.f32 	%f1742, %f2062, %f1924, %f1738;
	fma.rn.f32 	%f1743, %f2062, %f1923, %f1740;
	mul.f32 	%f1744, %f1741, %f1741;
	fma.rn.f32 	%f1745, %f1742, %f1742, %f1744;
	fma.rn.f32 	%f1746, %f1743, %f1743, %f1745;
	sqrt.rn.f32 	%f1747, %f1746;
	div.rn.f32 	%f1748, %f1741, %f1747;
	div.rn.f32 	%f1749, %f1742, %f1747;
	div.rn.f32 	%f1750, %f1743, %f1747;
	mul.f32 	%f1751, %f1748, %f1980;
	mul.f32 	%f1752, %f1748, %f1979;
	mul.f32 	%f1753, %f1748, %f1978;
	fma.rn.f32 	%f1754, %f1749, %f1983, %f1751;
	fma.rn.f32 	%f1755, %f1749, %f1982, %f1752;
	fma.rn.f32 	%f1756, %f1749, %f1981, %f1753;
	fma.rn.f32 	%f1757, %f1750, %f1986, %f1754;
	fma.rn.f32 	%f1758, %f1750, %f1985, %f1755;
	fma.rn.f32 	%f1759, %f1750, %f1984, %f1756;
	mul.f32 	%f1760, %f1757, %f1757;
	fma.rn.f32 	%f1761, %f1758, %f1758, %f1760;
	fma.rn.f32 	%f1762, %f1759, %f1759, %f1761;
	sqrt.rn.f32 	%f1763, %f1762;
	rcp.rn.f32 	%f1764, %f1763;
	mul.f32 	%f1765, %f1764, %f1757;
	mul.f32 	%f1766, %f1764, %f1758;
	mul.f32 	%f1767, %f1764, %f1759;
	mul.f32 	%f1768, %f1980, 0f00000000;
	mov.f32 	%f1769, 0f00000000;
	fma.rn.f32 	%f1770, %f1769, %f1983, %f1768;
	mul.f32 	%f1771, %f1979, 0f00000000;
	fma.rn.f32 	%f1772, %f1769, %f1982, %f1771;
	mul.f32 	%f1773, %f1978, 0f00000000;
	fma.rn.f32 	%f1774, %f1769, %f1981, %f1773;
	fma.rn.f32 	%f1775, %f1769, %f1986, %f1770;
	fma.rn.f32 	%f1776, %f1769, %f1985, %f1772;
	fma.rn.f32 	%f1777, %f1769, %f1984, %f1774;
	mul.f32 	%f1778, %f1775, %f1764;
	mul.f32 	%f1779, %f1776, %f1764;
	mul.f32 	%f1780, %f1777, %f1764;
	mul.f32 	%f1781, %f1765, %f1778;
	fma.rn.f32 	%f1782, %f1766, %f1779, %f1781;
	fma.rn.f32 	%f1783, %f1767, %f1780, %f1782;
	mul.f32 	%f1784, %f1765, %f1783;
	mul.f32 	%f1785, %f1766, %f1783;
	mul.f32 	%f1786, %f1767, %f1783;
	sub.f32 	%f2048, %f1778, %f1784;
	sub.f32 	%f2049, %f1779, %f1785;
	sub.f32 	%f2050, %f1780, %f1786;

BB3_103:
	st.global.u32 	[%rd27], %r343;
	bra.uni 	BB3_104;

BB3_57:
	mov.f32 	%f2049, %f2048;
	mov.f32 	%f2050, %f2048;
	mov.f32 	%f2057, %f2060;
	mov.f32 	%f2058, %f2061;
	mov.f32 	%f2059, %f2062;

BB3_104:
	ld.const.u64 	%rd567, [params+328];
	cvta.to.global.u64 	%rd568, %rd567;
	shl.b64 	%rd569, %rd26, 3;
	add.s64 	%rd570, %rd568, %rd569;
	st.global.u64 	[%rd570], %rd25;
	ld.const.u64 	%rd571, [params+336];
	cvta.to.global.u64 	%rd572, %rd571;
	shl.b64 	%rd573, %rd26, 2;
	add.s64 	%rd574, %rd572, %rd573;
	mov.u32 	%r643, 0;
	st.global.u32 	[%rd574], %r643;
	ld.const.u64 	%rd575, [params+160];
	cvta.to.global.u64 	%rd576, %rd575;
	add.s64 	%rd577, %rd576, %rd573;
	st.global.f32 	[%rd577], %f2063;
	ld.const.u64 	%rd578, [params+168];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd573;
	st.global.f32 	[%rd580], %f2064;
	ld.const.u64 	%rd581, [params+176];
	cvta.to.global.u64 	%rd582, %rd581;
	add.s64 	%rd583, %rd582, %rd573;
	st.global.f32 	[%rd583], %f2065;
	ld.const.u64 	%rd584, [params+72];
	cvta.to.global.u64 	%rd585, %rd584;
	add.s64 	%rd586, %rd585, %rd573;
	st.global.f32 	[%rd586], %f313;
	@%p23 bra 	BB3_106;

	cvta.to.global.u64 	%rd587, %rd24;
	add.s64 	%rd589, %rd587, %rd573;
	st.global.f32 	[%rd589], %f1907;
	ld.const.u64 	%rd590, [params+104];
	cvta.to.global.u64 	%rd591, %rd590;
	add.s64 	%rd592, %rd591, %rd573;
	st.global.f32 	[%rd592], %f1906;

BB3_106:
	ld.const.u64 	%rd44, [params+112];
	setp.eq.s64	%p62, %rd44, 0;
	@%p62 bra 	BB3_108;

	cvta.to.global.u64 	%rd593, %rd44;
	add.s64 	%rd595, %rd593, %rd573;
	st.global.f32 	[%rd595], %f2057;
	ld.const.u64 	%rd596, [params+120];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd573;
	st.global.f32 	[%rd598], %f2058;
	ld.const.u64 	%rd599, [params+128];
	cvta.to.global.u64 	%rd600, %rd599;
	add.s64 	%rd601, %rd600, %rd573;
	st.global.f32 	[%rd601], %f2059;

BB3_108:
	ld.const.u64 	%rd45, [params+136];
	setp.eq.s64	%p63, %rd45, 0;
	@%p63 bra 	BB3_110;

	cvta.to.global.u64 	%rd602, %rd45;
	add.s64 	%rd604, %rd602, %rd573;
	st.global.f32 	[%rd604], %f2060;
	ld.const.u64 	%rd605, [params+144];
	cvta.to.global.u64 	%rd606, %rd605;
	add.s64 	%rd607, %rd606, %rd573;
	st.global.f32 	[%rd607], %f2061;
	ld.const.u64 	%rd608, [params+152];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd573;
	st.global.f32 	[%rd610], %f2062;

BB3_110:
	ld.const.u64 	%rd46, [params+184];
	setp.eq.s64	%p64, %rd46, 0;
	@%p64 bra 	BB3_112;

	cvta.to.global.u64 	%rd611, %rd46;
	add.s64 	%rd613, %rd611, %rd573;
	st.global.f32 	[%rd613], %f340;
	ld.const.u64 	%rd614, [params+192];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd573;
	st.global.f32 	[%rd616], %f339;
	ld.const.u64 	%rd617, [params+200];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd573;
	st.global.f32 	[%rd619], %f338;
	ld.const.u64 	%rd620, [params+208];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd573;
	st.global.f32 	[%rd622], %f343;
	ld.const.u64 	%rd623, [params+216];
	cvta.to.global.u64 	%rd624, %rd623;
	add.s64 	%rd625, %rd624, %rd573;
	st.global.f32 	[%rd625], %f342;
	ld.const.u64 	%rd626, [params+224];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd573;
	st.global.f32 	[%rd628], %f341;

BB3_112:
	ld.const.u64 	%rd47, [params+232];
	setp.eq.s64	%p65, %rd47, 0;
	@%p65 bra 	BB3_114;

	cvta.to.global.u64 	%rd629, %rd47;
	add.s64 	%rd631, %rd629, %rd573;
	st.global.f32 	[%rd631], %f2048;
	ld.const.u64 	%rd632, [params+240];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd573;
	st.global.f32 	[%rd634], %f2049;
	ld.const.u64 	%rd635, [params+248];
	cvta.to.global.u64 	%rd636, %rd635;
	add.s64 	%rd637, %rd636, %rd573;
	st.global.f32 	[%rd637], %f2050;
	ld.const.u64 	%rd638, [params+256];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd573;
	st.global.f32 	[%rd640], %f2048;
	ld.const.u64 	%rd641, [params+264];
	cvta.to.global.u64 	%rd642, %rd641;
	add.s64 	%rd643, %rd642, %rd573;
	st.global.f32 	[%rd643], %f2049;
	ld.const.u64 	%rd644, [params+272];
	cvta.to.global.u64 	%rd645, %rd644;
	add.s64 	%rd646, %rd645, %rd573;
	st.global.f32 	[%rd646], %f2050;

BB3_114:
	ld.const.u64 	%rd48, [params+280];
	setp.eq.s64	%p66, %rd48, 0;
	@%p66 bra 	BB3_116;

	cvta.to.global.u64 	%rd647, %rd48;
	add.s64 	%rd649, %rd647, %rd573;
	st.global.f32 	[%rd649], %f2048;
	ld.const.u64 	%rd650, [params+288];
	cvta.to.global.u64 	%rd651, %rd650;
	add.s64 	%rd652, %rd651, %rd573;
	st.global.f32 	[%rd652], %f2049;
	ld.const.u64 	%rd653, [params+296];
	cvta.to.global.u64 	%rd654, %rd653;
	add.s64 	%rd655, %rd654, %rd573;
	st.global.f32 	[%rd655], %f2050;
	ld.const.u64 	%rd656, [params+304];
	cvta.to.global.u64 	%rd657, %rd656;
	add.s64 	%rd658, %rd657, %rd573;
	st.global.f32 	[%rd658], %f2048;
	ld.const.u64 	%rd659, [params+312];
	cvta.to.global.u64 	%rd660, %rd659;
	add.s64 	%rd661, %rd660, %rd573;
	st.global.f32 	[%rd661], %f2049;
	ld.const.u64 	%rd662, [params+320];
	cvta.to.global.u64 	%rd663, %rd662;
	add.s64 	%rd664, %rd663, %rd573;
	st.global.f32 	[%rd664], %f2050;

BB3_116:
	ret;
}

	// .globl	__closesthit__mesh
.visible .entry __closesthit__mesh(

)
{
	.reg .pred 	%p<45>;
	.reg .b16 	%rs<10>;
	.reg .f32 	%f<1259>;
	.reg .b32 	%r<336>;
	.reg .b64 	%rd<450>;


	// inline asm
	call (%r16), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r17), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r19), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r20), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r21), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r22, %r21, %r17, %r20;
	mad.lo.s32 	%r1, %r22, %r16, %r19;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	@%p1 bra 	BB4_2;

	cvta.to.global.u64 	%rd40, %rd1;
	cvt.u64.u32	%rd41, %r1;
	add.s64 	%rd42, %rd40, %rd41;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd42], %rs1;
	bra.uni 	BB4_77;

BB4_2:
	// inline asm
	call (%rd43), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	// inline asm
	call (%r23), _optix_read_primitive_idx, ();
	// inline asm
	// inline asm
	call (%f428), _optix_get_ray_tmax, ();
	// inline asm
	// inline asm
	call (%f1099, %f1100), _optix_get_triangle_barycentrics, ();
	// inline asm
	ld.const.u64 	%rd3, [params+80];
	setp.eq.s64	%p2, %rd3, 0;
	@%p2 bra 	BB4_7;

	ld.u64 	%rd44, [%rd43];
	ld.const.u64 	%rd45, [params+328];
	cvta.to.global.u64 	%rd46, %rd45;
	cvt.u64.u32	%rd4, %r1;
	mul.wide.u32 	%rd47, %r1, 8;
	add.s64 	%rd48, %rd46, %rd47;
	st.global.u64 	[%rd48], %rd44;
	ld.const.u64 	%rd49, [params+336];
	cvta.to.global.u64 	%rd50, %rd49;
	mul.wide.u32 	%rd51, %r1, 4;
	add.s64 	%rd52, %rd50, %rd51;
	st.global.u32 	[%rd52], %r23;
	ld.const.u64 	%rd53, [params+344];
	cvta.to.global.u64 	%rd54, %rd53;
	add.s64 	%rd5, %rd54, %rd51;
	ld.global.u32 	%r3, [%rd5];
	setp.eq.s32	%p3, %r3, 0;
	@%p3 bra 	BB4_6;

	// inline asm
	call (%r24), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p4, %r24, %r3;
	@%p4 bra 	BB4_6;

	st.global.u32 	[%rd5], %r24;

BB4_6:
	cvta.to.global.u64 	%rd55, %rd3;
	shl.b64 	%rd56, %rd4, 2;
	add.s64 	%rd57, %rd55, %rd56;
	st.global.f32 	[%rd57], %f1099;
	ld.const.u64 	%rd58, [params+88];
	cvta.to.global.u64 	%rd59, %rd58;
	add.s64 	%rd60, %rd59, %rd56;
	st.global.f32 	[%rd60], %f1100;
	ld.const.u64 	%rd61, [params+72];
	cvta.to.global.u64 	%rd62, %rd61;
	add.s64 	%rd63, %rd62, %rd56;
	st.global.f32 	[%rd63], %f428;
	bra.uni 	BB4_77;

BB4_7:
	ld.u64 	%rd6, [%rd43+8];
	mov.f32 	%f437, 0f3F800000;
	sub.f32 	%f438, %f437, %f1099;
	sub.f32 	%f4, %f438, %f1100;
	mul.wide.u32 	%rd64, %r23, 3;
	ld.u64 	%rd65, [%rd6];
	shl.b64 	%rd66, %rd64, 2;
	add.s64 	%rd67, %rd65, %rd66;
	ld.u32 	%r25, [%rd67];
	mul.wide.u32 	%rd8, %r25, 3;
	ld.u64 	%rd68, [%rd6+8];
	shl.b64 	%rd69, %rd8, 2;
	add.s64 	%rd70, %rd68, %rd69;
	ld.u32 	%r26, [%rd67+4];
	mul.wide.u32 	%rd10, %r26, 3;
	shl.b64 	%rd71, %rd10, 2;
	add.s64 	%rd72, %rd68, %rd71;
	ld.u32 	%r27, [%rd67+8];
	mul.wide.u32 	%rd12, %r27, 3;
	shl.b64 	%rd73, %rd12, 2;
	add.s64 	%rd74, %rd68, %rd73;
	ld.f32 	%f439, [%rd70];
	ld.f32 	%f440, [%rd70+4];
	ld.f32 	%f441, [%rd70+8];
	ld.f32 	%f442, [%rd72];
	mul.f32 	%f443, %f442, %f1099;
	ld.f32 	%f444, [%rd72+4];
	mul.f32 	%f445, %f444, %f1099;
	ld.f32 	%f446, [%rd72+8];
	mul.f32 	%f447, %f446, %f1099;
	fma.rn.f32 	%f448, %f439, %f4, %f443;
	fma.rn.f32 	%f449, %f440, %f4, %f445;
	fma.rn.f32 	%f450, %f441, %f4, %f447;
	ld.f32 	%f451, [%rd74];
	ld.f32 	%f452, [%rd74+4];
	ld.f32 	%f453, [%rd74+8];
	fma.rn.f32 	%f1256, %f451, %f1100, %f448;
	fma.rn.f32 	%f1257, %f452, %f1100, %f449;
	fma.rn.f32 	%f1258, %f453, %f1100, %f450;
	sub.f32 	%f8, %f442, %f439;
	sub.f32 	%f9, %f444, %f440;
	sub.f32 	%f10, %f446, %f441;
	sub.f32 	%f11, %f451, %f439;
	sub.f32 	%f12, %f452, %f440;
	sub.f32 	%f13, %f453, %f441;
	mul.f32 	%f454, %f9, %f13;
	mul.f32 	%f455, %f10, %f12;
	sub.f32 	%f456, %f454, %f455;
	mul.f32 	%f457, %f10, %f11;
	mul.f32 	%f458, %f8, %f13;
	sub.f32 	%f459, %f457, %f458;
	mul.f32 	%f460, %f8, %f12;
	mul.f32 	%f461, %f9, %f11;
	sub.f32 	%f462, %f460, %f461;
	mul.f32 	%f463, %f456, %f456;
	fma.rn.f32 	%f464, %f459, %f459, %f463;
	fma.rn.f32 	%f465, %f462, %f462, %f464;
	sqrt.rn.f32 	%f466, %f465;
	div.rn.f32 	%f1250, %f456, %f466;
	div.rn.f32 	%f1251, %f459, %f466;
	div.rn.f32 	%f1252, %f462, %f466;
	ld.const.u64 	%rd13, [params+136];
	setp.eq.s64	%p5, %rd13, 0;
	mov.f32 	%f1084, 0f00000000;
	mov.f32 	%f1085, %f1084;
	mov.f32 	%f1086, %f1084;
	mov.f32 	%f1087, %f1084;
	mov.f32 	%f1088, %f1084;
	mov.f32 	%f1089, %f1084;
	mov.f32 	%f1090, %f1252;
	mov.f32 	%f1091, %f1251;
	mov.f32 	%f1092, %f1250;
	@%p5 bra 	BB4_12;

	mov.f32 	%f1084, 0f00000000;
	ld.u64 	%rd14, [%rd6+16];
	setp.eq.s64	%p6, %rd14, 0;
	mov.f32 	%f1085, %f1084;
	mov.f32 	%f1086, %f1084;
	mov.f32 	%f1087, %f1084;
	mov.f32 	%f1088, %f1084;
	mov.f32 	%f1089, %f1084;
	mov.f32 	%f1090, %f1252;
	mov.f32 	%f1091, %f1251;
	mov.f32 	%f1092, %f1250;
	@%p6 bra 	BB4_12;

	mul.wide.u32 	%rd444, %r25, 3;
	shl.b64 	%rd443, %rd444, 2;
	mov.f32 	%f1084, 0f00000000;
	add.s64 	%rd76, %rd14, %rd443;
	add.s64 	%rd78, %rd14, %rd71;
	add.s64 	%rd80, %rd14, %rd73;
	ld.f32 	%f17, [%rd76];
	ld.f32 	%f18, [%rd76+4];
	ld.f32 	%f19, [%rd76+8];
	ld.f32 	%f20, [%rd78];
	mul.f32 	%f479, %f20, %f1099;
	ld.f32 	%f21, [%rd78+4];
	mul.f32 	%f480, %f21, %f1099;
	ld.f32 	%f22, [%rd78+8];
	mul.f32 	%f481, %f22, %f1099;
	fma.rn.f32 	%f482, %f17, %f4, %f479;
	fma.rn.f32 	%f483, %f18, %f4, %f480;
	fma.rn.f32 	%f484, %f19, %f4, %f481;
	ld.f32 	%f23, [%rd80];
	ld.f32 	%f24, [%rd80+4];
	ld.f32 	%f25, [%rd80+8];
	fma.rn.f32 	%f485, %f23, %f1100, %f482;
	fma.rn.f32 	%f486, %f24, %f1100, %f483;
	fma.rn.f32 	%f487, %f25, %f1100, %f484;
	mul.f32 	%f488, %f485, %f485;
	fma.rn.f32 	%f489, %f486, %f486, %f488;
	fma.rn.f32 	%f490, %f487, %f487, %f489;
	sqrt.rn.f32 	%f491, %f490;
	div.rn.f32 	%f1092, %f485, %f491;
	div.rn.f32 	%f1091, %f486, %f491;
	div.rn.f32 	%f1090, %f487, %f491;
	ld.const.u64 	%rd81, [params+280];
	setp.eq.s64	%p7, %rd81, 0;
	@%p7 bra 	BB4_10;

	mul.f32 	%f492, %f1099, %f23;
	fma.rn.f32 	%f493, %f4, %f20, %f492;
	mul.f32 	%f494, %f1099, %f24;
	fma.rn.f32 	%f495, %f4, %f21, %f494;
	mul.f32 	%f496, %f1099, %f25;
	fma.rn.f32 	%f497, %f4, %f22, %f496;
	fma.rn.f32 	%f498, %f1100, %f17, %f493;
	fma.rn.f32 	%f499, %f1100, %f18, %f495;
	fma.rn.f32 	%f500, %f1100, %f19, %f497;
	mul.f32 	%f501, %f498, %f498;
	fma.rn.f32 	%f502, %f499, %f499, %f501;
	fma.rn.f32 	%f503, %f500, %f500, %f502;
	sqrt.rn.f32 	%f504, %f503;
	rcp.rn.f32 	%f505, %f504;
	mul.f32 	%f506, %f505, %f498;
	mul.f32 	%f507, %f505, %f499;
	mul.f32 	%f508, %f505, %f500;
	sub.f32 	%f509, %f20, %f17;
	mul.f32 	%f510, %f509, %f505;
	sub.f32 	%f511, %f21, %f18;
	mul.f32 	%f512, %f511, %f505;
	sub.f32 	%f513, %f22, %f19;
	mul.f32 	%f514, %f513, %f505;
	sub.f32 	%f515, %f23, %f17;
	mul.f32 	%f516, %f515, %f505;
	sub.f32 	%f517, %f24, %f18;
	mul.f32 	%f518, %f517, %f505;
	sub.f32 	%f519, %f25, %f19;
	mul.f32 	%f520, %f519, %f505;
	mul.f32 	%f521, %f506, %f510;
	fma.rn.f32 	%f522, %f507, %f512, %f521;
	fma.rn.f32 	%f523, %f508, %f514, %f522;
	neg.f32 	%f524, %f506;
	neg.f32 	%f525, %f507;
	neg.f32 	%f526, %f508;
	fma.rn.f32 	%f1087, %f523, %f524, %f510;
	fma.rn.f32 	%f1088, %f523, %f525, %f512;
	fma.rn.f32 	%f1089, %f523, %f526, %f514;
	mul.f32 	%f527, %f506, %f1087;
	fma.rn.f32 	%f528, %f507, %f1088, %f527;
	fma.rn.f32 	%f529, %f508, %f1089, %f528;
	fma.rn.f32 	%f1084, %f529, %f524, %f516;
	fma.rn.f32 	%f1085, %f529, %f525, %f518;
	fma.rn.f32 	%f1086, %f529, %f526, %f520;
	bra.uni 	BB4_12;

BB4_10:
	mov.f32 	%f1085, %f1084;
	mov.f32 	%f1086, %f1084;
	mov.f32 	%f1087, %f1084;
	mov.f32 	%f1088, %f1084;
	mov.f32 	%f1089, %f1084;

BB4_12:
	mov.b32 	 %r28, %f1252;
	and.b32  	%r29, %r28, -2147483648;
	or.b32  	%r30, %r29, 1065353216;
	mov.b32 	 %f530, %r30;
	add.f32 	%f531, %f1252, %f530;
	mov.f32 	%f532, 0fBF800000;
	div.rn.f32 	%f533, %f532, %f531;
	mul.f32 	%f534, %f1250, %f1251;
	mul.f32 	%f1244, %f534, %f533;
	mul.f32 	%f535, %f1250, %f1250;
	mul.f32 	%f536, %f535, %f533;
	fma.rn.f32 	%f1247, %f530, %f536, 0f3F800000;
	mul.f32 	%f1248, %f530, %f1244;
	mul.f32 	%f537, %f1250, %f530;
	neg.f32 	%f1249, %f537;
	mul.f32 	%f538, %f1251, %f1251;
	fma.rn.f32 	%f1245, %f538, %f533, %f530;
	neg.f32 	%f1246, %f1251;
	ld.const.u64 	%rd15, [params+96];
	setp.eq.s64	%p8, %rd15, 0;
	@%p8 bra 	BB4_17;

	ld.u64 	%rd16, [%rd6+24];
	setp.eq.s64	%p9, %rd16, 0;
	@%p9 bra 	BB4_17;

	mov.f32 	%f1083, 0f3F800000;
	sub.f32 	%f1082, %f1083, %f1099;
	sub.f32 	%f1081, %f1082, %f1100;
	cvt.u64.u32	%rd447, %r27;
	cvt.u64.u32	%rd446, %r26;
	cvt.u64.u32	%rd445, %r25;
	shl.b64 	%rd82, %rd445, 3;
	add.s64 	%rd83, %rd16, %rd82;
	shl.b64 	%rd84, %rd446, 3;
	add.s64 	%rd85, %rd16, %rd84;
	shl.b64 	%rd86, %rd447, 3;
	add.s64 	%rd87, %rd16, %rd86;
	ld.f32 	%f50, [%rd83];
	ld.f32 	%f51, [%rd83+4];
	ld.f32 	%f52, [%rd85];
	mul.f32 	%f539, %f52, %f1099;
	ld.f32 	%f53, [%rd85+4];
	mul.f32 	%f540, %f53, %f1099;
	fma.rn.f32 	%f541, %f50, %f1081, %f539;
	fma.rn.f32 	%f542, %f51, %f1081, %f540;
	ld.f32 	%f54, [%rd87];
	ld.f32 	%f55, [%rd87+4];
	fma.rn.f32 	%f1099, %f54, %f1100, %f541;
	fma.rn.f32 	%f1100, %f55, %f1100, %f542;
	ld.const.u64 	%rd88, [params+184];
	setp.eq.s64	%p10, %rd88, 0;
	@%p10 bra 	BB4_17;

	sub.f32 	%f58, %f52, %f50;
	sub.f32 	%f59, %f55, %f51;
	mul.f32 	%f543, %f58, %f59;
	sub.f32 	%f60, %f54, %f50;
	sub.f32 	%f61, %f53, %f51;
	mul.f32 	%f544, %f61, %f60;
	sub.f32 	%f62, %f543, %f544;
	setp.eq.f32	%p11, %f62, 0f00000000;
	@%p11 bra 	BB4_17;

	rcp.rn.f32 	%f545, %f62;
	mul.f32 	%f546, %f61, %f11;
	mul.f32 	%f547, %f59, %f8;
	sub.f32 	%f548, %f547, %f546;
	mul.f32 	%f549, %f61, %f12;
	mul.f32 	%f550, %f59, %f9;
	sub.f32 	%f551, %f550, %f549;
	mul.f32 	%f552, %f61, %f13;
	mul.f32 	%f553, %f59, %f10;
	sub.f32 	%f554, %f553, %f552;
	mul.f32 	%f1247, %f548, %f545;
	mul.f32 	%f1248, %f551, %f545;
	mul.f32 	%f1249, %f554, %f545;
	mul.f32 	%f555, %f8, %f60;
	mul.f32 	%f556, %f9, %f60;
	mul.f32 	%f557, %f10, %f60;
	mul.f32 	%f558, %f58, %f11;
	sub.f32 	%f559, %f558, %f555;
	mul.f32 	%f560, %f58, %f12;
	sub.f32 	%f561, %f560, %f556;
	mul.f32 	%f562, %f58, %f13;
	sub.f32 	%f563, %f562, %f557;
	mul.f32 	%f1244, %f559, %f545;
	mul.f32 	%f1245, %f561, %f545;
	mul.f32 	%f1246, %f563, %f545;

BB4_17:
	ld.u64 	%rd17, [%rd43];
	ld.const.u64 	%rd89, [params+344];
	cvta.to.global.u64 	%rd90, %rd89;
	mul.wide.u32 	%rd91, %r1, 4;
	add.s64 	%rd19, %rd90, %rd91;
	ld.global.u32 	%r5, [%rd19];
	setp.eq.s32	%p12, %r5, 0;
	@%p12 bra 	BB4_65;

	// inline asm
	call (%r31), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p13, %r31, %r5;
	@%p13 bra 	BB4_65;

	mov.f32 	%f1111, 0f3F800000;
	// inline asm
	call (%r32), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p14, %r32, 0;
	mov.f32 	%f1112, 0f00000000;
	mov.f32 	%f1102, %f1112;
	mov.f32 	%f1101, %f1112;
	mov.f32 	%f1107, %f1112;
	mov.f32 	%f1108, %f1111;
	mov.f32 	%f1109, %f1112;
	mov.f32 	%f1110, %f1112;
	mov.f32 	%f1103, %f1112;
	mov.f32 	%f1104, %f1112;
	mov.f32 	%f1105, %f1111;
	mov.f32 	%f1106, %f1112;
	@%p14 bra 	BB4_37;

	// inline asm
	call (%f576), _optix_get_ray_time, ();
	// inline asm
	add.s32 	%r334, %r32, -1;
	setp.lt.s32	%p15, %r334, 0;
	@%p15 bra 	BB4_37;

BB4_21:
	.pragma "nounroll";
	// inline asm
	call (%rd92), _optix_get_transform_list_handle, (%r334);
	// inline asm
	// inline asm
	call (%r34), _optix_get_transform_type_from_handle, (%rd92);
	// inline asm
	and.b32  	%r35, %r34, -2;
	setp.eq.s32	%p16, %r35, 2;
	@%p16 bra 	BB4_27;
	bra.uni 	BB4_22;

BB4_27:
	setp.eq.s32	%p19, %r34, 2;
	@%p19 bra 	BB4_31;
	bra.uni 	BB4_28;

BB4_31:
	// inline asm
	call (%rd166), _optix_get_matrix_motion_transform_from_handle, (%rd92);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd168, %rd166;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd168];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r125;
	add.s64 	%rd172, %rd166, 16;
	// inline asm
	cvta.to.global.u64 %rd171, %rd172;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r127,%r128,%r129,%r130}, [%rd171];
	// inline asm
	add.s64 	%rd175, %rd166, 32;
	// inline asm
	cvta.to.global.u64 %rd174, %rd175;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd174];
	// inline asm
	add.s64 	%rd178, %rd166, 48;
	// inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd177];
	// inline asm
	add.s64 	%rd181, %rd166, 64;
	// inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd180];
	// inline asm
	add.s64 	%rd184, %rd166, 80;
	// inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd183];
	// inline asm
	add.s64 	%rd187, %rd166, 96;
	// inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd186];
	// inline asm
	add.s64 	%rd190, %rd166, 112;
	// inline asm
	cvta.to.global.u64 %rd189, %rd190;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd189];
	// inline asm
	mov.b32 	 %f703, %r126;
	mov.b32 	 %f704, %r127;
	cvt.u32.u16	%r167, %rs4;
	add.s32 	%r168, %r167, -1;
	cvt.rn.f32.s32	%f705, %r168;
	sub.f32 	%f706, %f576, %f703;
	mul.f32 	%f707, %f706, %f705;
	sub.f32 	%f708, %f704, %f703;
	div.rn.f32 	%f709, %f707, %f708;
	min.f32 	%f710, %f705, %f709;
	mov.f32 	%f711, 0f00000000;
	max.f32 	%f712, %f711, %f710;
	cvt.rmi.f32.f32	%f713, %f712;
	cvt.rzi.s32.f32	%r169, %f713;
	mul.wide.s32 	%rd201, %r169, 48;
	add.s64 	%rd193, %rd175, %rd201;
	// inline asm
	cvta.to.global.u64 %rd192, %rd193;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd192];
	// inline asm
	mov.b32 	 %f1137, %r155;
	mov.b32 	 %f1138, %r156;
	mov.b32 	 %f1139, %r157;
	mov.b32 	 %f1140, %r158;
	add.s64 	%rd196, %rd193, 16;
	// inline asm
	cvta.to.global.u64 %rd195, %rd196;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd195];
	// inline asm
	mov.b32 	 %f1133, %r159;
	mov.b32 	 %f1134, %r160;
	mov.b32 	 %f1135, %r161;
	mov.b32 	 %f1136, %r162;
	add.s64 	%rd199, %rd193, 32;
	// inline asm
	cvta.to.global.u64 %rd198, %rd199;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd198];
	// inline asm
	sub.f32 	%f171, %f712, %f713;
	mov.b32 	 %f1129, %r163;
	mov.b32 	 %f1130, %r164;
	mov.b32 	 %f1131, %r165;
	mov.b32 	 %f1132, %r166;
	setp.leu.f32	%p21, %f171, 0f00000000;
	@%p21 bra 	BB4_33;

	cvt.rmi.f32.f32	%f1077, %f712;
	cvt.rzi.s32.f32	%r333, %f1077;
	cvt.s64.s32	%rd442, %r333;
	mul.lo.s64 	%rd211, %rd442, 48;
	add.s64 	%rd212, %rd166, %rd211;
	add.s64 	%rd203, %rd212, 80;
	// inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r170,%r171,%r172,%r173}, [%rd202];
	// inline asm
	mov.b32 	 %f714, %r170;
	mov.b32 	 %f715, %r171;
	mov.b32 	 %f716, %r172;
	mov.b32 	 %f717, %r173;
	add.s64 	%rd206, %rd212, 96;
	// inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd205];
	// inline asm
	mov.b32 	 %f718, %r174;
	mov.b32 	 %f719, %r175;
	mov.b32 	 %f720, %r176;
	mov.b32 	 %f721, %r177;
	add.s64 	%rd209, %rd212, 112;
	// inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd208];
	// inline asm
	mov.f32 	%f722, 0f3F800000;
	sub.f32 	%f723, %f722, %f171;
	mul.f32 	%f724, %f171, %f714;
	mul.f32 	%f725, %f171, %f715;
	mul.f32 	%f726, %f171, %f716;
	mul.f32 	%f727, %f171, %f717;
	fma.rn.f32 	%f1137, %f723, %f1137, %f724;
	fma.rn.f32 	%f1138, %f723, %f1138, %f725;
	fma.rn.f32 	%f1139, %f723, %f1139, %f726;
	fma.rn.f32 	%f1140, %f723, %f1140, %f727;
	mul.f32 	%f728, %f171, %f718;
	mul.f32 	%f729, %f171, %f719;
	mul.f32 	%f730, %f171, %f720;
	mul.f32 	%f731, %f171, %f721;
	fma.rn.f32 	%f1133, %f723, %f1133, %f728;
	fma.rn.f32 	%f1134, %f723, %f1134, %f729;
	fma.rn.f32 	%f1135, %f723, %f1135, %f730;
	fma.rn.f32 	%f1136, %f723, %f1136, %f731;
	mov.b32 	 %f732, %r178;
	mov.b32 	 %f733, %r179;
	mov.b32 	 %f734, %r180;
	mov.b32 	 %f735, %r181;
	mul.f32 	%f736, %f171, %f732;
	mul.f32 	%f737, %f171, %f733;
	mul.f32 	%f738, %f171, %f734;
	mul.f32 	%f739, %f171, %f735;
	fma.rn.f32 	%f1129, %f723, %f1129, %f736;
	fma.rn.f32 	%f1130, %f723, %f1130, %f737;
	fma.rn.f32 	%f1131, %f723, %f1131, %f738;
	fma.rn.f32 	%f1132, %f723, %f1132, %f739;
	bra.uni 	BB4_33;

BB4_22:
	mov.f32 	%f1129, 0f00000000;
	mov.f32 	%f1131, 0f3F800000;
	setp.eq.s32	%p17, %r34, 4;
	@%p17 bra 	BB4_25;
	bra.uni 	BB4_23;

BB4_25:
	// inline asm
	call (%rd448), _optix_get_instance_transform_from_handle, (%rd92);
	// inline asm
	bra.uni 	BB4_26;

BB4_28:
	// inline asm
	call (%rd107), _optix_get_srt_motion_transform_from_handle, (%rd92);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd109, %rd107;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r48,%r49,%r50,%r51}, [%rd109];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r50;
	add.s64 	%rd113, %rd107, 16;
	// inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r52,%r53,%r54,%r55}, [%rd112];
	// inline asm
	add.s64 	%rd116, %rd107, 32;
	// inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r56,%r57,%r58,%r59}, [%rd115];
	// inline asm
	add.s64 	%rd119, %rd107, 48;
	// inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r60,%r61,%r62,%r63}, [%rd118];
	// inline asm
	add.s64 	%rd122, %rd107, 64;
	// inline asm
	cvta.to.global.u64 %rd121, %rd122;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r64,%r65,%r66,%r67}, [%rd121];
	// inline asm
	add.s64 	%rd125, %rd107, 80;
	// inline asm
	cvta.to.global.u64 %rd124, %rd125;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r68,%r69,%r70,%r71}, [%rd124];
	// inline asm
	add.s64 	%rd128, %rd107, 96;
	// inline asm
	cvta.to.global.u64 %rd127, %rd128;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r72,%r73,%r74,%r75}, [%rd127];
	// inline asm
	add.s64 	%rd131, %rd107, 112;
	// inline asm
	cvta.to.global.u64 %rd130, %rd131;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r76,%r77,%r78,%r79}, [%rd130];
	// inline asm
	add.s64 	%rd134, %rd107, 128;
	// inline asm
	cvta.to.global.u64 %rd133, %rd134;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r80,%r81,%r82,%r83}, [%rd133];
	// inline asm
	add.s64 	%rd137, %rd107, 144;
	// inline asm
	cvta.to.global.u64 %rd136, %rd137;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd136];
	// inline asm
	mov.b32 	 %f590, %r51;
	mov.b32 	 %f591, %r52;
	cvt.u32.u16	%r104, %rs2;
	add.s32 	%r105, %r104, -1;
	cvt.rn.f32.s32	%f592, %r105;
	sub.f32 	%f593, %f576, %f590;
	mul.f32 	%f594, %f593, %f592;
	sub.f32 	%f595, %f591, %f590;
	div.rn.f32 	%f596, %f594, %f595;
	min.f32 	%f597, %f592, %f596;
	mov.f32 	%f598, 0f00000000;
	max.f32 	%f599, %f598, %f597;
	cvt.rmi.f32.f32	%f600, %f599;
	cvt.rzi.s32.f32	%r106, %f600;
	mul.wide.s32 	%rd151, %r106, 64;
	add.s64 	%rd140, %rd116, %rd151;
	// inline asm
	cvta.to.global.u64 %rd139, %rd140;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd139];
	// inline asm
	mov.b32 	 %f1113, %r88;
	mov.b32 	 %f1114, %r89;
	mov.b32 	 %f1115, %r90;
	mov.b32 	 %f1116, %r91;
	add.s64 	%rd143, %rd140, 16;
	// inline asm
	cvta.to.global.u64 %rd142, %rd143;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd142];
	// inline asm
	mov.b32 	 %f1117, %r92;
	mov.b32 	 %f1118, %r93;
	mov.b32 	 %f1119, %r94;
	mov.b32 	 %f1120, %r95;
	add.s64 	%rd146, %rd140, 32;
	// inline asm
	cvta.to.global.u64 %rd145, %rd146;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd145];
	// inline asm
	sub.f32 	%f110, %f599, %f600;
	mov.b32 	 %f1121, %r96;
	mov.b32 	 %f1122, %r97;
	mov.b32 	 %f1123, %r98;
	mov.b32 	 %f1124, %r99;
	add.s64 	%rd149, %rd140, 48;
	// inline asm
	cvta.to.global.u64 %rd148, %rd149;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd148];
	// inline asm
	mov.b32 	 %f1125, %r100;
	mov.b32 	 %f1126, %r101;
	mov.b32 	 %f1127, %r102;
	mov.b32 	 %f1128, %r103;
	setp.leu.f32	%p20, %f110, 0f00000000;
	@%p20 bra 	BB4_30;

	cvt.rmi.f32.f32	%f1076, %f599;
	cvt.rzi.s32.f32	%r332, %f1076;
	cvt.s64.s32	%rd440, %r332;
	shl.b64 	%rd164, %rd440, 6;
	add.s64 	%rd165, %rd164, %rd107;
	add.s64 	%rd153, %rd165, 96;
	// inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r107,%r108,%r109,%r110}, [%rd152];
	// inline asm
	mov.b32 	 %f601, %r107;
	mov.b32 	 %f602, %r108;
	mov.b32 	 %f603, %r109;
	mov.b32 	 %f604, %r110;
	add.s64 	%rd156, %rd165, 112;
	// inline asm
	cvta.to.global.u64 %rd155, %rd156;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd155];
	// inline asm
	mov.b32 	 %f605, %r111;
	mov.b32 	 %f606, %r112;
	mov.b32 	 %f607, %r113;
	mov.b32 	 %f608, %r114;
	add.s64 	%rd159, %rd165, 128;
	// inline asm
	cvta.to.global.u64 %rd158, %rd159;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd158];
	// inline asm
	mov.b32 	 %f609, %r115;
	mov.b32 	 %f610, %r116;
	mov.b32 	 %f611, %r117;
	mov.b32 	 %f612, %r118;
	add.s64 	%rd162, %rd165, 144;
	// inline asm
	cvta.to.global.u64 %rd161, %rd162;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd161];
	// inline asm
	mov.f32 	%f613, 0f3F800000;
	sub.f32 	%f614, %f613, %f110;
	mul.f32 	%f615, %f110, %f601;
	mul.f32 	%f616, %f110, %f602;
	mul.f32 	%f617, %f110, %f603;
	mul.f32 	%f618, %f110, %f604;
	fma.rn.f32 	%f1113, %f614, %f1113, %f615;
	fma.rn.f32 	%f1114, %f614, %f1114, %f616;
	fma.rn.f32 	%f1115, %f614, %f1115, %f617;
	fma.rn.f32 	%f1116, %f614, %f1116, %f618;
	mul.f32 	%f619, %f110, %f605;
	mul.f32 	%f620, %f110, %f606;
	mul.f32 	%f621, %f110, %f607;
	mul.f32 	%f622, %f110, %f608;
	fma.rn.f32 	%f1117, %f614, %f1117, %f619;
	fma.rn.f32 	%f1118, %f614, %f1118, %f620;
	fma.rn.f32 	%f1119, %f614, %f1119, %f621;
	fma.rn.f32 	%f1120, %f614, %f1120, %f622;
	mul.f32 	%f623, %f110, %f609;
	mul.f32 	%f624, %f110, %f610;
	mul.f32 	%f625, %f110, %f611;
	mul.f32 	%f626, %f110, %f612;
	fma.rn.f32 	%f1121, %f614, %f1121, %f623;
	fma.rn.f32 	%f627, %f614, %f1122, %f624;
	fma.rn.f32 	%f628, %f614, %f1123, %f625;
	fma.rn.f32 	%f629, %f614, %f1124, %f626;
	mov.b32 	 %f630, %r119;
	mov.b32 	 %f631, %r120;
	mov.b32 	 %f632, %r121;
	mov.b32 	 %f633, %r122;
	mul.f32 	%f634, %f110, %f630;
	mul.f32 	%f635, %f110, %f631;
	mul.f32 	%f636, %f110, %f632;
	mul.f32 	%f637, %f110, %f633;
	fma.rn.f32 	%f638, %f614, %f1125, %f634;
	fma.rn.f32 	%f1126, %f614, %f1126, %f635;
	fma.rn.f32 	%f1127, %f614, %f1127, %f636;
	fma.rn.f32 	%f1128, %f614, %f1128, %f637;
	mul.f32 	%f639, %f628, %f628;
	fma.rn.f32 	%f640, %f627, %f627, %f639;
	fma.rn.f32 	%f641, %f629, %f629, %f640;
	fma.rn.f32 	%f642, %f638, %f638, %f641;
	sqrt.rn.f32 	%f643, %f642;
	rcp.rn.f32 	%f644, %f643;
	mul.f32 	%f1122, %f627, %f644;
	mul.f32 	%f1123, %f628, %f644;
	mul.f32 	%f1124, %f629, %f644;
	mul.f32 	%f1125, %f638, %f644;

BB4_30:
	mul.f32 	%f645, %f1123, %f1123;
	fma.rn.f32 	%f646, %f1122, %f1122, %f645;
	fma.rn.f32 	%f647, %f1124, %f1124, %f646;
	fma.rn.f32 	%f648, %f1125, %f1125, %f647;
	rcp.rn.f32 	%f649, %f648;
	mul.f32 	%f650, %f1122, %f649;
	mul.f32 	%f651, %f1123, %f649;
	mul.f32 	%f652, %f1124, %f649;
	mul.f32 	%f653, %f1125, %f649;
	mul.f32 	%f654, %f1122, %f650;
	mul.f32 	%f655, %f1123, %f651;
	mul.f32 	%f656, %f1124, %f652;
	mul.f32 	%f657, %f1122, %f651;
	mul.f32 	%f658, %f1124, %f653;
	mul.f32 	%f659, %f1122, %f652;
	mul.f32 	%f660, %f1123, %f653;
	mul.f32 	%f661, %f1123, %f652;
	mul.f32 	%f662, %f1122, %f653;
	sub.f32 	%f663, %f654, %f655;
	sub.f32 	%f664, %f663, %f656;
	fma.rn.f32 	%f665, %f1125, %f653, %f664;
	sub.f32 	%f666, %f657, %f658;
	add.f32 	%f667, %f666, %f666;
	add.f32 	%f668, %f659, %f660;
	add.f32 	%f669, %f668, %f668;
	add.f32 	%f670, %f657, %f658;
	add.f32 	%f671, %f670, %f670;
	sub.f32 	%f672, %f655, %f654;
	sub.f32 	%f673, %f672, %f656;
	fma.rn.f32 	%f674, %f1125, %f653, %f673;
	sub.f32 	%f675, %f661, %f662;
	add.f32 	%f676, %f675, %f675;
	sub.f32 	%f677, %f659, %f660;
	add.f32 	%f678, %f677, %f677;
	add.f32 	%f679, %f661, %f662;
	add.f32 	%f680, %f679, %f679;
	neg.f32 	%f681, %f654;
	sub.f32 	%f682, %f681, %f655;
	add.f32 	%f683, %f656, %f682;
	fma.rn.f32 	%f684, %f1125, %f653, %f683;
	mul.f32 	%f685, %f1116, %f665;
	fma.rn.f32 	%f686, %f1119, %f667, %f685;
	fma.rn.f32 	%f687, %f1121, %f669, %f686;
	sub.f32 	%f1140, %f1126, %f687;
	mul.f32 	%f688, %f1119, %f674;
	fma.rn.f32 	%f689, %f1116, %f671, %f688;
	fma.rn.f32 	%f690, %f1121, %f676, %f689;
	sub.f32 	%f1136, %f1127, %f690;
	mul.f32 	%f691, %f1119, %f680;
	fma.rn.f32 	%f692, %f1116, %f678, %f691;
	fma.rn.f32 	%f693, %f1121, %f684, %f692;
	sub.f32 	%f1132, %f1128, %f693;
	mul.f32 	%f694, %f1115, %f665;
	fma.rn.f32 	%f695, %f1118, %f667, %f694;
	fma.rn.f32 	%f1139, %f1120, %f669, %f695;
	mul.f32 	%f696, %f1118, %f674;
	fma.rn.f32 	%f697, %f1115, %f671, %f696;
	fma.rn.f32 	%f1135, %f1120, %f676, %f697;
	mul.f32 	%f698, %f1118, %f680;
	fma.rn.f32 	%f699, %f1115, %f678, %f698;
	fma.rn.f32 	%f1131, %f1120, %f684, %f699;
	mul.f32 	%f700, %f1114, %f665;
	fma.rn.f32 	%f1138, %f1117, %f667, %f700;
	mul.f32 	%f701, %f1117, %f674;
	fma.rn.f32 	%f1134, %f1114, %f671, %f701;
	mul.f32 	%f702, %f1117, %f680;
	fma.rn.f32 	%f1130, %f1114, %f678, %f702;
	mul.f32 	%f1137, %f1113, %f665;
	mul.f32 	%f1133, %f1113, %f671;
	mul.f32 	%f1129, %f1113, %f678;
	bra.uni 	BB4_33;

BB4_23:
	setp.ne.s32	%p18, %r34, 1;
	mov.f32 	%f1130, %f1129;
	mov.f32 	%f1132, %f1129;
	mov.f32 	%f1133, %f1129;
	mov.f32 	%f1134, %f1131;
	mov.f32 	%f1135, %f1129;
	mov.f32 	%f1136, %f1129;
	mov.f32 	%f1137, %f1131;
	mov.f32 	%f1138, %f1129;
	mov.f32 	%f1139, %f1129;
	mov.f32 	%f1140, %f1129;
	@%p18 bra 	BB4_33;

	// inline asm
	call (%rd94), _optix_get_static_transform_from_handle, (%rd92);
	// inline asm
	add.s64 	%rd448, %rd94, 16;

BB4_26:
	// inline asm
	cvta.to.global.u64 %rd98, %rd448;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r36,%r37,%r38,%r39}, [%rd98];
	// inline asm
	mov.b32 	 %f1137, %r36;
	mov.b32 	 %f1138, %r37;
	mov.b32 	 %f1139, %r38;
	mov.b32 	 %f1140, %r39;
	add.s64 	%rd102, %rd448, 16;
	// inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r40,%r41,%r42,%r43}, [%rd101];
	// inline asm
	mov.b32 	 %f1133, %r40;
	mov.b32 	 %f1134, %r41;
	mov.b32 	 %f1135, %r42;
	mov.b32 	 %f1136, %r43;
	add.s64 	%rd105, %rd448, 32;
	// inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r44,%r45,%r46,%r47}, [%rd104];
	// inline asm
	mov.b32 	 %f1129, %r44;
	mov.b32 	 %f1130, %r45;
	mov.b32 	 %f1131, %r46;
	mov.b32 	 %f1132, %r47;

BB4_33:
	add.s32 	%r11, %r334, 1;
	setp.eq.s32	%p22, %r11, %r32;
	@%p22 bra 	BB4_34;
	bra.uni 	BB4_35;

BB4_34:
	mov.f32 	%f1112, %f1138;
	mov.f32 	%f1111, %f1137;
	mov.f32 	%f1110, %f1136;
	mov.f32 	%f1109, %f1135;
	mov.f32 	%f1108, %f1134;
	mov.f32 	%f1107, %f1133;
	mov.f32 	%f1106, %f1132;
	mov.f32 	%f1105, %f1131;
	mov.f32 	%f1104, %f1130;
	mov.f32 	%f1103, %f1129;
	mov.f32 	%f1102, %f1139;
	mov.f32 	%f1101, %f1140;
	bra.uni 	BB4_36;

BB4_35:
	mul.f32 	%f740, %f1107, %f1138;
	fma.rn.f32 	%f741, %f1111, %f1137, %f740;
	fma.rn.f32 	%f200, %f1103, %f1139, %f741;
	mul.f32 	%f742, %f1108, %f1138;
	fma.rn.f32 	%f743, %f1112, %f1137, %f742;
	fma.rn.f32 	%f201, %f1104, %f1139, %f743;
	mul.f32 	%f744, %f1109, %f1138;
	fma.rn.f32 	%f745, %f1102, %f1137, %f744;
	fma.rn.f32 	%f202, %f1105, %f1139, %f745;
	mul.f32 	%f746, %f1110, %f1138;
	fma.rn.f32 	%f747, %f1101, %f1137, %f746;
	fma.rn.f32 	%f748, %f1106, %f1139, %f747;
	add.f32 	%f203, %f1140, %f748;
	mul.f32 	%f749, %f1107, %f1134;
	fma.rn.f32 	%f750, %f1111, %f1133, %f749;
	fma.rn.f32 	%f204, %f1103, %f1135, %f750;
	mul.f32 	%f751, %f1108, %f1134;
	fma.rn.f32 	%f752, %f1112, %f1133, %f751;
	fma.rn.f32 	%f205, %f1104, %f1135, %f752;
	mul.f32 	%f753, %f1109, %f1134;
	fma.rn.f32 	%f754, %f1102, %f1133, %f753;
	fma.rn.f32 	%f206, %f1105, %f1135, %f754;
	mul.f32 	%f755, %f1110, %f1134;
	fma.rn.f32 	%f756, %f1101, %f1133, %f755;
	fma.rn.f32 	%f757, %f1106, %f1135, %f756;
	add.f32 	%f207, %f1136, %f757;
	mul.f32 	%f758, %f1107, %f1130;
	fma.rn.f32 	%f759, %f1111, %f1129, %f758;
	fma.rn.f32 	%f1103, %f1103, %f1131, %f759;
	mul.f32 	%f760, %f1108, %f1130;
	fma.rn.f32 	%f761, %f1112, %f1129, %f760;
	fma.rn.f32 	%f1104, %f1104, %f1131, %f761;
	mul.f32 	%f762, %f1109, %f1130;
	fma.rn.f32 	%f763, %f1102, %f1129, %f762;
	fma.rn.f32 	%f1105, %f1105, %f1131, %f763;
	mul.f32 	%f764, %f1110, %f1130;
	fma.rn.f32 	%f765, %f1101, %f1129, %f764;
	fma.rn.f32 	%f766, %f1106, %f1131, %f765;
	add.f32 	%f1106, %f1132, %f766;
	mov.f32 	%f1112, %f201;
	mov.f32 	%f1111, %f200;
	mov.f32 	%f1110, %f207;
	mov.f32 	%f1109, %f206;
	mov.f32 	%f1108, %f205;
	mov.f32 	%f1107, %f204;
	mov.f32 	%f1102, %f202;
	mov.f32 	%f1101, %f203;

BB4_36:
	add.s32 	%r334, %r11, -2;
	setp.gt.s32	%p23, %r334, -1;
	@%p23 bra 	BB4_21;

BB4_37:
	mov.f32 	%f1166, 0f00000000;
	setp.eq.s32	%p43, %r32, 0;
	mov.f32 	%f1167, 0f3F800000;
	mov.f32 	%f1165, %f1166;
	mov.f32 	%f1170, %f1166;
	mov.f32 	%f1169, %f1167;
	mov.f32 	%f1168, %f1166;
	mov.f32 	%f1173, %f1166;
	mov.f32 	%f1172, %f1166;
	mov.f32 	%f1171, %f1167;
	@%p43 bra 	BB4_56;

	mov.u32 	%r335, 0;
	// inline asm
	call (%f776), _optix_get_ray_time, ();
	// inline asm

BB4_39:
	.pragma "nounroll";
	// inline asm
	call (%rd213), _optix_get_transform_list_handle, (%r335);
	// inline asm
	// inline asm
	call (%r184), _optix_get_transform_type_from_handle, (%rd213);
	// inline asm
	and.b32  	%r185, %r184, -2;
	setp.eq.s32	%p25, %r185, 2;
	@%p25 bra 	BB4_45;
	bra.uni 	BB4_40;

BB4_45:
	setp.eq.s32	%p28, %r184, 2;
	@%p28 bra 	BB4_49;
	bra.uni 	BB4_46;

BB4_49:
	// inline asm
	call (%rd287), _optix_get_matrix_motion_transform_from_handle, (%rd213);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd289, %rd287;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r273,%r274,%r275,%r276}, [%rd289];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r275;
	add.s64 	%rd293, %rd287, 16;
	// inline asm
	cvta.to.global.u64 %rd292, %rd293;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r277,%r278,%r279,%r280}, [%rd292];
	// inline asm
	add.s64 	%rd296, %rd287, 32;
	// inline asm
	cvta.to.global.u64 %rd295, %rd296;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r281,%r282,%r283,%r284}, [%rd295];
	// inline asm
	add.s64 	%rd299, %rd287, 48;
	// inline asm
	cvta.to.global.u64 %rd298, %rd299;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r285,%r286,%r287,%r288}, [%rd298];
	// inline asm
	add.s64 	%rd302, %rd287, 64;
	// inline asm
	cvta.to.global.u64 %rd301, %rd302;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r289,%r290,%r291,%r292}, [%rd301];
	// inline asm
	add.s64 	%rd305, %rd287, 80;
	// inline asm
	cvta.to.global.u64 %rd304, %rd305;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r293,%r294,%r295,%r296}, [%rd304];
	// inline asm
	add.s64 	%rd308, %rd287, 96;
	// inline asm
	cvta.to.global.u64 %rd307, %rd308;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd307];
	// inline asm
	add.s64 	%rd311, %rd287, 112;
	// inline asm
	cvta.to.global.u64 %rd310, %rd311;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd310];
	// inline asm
	mov.b32 	 %f879, %r276;
	mov.b32 	 %f880, %r277;
	cvt.u32.u16	%r317, %rs8;
	add.s32 	%r318, %r317, -1;
	cvt.rn.f32.s32	%f881, %r318;
	sub.f32 	%f882, %f776, %f879;
	mul.f32 	%f883, %f882, %f881;
	sub.f32 	%f884, %f880, %f879;
	div.rn.f32 	%f885, %f883, %f884;
	min.f32 	%f886, %f881, %f885;
	mov.f32 	%f887, 0f00000000;
	max.f32 	%f888, %f887, %f886;
	cvt.rmi.f32.f32	%f889, %f888;
	cvt.rzi.s32.f32	%r319, %f889;
	cvt.s64.s32	%rd35, %r319;
	mul.wide.s32 	%rd322, %r319, 48;
	add.s64 	%rd314, %rd296, %rd322;
	// inline asm
	cvta.to.global.u64 %rd313, %rd314;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd313];
	// inline asm
	mov.b32 	 %f1190, %r305;
	mov.b32 	 %f1191, %r306;
	mov.b32 	 %f1192, %r307;
	add.s64 	%rd317, %rd314, 16;
	// inline asm
	cvta.to.global.u64 %rd316, %rd317;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd316];
	// inline asm
	mov.b32 	 %f1187, %r309;
	mov.b32 	 %f1188, %r310;
	mov.b32 	 %f1189, %r311;
	add.s64 	%rd320, %rd314, 32;
	// inline asm
	cvta.to.global.u64 %rd319, %rd320;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r313,%r314,%r315,%r316}, [%rd319];
	// inline asm
	sub.f32 	%f301, %f888, %f889;
	mov.b32 	 %f1184, %r313;
	mov.b32 	 %f1185, %r314;
	mov.b32 	 %f1186, %r315;
	setp.leu.f32	%p30, %f301, 0f00000000;
	@%p30 bra 	BB4_51;

	mul.lo.s64 	%rd332, %rd35, 48;
	add.s64 	%rd333, %rd287, %rd332;
	add.s64 	%rd324, %rd333, 80;
	// inline asm
	cvta.to.global.u64 %rd323, %rd324;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r320,%r321,%r322,%r323}, [%rd323];
	// inline asm
	mov.b32 	 %f890, %r320;
	mov.b32 	 %f891, %r321;
	mov.b32 	 %f892, %r322;
	add.s64 	%rd327, %rd333, 96;
	// inline asm
	cvta.to.global.u64 %rd326, %rd327;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r324,%r325,%r326,%r327}, [%rd326];
	// inline asm
	mov.b32 	 %f893, %r324;
	mov.b32 	 %f894, %r325;
	mov.b32 	 %f895, %r326;
	add.s64 	%rd330, %rd333, 112;
	// inline asm
	cvta.to.global.u64 %rd329, %rd330;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r328,%r329,%r330,%r331}, [%rd329];
	// inline asm
	mov.f32 	%f896, 0f3F800000;
	sub.f32 	%f897, %f896, %f301;
	mul.f32 	%f898, %f301, %f890;
	mul.f32 	%f899, %f301, %f891;
	mul.f32 	%f900, %f301, %f892;
	fma.rn.f32 	%f1190, %f897, %f1190, %f898;
	fma.rn.f32 	%f1191, %f897, %f1191, %f899;
	fma.rn.f32 	%f1192, %f897, %f1192, %f900;
	mul.f32 	%f901, %f301, %f893;
	mul.f32 	%f902, %f301, %f894;
	mul.f32 	%f903, %f301, %f895;
	fma.rn.f32 	%f1187, %f897, %f1187, %f901;
	fma.rn.f32 	%f1188, %f897, %f1188, %f902;
	fma.rn.f32 	%f1189, %f897, %f1189, %f903;
	mov.b32 	 %f904, %r328;
	mov.b32 	 %f905, %r329;
	mov.b32 	 %f906, %r330;
	mul.f32 	%f907, %f301, %f904;
	mul.f32 	%f908, %f301, %f905;
	mul.f32 	%f909, %f301, %f906;
	fma.rn.f32 	%f1184, %f897, %f1184, %f907;
	fma.rn.f32 	%f1185, %f897, %f1185, %f908;
	fma.rn.f32 	%f1186, %f897, %f1186, %f909;
	bra.uni 	BB4_51;

BB4_40:
	mov.f32 	%f1193, 0f00000000;
	mov.f32 	%f1195, 0f3F800000;
	setp.eq.s32	%p26, %r184, 4;
	@%p26 bra 	BB4_43;
	bra.uni 	BB4_41;

BB4_43:
	// inline asm
	call (%rd449), _optix_get_instance_inverse_transform_from_handle, (%rd213);
	// inline asm
	bra.uni 	BB4_44;

BB4_46:
	// inline asm
	call (%rd228), _optix_get_srt_motion_transform_from_handle, (%rd213);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd230, %rd228;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r198,%r199,%r200,%r201}, [%rd230];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r200;
	add.s64 	%rd234, %rd228, 16;
	// inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r202,%r203,%r204,%r205}, [%rd233];
	// inline asm
	add.s64 	%rd237, %rd228, 32;
	// inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r206,%r207,%r208,%r209}, [%rd236];
	// inline asm
	add.s64 	%rd240, %rd228, 48;
	// inline asm
	cvta.to.global.u64 %rd239, %rd240;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r210,%r211,%r212,%r213}, [%rd239];
	// inline asm
	add.s64 	%rd243, %rd228, 64;
	// inline asm
	cvta.to.global.u64 %rd242, %rd243;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r214,%r215,%r216,%r217}, [%rd242];
	// inline asm
	add.s64 	%rd246, %rd228, 80;
	// inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r218,%r219,%r220,%r221}, [%rd245];
	// inline asm
	add.s64 	%rd249, %rd228, 96;
	// inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r222,%r223,%r224,%r225}, [%rd248];
	// inline asm
	add.s64 	%rd252, %rd228, 112;
	// inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r226,%r227,%r228,%r229}, [%rd251];
	// inline asm
	add.s64 	%rd255, %rd228, 128;
	// inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r230,%r231,%r232,%r233}, [%rd254];
	// inline asm
	add.s64 	%rd258, %rd228, 144;
	// inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd257];
	// inline asm
	mov.b32 	 %f787, %r201;
	mov.b32 	 %f788, %r202;
	cvt.u32.u16	%r254, %rs6;
	add.s32 	%r255, %r254, -1;
	cvt.rn.f32.s32	%f789, %r255;
	sub.f32 	%f790, %f776, %f787;
	mul.f32 	%f791, %f790, %f789;
	sub.f32 	%f792, %f788, %f787;
	div.rn.f32 	%f793, %f791, %f792;
	min.f32 	%f794, %f789, %f793;
	mov.f32 	%f795, 0f00000000;
	max.f32 	%f796, %f795, %f794;
	cvt.rmi.f32.f32	%f797, %f796;
	cvt.rzi.s32.f32	%r256, %f797;
	cvt.s64.s32	%rd33, %r256;
	mul.wide.s32 	%rd272, %r256, 64;
	add.s64 	%rd261, %rd237, %rd272;
	// inline asm
	cvta.to.global.u64 %rd260, %rd261;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd260];
	// inline asm
	mov.b32 	 %f1174, %r238;
	mov.b32 	 %f1175, %r239;
	mov.b32 	 %f1176, %r240;
	add.s64 	%rd264, %rd261, 16;
	// inline asm
	cvta.to.global.u64 %rd263, %rd264;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd263];
	// inline asm
	mov.b32 	 %f1177, %r242;
	mov.b32 	 %f1178, %r243;
	mov.b32 	 %f1179, %r245;
	add.s64 	%rd267, %rd261, 32;
	// inline asm
	cvta.to.global.u64 %rd266, %rd267;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd266];
	// inline asm
	sub.f32 	%f261, %f796, %f797;
	mov.b32 	 %f1180, %r247;
	mov.b32 	 %f1181, %r248;
	mov.b32 	 %f1182, %r249;
	add.s64 	%rd270, %rd261, 48;
	// inline asm
	cvta.to.global.u64 %rd269, %rd270;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd269];
	// inline asm
	mov.b32 	 %f1183, %r250;
	setp.leu.f32	%p29, %f261, 0f00000000;
	@%p29 bra 	BB4_48;

	shl.b64 	%rd285, %rd33, 6;
	add.s64 	%rd286, %rd285, %rd228;
	add.s64 	%rd274, %rd286, 96;
	// inline asm
	cvta.to.global.u64 %rd273, %rd274;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r257,%r258,%r259,%r260}, [%rd273];
	// inline asm
	mov.b32 	 %f798, %r257;
	mov.b32 	 %f799, %r258;
	mov.b32 	 %f800, %r259;
	add.s64 	%rd277, %rd286, 112;
	// inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r261,%r262,%r263,%r264}, [%rd276];
	// inline asm
	mov.b32 	 %f801, %r261;
	mov.b32 	 %f802, %r262;
	mov.b32 	 %f803, %r264;
	add.s64 	%rd280, %rd286, 128;
	// inline asm
	cvta.to.global.u64 %rd279, %rd280;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r265,%r266,%r267,%r268}, [%rd279];
	// inline asm
	mov.b32 	 %f804, %r266;
	mov.b32 	 %f805, %r267;
	mov.b32 	 %f806, %r268;
	add.s64 	%rd283, %rd286, 144;
	// inline asm
	cvta.to.global.u64 %rd282, %rd283;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r269,%r270,%r271,%r272}, [%rd282];
	// inline asm
	mov.f32 	%f807, 0f3F800000;
	sub.f32 	%f808, %f807, %f261;
	mul.f32 	%f809, %f261, %f798;
	mul.f32 	%f810, %f261, %f799;
	mul.f32 	%f811, %f261, %f800;
	fma.rn.f32 	%f1174, %f808, %f1174, %f809;
	fma.rn.f32 	%f1175, %f808, %f1175, %f810;
	fma.rn.f32 	%f1176, %f808, %f1176, %f811;
	mul.f32 	%f812, %f261, %f801;
	mul.f32 	%f813, %f261, %f802;
	mul.f32 	%f814, %f261, %f803;
	fma.rn.f32 	%f1177, %f808, %f1177, %f812;
	fma.rn.f32 	%f1178, %f808, %f1178, %f813;
	fma.rn.f32 	%f1179, %f808, %f1179, %f814;
	mul.f32 	%f815, %f261, %f804;
	mul.f32 	%f816, %f261, %f805;
	mul.f32 	%f817, %f261, %f806;
	fma.rn.f32 	%f818, %f808, %f1180, %f815;
	fma.rn.f32 	%f819, %f808, %f1181, %f816;
	fma.rn.f32 	%f820, %f808, %f1182, %f817;
	mov.b32 	 %f821, %r269;
	mul.f32 	%f822, %f261, %f821;
	fma.rn.f32 	%f823, %f808, %f1183, %f822;
	mul.f32 	%f824, %f819, %f819;
	fma.rn.f32 	%f825, %f818, %f818, %f824;
	fma.rn.f32 	%f826, %f820, %f820, %f825;
	fma.rn.f32 	%f827, %f823, %f823, %f826;
	sqrt.rn.f32 	%f828, %f827;
	rcp.rn.f32 	%f829, %f828;
	mul.f32 	%f1180, %f818, %f829;
	mul.f32 	%f1181, %f819, %f829;
	mul.f32 	%f1182, %f820, %f829;
	mul.f32 	%f1183, %f823, %f829;

BB4_48:
	mul.f32 	%f830, %f1181, %f1181;
	fma.rn.f32 	%f831, %f1180, %f1180, %f830;
	fma.rn.f32 	%f832, %f1182, %f1182, %f831;
	fma.rn.f32 	%f833, %f1183, %f1183, %f832;
	rcp.rn.f32 	%f834, %f833;
	mul.f32 	%f835, %f1180, %f834;
	mul.f32 	%f836, %f1181, %f834;
	mul.f32 	%f837, %f1182, %f834;
	mul.f32 	%f838, %f1183, %f834;
	mul.f32 	%f839, %f1180, %f835;
	mul.f32 	%f840, %f1181, %f836;
	mul.f32 	%f841, %f1182, %f837;
	mul.f32 	%f842, %f1180, %f836;
	mul.f32 	%f843, %f1182, %f838;
	mul.f32 	%f844, %f1180, %f837;
	mul.f32 	%f845, %f1181, %f838;
	mul.f32 	%f846, %f1181, %f837;
	mul.f32 	%f847, %f1180, %f838;
	sub.f32 	%f848, %f839, %f840;
	sub.f32 	%f849, %f848, %f841;
	fma.rn.f32 	%f850, %f1183, %f838, %f849;
	sub.f32 	%f851, %f842, %f843;
	add.f32 	%f852, %f851, %f851;
	add.f32 	%f853, %f844, %f845;
	add.f32 	%f854, %f853, %f853;
	add.f32 	%f855, %f842, %f843;
	add.f32 	%f856, %f855, %f855;
	sub.f32 	%f857, %f840, %f839;
	sub.f32 	%f858, %f857, %f841;
	fma.rn.f32 	%f859, %f1183, %f838, %f858;
	sub.f32 	%f860, %f846, %f847;
	add.f32 	%f861, %f860, %f860;
	sub.f32 	%f862, %f844, %f845;
	add.f32 	%f863, %f862, %f862;
	add.f32 	%f864, %f846, %f847;
	add.f32 	%f865, %f864, %f864;
	neg.f32 	%f866, %f839;
	sub.f32 	%f867, %f866, %f840;
	add.f32 	%f868, %f841, %f867;
	fma.rn.f32 	%f869, %f1183, %f838, %f868;
	mul.f32 	%f870, %f1176, %f850;
	fma.rn.f32 	%f871, %f1178, %f852, %f870;
	fma.rn.f32 	%f1192, %f1179, %f854, %f871;
	mul.f32 	%f872, %f1178, %f859;
	fma.rn.f32 	%f873, %f1176, %f856, %f872;
	fma.rn.f32 	%f1189, %f1179, %f861, %f873;
	mul.f32 	%f874, %f1178, %f865;
	fma.rn.f32 	%f875, %f1176, %f863, %f874;
	fma.rn.f32 	%f1186, %f1179, %f869, %f875;
	mul.f32 	%f876, %f1175, %f850;
	fma.rn.f32 	%f1191, %f1177, %f852, %f876;
	mul.f32 	%f877, %f1177, %f859;
	fma.rn.f32 	%f1188, %f1175, %f856, %f877;
	mul.f32 	%f878, %f1177, %f865;
	fma.rn.f32 	%f1185, %f1175, %f863, %f878;
	mul.f32 	%f1190, %f1174, %f850;
	mul.f32 	%f1187, %f1174, %f856;
	mul.f32 	%f1184, %f1174, %f863;

BB4_51:
	mul.f32 	%f910, %f1185, %f1189;
	mul.f32 	%f911, %f1186, %f1188;
	sub.f32 	%f912, %f911, %f910;
	mul.f32 	%f913, %f1190, %f912;
	mul.f32 	%f914, %f1184, %f1189;
	mul.f32 	%f915, %f1186, %f1187;
	sub.f32 	%f916, %f915, %f914;
	mul.f32 	%f917, %f916, %f1191;
	sub.f32 	%f918, %f913, %f917;
	mul.f32 	%f919, %f1184, %f1188;
	mul.f32 	%f920, %f1185, %f1187;
	sub.f32 	%f921, %f920, %f919;
	fma.rn.f32 	%f922, %f921, %f1192, %f918;
	rcp.rn.f32 	%f923, %f922;
	mul.f32 	%f1199, %f912, %f923;
	mul.f32 	%f924, %f1186, %f1191;
	mul.f32 	%f925, %f1185, %f1192;
	sub.f32 	%f926, %f925, %f924;
	mul.f32 	%f1200, %f923, %f926;
	mul.f32 	%f927, %f1188, %f1192;
	mul.f32 	%f928, %f1189, %f1191;
	sub.f32 	%f929, %f928, %f927;
	mul.f32 	%f1201, %f923, %f929;
	sub.f32 	%f930, %f914, %f915;
	mul.f32 	%f1196, %f930, %f923;
	mul.f32 	%f931, %f1184, %f1192;
	mul.f32 	%f932, %f1186, %f1190;
	sub.f32 	%f933, %f932, %f931;
	mul.f32 	%f1197, %f923, %f933;
	mul.f32 	%f934, %f1189, %f1190;
	mul.f32 	%f935, %f1187, %f1192;
	sub.f32 	%f936, %f935, %f934;
	mul.f32 	%f1198, %f923, %f936;
	mul.f32 	%f1193, %f921, %f923;
	mul.f32 	%f937, %f1185, %f1190;
	mul.f32 	%f938, %f1184, %f1191;
	sub.f32 	%f939, %f938, %f937;
	mul.f32 	%f1194, %f939, %f923;
	mul.f32 	%f940, %f1187, %f1191;
	mul.f32 	%f941, %f1188, %f1190;
	sub.f32 	%f942, %f941, %f940;
	mul.f32 	%f1195, %f942, %f923;
	bra.uni 	BB4_52;

BB4_41:
	setp.ne.s32	%p27, %r184, 1;
	mov.f32 	%f1194, %f1193;
	mov.f32 	%f1196, %f1193;
	mov.f32 	%f1197, %f1195;
	mov.f32 	%f1198, %f1193;
	mov.f32 	%f1199, %f1195;
	mov.f32 	%f1200, %f1193;
	mov.f32 	%f1201, %f1193;
	@%p27 bra 	BB4_52;

	// inline asm
	call (%rd215), _optix_get_static_transform_from_handle, (%rd213);
	// inline asm
	add.s64 	%rd449, %rd215, 64;

BB4_44:
	// inline asm
	cvta.to.global.u64 %rd219, %rd449;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r186,%r187,%r188,%r189}, [%rd219];
	// inline asm
	mov.b32 	 %f1199, %r186;
	mov.b32 	 %f1200, %r187;
	mov.b32 	 %f1201, %r188;
	add.s64 	%rd223, %rd449, 16;
	// inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r190,%r191,%r192,%r193}, [%rd222];
	// inline asm
	mov.b32 	 %f1196, %r190;
	mov.b32 	 %f1197, %r191;
	mov.b32 	 %f1198, %r192;
	add.s64 	%rd226, %rd449, 32;
	// inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r194,%r195,%r196,%r197}, [%rd225];
	// inline asm
	mov.b32 	 %f1193, %r194;
	mov.b32 	 %f1194, %r195;
	mov.b32 	 %f1195, %r196;

BB4_52:
	setp.eq.s32	%p31, %r335, 0;
	@%p31 bra 	BB4_53;
	bra.uni 	BB4_54;

BB4_53:
	mov.f32 	%f1173, %f1193;
	mov.f32 	%f1172, %f1194;
	mov.f32 	%f1171, %f1195;
	mov.f32 	%f1170, %f1196;
	mov.f32 	%f1169, %f1197;
	mov.f32 	%f1168, %f1198;
	mov.f32 	%f1167, %f1199;
	mov.f32 	%f1166, %f1200;
	mov.f32 	%f1165, %f1201;
	bra.uni 	BB4_55;

BB4_54:
	mul.f32 	%f943, %f1170, %f1200;
	fma.rn.f32 	%f944, %f1167, %f1199, %f943;
	fma.rn.f32 	%f341, %f1173, %f1201, %f944;
	mul.f32 	%f945, %f1169, %f1200;
	fma.rn.f32 	%f946, %f1166, %f1199, %f945;
	fma.rn.f32 	%f342, %f1172, %f1201, %f946;
	mul.f32 	%f947, %f1168, %f1200;
	fma.rn.f32 	%f948, %f1165, %f1199, %f947;
	fma.rn.f32 	%f343, %f1171, %f1201, %f948;
	mul.f32 	%f949, %f1170, %f1197;
	fma.rn.f32 	%f950, %f1167, %f1196, %f949;
	fma.rn.f32 	%f344, %f1173, %f1198, %f950;
	mul.f32 	%f951, %f1169, %f1197;
	fma.rn.f32 	%f952, %f1166, %f1196, %f951;
	fma.rn.f32 	%f345, %f1172, %f1198, %f952;
	mul.f32 	%f953, %f1168, %f1197;
	fma.rn.f32 	%f954, %f1165, %f1196, %f953;
	fma.rn.f32 	%f346, %f1171, %f1198, %f954;
	mul.f32 	%f955, %f1170, %f1194;
	fma.rn.f32 	%f956, %f1167, %f1193, %f955;
	fma.rn.f32 	%f1173, %f1173, %f1195, %f956;
	mul.f32 	%f957, %f1169, %f1194;
	fma.rn.f32 	%f958, %f1166, %f1193, %f957;
	fma.rn.f32 	%f1172, %f1172, %f1195, %f958;
	mul.f32 	%f959, %f1168, %f1194;
	fma.rn.f32 	%f960, %f1165, %f1193, %f959;
	fma.rn.f32 	%f1171, %f1171, %f1195, %f960;
	mov.f32 	%f1170, %f344;
	mov.f32 	%f1169, %f345;
	mov.f32 	%f1168, %f346;
	mov.f32 	%f1167, %f341;
	mov.f32 	%f1166, %f342;
	mov.f32 	%f1165, %f343;

BB4_55:
	add.s32 	%r335, %r335, 1;
	setp.lt.u32	%p32, %r335, %r32;
	@%p32 bra 	BB4_39;

BB4_56:
	fma.rn.f32 	%f961, %f1256, %f1111, %f1101;
	fma.rn.f32 	%f962, %f1257, %f1112, %f961;
	fma.rn.f32 	%f963, %f1256, %f1107, %f1110;
	fma.rn.f32 	%f964, %f1257, %f1108, %f963;
	fma.rn.f32 	%f965, %f1256, %f1103, %f1106;
	fma.rn.f32 	%f966, %f1257, %f1104, %f965;
	fma.rn.f32 	%f1256, %f1258, %f1102, %f962;
	fma.rn.f32 	%f1257, %f1258, %f1109, %f964;
	fma.rn.f32 	%f1258, %f1258, %f1105, %f966;
	ld.const.u64 	%rd334, [params+112];
	setp.eq.s64	%p33, %rd334, 0;
	@%p33 bra 	BB4_58;

	mul.f32 	%f967, %f1250, %f1167;
	fma.rn.f32 	%f968, %f1251, %f1170, %f967;
	mul.f32 	%f969, %f1250, %f1166;
	fma.rn.f32 	%f970, %f1251, %f1169, %f969;
	mul.f32 	%f971, %f1250, %f1165;
	fma.rn.f32 	%f972, %f1251, %f1168, %f971;
	fma.rn.f32 	%f973, %f1252, %f1173, %f968;
	fma.rn.f32 	%f974, %f1252, %f1172, %f970;
	fma.rn.f32 	%f975, %f1252, %f1171, %f972;
	mul.f32 	%f976, %f973, %f973;
	fma.rn.f32 	%f977, %f974, %f974, %f976;
	fma.rn.f32 	%f978, %f975, %f975, %f977;
	sqrt.rn.f32 	%f979, %f978;
	div.rn.f32 	%f1250, %f973, %f979;
	div.rn.f32 	%f1251, %f974, %f979;
	div.rn.f32 	%f1252, %f975, %f979;

BB4_58:
	@%p5 bra 	BB4_60;

	mul.f32 	%f980, %f1092, %f1167;
	fma.rn.f32 	%f981, %f1091, %f1170, %f980;
	mul.f32 	%f982, %f1092, %f1166;
	fma.rn.f32 	%f983, %f1091, %f1169, %f982;
	mul.f32 	%f984, %f1092, %f1165;
	fma.rn.f32 	%f985, %f1091, %f1168, %f984;
	fma.rn.f32 	%f986, %f1090, %f1173, %f981;
	fma.rn.f32 	%f987, %f1090, %f1172, %f983;
	fma.rn.f32 	%f988, %f1090, %f1171, %f985;
	mul.f32 	%f989, %f986, %f986;
	fma.rn.f32 	%f990, %f987, %f987, %f989;
	fma.rn.f32 	%f991, %f988, %f988, %f990;
	sqrt.rn.f32 	%f992, %f991;
	div.rn.f32 	%f1092, %f986, %f992;
	div.rn.f32 	%f1091, %f987, %f992;
	div.rn.f32 	%f1090, %f988, %f992;

BB4_60:
	ld.const.u64 	%rd335, [params+184];
	setp.eq.s64	%p35, %rd335, 0;
	@%p35 bra 	BB4_62;

	mul.f32 	%f993, %f1247, %f1111;
	fma.rn.f32 	%f994, %f1248, %f1112, %f993;
	mul.f32 	%f995, %f1247, %f1107;
	fma.rn.f32 	%f996, %f1248, %f1108, %f995;
	mul.f32 	%f997, %f1247, %f1103;
	fma.rn.f32 	%f998, %f1248, %f1104, %f997;
	fma.rn.f32 	%f1247, %f1249, %f1102, %f994;
	fma.rn.f32 	%f1248, %f1249, %f1109, %f996;
	fma.rn.f32 	%f1249, %f1249, %f1105, %f998;
	mul.f32 	%f999, %f1244, %f1111;
	fma.rn.f32 	%f1000, %f1245, %f1112, %f999;
	mul.f32 	%f1001, %f1244, %f1107;
	fma.rn.f32 	%f1002, %f1245, %f1108, %f1001;
	mul.f32 	%f1003, %f1244, %f1103;
	fma.rn.f32 	%f1004, %f1245, %f1104, %f1003;
	fma.rn.f32 	%f1244, %f1246, %f1102, %f1000;
	fma.rn.f32 	%f1245, %f1246, %f1109, %f1002;
	fma.rn.f32 	%f1246, %f1246, %f1105, %f1004;

BB4_62:
	ld.const.u64 	%rd336, [params+280];
	ld.const.u64 	%rd337, [params+232];
	or.b64  	%rd338, %rd336, %rd337;
	setp.eq.s64	%p36, %rd338, 0;
	@%p36 bra 	BB4_64;

	mul.f32 	%f1005, %f1092, %f1111;
	fma.rn.f32 	%f1006, %f1091, %f1107, %f1005;
	mul.f32 	%f1007, %f1092, %f1112;
	fma.rn.f32 	%f1008, %f1091, %f1108, %f1007;
	mul.f32 	%f1009, %f1092, %f1102;
	fma.rn.f32 	%f1010, %f1091, %f1109, %f1009;
	fma.rn.f32 	%f1011, %f1090, %f1103, %f1006;
	fma.rn.f32 	%f1012, %f1090, %f1104, %f1008;
	fma.rn.f32 	%f1013, %f1090, %f1105, %f1010;
	mul.f32 	%f1014, %f1011, %f1011;
	fma.rn.f32 	%f1015, %f1012, %f1012, %f1014;
	fma.rn.f32 	%f1016, %f1013, %f1013, %f1015;
	sqrt.rn.f32 	%f1017, %f1016;
	div.rn.f32 	%f1018, %f1011, %f1017;
	div.rn.f32 	%f1019, %f1012, %f1017;
	div.rn.f32 	%f1020, %f1013, %f1017;
	mul.f32 	%f1021, %f1018, %f1167;
	mul.f32 	%f1022, %f1018, %f1166;
	mul.f32 	%f1023, %f1018, %f1165;
	fma.rn.f32 	%f1024, %f1019, %f1170, %f1021;
	fma.rn.f32 	%f1025, %f1019, %f1169, %f1022;
	fma.rn.f32 	%f1026, %f1019, %f1168, %f1023;
	fma.rn.f32 	%f1027, %f1020, %f1173, %f1024;
	fma.rn.f32 	%f1028, %f1020, %f1172, %f1025;
	fma.rn.f32 	%f1029, %f1020, %f1171, %f1026;
	mul.f32 	%f1030, %f1027, %f1027;
	fma.rn.f32 	%f1031, %f1028, %f1028, %f1030;
	fma.rn.f32 	%f1032, %f1029, %f1029, %f1031;
	sqrt.rn.f32 	%f1033, %f1032;
	rcp.rn.f32 	%f1034, %f1033;
	mul.f32 	%f1035, %f1034, %f1027;
	mul.f32 	%f1036, %f1034, %f1028;
	mul.f32 	%f1037, %f1034, %f1029;
	mul.f32 	%f1038, %f1087, %f1167;
	fma.rn.f32 	%f1039, %f1088, %f1170, %f1038;
	mul.f32 	%f1040, %f1087, %f1166;
	fma.rn.f32 	%f1041, %f1088, %f1169, %f1040;
	mul.f32 	%f1042, %f1087, %f1165;
	fma.rn.f32 	%f1043, %f1088, %f1168, %f1042;
	fma.rn.f32 	%f1044, %f1089, %f1173, %f1039;
	fma.rn.f32 	%f1045, %f1089, %f1172, %f1041;
	fma.rn.f32 	%f1046, %f1089, %f1171, %f1043;
	mul.f32 	%f1047, %f1044, %f1034;
	mul.f32 	%f1048, %f1045, %f1034;
	mul.f32 	%f1049, %f1046, %f1034;
	mul.f32 	%f1050, %f1084, %f1167;
	fma.rn.f32 	%f1051, %f1085, %f1170, %f1050;
	mul.f32 	%f1052, %f1084, %f1166;
	fma.rn.f32 	%f1053, %f1085, %f1169, %f1052;
	mul.f32 	%f1054, %f1084, %f1165;
	fma.rn.f32 	%f1055, %f1085, %f1168, %f1054;
	fma.rn.f32 	%f1056, %f1086, %f1173, %f1051;
	fma.rn.f32 	%f1057, %f1086, %f1172, %f1053;
	fma.rn.f32 	%f1058, %f1086, %f1171, %f1055;
	mul.f32 	%f1059, %f1056, %f1034;
	mul.f32 	%f1060, %f1057, %f1034;
	mul.f32 	%f1061, %f1058, %f1034;
	mul.f32 	%f1062, %f1035, %f1047;
	fma.rn.f32 	%f1063, %f1036, %f1048, %f1062;
	fma.rn.f32 	%f1064, %f1037, %f1049, %f1063;
	mul.f32 	%f1065, %f1035, %f1064;
	mul.f32 	%f1066, %f1036, %f1064;
	mul.f32 	%f1067, %f1037, %f1064;
	sub.f32 	%f1087, %f1047, %f1065;
	sub.f32 	%f1088, %f1048, %f1066;
	sub.f32 	%f1089, %f1049, %f1067;
	mul.f32 	%f1068, %f1035, %f1059;
	fma.rn.f32 	%f1069, %f1036, %f1060, %f1068;
	fma.rn.f32 	%f1070, %f1037, %f1061, %f1069;
	mul.f32 	%f1071, %f1035, %f1070;
	mul.f32 	%f1072, %f1036, %f1070;
	mul.f32 	%f1073, %f1037, %f1070;
	sub.f32 	%f1084, %f1059, %f1071;
	sub.f32 	%f1085, %f1060, %f1072;
	sub.f32 	%f1086, %f1061, %f1073;

BB4_64:
	st.global.u32 	[%rd19], %r31;

BB4_65:
	ld.const.u64 	%rd441, [params+96];
	setp.eq.s64	%p44, %rd441, 0;
	cvt.u64.u32	%rd437, %r1;
	ld.const.u64 	%rd339, [params+328];
	cvta.to.global.u64 	%rd340, %rd339;
	shl.b64 	%rd341, %rd437, 3;
	add.s64 	%rd342, %rd340, %rd341;
	st.global.u64 	[%rd342], %rd17;
	ld.const.u64 	%rd343, [params+336];
	cvta.to.global.u64 	%rd344, %rd343;
	shl.b64 	%rd345, %rd437, 2;
	add.s64 	%rd346, %rd344, %rd345;
	st.global.u32 	[%rd346], %r23;
	ld.const.u64 	%rd347, [params+160];
	cvta.to.global.u64 	%rd348, %rd347;
	add.s64 	%rd349, %rd348, %rd345;
	st.global.f32 	[%rd349], %f1256;
	ld.const.u64 	%rd350, [params+168];
	cvta.to.global.u64 	%rd351, %rd350;
	add.s64 	%rd352, %rd351, %rd345;
	st.global.f32 	[%rd352], %f1257;
	ld.const.u64 	%rd353, [params+176];
	cvta.to.global.u64 	%rd354, %rd353;
	add.s64 	%rd355, %rd354, %rd345;
	st.global.f32 	[%rd355], %f1258;
	ld.const.u64 	%rd356, [params+72];
	cvta.to.global.u64 	%rd357, %rd356;
	add.s64 	%rd358, %rd357, %rd345;
	st.global.f32 	[%rd358], %f428;
	@%p44 bra 	BB4_67;

	ld.const.u64 	%rd438, [params+96];
	cvta.to.global.u64 	%rd359, %rd438;
	add.s64 	%rd361, %rd359, %rd345;
	st.global.f32 	[%rd361], %f1099;
	ld.const.u64 	%rd362, [params+104];
	cvta.to.global.u64 	%rd363, %rd362;
	add.s64 	%rd364, %rd363, %rd345;
	st.global.f32 	[%rd364], %f1100;

BB4_67:
	ld.const.u64 	%rd36, [params+112];
	setp.eq.s64	%p38, %rd36, 0;
	@%p38 bra 	BB4_69;

	cvta.to.global.u64 	%rd365, %rd36;
	add.s64 	%rd367, %rd365, %rd345;
	st.global.f32 	[%rd367], %f1250;
	ld.const.u64 	%rd368, [params+120];
	cvta.to.global.u64 	%rd369, %rd368;
	add.s64 	%rd370, %rd369, %rd345;
	st.global.f32 	[%rd370], %f1251;
	ld.const.u64 	%rd371, [params+128];
	cvta.to.global.u64 	%rd372, %rd371;
	add.s64 	%rd373, %rd372, %rd345;
	st.global.f32 	[%rd373], %f1252;

BB4_69:
	@%p5 bra 	BB4_71;

	ld.const.u64 	%rd439, [params+136];
	cvta.to.global.u64 	%rd374, %rd439;
	add.s64 	%rd376, %rd374, %rd345;
	st.global.f32 	[%rd376], %f1092;
	ld.const.u64 	%rd377, [params+144];
	cvta.to.global.u64 	%rd378, %rd377;
	add.s64 	%rd379, %rd378, %rd345;
	st.global.f32 	[%rd379], %f1091;
	ld.const.u64 	%rd380, [params+152];
	cvta.to.global.u64 	%rd381, %rd380;
	add.s64 	%rd382, %rd381, %rd345;
	st.global.f32 	[%rd382], %f1090;

BB4_71:
	ld.const.u64 	%rd37, [params+184];
	setp.eq.s64	%p40, %rd37, 0;
	@%p40 bra 	BB4_73;

	cvta.to.global.u64 	%rd383, %rd37;
	add.s64 	%rd385, %rd383, %rd345;
	st.global.f32 	[%rd385], %f1247;
	ld.const.u64 	%rd386, [params+192];
	cvta.to.global.u64 	%rd387, %rd386;
	add.s64 	%rd388, %rd387, %rd345;
	st.global.f32 	[%rd388], %f1248;
	ld.const.u64 	%rd389, [params+200];
	cvta.to.global.u64 	%rd390, %rd389;
	add.s64 	%rd391, %rd390, %rd345;
	st.global.f32 	[%rd391], %f1249;
	ld.const.u64 	%rd392, [params+208];
	cvta.to.global.u64 	%rd393, %rd392;
	add.s64 	%rd394, %rd393, %rd345;
	st.global.f32 	[%rd394], %f1244;
	ld.const.u64 	%rd395, [params+216];
	cvta.to.global.u64 	%rd396, %rd395;
	add.s64 	%rd397, %rd396, %rd345;
	st.global.f32 	[%rd397], %f1245;
	ld.const.u64 	%rd398, [params+224];
	cvta.to.global.u64 	%rd399, %rd398;
	add.s64 	%rd400, %rd399, %rd345;
	st.global.f32 	[%rd400], %f1246;

BB4_73:
	ld.const.u64 	%rd38, [params+232];
	setp.eq.s64	%p41, %rd38, 0;
	@%p41 bra 	BB4_75;

	cvta.to.global.u64 	%rd401, %rd38;
	add.s64 	%rd403, %rd401, %rd345;
	st.global.f32 	[%rd403], %f1087;
	ld.const.u64 	%rd404, [params+240];
	cvta.to.global.u64 	%rd405, %rd404;
	add.s64 	%rd406, %rd405, %rd345;
	st.global.f32 	[%rd406], %f1088;
	ld.const.u64 	%rd407, [params+248];
	cvta.to.global.u64 	%rd408, %rd407;
	add.s64 	%rd409, %rd408, %rd345;
	st.global.f32 	[%rd409], %f1089;
	ld.const.u64 	%rd410, [params+256];
	cvta.to.global.u64 	%rd411, %rd410;
	add.s64 	%rd412, %rd411, %rd345;
	st.global.f32 	[%rd412], %f1084;
	ld.const.u64 	%rd413, [params+264];
	cvta.to.global.u64 	%rd414, %rd413;
	add.s64 	%rd415, %rd414, %rd345;
	st.global.f32 	[%rd415], %f1085;
	ld.const.u64 	%rd416, [params+272];
	cvta.to.global.u64 	%rd417, %rd416;
	add.s64 	%rd418, %rd417, %rd345;
	st.global.f32 	[%rd418], %f1086;

BB4_75:
	ld.const.u64 	%rd39, [params+280];
	setp.eq.s64	%p42, %rd39, 0;
	@%p42 bra 	BB4_77;

	cvta.to.global.u64 	%rd419, %rd39;
	add.s64 	%rd421, %rd419, %rd345;
	st.global.f32 	[%rd421], %f1087;
	ld.const.u64 	%rd422, [params+288];
	cvta.to.global.u64 	%rd423, %rd422;
	add.s64 	%rd424, %rd423, %rd345;
	st.global.f32 	[%rd424], %f1088;
	ld.const.u64 	%rd425, [params+296];
	cvta.to.global.u64 	%rd426, %rd425;
	add.s64 	%rd427, %rd426, %rd345;
	st.global.f32 	[%rd427], %f1089;
	ld.const.u64 	%rd428, [params+304];
	cvta.to.global.u64 	%rd429, %rd428;
	add.s64 	%rd430, %rd429, %rd345;
	st.global.f32 	[%rd430], %f1084;
	ld.const.u64 	%rd431, [params+312];
	cvta.to.global.u64 	%rd432, %rd431;
	add.s64 	%rd433, %rd432, %rd345;
	st.global.f32 	[%rd433], %f1085;
	ld.const.u64 	%rd434, [params+320];
	cvta.to.global.u64 	%rd435, %rd434;
	add.s64 	%rd436, %rd435, %rd345;
	st.global.f32 	[%rd436], %f1086;

BB4_77:
	ret;
}

	// .globl	__intersection__rectangle
.visible .entry __intersection__rectangle(

)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<9>;
	.reg .f32 	%f<932>;
	.reg .b32 	%r<315>;
	.reg .b64 	%rd<265>;


	// inline asm
	call (%rd18), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd1, [%rd18+8];
	// inline asm
	call (%f315), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f316), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f880), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r8), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p1, %r8, 0;
	@%p1 bra 	BB5_1;

	mov.u32 	%r313, 0;
	// inline asm
	call (%f318), _optix_get_ray_time, ();
	// inline asm

BB5_3:
	.pragma "nounroll";
	// inline asm
	call (%rd19), _optix_get_transform_list_handle, (%r313);
	// inline asm
	// inline asm
	call (%r11), _optix_get_transform_type_from_handle, (%rd19);
	// inline asm
	and.b32  	%r12, %r11, -2;
	setp.eq.s32	%p2, %r12, 2;
	@%p2 bra 	BB5_9;
	bra.uni 	BB5_4;

BB5_9:
	setp.eq.s32	%p5, %r11, 2;
	@%p5 bra 	BB5_13;
	bra.uni 	BB5_10;

BB5_13:
	// inline asm
	call (%rd93), _optix_get_matrix_motion_transform_from_handle, (%rd19);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd95, %rd93;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd95];
	// inline asm
	mov.b32	{%rs3, %rs4}, %r102;
	add.s64 	%rd99, %rd93, 16;
	// inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd98];
	// inline asm
	add.s64 	%rd102, %rd93, 32;
	// inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd101];
	// inline asm
	add.s64 	%rd105, %rd93, 48;
	// inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd104];
	// inline asm
	add.s64 	%rd108, %rd93, 64;
	// inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd107];
	// inline asm
	add.s64 	%rd111, %rd93, 80;
	// inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd110];
	// inline asm
	add.s64 	%rd114, %rd93, 96;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd113];
	// inline asm
	add.s64 	%rd117, %rd93, 112;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd116];
	// inline asm
	mov.b32 	 %f445, %r103;
	mov.b32 	 %f446, %r104;
	cvt.u32.u16	%r144, %rs3;
	add.s32 	%r145, %r144, -1;
	cvt.rn.f32.s32	%f447, %r145;
	sub.f32 	%f448, %f318, %f445;
	mul.f32 	%f449, %f448, %f447;
	sub.f32 	%f450, %f446, %f445;
	div.rn.f32 	%f451, %f449, %f450;
	min.f32 	%f452, %f447, %f451;
	mov.f32 	%f453, 0f00000000;
	max.f32 	%f454, %f453, %f452;
	cvt.rmi.f32.f32	%f455, %f454;
	cvt.rzi.s32.f32	%r146, %f455;
	mul.wide.s32 	%rd128, %r146, 48;
	add.s64 	%rd120, %rd102, %rd128;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd119];
	// inline asm
	mov.b32 	 %f852, %r132;
	mov.b32 	 %f853, %r133;
	mov.b32 	 %f854, %r134;
	mov.b32 	 %f855, %r135;
	add.s64 	%rd123, %rd120, 16;
	// inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd122];
	// inline asm
	mov.b32 	 %f848, %r136;
	mov.b32 	 %f849, %r137;
	mov.b32 	 %f850, %r138;
	mov.b32 	 %f851, %r139;
	add.s64 	%rd126, %rd120, 32;
	// inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd125];
	// inline asm
	sub.f32 	%f98, %f454, %f455;
	mov.b32 	 %f844, %r140;
	mov.b32 	 %f845, %r141;
	mov.b32 	 %f846, %r142;
	mov.b32 	 %f847, %r143;
	setp.leu.f32	%p7, %f98, 0f00000000;
	@%p7 bra 	BB5_15;

	cvt.rmi.f32.f32	%f815, %f454;
	cvt.rzi.s32.f32	%r312, %f815;
	cvt.s64.s32	%rd262, %r312;
	mul.lo.s64 	%rd138, %rd262, 48;
	add.s64 	%rd139, %rd93, %rd138;
	add.s64 	%rd130, %rd139, 80;
	// inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd129];
	// inline asm
	mov.b32 	 %f456, %r147;
	mov.b32 	 %f457, %r148;
	mov.b32 	 %f458, %r149;
	mov.b32 	 %f459, %r150;
	add.s64 	%rd133, %rd139, 96;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd132];
	// inline asm
	mov.b32 	 %f460, %r151;
	mov.b32 	 %f461, %r152;
	mov.b32 	 %f462, %r153;
	mov.b32 	 %f463, %r154;
	add.s64 	%rd136, %rd139, 112;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd135];
	// inline asm
	mov.f32 	%f464, 0f3F800000;
	sub.f32 	%f465, %f464, %f98;
	mul.f32 	%f466, %f98, %f456;
	mul.f32 	%f467, %f98, %f457;
	mul.f32 	%f468, %f98, %f458;
	mul.f32 	%f469, %f98, %f459;
	fma.rn.f32 	%f852, %f465, %f852, %f466;
	fma.rn.f32 	%f853, %f465, %f853, %f467;
	fma.rn.f32 	%f854, %f465, %f854, %f468;
	fma.rn.f32 	%f855, %f465, %f855, %f469;
	mul.f32 	%f470, %f98, %f460;
	mul.f32 	%f471, %f98, %f461;
	mul.f32 	%f472, %f98, %f462;
	mul.f32 	%f473, %f98, %f463;
	fma.rn.f32 	%f848, %f465, %f848, %f470;
	fma.rn.f32 	%f849, %f465, %f849, %f471;
	fma.rn.f32 	%f850, %f465, %f850, %f472;
	fma.rn.f32 	%f851, %f465, %f851, %f473;
	mov.b32 	 %f474, %r155;
	mov.b32 	 %f475, %r156;
	mov.b32 	 %f476, %r157;
	mov.b32 	 %f477, %r158;
	mul.f32 	%f478, %f98, %f474;
	mul.f32 	%f479, %f98, %f475;
	mul.f32 	%f480, %f98, %f476;
	mul.f32 	%f481, %f98, %f477;
	fma.rn.f32 	%f844, %f465, %f844, %f478;
	fma.rn.f32 	%f845, %f465, %f845, %f479;
	fma.rn.f32 	%f846, %f465, %f846, %f480;
	fma.rn.f32 	%f847, %f465, %f847, %f481;
	bra.uni 	BB5_15;

BB5_4:
	mov.f32 	%f856, 0f00000000;
	mov.f32 	%f858, 0f3F800000;
	setp.eq.s32	%p3, %r11, 4;
	@%p3 bra 	BB5_7;
	bra.uni 	BB5_5;

BB5_7:
	// inline asm
	call (%rd263), _optix_get_instance_inverse_transform_from_handle, (%rd19);
	// inline asm
	bra.uni 	BB5_8;

BB5_10:
	// inline asm
	call (%rd34), _optix_get_srt_motion_transform_from_handle, (%rd19);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd36, %rd34;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r25,%r26,%r27,%r28}, [%rd36];
	// inline asm
	mov.b32	{%rs1, %rs2}, %r27;
	add.s64 	%rd40, %rd34, 16;
	// inline asm
	cvta.to.global.u64 %rd39, %rd40;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r29,%r30,%r31,%r32}, [%rd39];
	// inline asm
	add.s64 	%rd43, %rd34, 32;
	// inline asm
	cvta.to.global.u64 %rd42, %rd43;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd42];
	// inline asm
	add.s64 	%rd46, %rd34, 48;
	// inline asm
	cvta.to.global.u64 %rd45, %rd46;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd45];
	// inline asm
	add.s64 	%rd49, %rd34, 64;
	// inline asm
	cvta.to.global.u64 %rd48, %rd49;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd48];
	// inline asm
	add.s64 	%rd52, %rd34, 80;
	// inline asm
	cvta.to.global.u64 %rd51, %rd52;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd51];
	// inline asm
	add.s64 	%rd55, %rd34, 96;
	// inline asm
	cvta.to.global.u64 %rd54, %rd55;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd54];
	// inline asm
	add.s64 	%rd58, %rd34, 112;
	// inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd57];
	// inline asm
	add.s64 	%rd61, %rd34, 128;
	// inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd60];
	// inline asm
	add.s64 	%rd64, %rd34, 144;
	// inline asm
	cvta.to.global.u64 %rd63, %rd64;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd63];
	// inline asm
	mov.b32 	 %f332, %r28;
	mov.b32 	 %f333, %r29;
	cvt.u32.u16	%r81, %rs1;
	add.s32 	%r82, %r81, -1;
	cvt.rn.f32.s32	%f334, %r82;
	sub.f32 	%f335, %f318, %f332;
	mul.f32 	%f336, %f335, %f334;
	sub.f32 	%f337, %f333, %f332;
	div.rn.f32 	%f338, %f336, %f337;
	min.f32 	%f339, %f334, %f338;
	mov.f32 	%f340, 0f00000000;
	max.f32 	%f341, %f340, %f339;
	cvt.rmi.f32.f32	%f342, %f341;
	cvt.rzi.s32.f32	%r83, %f342;
	mul.wide.s32 	%rd78, %r83, 64;
	add.s64 	%rd67, %rd43, %rd78;
	// inline asm
	cvta.to.global.u64 %rd66, %rd67;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd66];
	// inline asm
	mov.b32 	 %f828, %r65;
	mov.b32 	 %f829, %r66;
	mov.b32 	 %f830, %r67;
	mov.b32 	 %f831, %r68;
	add.s64 	%rd70, %rd67, 16;
	// inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd69];
	// inline asm
	mov.b32 	 %f832, %r69;
	mov.b32 	 %f833, %r70;
	mov.b32 	 %f834, %r71;
	mov.b32 	 %f835, %r72;
	add.s64 	%rd73, %rd67, 32;
	// inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd72];
	// inline asm
	sub.f32 	%f37, %f341, %f342;
	mov.b32 	 %f836, %r73;
	mov.b32 	 %f837, %r74;
	mov.b32 	 %f838, %r75;
	mov.b32 	 %f839, %r76;
	add.s64 	%rd76, %rd67, 48;
	// inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd75];
	// inline asm
	mov.b32 	 %f840, %r77;
	mov.b32 	 %f841, %r78;
	mov.b32 	 %f842, %r79;
	mov.b32 	 %f843, %r80;
	setp.leu.f32	%p6, %f37, 0f00000000;
	@%p6 bra 	BB5_12;

	cvt.rmi.f32.f32	%f814, %f341;
	cvt.rzi.s32.f32	%r311, %f814;
	cvt.s64.s32	%rd261, %r311;
	shl.b64 	%rd91, %rd261, 6;
	add.s64 	%rd92, %rd91, %rd34;
	add.s64 	%rd80, %rd92, 96;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd79];
	// inline asm
	mov.b32 	 %f343, %r84;
	mov.b32 	 %f344, %r85;
	mov.b32 	 %f345, %r86;
	mov.b32 	 %f346, %r87;
	add.s64 	%rd83, %rd92, 112;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd82];
	// inline asm
	mov.b32 	 %f347, %r88;
	mov.b32 	 %f348, %r89;
	mov.b32 	 %f349, %r90;
	mov.b32 	 %f350, %r91;
	add.s64 	%rd86, %rd92, 128;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd85];
	// inline asm
	mov.b32 	 %f351, %r92;
	mov.b32 	 %f352, %r93;
	mov.b32 	 %f353, %r94;
	mov.b32 	 %f354, %r95;
	add.s64 	%rd89, %rd92, 144;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd88];
	// inline asm
	mov.f32 	%f355, 0f3F800000;
	sub.f32 	%f356, %f355, %f37;
	mul.f32 	%f357, %f37, %f343;
	mul.f32 	%f358, %f37, %f344;
	mul.f32 	%f359, %f37, %f345;
	mul.f32 	%f360, %f37, %f346;
	fma.rn.f32 	%f828, %f356, %f828, %f357;
	fma.rn.f32 	%f829, %f356, %f829, %f358;
	fma.rn.f32 	%f830, %f356, %f830, %f359;
	fma.rn.f32 	%f831, %f356, %f831, %f360;
	mul.f32 	%f361, %f37, %f347;
	mul.f32 	%f362, %f37, %f348;
	mul.f32 	%f363, %f37, %f349;
	mul.f32 	%f364, %f37, %f350;
	fma.rn.f32 	%f832, %f356, %f832, %f361;
	fma.rn.f32 	%f833, %f356, %f833, %f362;
	fma.rn.f32 	%f834, %f356, %f834, %f363;
	fma.rn.f32 	%f835, %f356, %f835, %f364;
	mul.f32 	%f365, %f37, %f351;
	mul.f32 	%f366, %f37, %f352;
	mul.f32 	%f367, %f37, %f353;
	mul.f32 	%f368, %f37, %f354;
	fma.rn.f32 	%f836, %f356, %f836, %f365;
	fma.rn.f32 	%f369, %f356, %f837, %f366;
	fma.rn.f32 	%f370, %f356, %f838, %f367;
	fma.rn.f32 	%f371, %f356, %f839, %f368;
	mov.b32 	 %f372, %r96;
	mov.b32 	 %f373, %r97;
	mov.b32 	 %f374, %r98;
	mov.b32 	 %f375, %r99;
	mul.f32 	%f376, %f37, %f372;
	mul.f32 	%f377, %f37, %f373;
	mul.f32 	%f378, %f37, %f374;
	mul.f32 	%f379, %f37, %f375;
	fma.rn.f32 	%f380, %f356, %f840, %f376;
	fma.rn.f32 	%f841, %f356, %f841, %f377;
	fma.rn.f32 	%f842, %f356, %f842, %f378;
	fma.rn.f32 	%f843, %f356, %f843, %f379;
	mul.f32 	%f381, %f370, %f370;
	fma.rn.f32 	%f382, %f369, %f369, %f381;
	fma.rn.f32 	%f383, %f371, %f371, %f382;
	fma.rn.f32 	%f384, %f380, %f380, %f383;
	sqrt.rn.f32 	%f385, %f384;
	rcp.rn.f32 	%f386, %f385;
	mul.f32 	%f837, %f369, %f386;
	mul.f32 	%f838, %f370, %f386;
	mul.f32 	%f839, %f371, %f386;
	mul.f32 	%f840, %f380, %f386;

BB5_12:
	mul.f32 	%f387, %f838, %f838;
	fma.rn.f32 	%f388, %f837, %f837, %f387;
	fma.rn.f32 	%f389, %f839, %f839, %f388;
	fma.rn.f32 	%f390, %f840, %f840, %f389;
	rcp.rn.f32 	%f391, %f390;
	mul.f32 	%f392, %f837, %f391;
	mul.f32 	%f393, %f838, %f391;
	mul.f32 	%f394, %f839, %f391;
	mul.f32 	%f395, %f840, %f391;
	mul.f32 	%f396, %f837, %f392;
	mul.f32 	%f397, %f838, %f393;
	mul.f32 	%f398, %f839, %f394;
	mul.f32 	%f399, %f837, %f393;
	mul.f32 	%f400, %f839, %f395;
	mul.f32 	%f401, %f837, %f394;
	mul.f32 	%f402, %f838, %f395;
	mul.f32 	%f403, %f838, %f394;
	mul.f32 	%f404, %f837, %f395;
	sub.f32 	%f405, %f396, %f397;
	sub.f32 	%f406, %f405, %f398;
	fma.rn.f32 	%f407, %f840, %f395, %f406;
	sub.f32 	%f408, %f399, %f400;
	add.f32 	%f409, %f408, %f408;
	add.f32 	%f410, %f401, %f402;
	add.f32 	%f411, %f410, %f410;
	add.f32 	%f412, %f399, %f400;
	add.f32 	%f413, %f412, %f412;
	sub.f32 	%f414, %f397, %f396;
	sub.f32 	%f415, %f414, %f398;
	fma.rn.f32 	%f416, %f840, %f395, %f415;
	sub.f32 	%f417, %f403, %f404;
	add.f32 	%f418, %f417, %f417;
	sub.f32 	%f419, %f401, %f402;
	add.f32 	%f420, %f419, %f419;
	add.f32 	%f421, %f403, %f404;
	add.f32 	%f422, %f421, %f421;
	neg.f32 	%f423, %f396;
	sub.f32 	%f424, %f423, %f397;
	add.f32 	%f425, %f398, %f424;
	fma.rn.f32 	%f426, %f840, %f395, %f425;
	mul.f32 	%f427, %f831, %f407;
	fma.rn.f32 	%f428, %f834, %f409, %f427;
	fma.rn.f32 	%f429, %f836, %f411, %f428;
	sub.f32 	%f855, %f841, %f429;
	mul.f32 	%f430, %f834, %f416;
	fma.rn.f32 	%f431, %f831, %f413, %f430;
	fma.rn.f32 	%f432, %f836, %f418, %f431;
	sub.f32 	%f851, %f842, %f432;
	mul.f32 	%f433, %f834, %f422;
	fma.rn.f32 	%f434, %f831, %f420, %f433;
	fma.rn.f32 	%f435, %f836, %f426, %f434;
	sub.f32 	%f847, %f843, %f435;
	mul.f32 	%f436, %f830, %f407;
	fma.rn.f32 	%f437, %f833, %f409, %f436;
	fma.rn.f32 	%f854, %f835, %f411, %f437;
	mul.f32 	%f438, %f833, %f416;
	fma.rn.f32 	%f439, %f830, %f413, %f438;
	fma.rn.f32 	%f850, %f835, %f418, %f439;
	mul.f32 	%f440, %f833, %f422;
	fma.rn.f32 	%f441, %f830, %f420, %f440;
	fma.rn.f32 	%f846, %f835, %f426, %f441;
	mul.f32 	%f442, %f829, %f407;
	fma.rn.f32 	%f853, %f832, %f409, %f442;
	mul.f32 	%f443, %f832, %f416;
	fma.rn.f32 	%f849, %f829, %f413, %f443;
	mul.f32 	%f444, %f832, %f422;
	fma.rn.f32 	%f845, %f829, %f420, %f444;
	mul.f32 	%f852, %f828, %f407;
	mul.f32 	%f848, %f828, %f413;
	mul.f32 	%f844, %f828, %f420;

BB5_15:
	mul.f32 	%f482, %f845, %f850;
	mul.f32 	%f483, %f846, %f849;
	sub.f32 	%f484, %f483, %f482;
	mul.f32 	%f485, %f852, %f484;
	mul.f32 	%f486, %f844, %f850;
	mul.f32 	%f487, %f846, %f848;
	sub.f32 	%f488, %f487, %f486;
	mul.f32 	%f489, %f488, %f853;
	sub.f32 	%f490, %f485, %f489;
	mul.f32 	%f491, %f844, %f849;
	mul.f32 	%f492, %f845, %f848;
	sub.f32 	%f493, %f492, %f491;
	fma.rn.f32 	%f494, %f493, %f854, %f490;
	rcp.rn.f32 	%f495, %f494;
	mul.f32 	%f864, %f484, %f495;
	mul.f32 	%f496, %f846, %f853;
	mul.f32 	%f497, %f845, %f854;
	sub.f32 	%f498, %f497, %f496;
	mul.f32 	%f865, %f495, %f498;
	mul.f32 	%f499, %f849, %f854;
	mul.f32 	%f500, %f850, %f853;
	sub.f32 	%f501, %f500, %f499;
	mul.f32 	%f866, %f495, %f501;
	sub.f32 	%f502, %f486, %f487;
	mul.f32 	%f860, %f502, %f495;
	mul.f32 	%f503, %f844, %f854;
	mul.f32 	%f504, %f846, %f852;
	sub.f32 	%f505, %f504, %f503;
	mul.f32 	%f861, %f495, %f505;
	mul.f32 	%f506, %f850, %f852;
	mul.f32 	%f507, %f848, %f854;
	sub.f32 	%f508, %f507, %f506;
	mul.f32 	%f862, %f495, %f508;
	mul.f32 	%f856, %f493, %f495;
	mul.f32 	%f509, %f845, %f852;
	mul.f32 	%f510, %f844, %f853;
	sub.f32 	%f511, %f510, %f509;
	mul.f32 	%f857, %f511, %f495;
	mul.f32 	%f512, %f848, %f853;
	mul.f32 	%f513, %f849, %f852;
	sub.f32 	%f514, %f513, %f512;
	mul.f32 	%f858, %f514, %f495;
	mul.f32 	%f515, %f855, %f864;
	neg.f32 	%f516, %f515;
	mul.f32 	%f517, %f851, %f865;
	sub.f32 	%f518, %f516, %f517;
	mul.f32 	%f519, %f847, %f866;
	sub.f32 	%f867, %f518, %f519;
	mul.f32 	%f520, %f855, %f860;
	neg.f32 	%f521, %f520;
	mul.f32 	%f522, %f851, %f861;
	sub.f32 	%f523, %f521, %f522;
	mul.f32 	%f524, %f847, %f862;
	sub.f32 	%f863, %f523, %f524;
	mul.f32 	%f525, %f855, %f856;
	neg.f32 	%f526, %f525;
	mul.f32 	%f527, %f851, %f857;
	sub.f32 	%f528, %f526, %f527;
	mul.f32 	%f529, %f847, %f858;
	sub.f32 	%f859, %f528, %f529;
	bra.uni 	BB5_16;

BB5_5:
	setp.ne.s32	%p4, %r11, 1;
	mov.f32 	%f857, %f856;
	mov.f32 	%f859, %f856;
	mov.f32 	%f860, %f856;
	mov.f32 	%f861, %f858;
	mov.f32 	%f862, %f856;
	mov.f32 	%f863, %f856;
	mov.f32 	%f864, %f858;
	mov.f32 	%f865, %f856;
	mov.f32 	%f866, %f856;
	mov.f32 	%f867, %f856;
	@%p4 bra 	BB5_16;

	// inline asm
	call (%rd21), _optix_get_static_transform_from_handle, (%rd19);
	// inline asm
	add.s64 	%rd263, %rd21, 64;

BB5_8:
	// inline asm
	cvta.to.global.u64 %rd25, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r13,%r14,%r15,%r16}, [%rd25];
	// inline asm
	mov.b32 	 %f864, %r13;
	mov.b32 	 %f865, %r14;
	mov.b32 	 %f866, %r15;
	mov.b32 	 %f867, %r16;
	add.s64 	%rd29, %rd263, 16;
	// inline asm
	cvta.to.global.u64 %rd28, %rd29;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r17,%r18,%r19,%r20}, [%rd28];
	// inline asm
	mov.b32 	 %f860, %r17;
	mov.b32 	 %f861, %r18;
	mov.b32 	 %f862, %r19;
	mov.b32 	 %f863, %r20;
	add.s64 	%rd32, %rd263, 32;
	// inline asm
	cvta.to.global.u64 %rd31, %rd32;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r21,%r22,%r23,%r24}, [%rd31];
	// inline asm
	mov.b32 	 %f856, %r21;
	mov.b32 	 %f857, %r22;
	mov.b32 	 %f858, %r23;
	mov.b32 	 %f859, %r24;

BB5_16:
	setp.eq.s32	%p8, %r313, 0;
	@%p8 bra 	BB5_17;
	bra.uni 	BB5_18;

BB5_17:
	mov.f32 	%f827, %f867;
	mov.f32 	%f826, %f866;
	mov.f32 	%f825, %f865;
	mov.f32 	%f824, %f864;
	mov.f32 	%f823, %f863;
	mov.f32 	%f822, %f862;
	mov.f32 	%f821, %f861;
	mov.f32 	%f820, %f860;
	mov.f32 	%f819, %f859;
	mov.f32 	%f818, %f858;
	mov.f32 	%f817, %f857;
	mov.f32 	%f816, %f856;
	bra.uni 	BB5_19;

BB5_18:
	mul.f32 	%f530, %f820, %f865;
	fma.rn.f32 	%f531, %f824, %f864, %f530;
	fma.rn.f32 	%f151, %f816, %f866, %f531;
	mul.f32 	%f532, %f821, %f865;
	fma.rn.f32 	%f533, %f825, %f864, %f532;
	fma.rn.f32 	%f152, %f817, %f866, %f533;
	mul.f32 	%f534, %f822, %f865;
	fma.rn.f32 	%f535, %f826, %f864, %f534;
	fma.rn.f32 	%f153, %f818, %f866, %f535;
	mul.f32 	%f536, %f823, %f865;
	fma.rn.f32 	%f537, %f827, %f864, %f536;
	fma.rn.f32 	%f538, %f819, %f866, %f537;
	add.f32 	%f154, %f867, %f538;
	mul.f32 	%f539, %f820, %f861;
	fma.rn.f32 	%f540, %f824, %f860, %f539;
	fma.rn.f32 	%f155, %f816, %f862, %f540;
	mul.f32 	%f541, %f821, %f861;
	fma.rn.f32 	%f542, %f825, %f860, %f541;
	fma.rn.f32 	%f156, %f817, %f862, %f542;
	mul.f32 	%f543, %f822, %f861;
	fma.rn.f32 	%f544, %f826, %f860, %f543;
	fma.rn.f32 	%f157, %f818, %f862, %f544;
	mul.f32 	%f545, %f823, %f861;
	fma.rn.f32 	%f546, %f827, %f860, %f545;
	fma.rn.f32 	%f547, %f819, %f862, %f546;
	add.f32 	%f158, %f863, %f547;
	mul.f32 	%f548, %f820, %f857;
	fma.rn.f32 	%f549, %f824, %f856, %f548;
	fma.rn.f32 	%f816, %f816, %f858, %f549;
	mul.f32 	%f550, %f821, %f857;
	fma.rn.f32 	%f551, %f825, %f856, %f550;
	fma.rn.f32 	%f817, %f817, %f858, %f551;
	mul.f32 	%f552, %f822, %f857;
	fma.rn.f32 	%f553, %f826, %f856, %f552;
	fma.rn.f32 	%f818, %f818, %f858, %f553;
	mul.f32 	%f554, %f823, %f857;
	fma.rn.f32 	%f555, %f827, %f856, %f554;
	fma.rn.f32 	%f556, %f819, %f858, %f555;
	add.f32 	%f819, %f859, %f556;
	mov.f32 	%f827, %f154;
	mov.f32 	%f826, %f153;
	mov.f32 	%f825, %f152;
	mov.f32 	%f824, %f151;
	mov.f32 	%f823, %f158;
	mov.f32 	%f822, %f157;
	mov.f32 	%f821, %f156;
	mov.f32 	%f820, %f155;

BB5_19:
	add.s32 	%r313, %r313, 1;
	setp.lt.u32	%p9, %r313, %r8;
	@%p9 bra 	BB5_3;

	mul.f32 	%f557, %f315, %f824;
	fma.rn.f32 	%f558, %f316, %f825, %f557;
	fma.rn.f32 	%f559, %f880, %f826, %f558;
	add.f32 	%f882, %f827, %f559;
	mul.f32 	%f560, %f315, %f820;
	fma.rn.f32 	%f561, %f316, %f821, %f560;
	fma.rn.f32 	%f562, %f880, %f822, %f561;
	add.f32 	%f881, %f823, %f562;
	mul.f32 	%f563, %f315, %f816;
	fma.rn.f32 	%f564, %f316, %f817, %f563;
	fma.rn.f32 	%f565, %f880, %f818, %f564;
	add.f32 	%f880, %f819, %f565;
	bra.uni 	BB5_21;

BB5_1:
	mov.f32 	%f881, %f316;
	mov.f32 	%f882, %f315;

BB5_21:
	setp.eq.s32	%p21, %r8, 0;
	// inline asm
	call (%f566), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f567), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f931), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f569), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r314, 0;
	@%p21 bra 	BB5_22;

BB5_23:
	.pragma "nounroll";
	// inline asm
	call (%rd140), _optix_get_transform_list_handle, (%r314);
	// inline asm
	// inline asm
	call (%r161), _optix_get_transform_type_from_handle, (%rd140);
	// inline asm
	and.b32  	%r162, %r161, -2;
	setp.eq.s32	%p11, %r162, 2;
	@%p11 bra 	BB5_29;
	bra.uni 	BB5_24;

BB5_29:
	setp.eq.s32	%p14, %r161, 2;
	@%p14 bra 	BB5_33;
	bra.uni 	BB5_30;

BB5_33:
	// inline asm
	call (%rd214), _optix_get_matrix_motion_transform_from_handle, (%rd140);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd216, %rd214;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd216];
	// inline asm
	mov.b32	{%rs7, %rs8}, %r252;
	add.s64 	%rd220, %rd214, 16;
	// inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd219];
	// inline asm
	add.s64 	%rd223, %rd214, 32;
	// inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd222];
	// inline asm
	add.s64 	%rd226, %rd214, 48;
	// inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd225];
	// inline asm
	add.s64 	%rd229, %rd214, 64;
	// inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd228];
	// inline asm
	add.s64 	%rd232, %rd214, 80;
	// inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd231];
	// inline asm
	add.s64 	%rd235, %rd214, 96;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd234];
	// inline asm
	add.s64 	%rd238, %rd214, 112;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd237];
	// inline asm
	mov.b32 	 %f672, %r253;
	mov.b32 	 %f673, %r254;
	cvt.u32.u16	%r294, %rs7;
	add.s32 	%r295, %r294, -1;
	cvt.rn.f32.s32	%f674, %r295;
	sub.f32 	%f675, %f569, %f672;
	mul.f32 	%f676, %f675, %f674;
	sub.f32 	%f677, %f673, %f672;
	div.rn.f32 	%f678, %f676, %f677;
	min.f32 	%f679, %f674, %f678;
	mov.f32 	%f680, 0f00000000;
	max.f32 	%f681, %f680, %f679;
	cvt.rmi.f32.f32	%f682, %f681;
	cvt.rzi.s32.f32	%r296, %f682;
	cvt.s64.s32	%rd17, %r296;
	mul.wide.s32 	%rd249, %r296, 48;
	add.s64 	%rd241, %rd223, %rd249;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd240];
	// inline asm
	mov.b32 	 %f908, %r282;
	mov.b32 	 %f909, %r283;
	mov.b32 	 %f910, %r284;
	add.s64 	%rd244, %rd241, 16;
	// inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd243];
	// inline asm
	mov.b32 	 %f905, %r286;
	mov.b32 	 %f906, %r287;
	mov.b32 	 %f907, %r288;
	add.s64 	%rd247, %rd241, 32;
	// inline asm
	cvta.to.global.u64 %rd246, %rd247;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd246];
	// inline asm
	sub.f32 	%f249, %f681, %f682;
	mov.b32 	 %f902, %r290;
	mov.b32 	 %f903, %r291;
	mov.b32 	 %f904, %r292;
	setp.leu.f32	%p16, %f249, 0f00000000;
	@%p16 bra 	BB5_35;

	mul.lo.s64 	%rd259, %rd17, 48;
	add.s64 	%rd260, %rd214, %rd259;
	add.s64 	%rd251, %rd260, 80;
	// inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd250];
	// inline asm
	mov.b32 	 %f683, %r297;
	mov.b32 	 %f684, %r298;
	mov.b32 	 %f685, %r299;
	add.s64 	%rd254, %rd260, 96;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd253];
	// inline asm
	mov.b32 	 %f686, %r301;
	mov.b32 	 %f687, %r302;
	mov.b32 	 %f688, %r303;
	add.s64 	%rd257, %rd260, 112;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd256];
	// inline asm
	mov.f32 	%f689, 0f3F800000;
	sub.f32 	%f690, %f689, %f249;
	mul.f32 	%f691, %f249, %f683;
	mul.f32 	%f692, %f249, %f684;
	mul.f32 	%f693, %f249, %f685;
	fma.rn.f32 	%f908, %f690, %f908, %f691;
	fma.rn.f32 	%f909, %f690, %f909, %f692;
	fma.rn.f32 	%f910, %f690, %f910, %f693;
	mul.f32 	%f694, %f249, %f686;
	mul.f32 	%f695, %f249, %f687;
	mul.f32 	%f696, %f249, %f688;
	fma.rn.f32 	%f905, %f690, %f905, %f694;
	fma.rn.f32 	%f906, %f690, %f906, %f695;
	fma.rn.f32 	%f907, %f690, %f907, %f696;
	mov.b32 	 %f697, %r305;
	mov.b32 	 %f698, %r306;
	mov.b32 	 %f699, %r307;
	mul.f32 	%f700, %f249, %f697;
	mul.f32 	%f701, %f249, %f698;
	mul.f32 	%f702, %f249, %f699;
	fma.rn.f32 	%f902, %f690, %f902, %f700;
	fma.rn.f32 	%f903, %f690, %f903, %f701;
	fma.rn.f32 	%f904, %f690, %f904, %f702;
	bra.uni 	BB5_35;

BB5_24:
	mov.f32 	%f911, 0f00000000;
	mov.f32 	%f913, 0f3F800000;
	setp.eq.s32	%p12, %r161, 4;
	@%p12 bra 	BB5_27;
	bra.uni 	BB5_25;

BB5_27:
	// inline asm
	call (%rd264), _optix_get_instance_inverse_transform_from_handle, (%rd140);
	// inline asm
	bra.uni 	BB5_28;

BB5_30:
	// inline asm
	call (%rd155), _optix_get_srt_motion_transform_from_handle, (%rd140);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd157, %rd155;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd157];
	// inline asm
	mov.b32	{%rs5, %rs6}, %r177;
	add.s64 	%rd161, %rd155, 16;
	// inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd160];
	// inline asm
	add.s64 	%rd164, %rd155, 32;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd163];
	// inline asm
	add.s64 	%rd167, %rd155, 48;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd166];
	// inline asm
	add.s64 	%rd170, %rd155, 64;
	// inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd169];
	// inline asm
	add.s64 	%rd173, %rd155, 80;
	// inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd172];
	// inline asm
	add.s64 	%rd176, %rd155, 96;
	// inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd175];
	// inline asm
	add.s64 	%rd179, %rd155, 112;
	// inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd178];
	// inline asm
	add.s64 	%rd182, %rd155, 128;
	// inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd181];
	// inline asm
	add.s64 	%rd185, %rd155, 144;
	// inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd184];
	// inline asm
	mov.b32 	 %f580, %r178;
	mov.b32 	 %f581, %r179;
	cvt.u32.u16	%r231, %rs5;
	add.s32 	%r232, %r231, -1;
	cvt.rn.f32.s32	%f582, %r232;
	sub.f32 	%f583, %f569, %f580;
	mul.f32 	%f584, %f583, %f582;
	sub.f32 	%f585, %f581, %f580;
	div.rn.f32 	%f586, %f584, %f585;
	min.f32 	%f587, %f582, %f586;
	mov.f32 	%f588, 0f00000000;
	max.f32 	%f589, %f588, %f587;
	cvt.rmi.f32.f32	%f590, %f589;
	cvt.rzi.s32.f32	%r233, %f590;
	cvt.s64.s32	%rd15, %r233;
	mul.wide.s32 	%rd199, %r233, 64;
	add.s64 	%rd188, %rd164, %rd199;
	// inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd187];
	// inline asm
	mov.b32 	 %f892, %r215;
	mov.b32 	 %f893, %r216;
	mov.b32 	 %f894, %r217;
	add.s64 	%rd191, %rd188, 16;
	// inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd190];
	// inline asm
	mov.b32 	 %f895, %r219;
	mov.b32 	 %f896, %r220;
	mov.b32 	 %f897, %r222;
	add.s64 	%rd194, %rd188, 32;
	// inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd193];
	// inline asm
	sub.f32 	%f209, %f589, %f590;
	mov.b32 	 %f898, %r224;
	mov.b32 	 %f899, %r225;
	mov.b32 	 %f900, %r226;
	add.s64 	%rd197, %rd188, 48;
	// inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd196];
	// inline asm
	mov.b32 	 %f901, %r227;
	setp.leu.f32	%p15, %f209, 0f00000000;
	@%p15 bra 	BB5_32;

	shl.b64 	%rd212, %rd15, 6;
	add.s64 	%rd213, %rd212, %rd155;
	add.s64 	%rd201, %rd213, 96;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd200];
	// inline asm
	mov.b32 	 %f591, %r234;
	mov.b32 	 %f592, %r235;
	mov.b32 	 %f593, %r236;
	add.s64 	%rd204, %rd213, 112;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd203];
	// inline asm
	mov.b32 	 %f594, %r238;
	mov.b32 	 %f595, %r239;
	mov.b32 	 %f596, %r241;
	add.s64 	%rd207, %rd213, 128;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd206];
	// inline asm
	mov.b32 	 %f597, %r243;
	mov.b32 	 %f598, %r244;
	mov.b32 	 %f599, %r245;
	add.s64 	%rd210, %rd213, 144;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd209];
	// inline asm
	mov.f32 	%f600, 0f3F800000;
	sub.f32 	%f601, %f600, %f209;
	mul.f32 	%f602, %f209, %f591;
	mul.f32 	%f603, %f209, %f592;
	mul.f32 	%f604, %f209, %f593;
	fma.rn.f32 	%f892, %f601, %f892, %f602;
	fma.rn.f32 	%f893, %f601, %f893, %f603;
	fma.rn.f32 	%f894, %f601, %f894, %f604;
	mul.f32 	%f605, %f209, %f594;
	mul.f32 	%f606, %f209, %f595;
	mul.f32 	%f607, %f209, %f596;
	fma.rn.f32 	%f895, %f601, %f895, %f605;
	fma.rn.f32 	%f896, %f601, %f896, %f606;
	fma.rn.f32 	%f897, %f601, %f897, %f607;
	mul.f32 	%f608, %f209, %f597;
	mul.f32 	%f609, %f209, %f598;
	mul.f32 	%f610, %f209, %f599;
	fma.rn.f32 	%f611, %f601, %f898, %f608;
	fma.rn.f32 	%f612, %f601, %f899, %f609;
	fma.rn.f32 	%f613, %f601, %f900, %f610;
	mov.b32 	 %f614, %r246;
	mul.f32 	%f615, %f209, %f614;
	fma.rn.f32 	%f616, %f601, %f901, %f615;
	mul.f32 	%f617, %f612, %f612;
	fma.rn.f32 	%f618, %f611, %f611, %f617;
	fma.rn.f32 	%f619, %f613, %f613, %f618;
	fma.rn.f32 	%f620, %f616, %f616, %f619;
	sqrt.rn.f32 	%f621, %f620;
	rcp.rn.f32 	%f622, %f621;
	mul.f32 	%f898, %f611, %f622;
	mul.f32 	%f899, %f612, %f622;
	mul.f32 	%f900, %f613, %f622;
	mul.f32 	%f901, %f616, %f622;

BB5_32:
	mul.f32 	%f623, %f899, %f899;
	fma.rn.f32 	%f624, %f898, %f898, %f623;
	fma.rn.f32 	%f625, %f900, %f900, %f624;
	fma.rn.f32 	%f626, %f901, %f901, %f625;
	rcp.rn.f32 	%f627, %f626;
	mul.f32 	%f628, %f898, %f627;
	mul.f32 	%f629, %f899, %f627;
	mul.f32 	%f630, %f900, %f627;
	mul.f32 	%f631, %f901, %f627;
	mul.f32 	%f632, %f898, %f628;
	mul.f32 	%f633, %f899, %f629;
	mul.f32 	%f634, %f900, %f630;
	mul.f32 	%f635, %f898, %f629;
	mul.f32 	%f636, %f900, %f631;
	mul.f32 	%f637, %f898, %f630;
	mul.f32 	%f638, %f899, %f631;
	mul.f32 	%f639, %f899, %f630;
	mul.f32 	%f640, %f898, %f631;
	sub.f32 	%f641, %f632, %f633;
	sub.f32 	%f642, %f641, %f634;
	fma.rn.f32 	%f643, %f901, %f631, %f642;
	sub.f32 	%f644, %f635, %f636;
	add.f32 	%f645, %f644, %f644;
	add.f32 	%f646, %f637, %f638;
	add.f32 	%f647, %f646, %f646;
	add.f32 	%f648, %f635, %f636;
	add.f32 	%f649, %f648, %f648;
	sub.f32 	%f650, %f633, %f632;
	sub.f32 	%f651, %f650, %f634;
	fma.rn.f32 	%f652, %f901, %f631, %f651;
	sub.f32 	%f653, %f639, %f640;
	add.f32 	%f654, %f653, %f653;
	sub.f32 	%f655, %f637, %f638;
	add.f32 	%f656, %f655, %f655;
	add.f32 	%f657, %f639, %f640;
	add.f32 	%f658, %f657, %f657;
	neg.f32 	%f659, %f632;
	sub.f32 	%f660, %f659, %f633;
	add.f32 	%f661, %f634, %f660;
	fma.rn.f32 	%f662, %f901, %f631, %f661;
	mul.f32 	%f663, %f894, %f643;
	fma.rn.f32 	%f664, %f896, %f645, %f663;
	fma.rn.f32 	%f910, %f897, %f647, %f664;
	mul.f32 	%f665, %f896, %f652;
	fma.rn.f32 	%f666, %f894, %f649, %f665;
	fma.rn.f32 	%f907, %f897, %f654, %f666;
	mul.f32 	%f667, %f896, %f658;
	fma.rn.f32 	%f668, %f894, %f656, %f667;
	fma.rn.f32 	%f904, %f897, %f662, %f668;
	mul.f32 	%f669, %f893, %f643;
	fma.rn.f32 	%f909, %f895, %f645, %f669;
	mul.f32 	%f670, %f895, %f652;
	fma.rn.f32 	%f906, %f893, %f649, %f670;
	mul.f32 	%f671, %f895, %f658;
	fma.rn.f32 	%f903, %f893, %f656, %f671;
	mul.f32 	%f908, %f892, %f643;
	mul.f32 	%f905, %f892, %f649;
	mul.f32 	%f902, %f892, %f656;

BB5_35:
	mul.f32 	%f703, %f903, %f907;
	mul.f32 	%f704, %f904, %f906;
	sub.f32 	%f705, %f704, %f703;
	mul.f32 	%f706, %f908, %f705;
	mul.f32 	%f707, %f902, %f907;
	mul.f32 	%f708, %f904, %f905;
	sub.f32 	%f709, %f708, %f707;
	mul.f32 	%f710, %f709, %f909;
	sub.f32 	%f711, %f706, %f710;
	mul.f32 	%f712, %f902, %f906;
	mul.f32 	%f713, %f903, %f905;
	sub.f32 	%f714, %f713, %f712;
	fma.rn.f32 	%f715, %f714, %f910, %f711;
	rcp.rn.f32 	%f716, %f715;
	mul.f32 	%f917, %f705, %f716;
	mul.f32 	%f717, %f904, %f909;
	mul.f32 	%f718, %f903, %f910;
	sub.f32 	%f719, %f718, %f717;
	mul.f32 	%f918, %f716, %f719;
	mul.f32 	%f720, %f906, %f910;
	mul.f32 	%f721, %f907, %f909;
	sub.f32 	%f722, %f721, %f720;
	mul.f32 	%f919, %f716, %f722;
	sub.f32 	%f723, %f707, %f708;
	mul.f32 	%f914, %f723, %f716;
	mul.f32 	%f724, %f902, %f910;
	mul.f32 	%f725, %f904, %f908;
	sub.f32 	%f726, %f725, %f724;
	mul.f32 	%f915, %f716, %f726;
	mul.f32 	%f727, %f907, %f908;
	mul.f32 	%f728, %f905, %f910;
	sub.f32 	%f729, %f728, %f727;
	mul.f32 	%f916, %f716, %f729;
	mul.f32 	%f911, %f714, %f716;
	mul.f32 	%f730, %f903, %f908;
	mul.f32 	%f731, %f902, %f909;
	sub.f32 	%f732, %f731, %f730;
	mul.f32 	%f912, %f732, %f716;
	mul.f32 	%f733, %f905, %f909;
	mul.f32 	%f734, %f906, %f908;
	sub.f32 	%f735, %f734, %f733;
	mul.f32 	%f913, %f735, %f716;
	bra.uni 	BB5_36;

BB5_25:
	setp.ne.s32	%p13, %r161, 1;
	mov.f32 	%f912, %f911;
	mov.f32 	%f914, %f911;
	mov.f32 	%f915, %f913;
	mov.f32 	%f916, %f911;
	mov.f32 	%f917, %f913;
	mov.f32 	%f918, %f911;
	mov.f32 	%f919, %f911;
	@%p13 bra 	BB5_36;

	// inline asm
	call (%rd142), _optix_get_static_transform_from_handle, (%rd140);
	// inline asm
	add.s64 	%rd264, %rd142, 64;

BB5_28:
	// inline asm
	cvta.to.global.u64 %rd146, %rd264;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd146];
	// inline asm
	mov.b32 	 %f917, %r163;
	mov.b32 	 %f918, %r164;
	mov.b32 	 %f919, %r165;
	add.s64 	%rd150, %rd264, 16;
	// inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd149];
	// inline asm
	mov.b32 	 %f914, %r167;
	mov.b32 	 %f915, %r168;
	mov.b32 	 %f916, %r169;
	add.s64 	%rd153, %rd264, 32;
	// inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd152];
	// inline asm
	mov.b32 	 %f911, %r171;
	mov.b32 	 %f912, %r172;
	mov.b32 	 %f913, %r173;

BB5_36:
	setp.eq.s32	%p17, %r314, 0;
	@%p17 bra 	BB5_37;
	bra.uni 	BB5_38;

BB5_37:
	mov.f32 	%f891, %f911;
	mov.f32 	%f890, %f912;
	mov.f32 	%f889, %f913;
	mov.f32 	%f888, %f914;
	mov.f32 	%f887, %f915;
	mov.f32 	%f886, %f916;
	mov.f32 	%f885, %f917;
	mov.f32 	%f884, %f918;
	mov.f32 	%f883, %f919;
	bra.uni 	BB5_39;

BB5_38:
	mul.f32 	%f736, %f888, %f918;
	fma.rn.f32 	%f737, %f885, %f917, %f736;
	fma.rn.f32 	%f289, %f891, %f919, %f737;
	mul.f32 	%f738, %f887, %f918;
	fma.rn.f32 	%f739, %f884, %f917, %f738;
	fma.rn.f32 	%f290, %f890, %f919, %f739;
	mul.f32 	%f740, %f886, %f918;
	fma.rn.f32 	%f741, %f883, %f917, %f740;
	fma.rn.f32 	%f291, %f889, %f919, %f741;
	mul.f32 	%f742, %f888, %f915;
	fma.rn.f32 	%f743, %f885, %f914, %f742;
	fma.rn.f32 	%f292, %f891, %f916, %f743;
	mul.f32 	%f744, %f887, %f915;
	fma.rn.f32 	%f745, %f884, %f914, %f744;
	fma.rn.f32 	%f293, %f890, %f916, %f745;
	mul.f32 	%f746, %f886, %f915;
	fma.rn.f32 	%f747, %f883, %f914, %f746;
	fma.rn.f32 	%f294, %f889, %f916, %f747;
	mul.f32 	%f748, %f888, %f912;
	fma.rn.f32 	%f749, %f885, %f911, %f748;
	fma.rn.f32 	%f891, %f891, %f913, %f749;
	mul.f32 	%f750, %f887, %f912;
	fma.rn.f32 	%f751, %f884, %f911, %f750;
	fma.rn.f32 	%f890, %f890, %f913, %f751;
	mul.f32 	%f752, %f886, %f912;
	fma.rn.f32 	%f753, %f883, %f911, %f752;
	fma.rn.f32 	%f889, %f889, %f913, %f753;
	mov.f32 	%f888, %f292;
	mov.f32 	%f887, %f293;
	mov.f32 	%f886, %f294;
	mov.f32 	%f885, %f289;
	mov.f32 	%f884, %f290;
	mov.f32 	%f883, %f291;

BB5_39:
	add.s32 	%r314, %r314, 1;
	setp.lt.u32	%p18, %r314, %r8;
	@%p18 bra 	BB5_23;

	mul.f32 	%f754, %f567, %f884;
	fma.rn.f32 	%f755, %f566, %f885, %f754;
	fma.rn.f32 	%f929, %f931, %f883, %f755;
	mul.f32 	%f756, %f567, %f887;
	fma.rn.f32 	%f757, %f566, %f888, %f756;
	fma.rn.f32 	%f930, %f931, %f886, %f757;
	mul.f32 	%f758, %f567, %f890;
	fma.rn.f32 	%f759, %f566, %f891, %f758;
	fma.rn.f32 	%f931, %f931, %f889, %f759;
	bra.uni 	BB5_41;

BB5_22:
	mov.f32 	%f929, %f566;
	mov.f32 	%f930, %f567;

BB5_41:
	ld.v4.f32 	{%f762, %f763, %f764, %f765}, [%rd1+80];
	ld.v4.f32 	{%f769, %f770, %f771, %f772}, [%rd1+32];
	fma.rn.f32 	%f774, %f882, %f769, %f762;
	fma.rn.f32 	%f776, %f882, %f770, %f763;
	fma.rn.f32 	%f778, %f882, %f771, %f764;
	ld.v4.f32 	{%f779, %f780, %f781, %f782}, [%rd1+48];
	fma.rn.f32 	%f784, %f881, %f779, %f774;
	fma.rn.f32 	%f786, %f881, %f780, %f776;
	fma.rn.f32 	%f788, %f881, %f781, %f778;
	ld.v4.f32 	{%f789, %f790, %f791, %f792}, [%rd1+64];
	fma.rn.f32 	%f794, %f880, %f789, %f784;
	fma.rn.f32 	%f796, %f880, %f790, %f786;
	fma.rn.f32 	%f798, %f880, %f791, %f788;
	mul.f32 	%f799, %f929, %f769;
	mul.f32 	%f800, %f929, %f770;
	mul.f32 	%f801, %f929, %f771;
	fma.rn.f32 	%f802, %f930, %f779, %f799;
	fma.rn.f32 	%f803, %f930, %f780, %f800;
	fma.rn.f32 	%f804, %f930, %f781, %f801;
	fma.rn.f32 	%f805, %f931, %f789, %f802;
	fma.rn.f32 	%f806, %f931, %f790, %f803;
	fma.rn.f32 	%f807, %f931, %f791, %f804;
	rcp.rn.f32 	%f808, %f807;
	mul.f32 	%f809, %f798, %f808;
	neg.f32 	%f313, %f809;
	fma.rn.f32 	%f810, %f313, %f805, %f794;
	fma.rn.f32 	%f314, %f313, %f806, %f796;
	abs.f32 	%f811, %f810;
	setp.gtu.f32	%p19, %f811, 0f3F800000;
	@%p19 bra 	BB5_44;

	abs.f32 	%f812, %f314;
	setp.gtu.f32	%p20, %f812, 0f3F800000;
	@%p20 bra 	BB5_44;

	mov.u32 	%r310, 254;
	// inline asm
	call (%r309), _optix_report_intersection_0, (%f313, %r310);
	// inline asm

BB5_44:
	ret;
}

	// .globl	__closesthit__rectangle
.visible .entry __closesthit__rectangle(

)
{
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<18>;
	.reg .f32 	%f<1947>;
	.reg .b32 	%r<638>;
	.reg .b64 	%rd<670>;


	// inline asm
	call (%r21), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r22), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r24), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r25), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r26), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r27, %r26, %r22, %r25;
	mad.lo.s32 	%r1, %r27, %r21, %r24;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	@%p1 bra 	BB6_2;

	cvta.to.global.u64 	%rd49, %rd1;
	cvt.u64.u32	%rd50, %r1;
	add.s64 	%rd51, %rd49, %rd50;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd51], %rs1;
	bra.uni 	BB6_108;

BB6_2:
	// inline asm
	call (%rd52), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd3, [%rd52+8];
	// inline asm
	call (%f670), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f671), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f1743), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r28), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p2, %r28, 0;
	@%p2 bra 	BB6_3;

	mov.u32 	%r634, 0;
	// inline asm
	call (%f673), _optix_get_ray_time, ();
	// inline asm

BB6_5:
	.pragma "nounroll";
	// inline asm
	call (%rd53), _optix_get_transform_list_handle, (%r634);
	// inline asm
	// inline asm
	call (%r31), _optix_get_transform_type_from_handle, (%rd53);
	// inline asm
	and.b32  	%r32, %r31, -2;
	setp.eq.s32	%p3, %r32, 2;
	@%p3 bra 	BB6_11;
	bra.uni 	BB6_6;

BB6_11:
	setp.eq.s32	%p6, %r31, 2;
	@%p6 bra 	BB6_15;
	bra.uni 	BB6_12;

BB6_15:
	// inline asm
	call (%rd127), _optix_get_matrix_motion_transform_from_handle, (%rd53);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd129, %rd127;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd129];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r122;
	add.s64 	%rd133, %rd127, 16;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd132];
	// inline asm
	add.s64 	%rd136, %rd127, 32;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd135];
	// inline asm
	add.s64 	%rd139, %rd127, 48;
	// inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd138];
	// inline asm
	add.s64 	%rd142, %rd127, 64;
	// inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd141];
	// inline asm
	add.s64 	%rd145, %rd127, 80;
	// inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd144];
	// inline asm
	add.s64 	%rd148, %rd127, 96;
	// inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r144,%r145,%r146,%r147}, [%rd147];
	// inline asm
	add.s64 	%rd151, %rd127, 112;
	// inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r148,%r149,%r150,%r151}, [%rd150];
	// inline asm
	mov.b32 	 %f800, %r123;
	mov.b32 	 %f801, %r124;
	cvt.u32.u16	%r164, %rs4;
	add.s32 	%r165, %r164, -1;
	cvt.rn.f32.s32	%f802, %r165;
	sub.f32 	%f803, %f673, %f800;
	mul.f32 	%f804, %f803, %f802;
	sub.f32 	%f805, %f801, %f800;
	div.rn.f32 	%f806, %f804, %f805;
	min.f32 	%f807, %f802, %f806;
	mov.f32 	%f808, 0f00000000;
	max.f32 	%f809, %f808, %f807;
	cvt.rmi.f32.f32	%f810, %f809;
	cvt.rzi.s32.f32	%r166, %f810;
	mul.wide.s32 	%rd162, %r166, 48;
	add.s64 	%rd154, %rd136, %rd162;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r152,%r153,%r154,%r155}, [%rd153];
	// inline asm
	mov.b32 	 %f1715, %r152;
	mov.b32 	 %f1716, %r153;
	mov.b32 	 %f1717, %r154;
	mov.b32 	 %f1718, %r155;
	add.s64 	%rd157, %rd154, 16;
	// inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r156,%r157,%r158,%r159}, [%rd156];
	// inline asm
	mov.b32 	 %f1711, %r156;
	mov.b32 	 %f1712, %r157;
	mov.b32 	 %f1713, %r158;
	mov.b32 	 %f1714, %r159;
	add.s64 	%rd160, %rd154, 32;
	// inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r160,%r161,%r162,%r163}, [%rd159];
	// inline asm
	sub.f32 	%f98, %f809, %f810;
	mov.b32 	 %f1710, %r160;
	mov.b32 	 %f1709, %r161;
	mov.b32 	 %f1708, %r162;
	mov.b32 	 %f1707, %r163;
	setp.leu.f32	%p8, %f98, 0f00000000;
	@%p8 bra 	BB6_17;

	cvt.rmi.f32.f32	%f1678, %f809;
	cvt.rzi.s32.f32	%r633, %f1678;
	cvt.s64.s32	%rd665, %r633;
	mul.lo.s64 	%rd172, %rd665, 48;
	add.s64 	%rd173, %rd127, %rd172;
	add.s64 	%rd164, %rd173, 80;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd163];
	// inline asm
	mov.b32 	 %f811, %r167;
	mov.b32 	 %f812, %r168;
	mov.b32 	 %f813, %r169;
	mov.b32 	 %f814, %r170;
	add.s64 	%rd167, %rd173, 96;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd166];
	// inline asm
	mov.b32 	 %f815, %r171;
	mov.b32 	 %f816, %r172;
	mov.b32 	 %f817, %r173;
	mov.b32 	 %f818, %r174;
	add.s64 	%rd170, %rd173, 112;
	// inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd169];
	// inline asm
	mov.f32 	%f819, 0f3F800000;
	sub.f32 	%f820, %f819, %f98;
	mul.f32 	%f821, %f98, %f811;
	mul.f32 	%f822, %f98, %f812;
	mul.f32 	%f823, %f98, %f813;
	mul.f32 	%f824, %f98, %f814;
	fma.rn.f32 	%f1715, %f820, %f1715, %f821;
	fma.rn.f32 	%f1716, %f820, %f1716, %f822;
	fma.rn.f32 	%f1717, %f820, %f1717, %f823;
	fma.rn.f32 	%f1718, %f820, %f1718, %f824;
	mul.f32 	%f825, %f98, %f815;
	mul.f32 	%f826, %f98, %f816;
	mul.f32 	%f827, %f98, %f817;
	mul.f32 	%f828, %f98, %f818;
	fma.rn.f32 	%f1711, %f820, %f1711, %f825;
	fma.rn.f32 	%f1712, %f820, %f1712, %f826;
	fma.rn.f32 	%f1713, %f820, %f1713, %f827;
	fma.rn.f32 	%f1714, %f820, %f1714, %f828;
	mov.b32 	 %f829, %r175;
	mov.b32 	 %f830, %r176;
	mov.b32 	 %f831, %r177;
	mov.b32 	 %f832, %r178;
	mul.f32 	%f833, %f98, %f829;
	mul.f32 	%f834, %f98, %f830;
	mul.f32 	%f835, %f98, %f831;
	mul.f32 	%f836, %f98, %f832;
	fma.rn.f32 	%f1710, %f820, %f1710, %f833;
	fma.rn.f32 	%f1709, %f820, %f1709, %f834;
	fma.rn.f32 	%f1708, %f820, %f1708, %f835;
	fma.rn.f32 	%f1707, %f820, %f1707, %f836;
	bra.uni 	BB6_17;

BB6_6:
	mov.f32 	%f1719, 0f00000000;
	mov.f32 	%f1720, 0f3F800000;
	setp.eq.s32	%p4, %r31, 4;
	@%p4 bra 	BB6_9;
	bra.uni 	BB6_7;

BB6_9:
	// inline asm
	call (%rd666), _optix_get_instance_inverse_transform_from_handle, (%rd53);
	// inline asm
	bra.uni 	BB6_10;

BB6_12:
	// inline asm
	call (%rd68), _optix_get_srt_motion_transform_from_handle, (%rd53);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd70, %rd68;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd70];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r47;
	add.s64 	%rd74, %rd68, 16;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd73];
	// inline asm
	add.s64 	%rd77, %rd68, 32;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd76];
	// inline asm
	add.s64 	%rd80, %rd68, 48;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd79];
	// inline asm
	add.s64 	%rd83, %rd68, 64;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd82];
	// inline asm
	add.s64 	%rd86, %rd68, 80;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd85];
	// inline asm
	add.s64 	%rd89, %rd68, 96;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd88];
	// inline asm
	add.s64 	%rd92, %rd68, 112;
	// inline asm
	cvta.to.global.u64 %rd91, %rd92;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd91];
	// inline asm
	add.s64 	%rd95, %rd68, 128;
	// inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd94];
	// inline asm
	add.s64 	%rd98, %rd68, 144;
	// inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r81,%r82,%r83,%r84}, [%rd97];
	// inline asm
	mov.b32 	 %f687, %r48;
	mov.b32 	 %f688, %r49;
	cvt.u32.u16	%r101, %rs2;
	add.s32 	%r102, %r101, -1;
	cvt.rn.f32.s32	%f689, %r102;
	sub.f32 	%f690, %f673, %f687;
	mul.f32 	%f691, %f690, %f689;
	sub.f32 	%f692, %f688, %f687;
	div.rn.f32 	%f693, %f691, %f692;
	min.f32 	%f694, %f689, %f693;
	mov.f32 	%f695, 0f00000000;
	max.f32 	%f696, %f695, %f694;
	cvt.rmi.f32.f32	%f697, %f696;
	cvt.rzi.s32.f32	%r103, %f697;
	mul.wide.s32 	%rd112, %r103, 64;
	add.s64 	%rd101, %rd77, %rd112;
	// inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r85,%r86,%r87,%r88}, [%rd100];
	// inline asm
	mov.b32 	 %f1691, %r85;
	mov.b32 	 %f1692, %r86;
	mov.b32 	 %f1693, %r87;
	mov.b32 	 %f1694, %r88;
	add.s64 	%rd104, %rd101, 16;
	// inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r89,%r90,%r91,%r92}, [%rd103];
	// inline asm
	mov.b32 	 %f1695, %r89;
	mov.b32 	 %f1696, %r90;
	mov.b32 	 %f1697, %r91;
	mov.b32 	 %f1698, %r92;
	add.s64 	%rd107, %rd101, 32;
	// inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r93,%r94,%r95,%r96}, [%rd106];
	// inline asm
	sub.f32 	%f37, %f696, %f697;
	mov.b32 	 %f1699, %r93;
	mov.b32 	 %f1700, %r94;
	mov.b32 	 %f1701, %r95;
	mov.b32 	 %f1702, %r96;
	add.s64 	%rd110, %rd101, 48;
	// inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r97,%r98,%r99,%r100}, [%rd109];
	// inline asm
	mov.b32 	 %f1703, %r97;
	mov.b32 	 %f1704, %r98;
	mov.b32 	 %f1705, %r99;
	mov.b32 	 %f1706, %r100;
	setp.leu.f32	%p7, %f37, 0f00000000;
	@%p7 bra 	BB6_14;

	cvt.rmi.f32.f32	%f1677, %f696;
	cvt.rzi.s32.f32	%r632, %f1677;
	cvt.s64.s32	%rd664, %r632;
	shl.b64 	%rd125, %rd664, 6;
	add.s64 	%rd126, %rd125, %rd68;
	add.s64 	%rd114, %rd126, 96;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd113];
	// inline asm
	mov.b32 	 %f698, %r104;
	mov.b32 	 %f699, %r105;
	mov.b32 	 %f700, %r106;
	mov.b32 	 %f701, %r107;
	add.s64 	%rd117, %rd126, 112;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd116];
	// inline asm
	mov.b32 	 %f702, %r108;
	mov.b32 	 %f703, %r109;
	mov.b32 	 %f704, %r110;
	mov.b32 	 %f705, %r111;
	add.s64 	%rd120, %rd126, 128;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd119];
	// inline asm
	mov.b32 	 %f706, %r112;
	mov.b32 	 %f707, %r113;
	mov.b32 	 %f708, %r114;
	mov.b32 	 %f709, %r115;
	add.s64 	%rd123, %rd126, 144;
	// inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd122];
	// inline asm
	mov.f32 	%f710, 0f3F800000;
	sub.f32 	%f711, %f710, %f37;
	mul.f32 	%f712, %f37, %f698;
	mul.f32 	%f713, %f37, %f699;
	mul.f32 	%f714, %f37, %f700;
	mul.f32 	%f715, %f37, %f701;
	fma.rn.f32 	%f1691, %f711, %f1691, %f712;
	fma.rn.f32 	%f1692, %f711, %f1692, %f713;
	fma.rn.f32 	%f1693, %f711, %f1693, %f714;
	fma.rn.f32 	%f1694, %f711, %f1694, %f715;
	mul.f32 	%f716, %f37, %f702;
	mul.f32 	%f717, %f37, %f703;
	mul.f32 	%f718, %f37, %f704;
	mul.f32 	%f719, %f37, %f705;
	fma.rn.f32 	%f1695, %f711, %f1695, %f716;
	fma.rn.f32 	%f1696, %f711, %f1696, %f717;
	fma.rn.f32 	%f1697, %f711, %f1697, %f718;
	fma.rn.f32 	%f1698, %f711, %f1698, %f719;
	mul.f32 	%f720, %f37, %f706;
	mul.f32 	%f721, %f37, %f707;
	mul.f32 	%f722, %f37, %f708;
	mul.f32 	%f723, %f37, %f709;
	fma.rn.f32 	%f1699, %f711, %f1699, %f720;
	fma.rn.f32 	%f724, %f711, %f1700, %f721;
	fma.rn.f32 	%f725, %f711, %f1701, %f722;
	fma.rn.f32 	%f726, %f711, %f1702, %f723;
	mov.b32 	 %f727, %r116;
	mov.b32 	 %f728, %r117;
	mov.b32 	 %f729, %r118;
	mov.b32 	 %f730, %r119;
	mul.f32 	%f731, %f37, %f727;
	mul.f32 	%f732, %f37, %f728;
	mul.f32 	%f733, %f37, %f729;
	mul.f32 	%f734, %f37, %f730;
	fma.rn.f32 	%f735, %f711, %f1703, %f731;
	fma.rn.f32 	%f1704, %f711, %f1704, %f732;
	fma.rn.f32 	%f1705, %f711, %f1705, %f733;
	fma.rn.f32 	%f1706, %f711, %f1706, %f734;
	mul.f32 	%f736, %f725, %f725;
	fma.rn.f32 	%f737, %f724, %f724, %f736;
	fma.rn.f32 	%f738, %f726, %f726, %f737;
	fma.rn.f32 	%f739, %f735, %f735, %f738;
	sqrt.rn.f32 	%f740, %f739;
	rcp.rn.f32 	%f741, %f740;
	mul.f32 	%f1700, %f724, %f741;
	mul.f32 	%f1701, %f725, %f741;
	mul.f32 	%f1702, %f726, %f741;
	mul.f32 	%f1703, %f735, %f741;

BB6_14:
	mul.f32 	%f742, %f1701, %f1701;
	fma.rn.f32 	%f743, %f1700, %f1700, %f742;
	fma.rn.f32 	%f744, %f1702, %f1702, %f743;
	fma.rn.f32 	%f745, %f1703, %f1703, %f744;
	rcp.rn.f32 	%f746, %f745;
	mul.f32 	%f747, %f1700, %f746;
	mul.f32 	%f748, %f1701, %f746;
	mul.f32 	%f749, %f1702, %f746;
	mul.f32 	%f750, %f1703, %f746;
	mul.f32 	%f751, %f1700, %f747;
	mul.f32 	%f752, %f1701, %f748;
	mul.f32 	%f753, %f1702, %f749;
	mul.f32 	%f754, %f1700, %f748;
	mul.f32 	%f755, %f1702, %f750;
	mul.f32 	%f756, %f1700, %f749;
	mul.f32 	%f757, %f1701, %f750;
	mul.f32 	%f758, %f1701, %f749;
	mul.f32 	%f759, %f1700, %f750;
	sub.f32 	%f760, %f751, %f752;
	sub.f32 	%f761, %f760, %f753;
	fma.rn.f32 	%f762, %f1703, %f750, %f761;
	sub.f32 	%f763, %f754, %f755;
	add.f32 	%f764, %f763, %f763;
	add.f32 	%f765, %f756, %f757;
	add.f32 	%f766, %f765, %f765;
	add.f32 	%f767, %f754, %f755;
	add.f32 	%f768, %f767, %f767;
	sub.f32 	%f769, %f752, %f751;
	sub.f32 	%f770, %f769, %f753;
	fma.rn.f32 	%f771, %f1703, %f750, %f770;
	sub.f32 	%f772, %f758, %f759;
	add.f32 	%f773, %f772, %f772;
	sub.f32 	%f774, %f756, %f757;
	add.f32 	%f775, %f774, %f774;
	add.f32 	%f776, %f758, %f759;
	add.f32 	%f777, %f776, %f776;
	neg.f32 	%f778, %f751;
	sub.f32 	%f779, %f778, %f752;
	add.f32 	%f780, %f753, %f779;
	fma.rn.f32 	%f781, %f1703, %f750, %f780;
	mul.f32 	%f782, %f1694, %f762;
	fma.rn.f32 	%f783, %f1697, %f764, %f782;
	fma.rn.f32 	%f784, %f1699, %f766, %f783;
	sub.f32 	%f1718, %f1704, %f784;
	mul.f32 	%f785, %f1697, %f771;
	fma.rn.f32 	%f786, %f1694, %f768, %f785;
	fma.rn.f32 	%f787, %f1699, %f773, %f786;
	sub.f32 	%f1714, %f1705, %f787;
	mul.f32 	%f788, %f1697, %f777;
	fma.rn.f32 	%f789, %f1694, %f775, %f788;
	fma.rn.f32 	%f790, %f1699, %f781, %f789;
	sub.f32 	%f1707, %f1706, %f790;
	mul.f32 	%f791, %f1693, %f762;
	fma.rn.f32 	%f792, %f1696, %f764, %f791;
	fma.rn.f32 	%f1717, %f1698, %f766, %f792;
	mul.f32 	%f793, %f1696, %f771;
	fma.rn.f32 	%f794, %f1693, %f768, %f793;
	fma.rn.f32 	%f1713, %f1698, %f773, %f794;
	mul.f32 	%f795, %f1696, %f777;
	fma.rn.f32 	%f796, %f1693, %f775, %f795;
	fma.rn.f32 	%f1708, %f1698, %f781, %f796;
	mul.f32 	%f797, %f1692, %f762;
	fma.rn.f32 	%f1716, %f1695, %f764, %f797;
	mul.f32 	%f798, %f1695, %f771;
	fma.rn.f32 	%f1712, %f1692, %f768, %f798;
	mul.f32 	%f799, %f1695, %f777;
	fma.rn.f32 	%f1709, %f1692, %f775, %f799;
	mul.f32 	%f1715, %f1691, %f762;
	mul.f32 	%f1711, %f1691, %f768;
	mul.f32 	%f1710, %f1691, %f775;

BB6_17:
	mul.f32 	%f837, %f1709, %f1713;
	mul.f32 	%f838, %f1708, %f1712;
	sub.f32 	%f839, %f838, %f837;
	mul.f32 	%f840, %f1715, %f839;
	mul.f32 	%f841, %f1710, %f1713;
	mul.f32 	%f842, %f1708, %f1711;
	sub.f32 	%f843, %f842, %f841;
	mul.f32 	%f844, %f843, %f1716;
	sub.f32 	%f845, %f840, %f844;
	mul.f32 	%f846, %f1710, %f1712;
	mul.f32 	%f847, %f1709, %f1711;
	sub.f32 	%f848, %f847, %f846;
	fma.rn.f32 	%f849, %f848, %f1717, %f845;
	rcp.rn.f32 	%f850, %f849;
	mul.f32 	%f1727, %f839, %f850;
	mul.f32 	%f851, %f1708, %f1716;
	mul.f32 	%f852, %f1709, %f1717;
	sub.f32 	%f853, %f852, %f851;
	mul.f32 	%f1728, %f850, %f853;
	mul.f32 	%f854, %f1712, %f1717;
	mul.f32 	%f855, %f1713, %f1716;
	sub.f32 	%f856, %f855, %f854;
	mul.f32 	%f1729, %f850, %f856;
	sub.f32 	%f857, %f841, %f842;
	mul.f32 	%f1723, %f857, %f850;
	mul.f32 	%f858, %f1710, %f1717;
	mul.f32 	%f859, %f1708, %f1715;
	sub.f32 	%f860, %f859, %f858;
	mul.f32 	%f1724, %f850, %f860;
	mul.f32 	%f861, %f1713, %f1715;
	mul.f32 	%f862, %f1711, %f1717;
	sub.f32 	%f863, %f862, %f861;
	mul.f32 	%f1725, %f850, %f863;
	mul.f32 	%f1722, %f848, %f850;
	mul.f32 	%f864, %f1709, %f1715;
	mul.f32 	%f865, %f1710, %f1716;
	sub.f32 	%f866, %f865, %f864;
	mul.f32 	%f1721, %f866, %f850;
	mul.f32 	%f867, %f1711, %f1716;
	mul.f32 	%f868, %f1712, %f1715;
	sub.f32 	%f869, %f868, %f867;
	mul.f32 	%f1720, %f869, %f850;
	mul.f32 	%f870, %f1718, %f1727;
	neg.f32 	%f871, %f870;
	mul.f32 	%f872, %f1714, %f1728;
	sub.f32 	%f873, %f871, %f872;
	mul.f32 	%f874, %f1707, %f1729;
	sub.f32 	%f1730, %f873, %f874;
	mul.f32 	%f875, %f1718, %f1723;
	neg.f32 	%f876, %f875;
	mul.f32 	%f877, %f1714, %f1724;
	sub.f32 	%f878, %f876, %f877;
	mul.f32 	%f879, %f1707, %f1725;
	sub.f32 	%f1726, %f878, %f879;
	mul.f32 	%f880, %f1718, %f1722;
	neg.f32 	%f881, %f880;
	mul.f32 	%f882, %f1714, %f1721;
	sub.f32 	%f883, %f881, %f882;
	mul.f32 	%f884, %f1707, %f1720;
	sub.f32 	%f1719, %f883, %f884;
	bra.uni 	BB6_18;

BB6_7:
	setp.ne.s32	%p5, %r31, 1;
	mov.f32 	%f1721, %f1719;
	mov.f32 	%f1722, %f1719;
	mov.f32 	%f1723, %f1719;
	mov.f32 	%f1724, %f1720;
	mov.f32 	%f1725, %f1719;
	mov.f32 	%f1726, %f1719;
	mov.f32 	%f1727, %f1720;
	mov.f32 	%f1728, %f1719;
	mov.f32 	%f1729, %f1719;
	mov.f32 	%f1730, %f1719;
	@%p5 bra 	BB6_18;

	// inline asm
	call (%rd55), _optix_get_static_transform_from_handle, (%rd53);
	// inline asm
	add.s64 	%rd666, %rd55, 64;

BB6_10:
	// inline asm
	cvta.to.global.u64 %rd59, %rd666;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd59];
	// inline asm
	mov.b32 	 %f1727, %r33;
	mov.b32 	 %f1728, %r34;
	mov.b32 	 %f1729, %r35;
	mov.b32 	 %f1730, %r36;
	add.s64 	%rd63, %rd666, 16;
	// inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd62];
	// inline asm
	mov.b32 	 %f1723, %r37;
	mov.b32 	 %f1724, %r38;
	mov.b32 	 %f1725, %r39;
	mov.b32 	 %f1726, %r40;
	add.s64 	%rd66, %rd666, 32;
	// inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd65];
	// inline asm
	mov.b32 	 %f1722, %r41;
	mov.b32 	 %f1721, %r42;
	mov.b32 	 %f1720, %r43;
	mov.b32 	 %f1719, %r44;

BB6_18:
	setp.eq.s32	%p9, %r634, 0;
	@%p9 bra 	BB6_19;
	bra.uni 	BB6_20;

BB6_19:
	mov.f32 	%f1690, %f1730;
	mov.f32 	%f1689, %f1729;
	mov.f32 	%f1688, %f1728;
	mov.f32 	%f1687, %f1727;
	mov.f32 	%f1686, %f1726;
	mov.f32 	%f1685, %f1725;
	mov.f32 	%f1684, %f1724;
	mov.f32 	%f1683, %f1723;
	mov.f32 	%f1682, %f1719;
	mov.f32 	%f1681, %f1720;
	mov.f32 	%f1680, %f1721;
	mov.f32 	%f1679, %f1722;
	bra.uni 	BB6_21;

BB6_20:
	mul.f32 	%f885, %f1683, %f1728;
	fma.rn.f32 	%f886, %f1687, %f1727, %f885;
	fma.rn.f32 	%f151, %f1679, %f1729, %f886;
	mul.f32 	%f887, %f1684, %f1728;
	fma.rn.f32 	%f888, %f1688, %f1727, %f887;
	fma.rn.f32 	%f152, %f1680, %f1729, %f888;
	mul.f32 	%f889, %f1685, %f1728;
	fma.rn.f32 	%f890, %f1689, %f1727, %f889;
	fma.rn.f32 	%f153, %f1681, %f1729, %f890;
	mul.f32 	%f891, %f1686, %f1728;
	fma.rn.f32 	%f892, %f1690, %f1727, %f891;
	fma.rn.f32 	%f893, %f1682, %f1729, %f892;
	add.f32 	%f154, %f1730, %f893;
	mul.f32 	%f894, %f1683, %f1724;
	fma.rn.f32 	%f895, %f1687, %f1723, %f894;
	fma.rn.f32 	%f155, %f1679, %f1725, %f895;
	mul.f32 	%f896, %f1684, %f1724;
	fma.rn.f32 	%f897, %f1688, %f1723, %f896;
	fma.rn.f32 	%f156, %f1680, %f1725, %f897;
	mul.f32 	%f898, %f1685, %f1724;
	fma.rn.f32 	%f899, %f1689, %f1723, %f898;
	fma.rn.f32 	%f157, %f1681, %f1725, %f899;
	mul.f32 	%f900, %f1686, %f1724;
	fma.rn.f32 	%f901, %f1690, %f1723, %f900;
	fma.rn.f32 	%f902, %f1682, %f1725, %f901;
	add.f32 	%f158, %f1726, %f902;
	mul.f32 	%f903, %f1687, %f1722;
	fma.rn.f32 	%f904, %f1683, %f1721, %f903;
	fma.rn.f32 	%f1679, %f1679, %f1720, %f904;
	mul.f32 	%f905, %f1688, %f1722;
	fma.rn.f32 	%f906, %f1684, %f1721, %f905;
	fma.rn.f32 	%f1680, %f1680, %f1720, %f906;
	mul.f32 	%f907, %f1689, %f1722;
	fma.rn.f32 	%f908, %f1685, %f1721, %f907;
	fma.rn.f32 	%f1681, %f1681, %f1720, %f908;
	mul.f32 	%f909, %f1690, %f1722;
	fma.rn.f32 	%f910, %f1686, %f1721, %f909;
	fma.rn.f32 	%f911, %f1682, %f1720, %f910;
	add.f32 	%f1682, %f1719, %f911;
	mov.f32 	%f1690, %f154;
	mov.f32 	%f1689, %f153;
	mov.f32 	%f1688, %f152;
	mov.f32 	%f1687, %f151;
	mov.f32 	%f1686, %f158;
	mov.f32 	%f1685, %f157;
	mov.f32 	%f1684, %f156;
	mov.f32 	%f1683, %f155;

BB6_21:
	add.s32 	%r634, %r634, 1;
	setp.lt.u32	%p10, %r634, %r28;
	@%p10 bra 	BB6_5;

	mul.f32 	%f912, %f670, %f1687;
	fma.rn.f32 	%f913, %f671, %f1688, %f912;
	fma.rn.f32 	%f914, %f1743, %f1689, %f913;
	add.f32 	%f1745, %f1690, %f914;
	mul.f32 	%f915, %f670, %f1683;
	fma.rn.f32 	%f916, %f671, %f1684, %f915;
	fma.rn.f32 	%f917, %f1743, %f1685, %f916;
	add.f32 	%f1744, %f1686, %f917;
	mul.f32 	%f918, %f670, %f1679;
	fma.rn.f32 	%f919, %f671, %f1680, %f918;
	fma.rn.f32 	%f920, %f1743, %f1681, %f919;
	add.f32 	%f1743, %f1682, %f920;
	bra.uni 	BB6_23;

BB6_3:
	mov.f32 	%f1744, %f671;
	mov.f32 	%f1745, %f670;

BB6_23:
	// inline asm
	call (%f921), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f922), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1794), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f924), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r635, 0;
	@%p2 bra 	BB6_24;

BB6_25:
	.pragma "nounroll";
	// inline asm
	call (%rd174), _optix_get_transform_list_handle, (%r635);
	// inline asm
	// inline asm
	call (%r181), _optix_get_transform_type_from_handle, (%rd174);
	// inline asm
	and.b32  	%r182, %r181, -2;
	setp.eq.s32	%p12, %r182, 2;
	@%p12 bra 	BB6_31;
	bra.uni 	BB6_26;

BB6_31:
	setp.eq.s32	%p15, %r181, 2;
	@%p15 bra 	BB6_35;
	bra.uni 	BB6_32;

BB6_35:
	// inline asm
	call (%rd248), _optix_get_matrix_motion_transform_from_handle, (%rd174);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd250, %rd248;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd250];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r272;
	add.s64 	%rd254, %rd248, 16;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd253];
	// inline asm
	add.s64 	%rd257, %rd248, 32;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd256];
	// inline asm
	add.s64 	%rd260, %rd248, 48;
	// inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd259];
	// inline asm
	add.s64 	%rd263, %rd248, 64;
	// inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd262];
	// inline asm
	add.s64 	%rd266, %rd248, 80;
	// inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd265];
	// inline asm
	add.s64 	%rd269, %rd248, 96;
	// inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd268];
	// inline asm
	add.s64 	%rd272, %rd248, 112;
	// inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r298,%r299,%r300,%r301}, [%rd271];
	// inline asm
	mov.b32 	 %f1027, %r273;
	mov.b32 	 %f1028, %r274;
	cvt.u32.u16	%r314, %rs8;
	add.s32 	%r315, %r314, -1;
	cvt.rn.f32.s32	%f1029, %r315;
	sub.f32 	%f1030, %f924, %f1027;
	mul.f32 	%f1031, %f1030, %f1029;
	sub.f32 	%f1032, %f1028, %f1027;
	div.rn.f32 	%f1033, %f1031, %f1032;
	min.f32 	%f1034, %f1029, %f1033;
	mov.f32 	%f1035, 0f00000000;
	max.f32 	%f1036, %f1035, %f1034;
	cvt.rmi.f32.f32	%f1037, %f1036;
	cvt.rzi.s32.f32	%r316, %f1037;
	cvt.s64.s32	%rd19, %r316;
	mul.wide.s32 	%rd283, %r316, 48;
	add.s64 	%rd275, %rd257, %rd283;
	// inline asm
	cvta.to.global.u64 %rd274, %rd275;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r302,%r303,%r304,%r305}, [%rd274];
	// inline asm
	mov.b32 	 %f1771, %r302;
	mov.b32 	 %f1772, %r303;
	mov.b32 	 %f1773, %r304;
	add.s64 	%rd278, %rd275, 16;
	// inline asm
	cvta.to.global.u64 %rd277, %rd278;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r306,%r307,%r308,%r309}, [%rd277];
	// inline asm
	mov.b32 	 %f1768, %r306;
	mov.b32 	 %f1769, %r307;
	mov.b32 	 %f1770, %r308;
	add.s64 	%rd281, %rd275, 32;
	// inline asm
	cvta.to.global.u64 %rd280, %rd281;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r310,%r311,%r312,%r313}, [%rd280];
	// inline asm
	sub.f32 	%f249, %f1036, %f1037;
	mov.b32 	 %f1765, %r310;
	mov.b32 	 %f1766, %r311;
	mov.b32 	 %f1767, %r312;
	setp.leu.f32	%p17, %f249, 0f00000000;
	@%p17 bra 	BB6_37;

	mul.lo.s64 	%rd293, %rd19, 48;
	add.s64 	%rd294, %rd248, %rd293;
	add.s64 	%rd285, %rd294, 80;
	// inline asm
	cvta.to.global.u64 %rd284, %rd285;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r317,%r318,%r319,%r320}, [%rd284];
	// inline asm
	mov.b32 	 %f1038, %r317;
	mov.b32 	 %f1039, %r318;
	mov.b32 	 %f1040, %r319;
	add.s64 	%rd288, %rd294, 96;
	// inline asm
	cvta.to.global.u64 %rd287, %rd288;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r321,%r322,%r323,%r324}, [%rd287];
	// inline asm
	mov.b32 	 %f1041, %r321;
	mov.b32 	 %f1042, %r322;
	mov.b32 	 %f1043, %r323;
	add.s64 	%rd291, %rd294, 112;
	// inline asm
	cvta.to.global.u64 %rd290, %rd291;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r325,%r326,%r327,%r328}, [%rd290];
	// inline asm
	mov.f32 	%f1044, 0f3F800000;
	sub.f32 	%f1045, %f1044, %f249;
	mul.f32 	%f1046, %f249, %f1038;
	mul.f32 	%f1047, %f249, %f1039;
	mul.f32 	%f1048, %f249, %f1040;
	fma.rn.f32 	%f1771, %f1045, %f1771, %f1046;
	fma.rn.f32 	%f1772, %f1045, %f1772, %f1047;
	fma.rn.f32 	%f1773, %f1045, %f1773, %f1048;
	mul.f32 	%f1049, %f249, %f1041;
	mul.f32 	%f1050, %f249, %f1042;
	mul.f32 	%f1051, %f249, %f1043;
	fma.rn.f32 	%f1768, %f1045, %f1768, %f1049;
	fma.rn.f32 	%f1769, %f1045, %f1769, %f1050;
	fma.rn.f32 	%f1770, %f1045, %f1770, %f1051;
	mov.b32 	 %f1052, %r325;
	mov.b32 	 %f1053, %r326;
	mov.b32 	 %f1054, %r327;
	mul.f32 	%f1055, %f249, %f1052;
	mul.f32 	%f1056, %f249, %f1053;
	mul.f32 	%f1057, %f249, %f1054;
	fma.rn.f32 	%f1765, %f1045, %f1765, %f1055;
	fma.rn.f32 	%f1766, %f1045, %f1766, %f1056;
	fma.rn.f32 	%f1767, %f1045, %f1767, %f1057;
	bra.uni 	BB6_37;

BB6_26:
	mov.f32 	%f1774, 0f00000000;
	mov.f32 	%f1776, 0f3F800000;
	setp.eq.s32	%p13, %r181, 4;
	@%p13 bra 	BB6_29;
	bra.uni 	BB6_27;

BB6_29:
	// inline asm
	call (%rd667), _optix_get_instance_inverse_transform_from_handle, (%rd174);
	// inline asm
	bra.uni 	BB6_30;

BB6_32:
	// inline asm
	call (%rd189), _optix_get_srt_motion_transform_from_handle, (%rd174);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd191, %rd189;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd191];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r197;
	add.s64 	%rd195, %rd189, 16;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd194];
	// inline asm
	add.s64 	%rd198, %rd189, 32;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd197];
	// inline asm
	add.s64 	%rd201, %rd189, 48;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd200];
	// inline asm
	add.s64 	%rd204, %rd189, 64;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd203];
	// inline asm
	add.s64 	%rd207, %rd189, 80;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd206];
	// inline asm
	add.s64 	%rd210, %rd189, 96;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd209];
	// inline asm
	add.s64 	%rd213, %rd189, 112;
	// inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd212];
	// inline asm
	add.s64 	%rd216, %rd189, 128;
	// inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd215];
	// inline asm
	add.s64 	%rd219, %rd189, 144;
	// inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd218];
	// inline asm
	mov.b32 	 %f935, %r198;
	mov.b32 	 %f936, %r199;
	cvt.u32.u16	%r251, %rs6;
	add.s32 	%r252, %r251, -1;
	cvt.rn.f32.s32	%f937, %r252;
	sub.f32 	%f938, %f924, %f935;
	mul.f32 	%f939, %f938, %f937;
	sub.f32 	%f940, %f936, %f935;
	div.rn.f32 	%f941, %f939, %f940;
	min.f32 	%f942, %f937, %f941;
	mov.f32 	%f943, 0f00000000;
	max.f32 	%f944, %f943, %f942;
	cvt.rmi.f32.f32	%f945, %f944;
	cvt.rzi.s32.f32	%r253, %f945;
	cvt.s64.s32	%rd17, %r253;
	mul.wide.s32 	%rd233, %r253, 64;
	add.s64 	%rd222, %rd198, %rd233;
	// inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r235,%r236,%r237,%r238}, [%rd221];
	// inline asm
	mov.b32 	 %f1755, %r235;
	mov.b32 	 %f1756, %r236;
	mov.b32 	 %f1757, %r237;
	add.s64 	%rd225, %rd222, 16;
	// inline asm
	cvta.to.global.u64 %rd224, %rd225;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r239,%r240,%r241,%r242}, [%rd224];
	// inline asm
	mov.b32 	 %f1758, %r239;
	mov.b32 	 %f1759, %r240;
	mov.b32 	 %f1760, %r242;
	add.s64 	%rd228, %rd222, 32;
	// inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r243,%r244,%r245,%r246}, [%rd227];
	// inline asm
	sub.f32 	%f209, %f944, %f945;
	mov.b32 	 %f1761, %r244;
	mov.b32 	 %f1762, %r245;
	mov.b32 	 %f1763, %r246;
	add.s64 	%rd231, %rd222, 48;
	// inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r247,%r248,%r249,%r250}, [%rd230];
	// inline asm
	mov.b32 	 %f1764, %r247;
	setp.leu.f32	%p16, %f209, 0f00000000;
	@%p16 bra 	BB6_34;

	shl.b64 	%rd246, %rd17, 6;
	add.s64 	%rd247, %rd246, %rd189;
	add.s64 	%rd235, %rd247, 96;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd234];
	// inline asm
	mov.b32 	 %f946, %r254;
	mov.b32 	 %f947, %r255;
	mov.b32 	 %f948, %r256;
	add.s64 	%rd238, %rd247, 112;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd237];
	// inline asm
	mov.b32 	 %f949, %r258;
	mov.b32 	 %f950, %r259;
	mov.b32 	 %f951, %r261;
	add.s64 	%rd241, %rd247, 128;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd240];
	// inline asm
	mov.b32 	 %f952, %r263;
	mov.b32 	 %f953, %r264;
	mov.b32 	 %f954, %r265;
	add.s64 	%rd244, %rd247, 144;
	// inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd243];
	// inline asm
	mov.f32 	%f955, 0f3F800000;
	sub.f32 	%f956, %f955, %f209;
	mul.f32 	%f957, %f209, %f946;
	mul.f32 	%f958, %f209, %f947;
	mul.f32 	%f959, %f209, %f948;
	fma.rn.f32 	%f1755, %f956, %f1755, %f957;
	fma.rn.f32 	%f1756, %f956, %f1756, %f958;
	fma.rn.f32 	%f1757, %f956, %f1757, %f959;
	mul.f32 	%f960, %f209, %f949;
	mul.f32 	%f961, %f209, %f950;
	mul.f32 	%f962, %f209, %f951;
	fma.rn.f32 	%f1758, %f956, %f1758, %f960;
	fma.rn.f32 	%f1759, %f956, %f1759, %f961;
	fma.rn.f32 	%f1760, %f956, %f1760, %f962;
	mul.f32 	%f963, %f209, %f952;
	mul.f32 	%f964, %f209, %f953;
	mul.f32 	%f965, %f209, %f954;
	fma.rn.f32 	%f966, %f956, %f1761, %f963;
	fma.rn.f32 	%f967, %f956, %f1762, %f964;
	fma.rn.f32 	%f968, %f956, %f1763, %f965;
	mov.b32 	 %f969, %r266;
	mul.f32 	%f970, %f209, %f969;
	fma.rn.f32 	%f971, %f956, %f1764, %f970;
	mul.f32 	%f972, %f967, %f967;
	fma.rn.f32 	%f973, %f966, %f966, %f972;
	fma.rn.f32 	%f974, %f968, %f968, %f973;
	fma.rn.f32 	%f975, %f971, %f971, %f974;
	sqrt.rn.f32 	%f976, %f975;
	rcp.rn.f32 	%f977, %f976;
	mul.f32 	%f1761, %f966, %f977;
	mul.f32 	%f1762, %f967, %f977;
	mul.f32 	%f1763, %f968, %f977;
	mul.f32 	%f1764, %f971, %f977;

BB6_34:
	mul.f32 	%f978, %f1762, %f1762;
	fma.rn.f32 	%f979, %f1761, %f1761, %f978;
	fma.rn.f32 	%f980, %f1763, %f1763, %f979;
	fma.rn.f32 	%f981, %f1764, %f1764, %f980;
	rcp.rn.f32 	%f982, %f981;
	mul.f32 	%f983, %f1761, %f982;
	mul.f32 	%f984, %f1762, %f982;
	mul.f32 	%f985, %f1763, %f982;
	mul.f32 	%f986, %f1764, %f982;
	mul.f32 	%f987, %f1761, %f983;
	mul.f32 	%f988, %f1762, %f984;
	mul.f32 	%f989, %f1763, %f985;
	mul.f32 	%f990, %f1761, %f984;
	mul.f32 	%f991, %f1763, %f986;
	mul.f32 	%f992, %f1761, %f985;
	mul.f32 	%f993, %f1762, %f986;
	mul.f32 	%f994, %f1762, %f985;
	mul.f32 	%f995, %f1761, %f986;
	sub.f32 	%f996, %f987, %f988;
	sub.f32 	%f997, %f996, %f989;
	fma.rn.f32 	%f998, %f1764, %f986, %f997;
	sub.f32 	%f999, %f990, %f991;
	add.f32 	%f1000, %f999, %f999;
	add.f32 	%f1001, %f992, %f993;
	add.f32 	%f1002, %f1001, %f1001;
	add.f32 	%f1003, %f990, %f991;
	add.f32 	%f1004, %f1003, %f1003;
	sub.f32 	%f1005, %f988, %f987;
	sub.f32 	%f1006, %f1005, %f989;
	fma.rn.f32 	%f1007, %f1764, %f986, %f1006;
	sub.f32 	%f1008, %f994, %f995;
	add.f32 	%f1009, %f1008, %f1008;
	sub.f32 	%f1010, %f992, %f993;
	add.f32 	%f1011, %f1010, %f1010;
	add.f32 	%f1012, %f994, %f995;
	add.f32 	%f1013, %f1012, %f1012;
	neg.f32 	%f1014, %f987;
	sub.f32 	%f1015, %f1014, %f988;
	add.f32 	%f1016, %f989, %f1015;
	fma.rn.f32 	%f1017, %f1764, %f986, %f1016;
	mul.f32 	%f1018, %f1757, %f998;
	fma.rn.f32 	%f1019, %f1759, %f1000, %f1018;
	fma.rn.f32 	%f1773, %f1760, %f1002, %f1019;
	mul.f32 	%f1020, %f1759, %f1007;
	fma.rn.f32 	%f1021, %f1757, %f1004, %f1020;
	fma.rn.f32 	%f1770, %f1760, %f1009, %f1021;
	mul.f32 	%f1022, %f1759, %f1013;
	fma.rn.f32 	%f1023, %f1757, %f1011, %f1022;
	fma.rn.f32 	%f1767, %f1760, %f1017, %f1023;
	mul.f32 	%f1024, %f1756, %f998;
	fma.rn.f32 	%f1772, %f1758, %f1000, %f1024;
	mul.f32 	%f1025, %f1758, %f1007;
	fma.rn.f32 	%f1769, %f1756, %f1004, %f1025;
	mul.f32 	%f1026, %f1758, %f1013;
	fma.rn.f32 	%f1766, %f1756, %f1011, %f1026;
	mul.f32 	%f1771, %f1755, %f998;
	mul.f32 	%f1768, %f1755, %f1004;
	mul.f32 	%f1765, %f1755, %f1011;

BB6_37:
	mul.f32 	%f1058, %f1766, %f1770;
	mul.f32 	%f1059, %f1767, %f1769;
	sub.f32 	%f1060, %f1059, %f1058;
	mul.f32 	%f1061, %f1771, %f1060;
	mul.f32 	%f1062, %f1765, %f1770;
	mul.f32 	%f1063, %f1767, %f1768;
	sub.f32 	%f1064, %f1063, %f1062;
	mul.f32 	%f1065, %f1064, %f1772;
	sub.f32 	%f1066, %f1061, %f1065;
	mul.f32 	%f1067, %f1765, %f1769;
	mul.f32 	%f1068, %f1766, %f1768;
	sub.f32 	%f1069, %f1068, %f1067;
	fma.rn.f32 	%f1070, %f1069, %f1773, %f1066;
	rcp.rn.f32 	%f1071, %f1070;
	mul.f32 	%f1780, %f1060, %f1071;
	mul.f32 	%f1072, %f1767, %f1772;
	mul.f32 	%f1073, %f1766, %f1773;
	sub.f32 	%f1074, %f1073, %f1072;
	mul.f32 	%f1781, %f1071, %f1074;
	mul.f32 	%f1075, %f1769, %f1773;
	mul.f32 	%f1076, %f1770, %f1772;
	sub.f32 	%f1077, %f1076, %f1075;
	mul.f32 	%f1782, %f1071, %f1077;
	sub.f32 	%f1078, %f1062, %f1063;
	mul.f32 	%f1777, %f1078, %f1071;
	mul.f32 	%f1079, %f1765, %f1773;
	mul.f32 	%f1080, %f1767, %f1771;
	sub.f32 	%f1081, %f1080, %f1079;
	mul.f32 	%f1778, %f1071, %f1081;
	mul.f32 	%f1082, %f1770, %f1771;
	mul.f32 	%f1083, %f1768, %f1773;
	sub.f32 	%f1084, %f1083, %f1082;
	mul.f32 	%f1779, %f1071, %f1084;
	mul.f32 	%f1774, %f1069, %f1071;
	mul.f32 	%f1085, %f1766, %f1771;
	mul.f32 	%f1086, %f1765, %f1772;
	sub.f32 	%f1087, %f1086, %f1085;
	mul.f32 	%f1775, %f1087, %f1071;
	mul.f32 	%f1088, %f1768, %f1772;
	mul.f32 	%f1089, %f1769, %f1771;
	sub.f32 	%f1090, %f1089, %f1088;
	mul.f32 	%f1776, %f1090, %f1071;
	bra.uni 	BB6_38;

BB6_27:
	setp.ne.s32	%p14, %r181, 1;
	mov.f32 	%f1775, %f1774;
	mov.f32 	%f1777, %f1774;
	mov.f32 	%f1778, %f1776;
	mov.f32 	%f1779, %f1774;
	mov.f32 	%f1780, %f1776;
	mov.f32 	%f1781, %f1774;
	mov.f32 	%f1782, %f1774;
	@%p14 bra 	BB6_38;

	// inline asm
	call (%rd176), _optix_get_static_transform_from_handle, (%rd174);
	// inline asm
	add.s64 	%rd667, %rd176, 64;

BB6_30:
	// inline asm
	cvta.to.global.u64 %rd180, %rd667;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd180];
	// inline asm
	mov.b32 	 %f1780, %r183;
	mov.b32 	 %f1781, %r184;
	mov.b32 	 %f1782, %r185;
	add.s64 	%rd184, %rd667, 16;
	// inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd183];
	// inline asm
	mov.b32 	 %f1777, %r187;
	mov.b32 	 %f1778, %r188;
	mov.b32 	 %f1779, %r189;
	add.s64 	%rd187, %rd667, 32;
	// inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd186];
	// inline asm
	mov.b32 	 %f1774, %r191;
	mov.b32 	 %f1775, %r192;
	mov.b32 	 %f1776, %r193;

BB6_38:
	setp.eq.s32	%p18, %r635, 0;
	@%p18 bra 	BB6_39;
	bra.uni 	BB6_40;

BB6_39:
	mov.f32 	%f1754, %f1774;
	mov.f32 	%f1753, %f1775;
	mov.f32 	%f1752, %f1776;
	mov.f32 	%f1751, %f1777;
	mov.f32 	%f1750, %f1778;
	mov.f32 	%f1749, %f1779;
	mov.f32 	%f1748, %f1780;
	mov.f32 	%f1747, %f1781;
	mov.f32 	%f1746, %f1782;
	bra.uni 	BB6_41;

BB6_40:
	mul.f32 	%f1091, %f1751, %f1781;
	fma.rn.f32 	%f1092, %f1748, %f1780, %f1091;
	fma.rn.f32 	%f289, %f1754, %f1782, %f1092;
	mul.f32 	%f1093, %f1750, %f1781;
	fma.rn.f32 	%f1094, %f1747, %f1780, %f1093;
	fma.rn.f32 	%f290, %f1753, %f1782, %f1094;
	mul.f32 	%f1095, %f1749, %f1781;
	fma.rn.f32 	%f1096, %f1746, %f1780, %f1095;
	fma.rn.f32 	%f291, %f1752, %f1782, %f1096;
	mul.f32 	%f1097, %f1751, %f1778;
	fma.rn.f32 	%f1098, %f1748, %f1777, %f1097;
	fma.rn.f32 	%f292, %f1754, %f1779, %f1098;
	mul.f32 	%f1099, %f1750, %f1778;
	fma.rn.f32 	%f1100, %f1747, %f1777, %f1099;
	fma.rn.f32 	%f293, %f1753, %f1779, %f1100;
	mul.f32 	%f1101, %f1749, %f1778;
	fma.rn.f32 	%f1102, %f1746, %f1777, %f1101;
	fma.rn.f32 	%f294, %f1752, %f1779, %f1102;
	mul.f32 	%f1103, %f1751, %f1775;
	fma.rn.f32 	%f1104, %f1748, %f1774, %f1103;
	fma.rn.f32 	%f1754, %f1754, %f1776, %f1104;
	mul.f32 	%f1105, %f1750, %f1775;
	fma.rn.f32 	%f1106, %f1747, %f1774, %f1105;
	fma.rn.f32 	%f1753, %f1753, %f1776, %f1106;
	mul.f32 	%f1107, %f1749, %f1775;
	fma.rn.f32 	%f1108, %f1746, %f1774, %f1107;
	fma.rn.f32 	%f1752, %f1752, %f1776, %f1108;
	mov.f32 	%f1751, %f292;
	mov.f32 	%f1750, %f293;
	mov.f32 	%f1749, %f294;
	mov.f32 	%f1748, %f289;
	mov.f32 	%f1747, %f290;
	mov.f32 	%f1746, %f291;

BB6_41:
	add.s32 	%r635, %r635, 1;
	setp.lt.u32	%p19, %r635, %r28;
	@%p19 bra 	BB6_25;

	mul.f32 	%f1109, %f922, %f1747;
	fma.rn.f32 	%f1110, %f921, %f1748, %f1109;
	fma.rn.f32 	%f1792, %f1794, %f1746, %f1110;
	mul.f32 	%f1111, %f922, %f1750;
	fma.rn.f32 	%f1112, %f921, %f1751, %f1111;
	fma.rn.f32 	%f1793, %f1794, %f1749, %f1112;
	mul.f32 	%f1113, %f922, %f1753;
	fma.rn.f32 	%f1114, %f921, %f1754, %f1113;
	fma.rn.f32 	%f1794, %f1794, %f1752, %f1114;
	bra.uni 	BB6_43;

BB6_24:
	mov.f32 	%f1792, %f921;
	mov.f32 	%f1793, %f922;

BB6_43:
	ld.v4.f32 	{%f1117, %f1118, %f1119, %f1120}, [%rd3+80];
	ld.v4.f32 	{%f1124, %f1125, %f1126, %f1127}, [%rd3+32];
	fma.rn.f32 	%f1129, %f1745, %f1124, %f1117;
	fma.rn.f32 	%f1131, %f1745, %f1125, %f1118;
	fma.rn.f32 	%f1133, %f1745, %f1126, %f1119;
	ld.v4.f32 	{%f1134, %f1135, %f1136, %f1137}, [%rd3+48];
	fma.rn.f32 	%f1139, %f1744, %f1134, %f1129;
	fma.rn.f32 	%f1141, %f1744, %f1135, %f1131;
	fma.rn.f32 	%f1143, %f1744, %f1136, %f1133;
	ld.v4.f32 	{%f1144, %f1145, %f1146, %f1147}, [%rd3+64];
	fma.rn.f32 	%f1149, %f1743, %f1144, %f1139;
	fma.rn.f32 	%f1151, %f1743, %f1145, %f1141;
	fma.rn.f32 	%f1153, %f1743, %f1146, %f1143;
	mul.f32 	%f1154, %f1792, %f1124;
	mul.f32 	%f1155, %f1792, %f1125;
	mul.f32 	%f1156, %f1792, %f1126;
	fma.rn.f32 	%f1157, %f1793, %f1134, %f1154;
	fma.rn.f32 	%f1158, %f1793, %f1135, %f1155;
	fma.rn.f32 	%f1159, %f1793, %f1136, %f1156;
	fma.rn.f32 	%f1160, %f1794, %f1144, %f1157;
	fma.rn.f32 	%f1161, %f1794, %f1145, %f1158;
	fma.rn.f32 	%f1162, %f1794, %f1146, %f1159;
	rcp.rn.f32 	%f1163, %f1162;
	mul.f32 	%f1164, %f1153, %f1163;
	neg.f32 	%f313, %f1164;
	fma.rn.f32 	%f314, %f313, %f1160, %f1149;
	fma.rn.f32 	%f315, %f313, %f1161, %f1151;
	ld.const.u64 	%rd21, [params+80];
	setp.eq.s64	%p20, %rd21, 0;
	cvt.u64.u32	%rd22, %r1;
	@%p20 bra 	BB6_48;

	ld.u64 	%rd295, [%rd52];
	ld.const.u64 	%rd296, [params+328];
	cvta.to.global.u64 	%rd297, %rd296;
	shl.b64 	%rd298, %rd22, 3;
	add.s64 	%rd299, %rd297, %rd298;
	st.global.u64 	[%rd299], %rd295;
	ld.const.u64 	%rd300, [params+336];
	cvta.to.global.u64 	%rd301, %rd300;
	shl.b64 	%rd302, %rd22, 2;
	add.s64 	%rd303, %rd301, %rd302;
	mov.u32 	%r329, 0;
	st.global.u32 	[%rd303], %r329;
	ld.const.u64 	%rd304, [params+344];
	cvta.to.global.u64 	%rd305, %rd304;
	add.s64 	%rd24, %rd305, %rd302;
	ld.global.u32 	%r9, [%rd24];
	setp.eq.s32	%p21, %r9, 0;
	@%p21 bra 	BB6_47;

	// inline asm
	call (%r330), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p22, %r330, %r9;
	@%p22 bra 	BB6_47;

	st.global.u32 	[%rd24], %r330;

BB6_47:
	cvta.to.global.u64 	%rd306, %rd21;
	add.s64 	%rd308, %rd306, %rd302;
	st.global.f32 	[%rd308], %f314;
	ld.const.u64 	%rd309, [params+88];
	cvta.to.global.u64 	%rd310, %rd309;
	add.s64 	%rd311, %rd310, %rd302;
	st.global.f32 	[%rd311], %f315;
	ld.const.u64 	%rd312, [params+72];
	cvta.to.global.u64 	%rd313, %rd312;
	add.s64 	%rd314, %rd313, %rd302;
	st.global.f32 	[%rd314], %f313;
	bra.uni 	BB6_108;

BB6_48:
	fma.rn.f32 	%f1944, %f313, %f1792, %f1745;
	fma.rn.f32 	%f1945, %f313, %f1793, %f1744;
	fma.rn.f32 	%f1946, %f313, %f1794, %f1743;
	fma.rn.f32 	%f319, %f314, 0f3F000000, 0f3F000000;
	fma.rn.f32 	%f320, %f315, 0f3F000000, 0f3F000000;
	ld.v4.f32 	{%f1941, %f1942, %f1943, %f1171}, [%rd3+160];
	ld.v4.f32 	{%f1935, %f1936, %f1937, %f1175}, [%rd3+176];
	ld.v4.f32 	{%f1932, %f1933, %f1934, %f1179}, [%rd3+192];
	ld.u64 	%rd25, [%rd52];
	ld.const.u64 	%rd315, [params+344];
	cvta.to.global.u64 	%rd316, %rd315;
	shl.b64 	%rd317, %rd22, 2;
	add.s64 	%rd26, %rd316, %rd317;
	ld.global.u32 	%r11, [%rd26];
	setp.eq.s32	%p23, %r11, 0;
	mov.f32 	%f1929, 0f00000000;
	@%p23 bra 	BB6_49;

	// inline asm
	call (%r331), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p24, %r331, %r11;
	@%p24 bra 	BB6_49;

	mov.f32 	%f1860, 0f00000000;
	mov.f32 	%f1861, 0f3F800000;
	mov.f32 	%f1798, %f1861;
	mov.f32 	%f1797, %f1860;
	mov.f32 	%f1796, %f1860;
	mov.f32 	%f1795, %f1860;
	mov.f32 	%f1802, %f1860;
	mov.f32 	%f1801, %f1861;
	mov.f32 	%f1800, %f1860;
	mov.f32 	%f1799, %f1860;
	mov.f32 	%f1806, %f1860;
	mov.f32 	%f1805, %f1860;
	mov.f32 	%f1804, %f1861;
	mov.f32 	%f1803, %f1860;
	@%p2 bra 	BB6_69;

	add.s32 	%r636, %r28, -1;
	setp.lt.s32	%p26, %r636, 0;
	@%p26 bra 	BB6_69;

BB6_53:
	.pragma "nounroll";
	// inline asm
	call (%rd318), _optix_get_transform_list_handle, (%r636);
	// inline asm
	// inline asm
	call (%r333), _optix_get_transform_type_from_handle, (%rd318);
	// inline asm
	and.b32  	%r334, %r333, -2;
	setp.eq.s32	%p27, %r334, 2;
	@%p27 bra 	BB6_59;
	bra.uni 	BB6_54;

BB6_59:
	setp.eq.s32	%p30, %r333, 2;
	@%p30 bra 	BB6_63;
	bra.uni 	BB6_60;

BB6_63:
	// inline asm
	call (%rd392), _optix_get_matrix_motion_transform_from_handle, (%rd318);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd394, %rd392;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r422,%r423,%r424,%r425}, [%rd394];
	// inline asm
	mov.b32	{%rs12, %rs13}, %r424;
	add.s64 	%rd398, %rd392, 16;
	// inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd397];
	// inline asm
	add.s64 	%rd401, %rd392, 32;
	// inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd400];
	// inline asm
	add.s64 	%rd404, %rd392, 48;
	// inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd403];
	// inline asm
	add.s64 	%rd407, %rd392, 64;
	// inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd406];
	// inline asm
	add.s64 	%rd410, %rd392, 80;
	// inline asm
	cvta.to.global.u64 %rd409, %rd410;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd409];
	// inline asm
	add.s64 	%rd413, %rd392, 96;
	// inline asm
	cvta.to.global.u64 %rd412, %rd413;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd412];
	// inline asm
	add.s64 	%rd416, %rd392, 112;
	// inline asm
	cvta.to.global.u64 %rd415, %rd416;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd415];
	// inline asm
	mov.b32 	 %f1321, %r425;
	mov.b32 	 %f1322, %r426;
	cvt.u32.u16	%r466, %rs12;
	add.s32 	%r467, %r466, -1;
	cvt.rn.f32.s32	%f1323, %r467;
	sub.f32 	%f1324, %f924, %f1321;
	mul.f32 	%f1325, %f1324, %f1323;
	sub.f32 	%f1326, %f1322, %f1321;
	div.rn.f32 	%f1327, %f1325, %f1326;
	min.f32 	%f1328, %f1323, %f1327;
	mov.f32 	%f1329, 0f00000000;
	max.f32 	%f1330, %f1329, %f1328;
	cvt.rmi.f32.f32	%f1331, %f1330;
	cvt.rzi.s32.f32	%r468, %f1331;
	cvt.s64.s32	%rd34, %r468;
	mul.wide.s32 	%rd427, %r468, 48;
	add.s64 	%rd419, %rd401, %rd427;
	// inline asm
	cvta.to.global.u64 %rd418, %rd419;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd418];
	// inline asm
	mov.b32 	 %f1831, %r454;
	mov.b32 	 %f1832, %r455;
	mov.b32 	 %f1833, %r456;
	mov.b32 	 %f1834, %r457;
	add.s64 	%rd422, %rd419, 16;
	// inline asm
	cvta.to.global.u64 %rd421, %rd422;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd421];
	// inline asm
	mov.b32 	 %f1827, %r458;
	mov.b32 	 %f1828, %r459;
	mov.b32 	 %f1829, %r460;
	mov.b32 	 %f1830, %r461;
	add.s64 	%rd425, %rd419, 32;
	// inline asm
	cvta.to.global.u64 %rd424, %rd425;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd424];
	// inline asm
	sub.f32 	%f423, %f1330, %f1331;
	mov.b32 	 %f1823, %r462;
	mov.b32 	 %f1824, %r463;
	mov.b32 	 %f1825, %r464;
	mov.b32 	 %f1826, %r465;
	setp.leu.f32	%p32, %f423, 0f00000000;
	@%p32 bra 	BB6_65;

	mul.lo.s64 	%rd437, %rd34, 48;
	add.s64 	%rd438, %rd392, %rd437;
	add.s64 	%rd429, %rd438, 80;
	// inline asm
	cvta.to.global.u64 %rd428, %rd429;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r469,%r470,%r471,%r472}, [%rd428];
	// inline asm
	mov.b32 	 %f1332, %r469;
	mov.b32 	 %f1333, %r470;
	mov.b32 	 %f1334, %r471;
	mov.b32 	 %f1335, %r472;
	add.s64 	%rd432, %rd438, 96;
	// inline asm
	cvta.to.global.u64 %rd431, %rd432;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r473,%r474,%r475,%r476}, [%rd431];
	// inline asm
	mov.b32 	 %f1336, %r473;
	mov.b32 	 %f1337, %r474;
	mov.b32 	 %f1338, %r475;
	mov.b32 	 %f1339, %r476;
	add.s64 	%rd435, %rd438, 112;
	// inline asm
	cvta.to.global.u64 %rd434, %rd435;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r477,%r478,%r479,%r480}, [%rd434];
	// inline asm
	mov.f32 	%f1340, 0f3F800000;
	sub.f32 	%f1341, %f1340, %f423;
	mul.f32 	%f1342, %f423, %f1332;
	mul.f32 	%f1343, %f423, %f1333;
	mul.f32 	%f1344, %f423, %f1334;
	mul.f32 	%f1345, %f423, %f1335;
	fma.rn.f32 	%f1831, %f1341, %f1831, %f1342;
	fma.rn.f32 	%f1832, %f1341, %f1832, %f1343;
	fma.rn.f32 	%f1833, %f1341, %f1833, %f1344;
	fma.rn.f32 	%f1834, %f1341, %f1834, %f1345;
	mul.f32 	%f1346, %f423, %f1336;
	mul.f32 	%f1347, %f423, %f1337;
	mul.f32 	%f1348, %f423, %f1338;
	mul.f32 	%f1349, %f423, %f1339;
	fma.rn.f32 	%f1827, %f1341, %f1827, %f1346;
	fma.rn.f32 	%f1828, %f1341, %f1828, %f1347;
	fma.rn.f32 	%f1829, %f1341, %f1829, %f1348;
	fma.rn.f32 	%f1830, %f1341, %f1830, %f1349;
	mov.b32 	 %f1350, %r477;
	mov.b32 	 %f1351, %r478;
	mov.b32 	 %f1352, %r479;
	mov.b32 	 %f1353, %r480;
	mul.f32 	%f1354, %f423, %f1350;
	mul.f32 	%f1355, %f423, %f1351;
	mul.f32 	%f1356, %f423, %f1352;
	mul.f32 	%f1357, %f423, %f1353;
	fma.rn.f32 	%f1823, %f1341, %f1823, %f1354;
	fma.rn.f32 	%f1824, %f1341, %f1824, %f1355;
	fma.rn.f32 	%f1825, %f1341, %f1825, %f1356;
	fma.rn.f32 	%f1826, %f1341, %f1826, %f1357;
	bra.uni 	BB6_65;

BB6_54:
	mov.f32 	%f1823, 0f00000000;
	mov.f32 	%f1825, 0f3F800000;
	setp.eq.s32	%p28, %r333, 4;
	@%p28 bra 	BB6_57;
	bra.uni 	BB6_55;

BB6_57:
	// inline asm
	call (%rd668), _optix_get_instance_transform_from_handle, (%rd318);
	// inline asm
	bra.uni 	BB6_58;

BB6_60:
	// inline asm
	call (%rd333), _optix_get_srt_motion_transform_from_handle, (%rd318);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd335, %rd333;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r347,%r348,%r349,%r350}, [%rd335];
	// inline asm
	mov.b32	{%rs10, %rs11}, %r349;
	add.s64 	%rd339, %rd333, 16;
	// inline asm
	cvta.to.global.u64 %rd338, %rd339;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r351,%r352,%r353,%r354}, [%rd338];
	// inline asm
	add.s64 	%rd342, %rd333, 32;
	// inline asm
	cvta.to.global.u64 %rd341, %rd342;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd341];
	// inline asm
	add.s64 	%rd345, %rd333, 48;
	// inline asm
	cvta.to.global.u64 %rd344, %rd345;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd344];
	// inline asm
	add.s64 	%rd348, %rd333, 64;
	// inline asm
	cvta.to.global.u64 %rd347, %rd348;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd347];
	// inline asm
	add.s64 	%rd351, %rd333, 80;
	// inline asm
	cvta.to.global.u64 %rd350, %rd351;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd350];
	// inline asm
	add.s64 	%rd354, %rd333, 96;
	// inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd353];
	// inline asm
	add.s64 	%rd357, %rd333, 112;
	// inline asm
	cvta.to.global.u64 %rd356, %rd357;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd356];
	// inline asm
	add.s64 	%rd360, %rd333, 128;
	// inline asm
	cvta.to.global.u64 %rd359, %rd360;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd359];
	// inline asm
	add.s64 	%rd363, %rd333, 144;
	// inline asm
	cvta.to.global.u64 %rd362, %rd363;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd362];
	// inline asm
	mov.b32 	 %f1208, %r350;
	mov.b32 	 %f1209, %r351;
	cvt.u32.u16	%r403, %rs10;
	add.s32 	%r404, %r403, -1;
	cvt.rn.f32.s32	%f1210, %r404;
	sub.f32 	%f1211, %f924, %f1208;
	mul.f32 	%f1212, %f1211, %f1210;
	sub.f32 	%f1213, %f1209, %f1208;
	div.rn.f32 	%f1214, %f1212, %f1213;
	min.f32 	%f1215, %f1210, %f1214;
	mov.f32 	%f1216, 0f00000000;
	max.f32 	%f1217, %f1216, %f1215;
	cvt.rmi.f32.f32	%f1218, %f1217;
	cvt.rzi.s32.f32	%r405, %f1218;
	cvt.s64.s32	%rd32, %r405;
	mul.wide.s32 	%rd377, %r405, 64;
	add.s64 	%rd366, %rd342, %rd377;
	// inline asm
	cvta.to.global.u64 %rd365, %rd366;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd365];
	// inline asm
	mov.b32 	 %f1807, %r387;
	mov.b32 	 %f1808, %r388;
	mov.b32 	 %f1809, %r389;
	mov.b32 	 %f1810, %r390;
	add.s64 	%rd369, %rd366, 16;
	// inline asm
	cvta.to.global.u64 %rd368, %rd369;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd368];
	// inline asm
	mov.b32 	 %f1811, %r391;
	mov.b32 	 %f1812, %r392;
	mov.b32 	 %f1813, %r393;
	mov.b32 	 %f1814, %r394;
	add.s64 	%rd372, %rd366, 32;
	// inline asm
	cvta.to.global.u64 %rd371, %rd372;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd371];
	// inline asm
	sub.f32 	%f362, %f1217, %f1218;
	mov.b32 	 %f1815, %r395;
	mov.b32 	 %f1816, %r396;
	mov.b32 	 %f1817, %r397;
	mov.b32 	 %f1818, %r398;
	add.s64 	%rd375, %rd366, 48;
	// inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd374];
	// inline asm
	mov.b32 	 %f1819, %r399;
	mov.b32 	 %f1820, %r400;
	mov.b32 	 %f1821, %r401;
	mov.b32 	 %f1822, %r402;
	setp.leu.f32	%p31, %f362, 0f00000000;
	@%p31 bra 	BB6_62;

	shl.b64 	%rd390, %rd32, 6;
	add.s64 	%rd391, %rd390, %rd333;
	add.s64 	%rd379, %rd391, 96;
	// inline asm
	cvta.to.global.u64 %rd378, %rd379;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r406,%r407,%r408,%r409}, [%rd378];
	// inline asm
	mov.b32 	 %f1219, %r406;
	mov.b32 	 %f1220, %r407;
	mov.b32 	 %f1221, %r408;
	mov.b32 	 %f1222, %r409;
	add.s64 	%rd382, %rd391, 112;
	// inline asm
	cvta.to.global.u64 %rd381, %rd382;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r410,%r411,%r412,%r413}, [%rd381];
	// inline asm
	mov.b32 	 %f1223, %r410;
	mov.b32 	 %f1224, %r411;
	mov.b32 	 %f1225, %r412;
	mov.b32 	 %f1226, %r413;
	add.s64 	%rd385, %rd391, 128;
	// inline asm
	cvta.to.global.u64 %rd384, %rd385;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r414,%r415,%r416,%r417}, [%rd384];
	// inline asm
	mov.b32 	 %f1227, %r414;
	mov.b32 	 %f1228, %r415;
	mov.b32 	 %f1229, %r416;
	mov.b32 	 %f1230, %r417;
	add.s64 	%rd388, %rd391, 144;
	// inline asm
	cvta.to.global.u64 %rd387, %rd388;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r418,%r419,%r420,%r421}, [%rd387];
	// inline asm
	mov.f32 	%f1231, 0f3F800000;
	sub.f32 	%f1232, %f1231, %f362;
	mul.f32 	%f1233, %f362, %f1219;
	mul.f32 	%f1234, %f362, %f1220;
	mul.f32 	%f1235, %f362, %f1221;
	mul.f32 	%f1236, %f362, %f1222;
	fma.rn.f32 	%f1807, %f1232, %f1807, %f1233;
	fma.rn.f32 	%f1808, %f1232, %f1808, %f1234;
	fma.rn.f32 	%f1809, %f1232, %f1809, %f1235;
	fma.rn.f32 	%f1810, %f1232, %f1810, %f1236;
	mul.f32 	%f1237, %f362, %f1223;
	mul.f32 	%f1238, %f362, %f1224;
	mul.f32 	%f1239, %f362, %f1225;
	mul.f32 	%f1240, %f362, %f1226;
	fma.rn.f32 	%f1811, %f1232, %f1811, %f1237;
	fma.rn.f32 	%f1812, %f1232, %f1812, %f1238;
	fma.rn.f32 	%f1813, %f1232, %f1813, %f1239;
	fma.rn.f32 	%f1814, %f1232, %f1814, %f1240;
	mul.f32 	%f1241, %f362, %f1227;
	mul.f32 	%f1242, %f362, %f1228;
	mul.f32 	%f1243, %f362, %f1229;
	mul.f32 	%f1244, %f362, %f1230;
	fma.rn.f32 	%f1815, %f1232, %f1815, %f1241;
	fma.rn.f32 	%f1245, %f1232, %f1816, %f1242;
	fma.rn.f32 	%f1246, %f1232, %f1817, %f1243;
	fma.rn.f32 	%f1247, %f1232, %f1818, %f1244;
	mov.b32 	 %f1248, %r418;
	mov.b32 	 %f1249, %r419;
	mov.b32 	 %f1250, %r420;
	mov.b32 	 %f1251, %r421;
	mul.f32 	%f1252, %f362, %f1248;
	mul.f32 	%f1253, %f362, %f1249;
	mul.f32 	%f1254, %f362, %f1250;
	mul.f32 	%f1255, %f362, %f1251;
	fma.rn.f32 	%f1256, %f1232, %f1819, %f1252;
	fma.rn.f32 	%f1820, %f1232, %f1820, %f1253;
	fma.rn.f32 	%f1821, %f1232, %f1821, %f1254;
	fma.rn.f32 	%f1822, %f1232, %f1822, %f1255;
	mul.f32 	%f1257, %f1246, %f1246;
	fma.rn.f32 	%f1258, %f1245, %f1245, %f1257;
	fma.rn.f32 	%f1259, %f1247, %f1247, %f1258;
	fma.rn.f32 	%f1260, %f1256, %f1256, %f1259;
	sqrt.rn.f32 	%f1261, %f1260;
	rcp.rn.f32 	%f1262, %f1261;
	mul.f32 	%f1816, %f1245, %f1262;
	mul.f32 	%f1817, %f1246, %f1262;
	mul.f32 	%f1818, %f1247, %f1262;
	mul.f32 	%f1819, %f1256, %f1262;

BB6_62:
	mul.f32 	%f1263, %f1817, %f1817;
	fma.rn.f32 	%f1264, %f1816, %f1816, %f1263;
	fma.rn.f32 	%f1265, %f1818, %f1818, %f1264;
	fma.rn.f32 	%f1266, %f1819, %f1819, %f1265;
	rcp.rn.f32 	%f1267, %f1266;
	mul.f32 	%f1268, %f1816, %f1267;
	mul.f32 	%f1269, %f1817, %f1267;
	mul.f32 	%f1270, %f1818, %f1267;
	mul.f32 	%f1271, %f1819, %f1267;
	mul.f32 	%f1272, %f1816, %f1268;
	mul.f32 	%f1273, %f1817, %f1269;
	mul.f32 	%f1274, %f1818, %f1270;
	mul.f32 	%f1275, %f1816, %f1269;
	mul.f32 	%f1276, %f1818, %f1271;
	mul.f32 	%f1277, %f1816, %f1270;
	mul.f32 	%f1278, %f1817, %f1271;
	mul.f32 	%f1279, %f1817, %f1270;
	mul.f32 	%f1280, %f1816, %f1271;
	sub.f32 	%f1281, %f1272, %f1273;
	sub.f32 	%f1282, %f1281, %f1274;
	fma.rn.f32 	%f1283, %f1819, %f1271, %f1282;
	sub.f32 	%f1284, %f1275, %f1276;
	add.f32 	%f1285, %f1284, %f1284;
	add.f32 	%f1286, %f1277, %f1278;
	add.f32 	%f1287, %f1286, %f1286;
	add.f32 	%f1288, %f1275, %f1276;
	add.f32 	%f1289, %f1288, %f1288;
	sub.f32 	%f1290, %f1273, %f1272;
	sub.f32 	%f1291, %f1290, %f1274;
	fma.rn.f32 	%f1292, %f1819, %f1271, %f1291;
	sub.f32 	%f1293, %f1279, %f1280;
	add.f32 	%f1294, %f1293, %f1293;
	sub.f32 	%f1295, %f1277, %f1278;
	add.f32 	%f1296, %f1295, %f1295;
	add.f32 	%f1297, %f1279, %f1280;
	add.f32 	%f1298, %f1297, %f1297;
	neg.f32 	%f1299, %f1272;
	sub.f32 	%f1300, %f1299, %f1273;
	add.f32 	%f1301, %f1274, %f1300;
	fma.rn.f32 	%f1302, %f1819, %f1271, %f1301;
	mul.f32 	%f1303, %f1810, %f1283;
	fma.rn.f32 	%f1304, %f1813, %f1285, %f1303;
	fma.rn.f32 	%f1305, %f1815, %f1287, %f1304;
	sub.f32 	%f1834, %f1820, %f1305;
	mul.f32 	%f1306, %f1813, %f1292;
	fma.rn.f32 	%f1307, %f1810, %f1289, %f1306;
	fma.rn.f32 	%f1308, %f1815, %f1294, %f1307;
	sub.f32 	%f1830, %f1821, %f1308;
	mul.f32 	%f1309, %f1813, %f1298;
	fma.rn.f32 	%f1310, %f1810, %f1296, %f1309;
	fma.rn.f32 	%f1311, %f1815, %f1302, %f1310;
	sub.f32 	%f1826, %f1822, %f1311;
	mul.f32 	%f1312, %f1809, %f1283;
	fma.rn.f32 	%f1313, %f1812, %f1285, %f1312;
	fma.rn.f32 	%f1833, %f1814, %f1287, %f1313;
	mul.f32 	%f1314, %f1812, %f1292;
	fma.rn.f32 	%f1315, %f1809, %f1289, %f1314;
	fma.rn.f32 	%f1829, %f1814, %f1294, %f1315;
	mul.f32 	%f1316, %f1812, %f1298;
	fma.rn.f32 	%f1317, %f1809, %f1296, %f1316;
	fma.rn.f32 	%f1825, %f1814, %f1302, %f1317;
	mul.f32 	%f1318, %f1808, %f1283;
	fma.rn.f32 	%f1832, %f1811, %f1285, %f1318;
	mul.f32 	%f1319, %f1811, %f1292;
	fma.rn.f32 	%f1828, %f1808, %f1289, %f1319;
	mul.f32 	%f1320, %f1811, %f1298;
	fma.rn.f32 	%f1824, %f1808, %f1296, %f1320;
	mul.f32 	%f1831, %f1807, %f1283;
	mul.f32 	%f1827, %f1807, %f1289;
	mul.f32 	%f1823, %f1807, %f1296;
	bra.uni 	BB6_65;

BB6_55:
	setp.ne.s32	%p29, %r333, 1;
	mov.f32 	%f1824, %f1823;
	mov.f32 	%f1826, %f1823;
	mov.f32 	%f1827, %f1823;
	mov.f32 	%f1828, %f1825;
	mov.f32 	%f1829, %f1823;
	mov.f32 	%f1830, %f1823;
	mov.f32 	%f1831, %f1825;
	mov.f32 	%f1832, %f1823;
	mov.f32 	%f1833, %f1823;
	mov.f32 	%f1834, %f1823;
	@%p29 bra 	BB6_65;

	// inline asm
	call (%rd320), _optix_get_static_transform_from_handle, (%rd318);
	// inline asm
	add.s64 	%rd668, %rd320, 16;

BB6_58:
	// inline asm
	cvta.to.global.u64 %rd324, %rd668;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r335,%r336,%r337,%r338}, [%rd324];
	// inline asm
	mov.b32 	 %f1831, %r335;
	mov.b32 	 %f1832, %r336;
	mov.b32 	 %f1833, %r337;
	mov.b32 	 %f1834, %r338;
	add.s64 	%rd328, %rd668, 16;
	// inline asm
	cvta.to.global.u64 %rd327, %rd328;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r339,%r340,%r341,%r342}, [%rd327];
	// inline asm
	mov.b32 	 %f1827, %r339;
	mov.b32 	 %f1828, %r340;
	mov.b32 	 %f1829, %r341;
	mov.b32 	 %f1830, %r342;
	add.s64 	%rd331, %rd668, 32;
	// inline asm
	cvta.to.global.u64 %rd330, %rd331;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r343,%r344,%r345,%r346}, [%rd330];
	// inline asm
	mov.b32 	 %f1823, %r343;
	mov.b32 	 %f1824, %r344;
	mov.b32 	 %f1825, %r345;
	mov.b32 	 %f1826, %r346;

BB6_65:
	add.s32 	%r16, %r636, 1;
	setp.eq.s32	%p33, %r16, %r28;
	@%p33 bra 	BB6_66;
	bra.uni 	BB6_67;

BB6_66:
	mov.f32 	%f1806, %f1823;
	mov.f32 	%f1805, %f1824;
	mov.f32 	%f1804, %f1825;
	mov.f32 	%f1803, %f1826;
	mov.f32 	%f1802, %f1827;
	mov.f32 	%f1801, %f1828;
	mov.f32 	%f1800, %f1829;
	mov.f32 	%f1799, %f1830;
	mov.f32 	%f1798, %f1831;
	mov.f32 	%f1797, %f1832;
	mov.f32 	%f1796, %f1833;
	mov.f32 	%f1795, %f1834;
	bra.uni 	BB6_68;

BB6_67:
	mul.f32 	%f1358, %f1802, %f1832;
	fma.rn.f32 	%f1359, %f1798, %f1831, %f1358;
	fma.rn.f32 	%f452, %f1806, %f1833, %f1359;
	mul.f32 	%f1360, %f1801, %f1832;
	fma.rn.f32 	%f1361, %f1797, %f1831, %f1360;
	fma.rn.f32 	%f453, %f1805, %f1833, %f1361;
	mul.f32 	%f1362, %f1800, %f1832;
	fma.rn.f32 	%f1363, %f1796, %f1831, %f1362;
	fma.rn.f32 	%f454, %f1804, %f1833, %f1363;
	mul.f32 	%f1364, %f1799, %f1832;
	fma.rn.f32 	%f1365, %f1795, %f1831, %f1364;
	fma.rn.f32 	%f1366, %f1803, %f1833, %f1365;
	add.f32 	%f455, %f1834, %f1366;
	mul.f32 	%f1367, %f1802, %f1828;
	fma.rn.f32 	%f1368, %f1798, %f1827, %f1367;
	fma.rn.f32 	%f456, %f1806, %f1829, %f1368;
	mul.f32 	%f1369, %f1801, %f1828;
	fma.rn.f32 	%f1370, %f1797, %f1827, %f1369;
	fma.rn.f32 	%f457, %f1805, %f1829, %f1370;
	mul.f32 	%f1371, %f1800, %f1828;
	fma.rn.f32 	%f1372, %f1796, %f1827, %f1371;
	fma.rn.f32 	%f458, %f1804, %f1829, %f1372;
	mul.f32 	%f1373, %f1799, %f1828;
	fma.rn.f32 	%f1374, %f1795, %f1827, %f1373;
	fma.rn.f32 	%f1375, %f1803, %f1829, %f1374;
	add.f32 	%f459, %f1830, %f1375;
	mul.f32 	%f1376, %f1802, %f1824;
	fma.rn.f32 	%f1377, %f1798, %f1823, %f1376;
	fma.rn.f32 	%f1806, %f1806, %f1825, %f1377;
	mul.f32 	%f1378, %f1801, %f1824;
	fma.rn.f32 	%f1379, %f1797, %f1823, %f1378;
	fma.rn.f32 	%f1805, %f1805, %f1825, %f1379;
	mul.f32 	%f1380, %f1800, %f1824;
	fma.rn.f32 	%f1381, %f1796, %f1823, %f1380;
	fma.rn.f32 	%f1804, %f1804, %f1825, %f1381;
	mul.f32 	%f1382, %f1799, %f1824;
	fma.rn.f32 	%f1383, %f1795, %f1823, %f1382;
	fma.rn.f32 	%f1384, %f1803, %f1825, %f1383;
	add.f32 	%f1803, %f1826, %f1384;
	mov.f32 	%f1802, %f456;
	mov.f32 	%f1801, %f457;
	mov.f32 	%f1800, %f458;
	mov.f32 	%f1799, %f459;
	mov.f32 	%f1798, %f452;
	mov.f32 	%f1797, %f453;
	mov.f32 	%f1796, %f454;
	mov.f32 	%f1795, %f455;

BB6_68:
	add.s32 	%r636, %r16, -2;
	setp.gt.s32	%p34, %r636, -1;
	@%p34 bra 	BB6_53;

BB6_69:
	mov.u32 	%r637, 0;
	mov.f32 	%f1859, %f1860;
	mov.f32 	%f1864, %f1860;
	mov.f32 	%f1863, %f1861;
	mov.f32 	%f1862, %f1860;
	mov.f32 	%f1867, %f1860;
	mov.f32 	%f1866, %f1860;
	mov.f32 	%f1865, %f1861;
	@%p2 bra 	BB6_87;

BB6_70:
	.pragma "nounroll";
	// inline asm
	call (%rd439), _optix_get_transform_list_handle, (%r637);
	// inline asm
	// inline asm
	call (%r483), _optix_get_transform_type_from_handle, (%rd439);
	// inline asm
	and.b32  	%r484, %r483, -2;
	setp.eq.s32	%p36, %r484, 2;
	@%p36 bra 	BB6_76;
	bra.uni 	BB6_71;

BB6_76:
	setp.eq.s32	%p39, %r483, 2;
	@%p39 bra 	BB6_80;
	bra.uni 	BB6_77;

BB6_80:
	// inline asm
	call (%rd513), _optix_get_matrix_motion_transform_from_handle, (%rd439);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd515, %rd513;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd515];
	// inline asm
	mov.b32	{%rs16, %rs17}, %r574;
	add.s64 	%rd519, %rd513, 16;
	// inline asm
	cvta.to.global.u64 %rd518, %rd519;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd518];
	// inline asm
	add.s64 	%rd522, %rd513, 32;
	// inline asm
	cvta.to.global.u64 %rd521, %rd522;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd521];
	// inline asm
	add.s64 	%rd525, %rd513, 48;
	// inline asm
	cvta.to.global.u64 %rd524, %rd525;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd524];
	// inline asm
	add.s64 	%rd528, %rd513, 64;
	// inline asm
	cvta.to.global.u64 %rd527, %rd528;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd527];
	// inline asm
	add.s64 	%rd531, %rd513, 80;
	// inline asm
	cvta.to.global.u64 %rd530, %rd531;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd530];
	// inline asm
	add.s64 	%rd534, %rd513, 96;
	// inline asm
	cvta.to.global.u64 %rd533, %rd534;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd533];
	// inline asm
	add.s64 	%rd537, %rd513, 112;
	// inline asm
	cvta.to.global.u64 %rd536, %rd537;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd536];
	// inline asm
	mov.b32 	 %f1496, %r575;
	mov.b32 	 %f1497, %r576;
	cvt.u32.u16	%r616, %rs16;
	add.s32 	%r617, %r616, -1;
	cvt.rn.f32.s32	%f1498, %r617;
	sub.f32 	%f1499, %f924, %f1496;
	mul.f32 	%f1500, %f1499, %f1498;
	sub.f32 	%f1501, %f1497, %f1496;
	div.rn.f32 	%f1502, %f1500, %f1501;
	min.f32 	%f1503, %f1498, %f1502;
	mov.f32 	%f1504, 0f00000000;
	max.f32 	%f1505, %f1504, %f1503;
	cvt.rmi.f32.f32	%f1506, %f1505;
	cvt.rzi.s32.f32	%r618, %f1506;
	cvt.s64.s32	%rd42, %r618;
	mul.wide.s32 	%rd548, %r618, 48;
	add.s64 	%rd540, %rd522, %rd548;
	// inline asm
	cvta.to.global.u64 %rd539, %rd540;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd539];
	// inline asm
	mov.b32 	 %f1884, %r604;
	mov.b32 	 %f1885, %r605;
	mov.b32 	 %f1886, %r606;
	add.s64 	%rd543, %rd540, 16;
	// inline asm
	cvta.to.global.u64 %rd542, %rd543;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd542];
	// inline asm
	mov.b32 	 %f1881, %r608;
	mov.b32 	 %f1882, %r609;
	mov.b32 	 %f1883, %r610;
	add.s64 	%rd546, %rd540, 32;
	// inline asm
	cvta.to.global.u64 %rd545, %rd546;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd545];
	// inline asm
	sub.f32 	%f552, %f1505, %f1506;
	mov.b32 	 %f1878, %r612;
	mov.b32 	 %f1879, %r613;
	mov.b32 	 %f1880, %r614;
	setp.leu.f32	%p41, %f552, 0f00000000;
	@%p41 bra 	BB6_82;

	mul.lo.s64 	%rd558, %rd42, 48;
	add.s64 	%rd559, %rd513, %rd558;
	add.s64 	%rd550, %rd559, 80;
	// inline asm
	cvta.to.global.u64 %rd549, %rd550;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r619,%r620,%r621,%r622}, [%rd549];
	// inline asm
	mov.b32 	 %f1507, %r619;
	mov.b32 	 %f1508, %r620;
	mov.b32 	 %f1509, %r621;
	add.s64 	%rd553, %rd559, 96;
	// inline asm
	cvta.to.global.u64 %rd552, %rd553;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r623,%r624,%r625,%r626}, [%rd552];
	// inline asm
	mov.b32 	 %f1510, %r623;
	mov.b32 	 %f1511, %r624;
	mov.b32 	 %f1512, %r625;
	add.s64 	%rd556, %rd559, 112;
	// inline asm
	cvta.to.global.u64 %rd555, %rd556;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r627,%r628,%r629,%r630}, [%rd555];
	// inline asm
	mov.f32 	%f1513, 0f3F800000;
	sub.f32 	%f1514, %f1513, %f552;
	mul.f32 	%f1515, %f552, %f1507;
	mul.f32 	%f1516, %f552, %f1508;
	mul.f32 	%f1517, %f552, %f1509;
	fma.rn.f32 	%f1884, %f1514, %f1884, %f1515;
	fma.rn.f32 	%f1885, %f1514, %f1885, %f1516;
	fma.rn.f32 	%f1886, %f1514, %f1886, %f1517;
	mul.f32 	%f1518, %f552, %f1510;
	mul.f32 	%f1519, %f552, %f1511;
	mul.f32 	%f1520, %f552, %f1512;
	fma.rn.f32 	%f1881, %f1514, %f1881, %f1518;
	fma.rn.f32 	%f1882, %f1514, %f1882, %f1519;
	fma.rn.f32 	%f1883, %f1514, %f1883, %f1520;
	mov.b32 	 %f1521, %r627;
	mov.b32 	 %f1522, %r628;
	mov.b32 	 %f1523, %r629;
	mul.f32 	%f1524, %f552, %f1521;
	mul.f32 	%f1525, %f552, %f1522;
	mul.f32 	%f1526, %f552, %f1523;
	fma.rn.f32 	%f1878, %f1514, %f1878, %f1524;
	fma.rn.f32 	%f1879, %f1514, %f1879, %f1525;
	fma.rn.f32 	%f1880, %f1514, %f1880, %f1526;
	bra.uni 	BB6_82;

BB6_71:
	mov.f32 	%f1887, 0f00000000;
	mov.f32 	%f1889, 0f3F800000;
	setp.eq.s32	%p37, %r483, 4;
	@%p37 bra 	BB6_74;
	bra.uni 	BB6_72;

BB6_74:
	// inline asm
	call (%rd669), _optix_get_instance_inverse_transform_from_handle, (%rd439);
	// inline asm
	bra.uni 	BB6_75;

BB6_77:
	// inline asm
	call (%rd454), _optix_get_srt_motion_transform_from_handle, (%rd439);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd456, %rd454;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd456];
	// inline asm
	mov.b32	{%rs14, %rs15}, %r499;
	add.s64 	%rd460, %rd454, 16;
	// inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd459];
	// inline asm
	add.s64 	%rd463, %rd454, 32;
	// inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd462];
	// inline asm
	add.s64 	%rd466, %rd454, 48;
	// inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd465];
	// inline asm
	add.s64 	%rd469, %rd454, 64;
	// inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd468];
	// inline asm
	add.s64 	%rd472, %rd454, 80;
	// inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd471];
	// inline asm
	add.s64 	%rd475, %rd454, 96;
	// inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd474];
	// inline asm
	add.s64 	%rd478, %rd454, 112;
	// inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd477];
	// inline asm
	add.s64 	%rd481, %rd454, 128;
	// inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd480];
	// inline asm
	add.s64 	%rd484, %rd454, 144;
	// inline asm
	cvta.to.global.u64 %rd483, %rd484;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd483];
	// inline asm
	mov.b32 	 %f1404, %r500;
	mov.b32 	 %f1405, %r501;
	cvt.u32.u16	%r553, %rs14;
	add.s32 	%r554, %r553, -1;
	cvt.rn.f32.s32	%f1406, %r554;
	sub.f32 	%f1407, %f924, %f1404;
	mul.f32 	%f1408, %f1407, %f1406;
	sub.f32 	%f1409, %f1405, %f1404;
	div.rn.f32 	%f1410, %f1408, %f1409;
	min.f32 	%f1411, %f1406, %f1410;
	mov.f32 	%f1412, 0f00000000;
	max.f32 	%f1413, %f1412, %f1411;
	cvt.rmi.f32.f32	%f1414, %f1413;
	cvt.rzi.s32.f32	%r555, %f1414;
	cvt.s64.s32	%rd40, %r555;
	mul.wide.s32 	%rd498, %r555, 64;
	add.s64 	%rd487, %rd463, %rd498;
	// inline asm
	cvta.to.global.u64 %rd486, %rd487;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd486];
	// inline asm
	mov.b32 	 %f1868, %r537;
	mov.b32 	 %f1869, %r538;
	mov.b32 	 %f1870, %r539;
	add.s64 	%rd490, %rd487, 16;
	// inline asm
	cvta.to.global.u64 %rd489, %rd490;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd489];
	// inline asm
	mov.b32 	 %f1871, %r541;
	mov.b32 	 %f1872, %r542;
	mov.b32 	 %f1873, %r544;
	add.s64 	%rd493, %rd487, 32;
	// inline asm
	cvta.to.global.u64 %rd492, %rd493;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd492];
	// inline asm
	sub.f32 	%f512, %f1413, %f1414;
	mov.b32 	 %f1874, %r546;
	mov.b32 	 %f1875, %r547;
	mov.b32 	 %f1876, %r548;
	add.s64 	%rd496, %rd487, 48;
	// inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd495];
	// inline asm
	mov.b32 	 %f1877, %r549;
	setp.leu.f32	%p40, %f512, 0f00000000;
	@%p40 bra 	BB6_79;

	shl.b64 	%rd511, %rd40, 6;
	add.s64 	%rd512, %rd511, %rd454;
	add.s64 	%rd500, %rd512, 96;
	// inline asm
	cvta.to.global.u64 %rd499, %rd500;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r556,%r557,%r558,%r559}, [%rd499];
	// inline asm
	mov.b32 	 %f1415, %r556;
	mov.b32 	 %f1416, %r557;
	mov.b32 	 %f1417, %r558;
	add.s64 	%rd503, %rd512, 112;
	// inline asm
	cvta.to.global.u64 %rd502, %rd503;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r560,%r561,%r562,%r563}, [%rd502];
	// inline asm
	mov.b32 	 %f1418, %r560;
	mov.b32 	 %f1419, %r561;
	mov.b32 	 %f1420, %r563;
	add.s64 	%rd506, %rd512, 128;
	// inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r564,%r565,%r566,%r567}, [%rd505];
	// inline asm
	mov.b32 	 %f1421, %r565;
	mov.b32 	 %f1422, %r566;
	mov.b32 	 %f1423, %r567;
	add.s64 	%rd509, %rd512, 144;
	// inline asm
	cvta.to.global.u64 %rd508, %rd509;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd508];
	// inline asm
	mov.f32 	%f1424, 0f3F800000;
	sub.f32 	%f1425, %f1424, %f512;
	mul.f32 	%f1426, %f512, %f1415;
	mul.f32 	%f1427, %f512, %f1416;
	mul.f32 	%f1428, %f512, %f1417;
	fma.rn.f32 	%f1868, %f1425, %f1868, %f1426;
	fma.rn.f32 	%f1869, %f1425, %f1869, %f1427;
	fma.rn.f32 	%f1870, %f1425, %f1870, %f1428;
	mul.f32 	%f1429, %f512, %f1418;
	mul.f32 	%f1430, %f512, %f1419;
	mul.f32 	%f1431, %f512, %f1420;
	fma.rn.f32 	%f1871, %f1425, %f1871, %f1429;
	fma.rn.f32 	%f1872, %f1425, %f1872, %f1430;
	fma.rn.f32 	%f1873, %f1425, %f1873, %f1431;
	mul.f32 	%f1432, %f512, %f1421;
	mul.f32 	%f1433, %f512, %f1422;
	mul.f32 	%f1434, %f512, %f1423;
	fma.rn.f32 	%f1435, %f1425, %f1874, %f1432;
	fma.rn.f32 	%f1436, %f1425, %f1875, %f1433;
	fma.rn.f32 	%f1437, %f1425, %f1876, %f1434;
	mov.b32 	 %f1438, %r568;
	mul.f32 	%f1439, %f512, %f1438;
	fma.rn.f32 	%f1440, %f1425, %f1877, %f1439;
	mul.f32 	%f1441, %f1436, %f1436;
	fma.rn.f32 	%f1442, %f1435, %f1435, %f1441;
	fma.rn.f32 	%f1443, %f1437, %f1437, %f1442;
	fma.rn.f32 	%f1444, %f1440, %f1440, %f1443;
	sqrt.rn.f32 	%f1445, %f1444;
	rcp.rn.f32 	%f1446, %f1445;
	mul.f32 	%f1874, %f1435, %f1446;
	mul.f32 	%f1875, %f1436, %f1446;
	mul.f32 	%f1876, %f1437, %f1446;
	mul.f32 	%f1877, %f1440, %f1446;

BB6_79:
	mul.f32 	%f1447, %f1875, %f1875;
	fma.rn.f32 	%f1448, %f1874, %f1874, %f1447;
	fma.rn.f32 	%f1449, %f1876, %f1876, %f1448;
	fma.rn.f32 	%f1450, %f1877, %f1877, %f1449;
	rcp.rn.f32 	%f1451, %f1450;
	mul.f32 	%f1452, %f1874, %f1451;
	mul.f32 	%f1453, %f1875, %f1451;
	mul.f32 	%f1454, %f1876, %f1451;
	mul.f32 	%f1455, %f1877, %f1451;
	mul.f32 	%f1456, %f1874, %f1452;
	mul.f32 	%f1457, %f1875, %f1453;
	mul.f32 	%f1458, %f1876, %f1454;
	mul.f32 	%f1459, %f1874, %f1453;
	mul.f32 	%f1460, %f1876, %f1455;
	mul.f32 	%f1461, %f1874, %f1454;
	mul.f32 	%f1462, %f1875, %f1455;
	mul.f32 	%f1463, %f1875, %f1454;
	mul.f32 	%f1464, %f1874, %f1455;
	sub.f32 	%f1465, %f1456, %f1457;
	sub.f32 	%f1466, %f1465, %f1458;
	fma.rn.f32 	%f1467, %f1877, %f1455, %f1466;
	sub.f32 	%f1468, %f1459, %f1460;
	add.f32 	%f1469, %f1468, %f1468;
	add.f32 	%f1470, %f1461, %f1462;
	add.f32 	%f1471, %f1470, %f1470;
	add.f32 	%f1472, %f1459, %f1460;
	add.f32 	%f1473, %f1472, %f1472;
	sub.f32 	%f1474, %f1457, %f1456;
	sub.f32 	%f1475, %f1474, %f1458;
	fma.rn.f32 	%f1476, %f1877, %f1455, %f1475;
	sub.f32 	%f1477, %f1463, %f1464;
	add.f32 	%f1478, %f1477, %f1477;
	sub.f32 	%f1479, %f1461, %f1462;
	add.f32 	%f1480, %f1479, %f1479;
	add.f32 	%f1481, %f1463, %f1464;
	add.f32 	%f1482, %f1481, %f1481;
	neg.f32 	%f1483, %f1456;
	sub.f32 	%f1484, %f1483, %f1457;
	add.f32 	%f1485, %f1458, %f1484;
	fma.rn.f32 	%f1486, %f1877, %f1455, %f1485;
	mul.f32 	%f1487, %f1870, %f1467;
	fma.rn.f32 	%f1488, %f1872, %f1469, %f1487;
	fma.rn.f32 	%f1886, %f1873, %f1471, %f1488;
	mul.f32 	%f1489, %f1872, %f1476;
	fma.rn.f32 	%f1490, %f1870, %f1473, %f1489;
	fma.rn.f32 	%f1883, %f1873, %f1478, %f1490;
	mul.f32 	%f1491, %f1872, %f1482;
	fma.rn.f32 	%f1492, %f1870, %f1480, %f1491;
	fma.rn.f32 	%f1880, %f1873, %f1486, %f1492;
	mul.f32 	%f1493, %f1869, %f1467;
	fma.rn.f32 	%f1885, %f1871, %f1469, %f1493;
	mul.f32 	%f1494, %f1871, %f1476;
	fma.rn.f32 	%f1882, %f1869, %f1473, %f1494;
	mul.f32 	%f1495, %f1871, %f1482;
	fma.rn.f32 	%f1879, %f1869, %f1480, %f1495;
	mul.f32 	%f1884, %f1868, %f1467;
	mul.f32 	%f1881, %f1868, %f1473;
	mul.f32 	%f1878, %f1868, %f1480;

BB6_82:
	mul.f32 	%f1527, %f1879, %f1883;
	mul.f32 	%f1528, %f1880, %f1882;
	sub.f32 	%f1529, %f1528, %f1527;
	mul.f32 	%f1530, %f1884, %f1529;
	mul.f32 	%f1531, %f1878, %f1883;
	mul.f32 	%f1532, %f1880, %f1881;
	sub.f32 	%f1533, %f1532, %f1531;
	mul.f32 	%f1534, %f1533, %f1885;
	sub.f32 	%f1535, %f1530, %f1534;
	mul.f32 	%f1536, %f1878, %f1882;
	mul.f32 	%f1537, %f1879, %f1881;
	sub.f32 	%f1538, %f1537, %f1536;
	fma.rn.f32 	%f1539, %f1538, %f1886, %f1535;
	rcp.rn.f32 	%f1540, %f1539;
	mul.f32 	%f1893, %f1529, %f1540;
	mul.f32 	%f1541, %f1880, %f1885;
	mul.f32 	%f1542, %f1879, %f1886;
	sub.f32 	%f1543, %f1542, %f1541;
	mul.f32 	%f1894, %f1540, %f1543;
	mul.f32 	%f1544, %f1882, %f1886;
	mul.f32 	%f1545, %f1883, %f1885;
	sub.f32 	%f1546, %f1545, %f1544;
	mul.f32 	%f1895, %f1540, %f1546;
	sub.f32 	%f1547, %f1531, %f1532;
	mul.f32 	%f1890, %f1547, %f1540;
	mul.f32 	%f1548, %f1878, %f1886;
	mul.f32 	%f1549, %f1880, %f1884;
	sub.f32 	%f1550, %f1549, %f1548;
	mul.f32 	%f1891, %f1540, %f1550;
	mul.f32 	%f1551, %f1883, %f1884;
	mul.f32 	%f1552, %f1881, %f1886;
	sub.f32 	%f1553, %f1552, %f1551;
	mul.f32 	%f1892, %f1540, %f1553;
	mul.f32 	%f1887, %f1538, %f1540;
	mul.f32 	%f1554, %f1879, %f1884;
	mul.f32 	%f1555, %f1878, %f1885;
	sub.f32 	%f1556, %f1555, %f1554;
	mul.f32 	%f1888, %f1556, %f1540;
	mul.f32 	%f1557, %f1881, %f1885;
	mul.f32 	%f1558, %f1882, %f1884;
	sub.f32 	%f1559, %f1558, %f1557;
	mul.f32 	%f1889, %f1559, %f1540;
	bra.uni 	BB6_83;

BB6_72:
	setp.ne.s32	%p38, %r483, 1;
	mov.f32 	%f1888, %f1887;
	mov.f32 	%f1890, %f1887;
	mov.f32 	%f1891, %f1889;
	mov.f32 	%f1892, %f1887;
	mov.f32 	%f1893, %f1889;
	mov.f32 	%f1894, %f1887;
	mov.f32 	%f1895, %f1887;
	@%p38 bra 	BB6_83;

	// inline asm
	call (%rd441), _optix_get_static_transform_from_handle, (%rd439);
	// inline asm
	add.s64 	%rd669, %rd441, 64;

BB6_75:
	// inline asm
	cvta.to.global.u64 %rd445, %rd669;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r485,%r486,%r487,%r488}, [%rd445];
	// inline asm
	mov.b32 	 %f1893, %r485;
	mov.b32 	 %f1894, %r486;
	mov.b32 	 %f1895, %r487;
	add.s64 	%rd449, %rd669, 16;
	// inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd448];
	// inline asm
	mov.b32 	 %f1890, %r489;
	mov.b32 	 %f1891, %r490;
	mov.b32 	 %f1892, %r491;
	add.s64 	%rd452, %rd669, 32;
	// inline asm
	cvta.to.global.u64 %rd451, %rd452;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r493,%r494,%r495,%r496}, [%rd451];
	// inline asm
	mov.b32 	 %f1887, %r493;
	mov.b32 	 %f1888, %r494;
	mov.b32 	 %f1889, %r495;

BB6_83:
	setp.eq.s32	%p42, %r637, 0;
	@%p42 bra 	BB6_84;
	bra.uni 	BB6_85;

BB6_84:
	mov.f32 	%f1867, %f1887;
	mov.f32 	%f1866, %f1888;
	mov.f32 	%f1865, %f1889;
	mov.f32 	%f1864, %f1890;
	mov.f32 	%f1863, %f1891;
	mov.f32 	%f1862, %f1892;
	mov.f32 	%f1861, %f1893;
	mov.f32 	%f1860, %f1894;
	mov.f32 	%f1859, %f1895;
	bra.uni 	BB6_86;

BB6_85:
	mul.f32 	%f1560, %f1864, %f1894;
	fma.rn.f32 	%f1561, %f1861, %f1893, %f1560;
	fma.rn.f32 	%f592, %f1867, %f1895, %f1561;
	mul.f32 	%f1562, %f1863, %f1894;
	fma.rn.f32 	%f1563, %f1860, %f1893, %f1562;
	fma.rn.f32 	%f593, %f1866, %f1895, %f1563;
	mul.f32 	%f1564, %f1862, %f1894;
	fma.rn.f32 	%f1565, %f1859, %f1893, %f1564;
	fma.rn.f32 	%f594, %f1865, %f1895, %f1565;
	mul.f32 	%f1566, %f1864, %f1891;
	fma.rn.f32 	%f1567, %f1861, %f1890, %f1566;
	fma.rn.f32 	%f595, %f1867, %f1892, %f1567;
	mul.f32 	%f1568, %f1863, %f1891;
	fma.rn.f32 	%f1569, %f1860, %f1890, %f1568;
	fma.rn.f32 	%f596, %f1866, %f1892, %f1569;
	mul.f32 	%f1570, %f1862, %f1891;
	fma.rn.f32 	%f1571, %f1859, %f1890, %f1570;
	fma.rn.f32 	%f597, %f1865, %f1892, %f1571;
	mul.f32 	%f1572, %f1864, %f1888;
	fma.rn.f32 	%f1573, %f1861, %f1887, %f1572;
	fma.rn.f32 	%f1867, %f1867, %f1889, %f1573;
	mul.f32 	%f1574, %f1863, %f1888;
	fma.rn.f32 	%f1575, %f1860, %f1887, %f1574;
	fma.rn.f32 	%f1866, %f1866, %f1889, %f1575;
	mul.f32 	%f1576, %f1862, %f1888;
	fma.rn.f32 	%f1577, %f1859, %f1887, %f1576;
	fma.rn.f32 	%f1865, %f1865, %f1889, %f1577;
	mov.f32 	%f1864, %f595;
	mov.f32 	%f1863, %f596;
	mov.f32 	%f1862, %f597;
	mov.f32 	%f1861, %f592;
	mov.f32 	%f1860, %f593;
	mov.f32 	%f1859, %f594;

BB6_86:
	add.s32 	%r637, %r637, 1;
	setp.lt.u32	%p43, %r637, %r28;
	@%p43 bra 	BB6_70;

BB6_87:
	fma.rn.f32 	%f1578, %f1944, %f1798, %f1795;
	fma.rn.f32 	%f1579, %f1945, %f1797, %f1578;
	fma.rn.f32 	%f1580, %f1944, %f1802, %f1799;
	fma.rn.f32 	%f1581, %f1945, %f1801, %f1580;
	fma.rn.f32 	%f1582, %f1944, %f1806, %f1803;
	fma.rn.f32 	%f1583, %f1945, %f1805, %f1582;
	fma.rn.f32 	%f1944, %f1946, %f1796, %f1579;
	fma.rn.f32 	%f1945, %f1946, %f1800, %f1581;
	fma.rn.f32 	%f1946, %f1946, %f1804, %f1583;
	ld.const.u64 	%rd560, [params+112];
	setp.eq.s64	%p44, %rd560, 0;
	mov.f32 	%f1938, %f1941;
	mov.f32 	%f1939, %f1942;
	mov.f32 	%f1940, %f1943;
	@%p44 bra 	BB6_89;

	mul.f32 	%f1584, %f1941, %f1861;
	fma.rn.f32 	%f1585, %f1942, %f1864, %f1584;
	mul.f32 	%f1586, %f1941, %f1860;
	fma.rn.f32 	%f1587, %f1942, %f1863, %f1586;
	mul.f32 	%f1588, %f1941, %f1859;
	fma.rn.f32 	%f1589, %f1942, %f1862, %f1588;
	fma.rn.f32 	%f1590, %f1943, %f1867, %f1585;
	fma.rn.f32 	%f1591, %f1943, %f1866, %f1587;
	fma.rn.f32 	%f1592, %f1943, %f1865, %f1589;
	mul.f32 	%f1593, %f1590, %f1590;
	fma.rn.f32 	%f1594, %f1591, %f1591, %f1593;
	fma.rn.f32 	%f1595, %f1592, %f1592, %f1594;
	sqrt.rn.f32 	%f1596, %f1595;
	div.rn.f32 	%f1938, %f1590, %f1596;
	div.rn.f32 	%f1939, %f1591, %f1596;
	div.rn.f32 	%f1940, %f1592, %f1596;

BB6_89:
	ld.const.u64 	%rd561, [params+136];
	setp.eq.s64	%p45, %rd561, 0;
	@%p45 bra 	BB6_91;

	mul.f32 	%f1597, %f1941, %f1861;
	fma.rn.f32 	%f1598, %f1942, %f1864, %f1597;
	mul.f32 	%f1599, %f1941, %f1860;
	fma.rn.f32 	%f1600, %f1942, %f1863, %f1599;
	mul.f32 	%f1601, %f1941, %f1859;
	fma.rn.f32 	%f1602, %f1942, %f1862, %f1601;
	fma.rn.f32 	%f1603, %f1943, %f1867, %f1598;
	fma.rn.f32 	%f1604, %f1943, %f1866, %f1600;
	fma.rn.f32 	%f1605, %f1943, %f1865, %f1602;
	mul.f32 	%f1606, %f1603, %f1603;
	fma.rn.f32 	%f1607, %f1604, %f1604, %f1606;
	fma.rn.f32 	%f1608, %f1605, %f1605, %f1607;
	sqrt.rn.f32 	%f1609, %f1608;
	div.rn.f32 	%f1941, %f1603, %f1609;
	div.rn.f32 	%f1942, %f1604, %f1609;
	div.rn.f32 	%f1943, %f1605, %f1609;

BB6_91:
	ld.const.u64 	%rd562, [params+184];
	setp.eq.s64	%p46, %rd562, 0;
	@%p46 bra 	BB6_93;

	mul.f32 	%f1610, %f1935, %f1798;
	fma.rn.f32 	%f1611, %f1936, %f1797, %f1610;
	mul.f32 	%f1612, %f1935, %f1802;
	fma.rn.f32 	%f1613, %f1936, %f1801, %f1612;
	mul.f32 	%f1614, %f1935, %f1806;
	fma.rn.f32 	%f1615, %f1936, %f1805, %f1614;
	fma.rn.f32 	%f1935, %f1937, %f1796, %f1611;
	fma.rn.f32 	%f1936, %f1937, %f1800, %f1613;
	fma.rn.f32 	%f1937, %f1937, %f1804, %f1615;
	mul.f32 	%f1616, %f1932, %f1798;
	fma.rn.f32 	%f1617, %f1933, %f1797, %f1616;
	mul.f32 	%f1618, %f1932, %f1802;
	fma.rn.f32 	%f1619, %f1933, %f1801, %f1618;
	mul.f32 	%f1620, %f1932, %f1806;
	fma.rn.f32 	%f1621, %f1933, %f1805, %f1620;
	fma.rn.f32 	%f1932, %f1934, %f1796, %f1617;
	fma.rn.f32 	%f1933, %f1934, %f1800, %f1619;
	fma.rn.f32 	%f1934, %f1934, %f1804, %f1621;

BB6_93:
	ld.const.u64 	%rd563, [params+280];
	ld.const.u64 	%rd564, [params+232];
	mov.f32 	%f1929, 0f00000000;
	or.b64  	%rd565, %rd563, %rd564;
	setp.eq.s64	%p47, %rd565, 0;
	mov.f32 	%f1930, %f1929;
	mov.f32 	%f1931, %f1929;
	@%p47 bra 	BB6_95;

	mul.f32 	%f1625, %f1941, %f1798;
	fma.rn.f32 	%f1626, %f1942, %f1802, %f1625;
	mul.f32 	%f1627, %f1941, %f1797;
	fma.rn.f32 	%f1628, %f1942, %f1801, %f1627;
	mul.f32 	%f1629, %f1941, %f1796;
	fma.rn.f32 	%f1630, %f1942, %f1800, %f1629;
	fma.rn.f32 	%f1631, %f1943, %f1806, %f1626;
	fma.rn.f32 	%f1632, %f1943, %f1805, %f1628;
	fma.rn.f32 	%f1633, %f1943, %f1804, %f1630;
	mul.f32 	%f1634, %f1631, %f1631;
	fma.rn.f32 	%f1635, %f1632, %f1632, %f1634;
	fma.rn.f32 	%f1636, %f1633, %f1633, %f1635;
	sqrt.rn.f32 	%f1637, %f1636;
	div.rn.f32 	%f1638, %f1631, %f1637;
	div.rn.f32 	%f1639, %f1632, %f1637;
	div.rn.f32 	%f1640, %f1633, %f1637;
	mul.f32 	%f1641, %f1638, %f1861;
	mul.f32 	%f1642, %f1638, %f1860;
	mul.f32 	%f1643, %f1638, %f1859;
	fma.rn.f32 	%f1644, %f1639, %f1864, %f1641;
	fma.rn.f32 	%f1645, %f1639, %f1863, %f1642;
	fma.rn.f32 	%f1646, %f1639, %f1862, %f1643;
	fma.rn.f32 	%f1647, %f1640, %f1867, %f1644;
	fma.rn.f32 	%f1648, %f1640, %f1866, %f1645;
	fma.rn.f32 	%f1649, %f1640, %f1865, %f1646;
	mul.f32 	%f1650, %f1647, %f1647;
	fma.rn.f32 	%f1651, %f1648, %f1648, %f1650;
	fma.rn.f32 	%f1652, %f1649, %f1649, %f1651;
	sqrt.rn.f32 	%f1653, %f1652;
	rcp.rn.f32 	%f1654, %f1653;
	mul.f32 	%f1655, %f1654, %f1647;
	mul.f32 	%f1656, %f1654, %f1648;
	mul.f32 	%f1657, %f1654, %f1649;
	mul.f32 	%f1658, %f1861, 0f00000000;
	mov.f32 	%f1659, 0f00000000;
	fma.rn.f32 	%f1660, %f1659, %f1864, %f1658;
	mul.f32 	%f1661, %f1860, 0f00000000;
	fma.rn.f32 	%f1662, %f1659, %f1863, %f1661;
	mul.f32 	%f1663, %f1859, 0f00000000;
	fma.rn.f32 	%f1664, %f1659, %f1862, %f1663;
	fma.rn.f32 	%f1665, %f1659, %f1867, %f1660;
	fma.rn.f32 	%f1666, %f1659, %f1866, %f1662;
	fma.rn.f32 	%f1667, %f1659, %f1865, %f1664;
	mul.f32 	%f1668, %f1665, %f1654;
	mul.f32 	%f1669, %f1666, %f1654;
	mul.f32 	%f1670, %f1667, %f1654;
	mul.f32 	%f1671, %f1655, %f1668;
	fma.rn.f32 	%f1672, %f1656, %f1669, %f1671;
	fma.rn.f32 	%f1673, %f1657, %f1670, %f1672;
	mul.f32 	%f1674, %f1655, %f1673;
	mul.f32 	%f1675, %f1656, %f1673;
	mul.f32 	%f1676, %f1657, %f1673;
	sub.f32 	%f1929, %f1668, %f1674;
	sub.f32 	%f1930, %f1669, %f1675;
	sub.f32 	%f1931, %f1670, %f1676;

BB6_95:
	st.global.u32 	[%rd26], %r331;
	bra.uni 	BB6_96;

BB6_49:
	mov.f32 	%f1930, %f1929;
	mov.f32 	%f1931, %f1929;
	mov.f32 	%f1938, %f1941;
	mov.f32 	%f1939, %f1942;
	mov.f32 	%f1940, %f1943;

BB6_96:
	ld.const.u64 	%rd566, [params+328];
	cvta.to.global.u64 	%rd567, %rd566;
	shl.b64 	%rd568, %rd22, 3;
	add.s64 	%rd569, %rd567, %rd568;
	st.global.u64 	[%rd569], %rd25;
	ld.const.u64 	%rd570, [params+336];
	cvta.to.global.u64 	%rd571, %rd570;
	add.s64 	%rd573, %rd571, %rd317;
	mov.u32 	%r631, 0;
	st.global.u32 	[%rd573], %r631;
	ld.const.u64 	%rd574, [params+160];
	cvta.to.global.u64 	%rd575, %rd574;
	add.s64 	%rd576, %rd575, %rd317;
	st.global.f32 	[%rd576], %f1944;
	ld.const.u64 	%rd577, [params+168];
	cvta.to.global.u64 	%rd578, %rd577;
	add.s64 	%rd579, %rd578, %rd317;
	st.global.f32 	[%rd579], %f1945;
	ld.const.u64 	%rd580, [params+176];
	cvta.to.global.u64 	%rd581, %rd580;
	add.s64 	%rd582, %rd581, %rd317;
	st.global.f32 	[%rd582], %f1946;
	ld.const.u64 	%rd583, [params+72];
	cvta.to.global.u64 	%rd584, %rd583;
	add.s64 	%rd585, %rd584, %rd317;
	st.global.f32 	[%rd585], %f313;
	ld.const.u64 	%rd43, [params+96];
	setp.eq.s64	%p48, %rd43, 0;
	@%p48 bra 	BB6_98;

	cvta.to.global.u64 	%rd586, %rd43;
	add.s64 	%rd588, %rd586, %rd317;
	st.global.f32 	[%rd588], %f319;
	ld.const.u64 	%rd589, [params+104];
	cvta.to.global.u64 	%rd590, %rd589;
	add.s64 	%rd591, %rd590, %rd317;
	st.global.f32 	[%rd591], %f320;

BB6_98:
	ld.const.u64 	%rd44, [params+112];
	setp.eq.s64	%p49, %rd44, 0;
	@%p49 bra 	BB6_100;

	cvta.to.global.u64 	%rd592, %rd44;
	add.s64 	%rd594, %rd592, %rd317;
	st.global.f32 	[%rd594], %f1938;
	ld.const.u64 	%rd595, [params+120];
	cvta.to.global.u64 	%rd596, %rd595;
	add.s64 	%rd597, %rd596, %rd317;
	st.global.f32 	[%rd597], %f1939;
	ld.const.u64 	%rd598, [params+128];
	cvta.to.global.u64 	%rd599, %rd598;
	add.s64 	%rd600, %rd599, %rd317;
	st.global.f32 	[%rd600], %f1940;

BB6_100:
	ld.const.u64 	%rd45, [params+136];
	setp.eq.s64	%p50, %rd45, 0;
	@%p50 bra 	BB6_102;

	cvta.to.global.u64 	%rd601, %rd45;
	add.s64 	%rd603, %rd601, %rd317;
	st.global.f32 	[%rd603], %f1941;
	ld.const.u64 	%rd604, [params+144];
	cvta.to.global.u64 	%rd605, %rd604;
	add.s64 	%rd606, %rd605, %rd317;
	st.global.f32 	[%rd606], %f1942;
	ld.const.u64 	%rd607, [params+152];
	cvta.to.global.u64 	%rd608, %rd607;
	add.s64 	%rd609, %rd608, %rd317;
	st.global.f32 	[%rd609], %f1943;

BB6_102:
	ld.const.u64 	%rd46, [params+184];
	setp.eq.s64	%p51, %rd46, 0;
	@%p51 bra 	BB6_104;

	cvta.to.global.u64 	%rd610, %rd46;
	add.s64 	%rd612, %rd610, %rd317;
	st.global.f32 	[%rd612], %f1935;
	ld.const.u64 	%rd613, [params+192];
	cvta.to.global.u64 	%rd614, %rd613;
	add.s64 	%rd615, %rd614, %rd317;
	st.global.f32 	[%rd615], %f1936;
	ld.const.u64 	%rd616, [params+200];
	cvta.to.global.u64 	%rd617, %rd616;
	add.s64 	%rd618, %rd617, %rd317;
	st.global.f32 	[%rd618], %f1937;
	ld.const.u64 	%rd619, [params+208];
	cvta.to.global.u64 	%rd620, %rd619;
	add.s64 	%rd621, %rd620, %rd317;
	st.global.f32 	[%rd621], %f1932;
	ld.const.u64 	%rd622, [params+216];
	cvta.to.global.u64 	%rd623, %rd622;
	add.s64 	%rd624, %rd623, %rd317;
	st.global.f32 	[%rd624], %f1933;
	ld.const.u64 	%rd625, [params+224];
	cvta.to.global.u64 	%rd626, %rd625;
	add.s64 	%rd627, %rd626, %rd317;
	st.global.f32 	[%rd627], %f1934;

BB6_104:
	ld.const.u64 	%rd47, [params+232];
	setp.eq.s64	%p52, %rd47, 0;
	@%p52 bra 	BB6_106;

	cvta.to.global.u64 	%rd628, %rd47;
	add.s64 	%rd630, %rd628, %rd317;
	st.global.f32 	[%rd630], %f1929;
	ld.const.u64 	%rd631, [params+240];
	cvta.to.global.u64 	%rd632, %rd631;
	add.s64 	%rd633, %rd632, %rd317;
	st.global.f32 	[%rd633], %f1930;
	ld.const.u64 	%rd634, [params+248];
	cvta.to.global.u64 	%rd635, %rd634;
	add.s64 	%rd636, %rd635, %rd317;
	st.global.f32 	[%rd636], %f1931;
	ld.const.u64 	%rd637, [params+256];
	cvta.to.global.u64 	%rd638, %rd637;
	add.s64 	%rd639, %rd638, %rd317;
	st.global.f32 	[%rd639], %f1929;
	ld.const.u64 	%rd640, [params+264];
	cvta.to.global.u64 	%rd641, %rd640;
	add.s64 	%rd642, %rd641, %rd317;
	st.global.f32 	[%rd642], %f1930;
	ld.const.u64 	%rd643, [params+272];
	cvta.to.global.u64 	%rd644, %rd643;
	add.s64 	%rd645, %rd644, %rd317;
	st.global.f32 	[%rd645], %f1931;

BB6_106:
	ld.const.u64 	%rd48, [params+280];
	setp.eq.s64	%p53, %rd48, 0;
	@%p53 bra 	BB6_108;

	cvta.to.global.u64 	%rd646, %rd48;
	add.s64 	%rd648, %rd646, %rd317;
	st.global.f32 	[%rd648], %f1929;
	ld.const.u64 	%rd649, [params+288];
	cvta.to.global.u64 	%rd650, %rd649;
	add.s64 	%rd651, %rd650, %rd317;
	st.global.f32 	[%rd651], %f1930;
	ld.const.u64 	%rd652, [params+296];
	cvta.to.global.u64 	%rd653, %rd652;
	add.s64 	%rd654, %rd653, %rd317;
	st.global.f32 	[%rd654], %f1931;
	ld.const.u64 	%rd655, [params+304];
	cvta.to.global.u64 	%rd656, %rd655;
	add.s64 	%rd657, %rd656, %rd317;
	st.global.f32 	[%rd657], %f1929;
	ld.const.u64 	%rd658, [params+312];
	cvta.to.global.u64 	%rd659, %rd658;
	add.s64 	%rd660, %rd659, %rd317;
	st.global.f32 	[%rd660], %f1930;
	ld.const.u64 	%rd661, [params+320];
	cvta.to.global.u64 	%rd662, %rd661;
	add.s64 	%rd663, %rd662, %rd317;
	st.global.f32 	[%rd663], %f1931;

BB6_108:
	ret;
}

	// .globl	__intersection__sphere
.visible .entry __intersection__sphere(

)
{
	.reg .pred 	%p<39>;
	.reg .b16 	%rs<14>;
	.reg .f32 	%f<921>;
	.reg .b32 	%r<320>;
	.reg .b64 	%rd<265>;


	// inline asm
	call (%rd18), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd1, [%rd18+8];
	// inline asm
	call (%f325), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f326), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f867), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r8), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p3, %r8, 0;
	@%p3 bra 	BB7_1;

	mov.u32 	%r318, 0;
	// inline asm
	call (%f328), _optix_get_ray_time, ();
	// inline asm

BB7_3:
	.pragma "nounroll";
	// inline asm
	call (%rd19), _optix_get_transform_list_handle, (%r318);
	// inline asm
	// inline asm
	call (%r11), _optix_get_transform_type_from_handle, (%rd19);
	// inline asm
	and.b32  	%r12, %r11, -2;
	setp.eq.s32	%p4, %r12, 2;
	@%p4 bra 	BB7_9;
	bra.uni 	BB7_4;

BB7_9:
	setp.eq.s32	%p7, %r11, 2;
	@%p7 bra 	BB7_13;
	bra.uni 	BB7_10;

BB7_13:
	// inline asm
	call (%rd93), _optix_get_matrix_motion_transform_from_handle, (%rd19);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd95, %rd93;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd95];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r102;
	add.s64 	%rd99, %rd93, 16;
	// inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd98];
	// inline asm
	add.s64 	%rd102, %rd93, 32;
	// inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd101];
	// inline asm
	add.s64 	%rd105, %rd93, 48;
	// inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd104];
	// inline asm
	add.s64 	%rd108, %rd93, 64;
	// inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd107];
	// inline asm
	add.s64 	%rd111, %rd93, 80;
	// inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd110];
	// inline asm
	add.s64 	%rd114, %rd93, 96;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd113];
	// inline asm
	add.s64 	%rd117, %rd93, 112;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd116];
	// inline asm
	mov.b32 	 %f455, %r103;
	mov.b32 	 %f456, %r104;
	cvt.u32.u16	%r144, %rs4;
	add.s32 	%r145, %r144, -1;
	cvt.rn.f32.s32	%f457, %r145;
	sub.f32 	%f458, %f328, %f455;
	mul.f32 	%f459, %f458, %f457;
	sub.f32 	%f460, %f456, %f455;
	div.rn.f32 	%f461, %f459, %f460;
	min.f32 	%f462, %f457, %f461;
	mov.f32 	%f463, 0f00000000;
	max.f32 	%f464, %f463, %f462;
	cvt.rmi.f32.f32	%f465, %f464;
	cvt.rzi.s32.f32	%r146, %f465;
	mul.wide.s32 	%rd128, %r146, 48;
	add.s64 	%rd120, %rd102, %rd128;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd119];
	// inline asm
	mov.b32 	 %f839, %r132;
	mov.b32 	 %f840, %r133;
	mov.b32 	 %f841, %r134;
	mov.b32 	 %f842, %r135;
	add.s64 	%rd123, %rd120, 16;
	// inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd122];
	// inline asm
	mov.b32 	 %f835, %r136;
	mov.b32 	 %f836, %r137;
	mov.b32 	 %f837, %r138;
	mov.b32 	 %f838, %r139;
	add.s64 	%rd126, %rd120, 32;
	// inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd125];
	// inline asm
	sub.f32 	%f98, %f464, %f465;
	mov.b32 	 %f831, %r140;
	mov.b32 	 %f832, %r141;
	mov.b32 	 %f833, %r142;
	mov.b32 	 %f834, %r143;
	setp.leu.f32	%p9, %f98, 0f00000000;
	@%p9 bra 	BB7_15;

	cvt.rmi.f32.f32	%f802, %f464;
	cvt.rzi.s32.f32	%r317, %f802;
	cvt.s64.s32	%rd262, %r317;
	mul.lo.s64 	%rd138, %rd262, 48;
	add.s64 	%rd139, %rd93, %rd138;
	add.s64 	%rd130, %rd139, 80;
	// inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd129];
	// inline asm
	mov.b32 	 %f466, %r147;
	mov.b32 	 %f467, %r148;
	mov.b32 	 %f468, %r149;
	mov.b32 	 %f469, %r150;
	add.s64 	%rd133, %rd139, 96;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd132];
	// inline asm
	mov.b32 	 %f470, %r151;
	mov.b32 	 %f471, %r152;
	mov.b32 	 %f472, %r153;
	mov.b32 	 %f473, %r154;
	add.s64 	%rd136, %rd139, 112;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd135];
	// inline asm
	mov.f32 	%f474, 0f3F800000;
	sub.f32 	%f475, %f474, %f98;
	mul.f32 	%f476, %f98, %f466;
	mul.f32 	%f477, %f98, %f467;
	mul.f32 	%f478, %f98, %f468;
	mul.f32 	%f479, %f98, %f469;
	fma.rn.f32 	%f839, %f475, %f839, %f476;
	fma.rn.f32 	%f840, %f475, %f840, %f477;
	fma.rn.f32 	%f841, %f475, %f841, %f478;
	fma.rn.f32 	%f842, %f475, %f842, %f479;
	mul.f32 	%f480, %f98, %f470;
	mul.f32 	%f481, %f98, %f471;
	mul.f32 	%f482, %f98, %f472;
	mul.f32 	%f483, %f98, %f473;
	fma.rn.f32 	%f835, %f475, %f835, %f480;
	fma.rn.f32 	%f836, %f475, %f836, %f481;
	fma.rn.f32 	%f837, %f475, %f837, %f482;
	fma.rn.f32 	%f838, %f475, %f838, %f483;
	mov.b32 	 %f484, %r155;
	mov.b32 	 %f485, %r156;
	mov.b32 	 %f486, %r157;
	mov.b32 	 %f487, %r158;
	mul.f32 	%f488, %f98, %f484;
	mul.f32 	%f489, %f98, %f485;
	mul.f32 	%f490, %f98, %f486;
	mul.f32 	%f491, %f98, %f487;
	fma.rn.f32 	%f831, %f475, %f831, %f488;
	fma.rn.f32 	%f832, %f475, %f832, %f489;
	fma.rn.f32 	%f833, %f475, %f833, %f490;
	fma.rn.f32 	%f834, %f475, %f834, %f491;
	bra.uni 	BB7_15;

BB7_4:
	mov.f32 	%f843, 0f00000000;
	mov.f32 	%f845, 0f3F800000;
	setp.eq.s32	%p5, %r11, 4;
	@%p5 bra 	BB7_7;
	bra.uni 	BB7_5;

BB7_7:
	// inline asm
	call (%rd263), _optix_get_instance_inverse_transform_from_handle, (%rd19);
	// inline asm
	bra.uni 	BB7_8;

BB7_10:
	// inline asm
	call (%rd34), _optix_get_srt_motion_transform_from_handle, (%rd19);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd36, %rd34;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r25,%r26,%r27,%r28}, [%rd36];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r27;
	add.s64 	%rd40, %rd34, 16;
	// inline asm
	cvta.to.global.u64 %rd39, %rd40;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r29,%r30,%r31,%r32}, [%rd39];
	// inline asm
	add.s64 	%rd43, %rd34, 32;
	// inline asm
	cvta.to.global.u64 %rd42, %rd43;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd42];
	// inline asm
	add.s64 	%rd46, %rd34, 48;
	// inline asm
	cvta.to.global.u64 %rd45, %rd46;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd45];
	// inline asm
	add.s64 	%rd49, %rd34, 64;
	// inline asm
	cvta.to.global.u64 %rd48, %rd49;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd48];
	// inline asm
	add.s64 	%rd52, %rd34, 80;
	// inline asm
	cvta.to.global.u64 %rd51, %rd52;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd51];
	// inline asm
	add.s64 	%rd55, %rd34, 96;
	// inline asm
	cvta.to.global.u64 %rd54, %rd55;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd54];
	// inline asm
	add.s64 	%rd58, %rd34, 112;
	// inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd57];
	// inline asm
	add.s64 	%rd61, %rd34, 128;
	// inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd60];
	// inline asm
	add.s64 	%rd64, %rd34, 144;
	// inline asm
	cvta.to.global.u64 %rd63, %rd64;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd63];
	// inline asm
	mov.b32 	 %f342, %r28;
	mov.b32 	 %f343, %r29;
	cvt.u32.u16	%r81, %rs2;
	add.s32 	%r82, %r81, -1;
	cvt.rn.f32.s32	%f344, %r82;
	sub.f32 	%f345, %f328, %f342;
	mul.f32 	%f346, %f345, %f344;
	sub.f32 	%f347, %f343, %f342;
	div.rn.f32 	%f348, %f346, %f347;
	min.f32 	%f349, %f344, %f348;
	mov.f32 	%f350, 0f00000000;
	max.f32 	%f351, %f350, %f349;
	cvt.rmi.f32.f32	%f352, %f351;
	cvt.rzi.s32.f32	%r83, %f352;
	mul.wide.s32 	%rd78, %r83, 64;
	add.s64 	%rd67, %rd43, %rd78;
	// inline asm
	cvta.to.global.u64 %rd66, %rd67;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd66];
	// inline asm
	mov.b32 	 %f815, %r65;
	mov.b32 	 %f816, %r66;
	mov.b32 	 %f817, %r67;
	mov.b32 	 %f818, %r68;
	add.s64 	%rd70, %rd67, 16;
	// inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd69];
	// inline asm
	mov.b32 	 %f819, %r69;
	mov.b32 	 %f820, %r70;
	mov.b32 	 %f821, %r71;
	mov.b32 	 %f822, %r72;
	add.s64 	%rd73, %rd67, 32;
	// inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd72];
	// inline asm
	sub.f32 	%f37, %f351, %f352;
	mov.b32 	 %f823, %r73;
	mov.b32 	 %f824, %r74;
	mov.b32 	 %f825, %r75;
	mov.b32 	 %f826, %r76;
	add.s64 	%rd76, %rd67, 48;
	// inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd75];
	// inline asm
	mov.b32 	 %f827, %r77;
	mov.b32 	 %f828, %r78;
	mov.b32 	 %f829, %r79;
	mov.b32 	 %f830, %r80;
	setp.leu.f32	%p8, %f37, 0f00000000;
	@%p8 bra 	BB7_12;

	cvt.rmi.f32.f32	%f801, %f351;
	cvt.rzi.s32.f32	%r316, %f801;
	cvt.s64.s32	%rd261, %r316;
	shl.b64 	%rd91, %rd261, 6;
	add.s64 	%rd92, %rd91, %rd34;
	add.s64 	%rd80, %rd92, 96;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd79];
	// inline asm
	mov.b32 	 %f353, %r84;
	mov.b32 	 %f354, %r85;
	mov.b32 	 %f355, %r86;
	mov.b32 	 %f356, %r87;
	add.s64 	%rd83, %rd92, 112;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd82];
	// inline asm
	mov.b32 	 %f357, %r88;
	mov.b32 	 %f358, %r89;
	mov.b32 	 %f359, %r90;
	mov.b32 	 %f360, %r91;
	add.s64 	%rd86, %rd92, 128;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd85];
	// inline asm
	mov.b32 	 %f361, %r92;
	mov.b32 	 %f362, %r93;
	mov.b32 	 %f363, %r94;
	mov.b32 	 %f364, %r95;
	add.s64 	%rd89, %rd92, 144;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd88];
	// inline asm
	mov.f32 	%f365, 0f3F800000;
	sub.f32 	%f366, %f365, %f37;
	mul.f32 	%f367, %f37, %f353;
	mul.f32 	%f368, %f37, %f354;
	mul.f32 	%f369, %f37, %f355;
	mul.f32 	%f370, %f37, %f356;
	fma.rn.f32 	%f815, %f366, %f815, %f367;
	fma.rn.f32 	%f816, %f366, %f816, %f368;
	fma.rn.f32 	%f817, %f366, %f817, %f369;
	fma.rn.f32 	%f818, %f366, %f818, %f370;
	mul.f32 	%f371, %f37, %f357;
	mul.f32 	%f372, %f37, %f358;
	mul.f32 	%f373, %f37, %f359;
	mul.f32 	%f374, %f37, %f360;
	fma.rn.f32 	%f819, %f366, %f819, %f371;
	fma.rn.f32 	%f820, %f366, %f820, %f372;
	fma.rn.f32 	%f821, %f366, %f821, %f373;
	fma.rn.f32 	%f822, %f366, %f822, %f374;
	mul.f32 	%f375, %f37, %f361;
	mul.f32 	%f376, %f37, %f362;
	mul.f32 	%f377, %f37, %f363;
	mul.f32 	%f378, %f37, %f364;
	fma.rn.f32 	%f823, %f366, %f823, %f375;
	fma.rn.f32 	%f379, %f366, %f824, %f376;
	fma.rn.f32 	%f380, %f366, %f825, %f377;
	fma.rn.f32 	%f381, %f366, %f826, %f378;
	mov.b32 	 %f382, %r96;
	mov.b32 	 %f383, %r97;
	mov.b32 	 %f384, %r98;
	mov.b32 	 %f385, %r99;
	mul.f32 	%f386, %f37, %f382;
	mul.f32 	%f387, %f37, %f383;
	mul.f32 	%f388, %f37, %f384;
	mul.f32 	%f389, %f37, %f385;
	fma.rn.f32 	%f390, %f366, %f827, %f386;
	fma.rn.f32 	%f828, %f366, %f828, %f387;
	fma.rn.f32 	%f829, %f366, %f829, %f388;
	fma.rn.f32 	%f830, %f366, %f830, %f389;
	mul.f32 	%f391, %f380, %f380;
	fma.rn.f32 	%f392, %f379, %f379, %f391;
	fma.rn.f32 	%f393, %f381, %f381, %f392;
	fma.rn.f32 	%f394, %f390, %f390, %f393;
	sqrt.rn.f32 	%f395, %f394;
	rcp.rn.f32 	%f396, %f395;
	mul.f32 	%f824, %f379, %f396;
	mul.f32 	%f825, %f380, %f396;
	mul.f32 	%f826, %f381, %f396;
	mul.f32 	%f827, %f390, %f396;

BB7_12:
	mul.f32 	%f397, %f825, %f825;
	fma.rn.f32 	%f398, %f824, %f824, %f397;
	fma.rn.f32 	%f399, %f826, %f826, %f398;
	fma.rn.f32 	%f400, %f827, %f827, %f399;
	rcp.rn.f32 	%f401, %f400;
	mul.f32 	%f402, %f824, %f401;
	mul.f32 	%f403, %f825, %f401;
	mul.f32 	%f404, %f826, %f401;
	mul.f32 	%f405, %f827, %f401;
	mul.f32 	%f406, %f824, %f402;
	mul.f32 	%f407, %f825, %f403;
	mul.f32 	%f408, %f826, %f404;
	mul.f32 	%f409, %f824, %f403;
	mul.f32 	%f410, %f826, %f405;
	mul.f32 	%f411, %f824, %f404;
	mul.f32 	%f412, %f825, %f405;
	mul.f32 	%f413, %f825, %f404;
	mul.f32 	%f414, %f824, %f405;
	sub.f32 	%f415, %f406, %f407;
	sub.f32 	%f416, %f415, %f408;
	fma.rn.f32 	%f417, %f827, %f405, %f416;
	sub.f32 	%f418, %f409, %f410;
	add.f32 	%f419, %f418, %f418;
	add.f32 	%f420, %f411, %f412;
	add.f32 	%f421, %f420, %f420;
	add.f32 	%f422, %f409, %f410;
	add.f32 	%f423, %f422, %f422;
	sub.f32 	%f424, %f407, %f406;
	sub.f32 	%f425, %f424, %f408;
	fma.rn.f32 	%f426, %f827, %f405, %f425;
	sub.f32 	%f427, %f413, %f414;
	add.f32 	%f428, %f427, %f427;
	sub.f32 	%f429, %f411, %f412;
	add.f32 	%f430, %f429, %f429;
	add.f32 	%f431, %f413, %f414;
	add.f32 	%f432, %f431, %f431;
	neg.f32 	%f433, %f406;
	sub.f32 	%f434, %f433, %f407;
	add.f32 	%f435, %f408, %f434;
	fma.rn.f32 	%f436, %f827, %f405, %f435;
	mul.f32 	%f437, %f818, %f417;
	fma.rn.f32 	%f438, %f821, %f419, %f437;
	fma.rn.f32 	%f439, %f823, %f421, %f438;
	sub.f32 	%f842, %f828, %f439;
	mul.f32 	%f440, %f821, %f426;
	fma.rn.f32 	%f441, %f818, %f423, %f440;
	fma.rn.f32 	%f442, %f823, %f428, %f441;
	sub.f32 	%f838, %f829, %f442;
	mul.f32 	%f443, %f821, %f432;
	fma.rn.f32 	%f444, %f818, %f430, %f443;
	fma.rn.f32 	%f445, %f823, %f436, %f444;
	sub.f32 	%f834, %f830, %f445;
	mul.f32 	%f446, %f817, %f417;
	fma.rn.f32 	%f447, %f820, %f419, %f446;
	fma.rn.f32 	%f841, %f822, %f421, %f447;
	mul.f32 	%f448, %f820, %f426;
	fma.rn.f32 	%f449, %f817, %f423, %f448;
	fma.rn.f32 	%f837, %f822, %f428, %f449;
	mul.f32 	%f450, %f820, %f432;
	fma.rn.f32 	%f451, %f817, %f430, %f450;
	fma.rn.f32 	%f833, %f822, %f436, %f451;
	mul.f32 	%f452, %f816, %f417;
	fma.rn.f32 	%f840, %f819, %f419, %f452;
	mul.f32 	%f453, %f819, %f426;
	fma.rn.f32 	%f836, %f816, %f423, %f453;
	mul.f32 	%f454, %f819, %f432;
	fma.rn.f32 	%f832, %f816, %f430, %f454;
	mul.f32 	%f839, %f815, %f417;
	mul.f32 	%f835, %f815, %f423;
	mul.f32 	%f831, %f815, %f430;

BB7_15:
	mul.f32 	%f492, %f832, %f837;
	mul.f32 	%f493, %f833, %f836;
	sub.f32 	%f494, %f493, %f492;
	mul.f32 	%f495, %f839, %f494;
	mul.f32 	%f496, %f831, %f837;
	mul.f32 	%f497, %f833, %f835;
	sub.f32 	%f498, %f497, %f496;
	mul.f32 	%f499, %f498, %f840;
	sub.f32 	%f500, %f495, %f499;
	mul.f32 	%f501, %f831, %f836;
	mul.f32 	%f502, %f832, %f835;
	sub.f32 	%f503, %f502, %f501;
	fma.rn.f32 	%f504, %f503, %f841, %f500;
	rcp.rn.f32 	%f505, %f504;
	mul.f32 	%f851, %f494, %f505;
	mul.f32 	%f506, %f833, %f840;
	mul.f32 	%f507, %f832, %f841;
	sub.f32 	%f508, %f507, %f506;
	mul.f32 	%f852, %f505, %f508;
	mul.f32 	%f509, %f836, %f841;
	mul.f32 	%f510, %f837, %f840;
	sub.f32 	%f511, %f510, %f509;
	mul.f32 	%f853, %f505, %f511;
	sub.f32 	%f512, %f496, %f497;
	mul.f32 	%f847, %f512, %f505;
	mul.f32 	%f513, %f831, %f841;
	mul.f32 	%f514, %f833, %f839;
	sub.f32 	%f515, %f514, %f513;
	mul.f32 	%f848, %f505, %f515;
	mul.f32 	%f516, %f837, %f839;
	mul.f32 	%f517, %f835, %f841;
	sub.f32 	%f518, %f517, %f516;
	mul.f32 	%f849, %f505, %f518;
	mul.f32 	%f843, %f503, %f505;
	mul.f32 	%f519, %f832, %f839;
	mul.f32 	%f520, %f831, %f840;
	sub.f32 	%f521, %f520, %f519;
	mul.f32 	%f844, %f521, %f505;
	mul.f32 	%f522, %f835, %f840;
	mul.f32 	%f523, %f836, %f839;
	sub.f32 	%f524, %f523, %f522;
	mul.f32 	%f845, %f524, %f505;
	mul.f32 	%f525, %f842, %f851;
	neg.f32 	%f526, %f525;
	mul.f32 	%f527, %f838, %f852;
	sub.f32 	%f528, %f526, %f527;
	mul.f32 	%f529, %f834, %f853;
	sub.f32 	%f854, %f528, %f529;
	mul.f32 	%f530, %f842, %f847;
	neg.f32 	%f531, %f530;
	mul.f32 	%f532, %f838, %f848;
	sub.f32 	%f533, %f531, %f532;
	mul.f32 	%f534, %f834, %f849;
	sub.f32 	%f850, %f533, %f534;
	mul.f32 	%f535, %f842, %f843;
	neg.f32 	%f536, %f535;
	mul.f32 	%f537, %f838, %f844;
	sub.f32 	%f538, %f536, %f537;
	mul.f32 	%f539, %f834, %f845;
	sub.f32 	%f846, %f538, %f539;
	bra.uni 	BB7_16;

BB7_5:
	setp.ne.s32	%p6, %r11, 1;
	mov.f32 	%f844, %f843;
	mov.f32 	%f846, %f843;
	mov.f32 	%f847, %f843;
	mov.f32 	%f848, %f845;
	mov.f32 	%f849, %f843;
	mov.f32 	%f850, %f843;
	mov.f32 	%f851, %f845;
	mov.f32 	%f852, %f843;
	mov.f32 	%f853, %f843;
	mov.f32 	%f854, %f843;
	@%p6 bra 	BB7_16;

	// inline asm
	call (%rd21), _optix_get_static_transform_from_handle, (%rd19);
	// inline asm
	add.s64 	%rd263, %rd21, 64;

BB7_8:
	// inline asm
	cvta.to.global.u64 %rd25, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r13,%r14,%r15,%r16}, [%rd25];
	// inline asm
	mov.b32 	 %f851, %r13;
	mov.b32 	 %f852, %r14;
	mov.b32 	 %f853, %r15;
	mov.b32 	 %f854, %r16;
	add.s64 	%rd29, %rd263, 16;
	// inline asm
	cvta.to.global.u64 %rd28, %rd29;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r17,%r18,%r19,%r20}, [%rd28];
	// inline asm
	mov.b32 	 %f847, %r17;
	mov.b32 	 %f848, %r18;
	mov.b32 	 %f849, %r19;
	mov.b32 	 %f850, %r20;
	add.s64 	%rd32, %rd263, 32;
	// inline asm
	cvta.to.global.u64 %rd31, %rd32;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r21,%r22,%r23,%r24}, [%rd31];
	// inline asm
	mov.b32 	 %f843, %r21;
	mov.b32 	 %f844, %r22;
	mov.b32 	 %f845, %r23;
	mov.b32 	 %f846, %r24;

BB7_16:
	setp.eq.s32	%p10, %r318, 0;
	@%p10 bra 	BB7_17;
	bra.uni 	BB7_18;

BB7_17:
	mov.f32 	%f814, %f854;
	mov.f32 	%f813, %f853;
	mov.f32 	%f812, %f852;
	mov.f32 	%f811, %f851;
	mov.f32 	%f810, %f850;
	mov.f32 	%f809, %f849;
	mov.f32 	%f808, %f848;
	mov.f32 	%f807, %f847;
	mov.f32 	%f806, %f846;
	mov.f32 	%f805, %f845;
	mov.f32 	%f804, %f844;
	mov.f32 	%f803, %f843;
	bra.uni 	BB7_19;

BB7_18:
	mul.f32 	%f540, %f807, %f852;
	fma.rn.f32 	%f541, %f811, %f851, %f540;
	fma.rn.f32 	%f151, %f803, %f853, %f541;
	mul.f32 	%f542, %f808, %f852;
	fma.rn.f32 	%f543, %f812, %f851, %f542;
	fma.rn.f32 	%f152, %f804, %f853, %f543;
	mul.f32 	%f544, %f809, %f852;
	fma.rn.f32 	%f545, %f813, %f851, %f544;
	fma.rn.f32 	%f153, %f805, %f853, %f545;
	mul.f32 	%f546, %f810, %f852;
	fma.rn.f32 	%f547, %f814, %f851, %f546;
	fma.rn.f32 	%f548, %f806, %f853, %f547;
	add.f32 	%f154, %f854, %f548;
	mul.f32 	%f549, %f807, %f848;
	fma.rn.f32 	%f550, %f811, %f847, %f549;
	fma.rn.f32 	%f155, %f803, %f849, %f550;
	mul.f32 	%f551, %f808, %f848;
	fma.rn.f32 	%f552, %f812, %f847, %f551;
	fma.rn.f32 	%f156, %f804, %f849, %f552;
	mul.f32 	%f553, %f809, %f848;
	fma.rn.f32 	%f554, %f813, %f847, %f553;
	fma.rn.f32 	%f157, %f805, %f849, %f554;
	mul.f32 	%f555, %f810, %f848;
	fma.rn.f32 	%f556, %f814, %f847, %f555;
	fma.rn.f32 	%f557, %f806, %f849, %f556;
	add.f32 	%f158, %f850, %f557;
	mul.f32 	%f558, %f807, %f844;
	fma.rn.f32 	%f559, %f811, %f843, %f558;
	fma.rn.f32 	%f803, %f803, %f845, %f559;
	mul.f32 	%f560, %f808, %f844;
	fma.rn.f32 	%f561, %f812, %f843, %f560;
	fma.rn.f32 	%f804, %f804, %f845, %f561;
	mul.f32 	%f562, %f809, %f844;
	fma.rn.f32 	%f563, %f813, %f843, %f562;
	fma.rn.f32 	%f805, %f805, %f845, %f563;
	mul.f32 	%f564, %f810, %f844;
	fma.rn.f32 	%f565, %f814, %f843, %f564;
	fma.rn.f32 	%f566, %f806, %f845, %f565;
	add.f32 	%f806, %f846, %f566;
	mov.f32 	%f814, %f154;
	mov.f32 	%f813, %f153;
	mov.f32 	%f812, %f152;
	mov.f32 	%f811, %f151;
	mov.f32 	%f810, %f158;
	mov.f32 	%f809, %f157;
	mov.f32 	%f808, %f156;
	mov.f32 	%f807, %f155;

BB7_19:
	add.s32 	%r318, %r318, 1;
	setp.lt.u32	%p11, %r318, %r8;
	@%p11 bra 	BB7_3;

	mul.f32 	%f567, %f325, %f811;
	fma.rn.f32 	%f568, %f326, %f812, %f567;
	fma.rn.f32 	%f569, %f867, %f813, %f568;
	add.f32 	%f869, %f814, %f569;
	mul.f32 	%f570, %f325, %f807;
	fma.rn.f32 	%f571, %f326, %f808, %f570;
	fma.rn.f32 	%f572, %f867, %f809, %f571;
	add.f32 	%f868, %f810, %f572;
	mul.f32 	%f573, %f325, %f803;
	fma.rn.f32 	%f574, %f326, %f804, %f573;
	fma.rn.f32 	%f575, %f867, %f805, %f574;
	add.f32 	%f867, %f806, %f575;
	bra.uni 	BB7_21;

BB7_1:
	mov.f32 	%f868, %f326;
	mov.f32 	%f869, %f325;

BB7_21:
	setp.eq.s32	%p37, %r8, 0;
	// inline asm
	call (%f576), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f577), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f918), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f579), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r319, 0;
	@%p37 bra 	BB7_22;

BB7_23:
	.pragma "nounroll";
	// inline asm
	call (%rd140), _optix_get_transform_list_handle, (%r319);
	// inline asm
	// inline asm
	call (%r161), _optix_get_transform_type_from_handle, (%rd140);
	// inline asm
	and.b32  	%r162, %r161, -2;
	setp.eq.s32	%p13, %r162, 2;
	@%p13 bra 	BB7_29;
	bra.uni 	BB7_24;

BB7_29:
	setp.eq.s32	%p16, %r161, 2;
	@%p16 bra 	BB7_33;
	bra.uni 	BB7_30;

BB7_33:
	// inline asm
	call (%rd214), _optix_get_matrix_motion_transform_from_handle, (%rd140);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd216, %rd214;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd216];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r252;
	add.s64 	%rd220, %rd214, 16;
	// inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd219];
	// inline asm
	add.s64 	%rd223, %rd214, 32;
	// inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd222];
	// inline asm
	add.s64 	%rd226, %rd214, 48;
	// inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd225];
	// inline asm
	add.s64 	%rd229, %rd214, 64;
	// inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd228];
	// inline asm
	add.s64 	%rd232, %rd214, 80;
	// inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd231];
	// inline asm
	add.s64 	%rd235, %rd214, 96;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd234];
	// inline asm
	add.s64 	%rd238, %rd214, 112;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd237];
	// inline asm
	mov.b32 	 %f682, %r253;
	mov.b32 	 %f683, %r254;
	cvt.u32.u16	%r294, %rs8;
	add.s32 	%r295, %r294, -1;
	cvt.rn.f32.s32	%f684, %r295;
	sub.f32 	%f685, %f579, %f682;
	mul.f32 	%f686, %f685, %f684;
	sub.f32 	%f687, %f683, %f682;
	div.rn.f32 	%f688, %f686, %f687;
	min.f32 	%f689, %f684, %f688;
	mov.f32 	%f690, 0f00000000;
	max.f32 	%f691, %f690, %f689;
	cvt.rmi.f32.f32	%f692, %f691;
	cvt.rzi.s32.f32	%r296, %f692;
	cvt.s64.s32	%rd17, %r296;
	mul.wide.s32 	%rd249, %r296, 48;
	add.s64 	%rd241, %rd223, %rd249;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd240];
	// inline asm
	mov.b32 	 %f895, %r282;
	mov.b32 	 %f896, %r283;
	mov.b32 	 %f897, %r284;
	add.s64 	%rd244, %rd241, 16;
	// inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd243];
	// inline asm
	mov.b32 	 %f892, %r286;
	mov.b32 	 %f893, %r287;
	mov.b32 	 %f894, %r288;
	add.s64 	%rd247, %rd241, 32;
	// inline asm
	cvta.to.global.u64 %rd246, %rd247;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd246];
	// inline asm
	sub.f32 	%f249, %f691, %f692;
	mov.b32 	 %f889, %r290;
	mov.b32 	 %f890, %r291;
	mov.b32 	 %f891, %r292;
	setp.leu.f32	%p18, %f249, 0f00000000;
	@%p18 bra 	BB7_35;

	mul.lo.s64 	%rd259, %rd17, 48;
	add.s64 	%rd260, %rd214, %rd259;
	add.s64 	%rd251, %rd260, 80;
	// inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd250];
	// inline asm
	mov.b32 	 %f693, %r297;
	mov.b32 	 %f694, %r298;
	mov.b32 	 %f695, %r299;
	add.s64 	%rd254, %rd260, 96;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd253];
	// inline asm
	mov.b32 	 %f696, %r301;
	mov.b32 	 %f697, %r302;
	mov.b32 	 %f698, %r303;
	add.s64 	%rd257, %rd260, 112;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd256];
	// inline asm
	mov.f32 	%f699, 0f3F800000;
	sub.f32 	%f700, %f699, %f249;
	mul.f32 	%f701, %f249, %f693;
	mul.f32 	%f702, %f249, %f694;
	mul.f32 	%f703, %f249, %f695;
	fma.rn.f32 	%f895, %f700, %f895, %f701;
	fma.rn.f32 	%f896, %f700, %f896, %f702;
	fma.rn.f32 	%f897, %f700, %f897, %f703;
	mul.f32 	%f704, %f249, %f696;
	mul.f32 	%f705, %f249, %f697;
	mul.f32 	%f706, %f249, %f698;
	fma.rn.f32 	%f892, %f700, %f892, %f704;
	fma.rn.f32 	%f893, %f700, %f893, %f705;
	fma.rn.f32 	%f894, %f700, %f894, %f706;
	mov.b32 	 %f707, %r305;
	mov.b32 	 %f708, %r306;
	mov.b32 	 %f709, %r307;
	mul.f32 	%f710, %f249, %f707;
	mul.f32 	%f711, %f249, %f708;
	mul.f32 	%f712, %f249, %f709;
	fma.rn.f32 	%f889, %f700, %f889, %f710;
	fma.rn.f32 	%f890, %f700, %f890, %f711;
	fma.rn.f32 	%f891, %f700, %f891, %f712;
	bra.uni 	BB7_35;

BB7_24:
	mov.f32 	%f898, 0f00000000;
	mov.f32 	%f900, 0f3F800000;
	setp.eq.s32	%p14, %r161, 4;
	@%p14 bra 	BB7_27;
	bra.uni 	BB7_25;

BB7_27:
	// inline asm
	call (%rd264), _optix_get_instance_inverse_transform_from_handle, (%rd140);
	// inline asm
	bra.uni 	BB7_28;

BB7_30:
	// inline asm
	call (%rd155), _optix_get_srt_motion_transform_from_handle, (%rd140);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd157, %rd155;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd157];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r177;
	add.s64 	%rd161, %rd155, 16;
	// inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd160];
	// inline asm
	add.s64 	%rd164, %rd155, 32;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd163];
	// inline asm
	add.s64 	%rd167, %rd155, 48;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd166];
	// inline asm
	add.s64 	%rd170, %rd155, 64;
	// inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd169];
	// inline asm
	add.s64 	%rd173, %rd155, 80;
	// inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd172];
	// inline asm
	add.s64 	%rd176, %rd155, 96;
	// inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd175];
	// inline asm
	add.s64 	%rd179, %rd155, 112;
	// inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd178];
	// inline asm
	add.s64 	%rd182, %rd155, 128;
	// inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd181];
	// inline asm
	add.s64 	%rd185, %rd155, 144;
	// inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd184];
	// inline asm
	mov.b32 	 %f590, %r178;
	mov.b32 	 %f591, %r179;
	cvt.u32.u16	%r231, %rs6;
	add.s32 	%r232, %r231, -1;
	cvt.rn.f32.s32	%f592, %r232;
	sub.f32 	%f593, %f579, %f590;
	mul.f32 	%f594, %f593, %f592;
	sub.f32 	%f595, %f591, %f590;
	div.rn.f32 	%f596, %f594, %f595;
	min.f32 	%f597, %f592, %f596;
	mov.f32 	%f598, 0f00000000;
	max.f32 	%f599, %f598, %f597;
	cvt.rmi.f32.f32	%f600, %f599;
	cvt.rzi.s32.f32	%r233, %f600;
	cvt.s64.s32	%rd15, %r233;
	mul.wide.s32 	%rd199, %r233, 64;
	add.s64 	%rd188, %rd164, %rd199;
	// inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd187];
	// inline asm
	mov.b32 	 %f879, %r215;
	mov.b32 	 %f880, %r216;
	mov.b32 	 %f881, %r217;
	add.s64 	%rd191, %rd188, 16;
	// inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd190];
	// inline asm
	mov.b32 	 %f882, %r219;
	mov.b32 	 %f883, %r220;
	mov.b32 	 %f884, %r222;
	add.s64 	%rd194, %rd188, 32;
	// inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd193];
	// inline asm
	sub.f32 	%f209, %f599, %f600;
	mov.b32 	 %f885, %r224;
	mov.b32 	 %f886, %r225;
	mov.b32 	 %f887, %r226;
	add.s64 	%rd197, %rd188, 48;
	// inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd196];
	// inline asm
	mov.b32 	 %f888, %r227;
	setp.leu.f32	%p17, %f209, 0f00000000;
	@%p17 bra 	BB7_32;

	shl.b64 	%rd212, %rd15, 6;
	add.s64 	%rd213, %rd212, %rd155;
	add.s64 	%rd201, %rd213, 96;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd200];
	// inline asm
	mov.b32 	 %f601, %r234;
	mov.b32 	 %f602, %r235;
	mov.b32 	 %f603, %r236;
	add.s64 	%rd204, %rd213, 112;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd203];
	// inline asm
	mov.b32 	 %f604, %r238;
	mov.b32 	 %f605, %r239;
	mov.b32 	 %f606, %r241;
	add.s64 	%rd207, %rd213, 128;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd206];
	// inline asm
	mov.b32 	 %f607, %r243;
	mov.b32 	 %f608, %r244;
	mov.b32 	 %f609, %r245;
	add.s64 	%rd210, %rd213, 144;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd209];
	// inline asm
	mov.f32 	%f610, 0f3F800000;
	sub.f32 	%f611, %f610, %f209;
	mul.f32 	%f612, %f209, %f601;
	mul.f32 	%f613, %f209, %f602;
	mul.f32 	%f614, %f209, %f603;
	fma.rn.f32 	%f879, %f611, %f879, %f612;
	fma.rn.f32 	%f880, %f611, %f880, %f613;
	fma.rn.f32 	%f881, %f611, %f881, %f614;
	mul.f32 	%f615, %f209, %f604;
	mul.f32 	%f616, %f209, %f605;
	mul.f32 	%f617, %f209, %f606;
	fma.rn.f32 	%f882, %f611, %f882, %f615;
	fma.rn.f32 	%f883, %f611, %f883, %f616;
	fma.rn.f32 	%f884, %f611, %f884, %f617;
	mul.f32 	%f618, %f209, %f607;
	mul.f32 	%f619, %f209, %f608;
	mul.f32 	%f620, %f209, %f609;
	fma.rn.f32 	%f621, %f611, %f885, %f618;
	fma.rn.f32 	%f622, %f611, %f886, %f619;
	fma.rn.f32 	%f623, %f611, %f887, %f620;
	mov.b32 	 %f624, %r246;
	mul.f32 	%f625, %f209, %f624;
	fma.rn.f32 	%f626, %f611, %f888, %f625;
	mul.f32 	%f627, %f622, %f622;
	fma.rn.f32 	%f628, %f621, %f621, %f627;
	fma.rn.f32 	%f629, %f623, %f623, %f628;
	fma.rn.f32 	%f630, %f626, %f626, %f629;
	sqrt.rn.f32 	%f631, %f630;
	rcp.rn.f32 	%f632, %f631;
	mul.f32 	%f885, %f621, %f632;
	mul.f32 	%f886, %f622, %f632;
	mul.f32 	%f887, %f623, %f632;
	mul.f32 	%f888, %f626, %f632;

BB7_32:
	mul.f32 	%f633, %f886, %f886;
	fma.rn.f32 	%f634, %f885, %f885, %f633;
	fma.rn.f32 	%f635, %f887, %f887, %f634;
	fma.rn.f32 	%f636, %f888, %f888, %f635;
	rcp.rn.f32 	%f637, %f636;
	mul.f32 	%f638, %f885, %f637;
	mul.f32 	%f639, %f886, %f637;
	mul.f32 	%f640, %f887, %f637;
	mul.f32 	%f641, %f888, %f637;
	mul.f32 	%f642, %f885, %f638;
	mul.f32 	%f643, %f886, %f639;
	mul.f32 	%f644, %f887, %f640;
	mul.f32 	%f645, %f885, %f639;
	mul.f32 	%f646, %f887, %f641;
	mul.f32 	%f647, %f885, %f640;
	mul.f32 	%f648, %f886, %f641;
	mul.f32 	%f649, %f886, %f640;
	mul.f32 	%f650, %f885, %f641;
	sub.f32 	%f651, %f642, %f643;
	sub.f32 	%f652, %f651, %f644;
	fma.rn.f32 	%f653, %f888, %f641, %f652;
	sub.f32 	%f654, %f645, %f646;
	add.f32 	%f655, %f654, %f654;
	add.f32 	%f656, %f647, %f648;
	add.f32 	%f657, %f656, %f656;
	add.f32 	%f658, %f645, %f646;
	add.f32 	%f659, %f658, %f658;
	sub.f32 	%f660, %f643, %f642;
	sub.f32 	%f661, %f660, %f644;
	fma.rn.f32 	%f662, %f888, %f641, %f661;
	sub.f32 	%f663, %f649, %f650;
	add.f32 	%f664, %f663, %f663;
	sub.f32 	%f665, %f647, %f648;
	add.f32 	%f666, %f665, %f665;
	add.f32 	%f667, %f649, %f650;
	add.f32 	%f668, %f667, %f667;
	neg.f32 	%f669, %f642;
	sub.f32 	%f670, %f669, %f643;
	add.f32 	%f671, %f644, %f670;
	fma.rn.f32 	%f672, %f888, %f641, %f671;
	mul.f32 	%f673, %f881, %f653;
	fma.rn.f32 	%f674, %f883, %f655, %f673;
	fma.rn.f32 	%f897, %f884, %f657, %f674;
	mul.f32 	%f675, %f883, %f662;
	fma.rn.f32 	%f676, %f881, %f659, %f675;
	fma.rn.f32 	%f894, %f884, %f664, %f676;
	mul.f32 	%f677, %f883, %f668;
	fma.rn.f32 	%f678, %f881, %f666, %f677;
	fma.rn.f32 	%f891, %f884, %f672, %f678;
	mul.f32 	%f679, %f880, %f653;
	fma.rn.f32 	%f896, %f882, %f655, %f679;
	mul.f32 	%f680, %f882, %f662;
	fma.rn.f32 	%f893, %f880, %f659, %f680;
	mul.f32 	%f681, %f882, %f668;
	fma.rn.f32 	%f890, %f880, %f666, %f681;
	mul.f32 	%f895, %f879, %f653;
	mul.f32 	%f892, %f879, %f659;
	mul.f32 	%f889, %f879, %f666;

BB7_35:
	mul.f32 	%f713, %f890, %f894;
	mul.f32 	%f714, %f891, %f893;
	sub.f32 	%f715, %f714, %f713;
	mul.f32 	%f716, %f895, %f715;
	mul.f32 	%f717, %f889, %f894;
	mul.f32 	%f718, %f891, %f892;
	sub.f32 	%f719, %f718, %f717;
	mul.f32 	%f720, %f719, %f896;
	sub.f32 	%f721, %f716, %f720;
	mul.f32 	%f722, %f889, %f893;
	mul.f32 	%f723, %f890, %f892;
	sub.f32 	%f724, %f723, %f722;
	fma.rn.f32 	%f725, %f724, %f897, %f721;
	rcp.rn.f32 	%f726, %f725;
	mul.f32 	%f904, %f715, %f726;
	mul.f32 	%f727, %f891, %f896;
	mul.f32 	%f728, %f890, %f897;
	sub.f32 	%f729, %f728, %f727;
	mul.f32 	%f905, %f726, %f729;
	mul.f32 	%f730, %f893, %f897;
	mul.f32 	%f731, %f894, %f896;
	sub.f32 	%f732, %f731, %f730;
	mul.f32 	%f906, %f726, %f732;
	sub.f32 	%f733, %f717, %f718;
	mul.f32 	%f901, %f733, %f726;
	mul.f32 	%f734, %f889, %f897;
	mul.f32 	%f735, %f891, %f895;
	sub.f32 	%f736, %f735, %f734;
	mul.f32 	%f902, %f726, %f736;
	mul.f32 	%f737, %f894, %f895;
	mul.f32 	%f738, %f892, %f897;
	sub.f32 	%f739, %f738, %f737;
	mul.f32 	%f903, %f726, %f739;
	mul.f32 	%f898, %f724, %f726;
	mul.f32 	%f740, %f890, %f895;
	mul.f32 	%f741, %f889, %f896;
	sub.f32 	%f742, %f741, %f740;
	mul.f32 	%f899, %f742, %f726;
	mul.f32 	%f743, %f892, %f896;
	mul.f32 	%f744, %f893, %f895;
	sub.f32 	%f745, %f744, %f743;
	mul.f32 	%f900, %f745, %f726;
	bra.uni 	BB7_36;

BB7_25:
	setp.ne.s32	%p15, %r161, 1;
	mov.f32 	%f899, %f898;
	mov.f32 	%f901, %f898;
	mov.f32 	%f902, %f900;
	mov.f32 	%f903, %f898;
	mov.f32 	%f904, %f900;
	mov.f32 	%f905, %f898;
	mov.f32 	%f906, %f898;
	@%p15 bra 	BB7_36;

	// inline asm
	call (%rd142), _optix_get_static_transform_from_handle, (%rd140);
	// inline asm
	add.s64 	%rd264, %rd142, 64;

BB7_28:
	// inline asm
	cvta.to.global.u64 %rd146, %rd264;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd146];
	// inline asm
	mov.b32 	 %f904, %r163;
	mov.b32 	 %f905, %r164;
	mov.b32 	 %f906, %r165;
	add.s64 	%rd150, %rd264, 16;
	// inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd149];
	// inline asm
	mov.b32 	 %f901, %r167;
	mov.b32 	 %f902, %r168;
	mov.b32 	 %f903, %r169;
	add.s64 	%rd153, %rd264, 32;
	// inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd152];
	// inline asm
	mov.b32 	 %f898, %r171;
	mov.b32 	 %f899, %r172;
	mov.b32 	 %f900, %r173;

BB7_36:
	setp.eq.s32	%p19, %r319, 0;
	@%p19 bra 	BB7_37;
	bra.uni 	BB7_38;

BB7_37:
	mov.f32 	%f878, %f898;
	mov.f32 	%f877, %f899;
	mov.f32 	%f876, %f900;
	mov.f32 	%f875, %f901;
	mov.f32 	%f874, %f902;
	mov.f32 	%f873, %f903;
	mov.f32 	%f872, %f904;
	mov.f32 	%f871, %f905;
	mov.f32 	%f870, %f906;
	bra.uni 	BB7_39;

BB7_38:
	mul.f32 	%f746, %f875, %f905;
	fma.rn.f32 	%f747, %f872, %f904, %f746;
	fma.rn.f32 	%f289, %f878, %f906, %f747;
	mul.f32 	%f748, %f874, %f905;
	fma.rn.f32 	%f749, %f871, %f904, %f748;
	fma.rn.f32 	%f290, %f877, %f906, %f749;
	mul.f32 	%f750, %f873, %f905;
	fma.rn.f32 	%f751, %f870, %f904, %f750;
	fma.rn.f32 	%f291, %f876, %f906, %f751;
	mul.f32 	%f752, %f875, %f902;
	fma.rn.f32 	%f753, %f872, %f901, %f752;
	fma.rn.f32 	%f292, %f878, %f903, %f753;
	mul.f32 	%f754, %f874, %f902;
	fma.rn.f32 	%f755, %f871, %f901, %f754;
	fma.rn.f32 	%f293, %f877, %f903, %f755;
	mul.f32 	%f756, %f873, %f902;
	fma.rn.f32 	%f757, %f870, %f901, %f756;
	fma.rn.f32 	%f294, %f876, %f903, %f757;
	mul.f32 	%f758, %f875, %f899;
	fma.rn.f32 	%f759, %f872, %f898, %f758;
	fma.rn.f32 	%f878, %f878, %f900, %f759;
	mul.f32 	%f760, %f874, %f899;
	fma.rn.f32 	%f761, %f871, %f898, %f760;
	fma.rn.f32 	%f877, %f877, %f900, %f761;
	mul.f32 	%f762, %f873, %f899;
	fma.rn.f32 	%f763, %f870, %f898, %f762;
	fma.rn.f32 	%f876, %f876, %f900, %f763;
	mov.f32 	%f875, %f292;
	mov.f32 	%f874, %f293;
	mov.f32 	%f873, %f294;
	mov.f32 	%f872, %f289;
	mov.f32 	%f871, %f290;
	mov.f32 	%f870, %f291;

BB7_39:
	add.s32 	%r319, %r319, 1;
	setp.lt.u32	%p20, %r319, %r8;
	@%p20 bra 	BB7_23;

	mul.f32 	%f764, %f577, %f871;
	fma.rn.f32 	%f765, %f576, %f872, %f764;
	fma.rn.f32 	%f916, %f918, %f870, %f765;
	mul.f32 	%f766, %f577, %f874;
	fma.rn.f32 	%f767, %f576, %f875, %f766;
	fma.rn.f32 	%f917, %f918, %f873, %f767;
	mul.f32 	%f768, %f577, %f877;
	fma.rn.f32 	%f769, %f576, %f878, %f768;
	fma.rn.f32 	%f918, %f918, %f876, %f769;
	bra.uni 	BB7_41;

BB7_22:
	mov.f32 	%f916, %f576;
	mov.f32 	%f917, %f577;

BB7_41:
	// inline asm
	call (%f770), _optix_get_ray_tmin, ();
	// inline asm
	// inline asm
	call (%f771), _optix_get_ray_tmax, ();
	// inline asm
	ld.f32 	%f773, [%rd1+288];
	sub.f32 	%f774, %f869, %f773;
	ld.f32 	%f775, [%rd1+292];
	sub.f32 	%f776, %f868, %f775;
	ld.f32 	%f777, [%rd1+296];
	sub.f32 	%f778, %f867, %f777;
	mul.f32 	%f779, %f916, %f916;
	fma.rn.f32 	%f780, %f917, %f917, %f779;
	fma.rn.f32 	%f315, %f918, %f918, %f780;
	mul.f32 	%f781, %f774, %f916;
	fma.rn.f32 	%f782, %f776, %f917, %f781;
	fma.rn.f32 	%f783, %f778, %f918, %f782;
	add.f32 	%f316, %f783, %f783;
	mul.f32 	%f784, %f774, %f774;
	fma.rn.f32 	%f785, %f776, %f776, %f784;
	fma.rn.f32 	%f786, %f778, %f778, %f785;
	ld.f32 	%f787, [%rd1+304];
	mul.f32 	%f788, %f787, %f787;
	sub.f32 	%f317, %f786, %f788;
	setp.eq.f32	%p21, %f315, 0f00000000;
	setp.eq.f32	%p22, %f316, 0f00000000;
	and.pred  	%p23, %p21, %p22;
	mov.u16 	%rs13, 0;
	@%p23 bra 	BB7_45;

	neg.f32 	%f789, %f317;
	div.rn.f32 	%f920, %f789, %f316;
	mul.f32 	%f790, %f315, 0fC0800000;
	mul.f32 	%f791, %f790, %f317;
	fma.rn.f32 	%f319, %f316, %f316, %f791;
	setp.lt.f32	%p24, %f319, 0f00000000;
	setp.neu.f32	%p25, %f315, 0f00000000;
	and.pred  	%p26, %p24, %p25;
	@%p26 bra 	BB7_43;
	bra.uni 	BB7_44;

BB7_43:
	mov.f32 	%f919, %f920;
	bra.uni 	BB7_45;

BB7_44:
	mov.b32 	 %r309, %f316;
	and.b32  	%r310, %r309, -2147483648;
	sqrt.rn.f32 	%f792, %f319;
	mov.b32 	 %r311, %f792;
	and.b32  	%r312, %r311, 2147483647;
	or.b32  	%r313, %r312, %r310;
	mov.b32 	 %f793, %r313;
	add.f32 	%f794, %f316, %f793;
	mul.f32 	%f795, %f794, 0fBF000000;
	div.rn.f32 	%f796, %f795, %f315;
	div.rn.f32 	%f797, %f317, %f795;
	min.f32 	%f798, %f796, %f797;
	max.f32 	%f799, %f796, %f797;
	selp.f32	%f919, %f920, %f798, %p21;
	selp.f32	%f920, %f920, %f799, %p21;
	mov.u16 	%rs13, 1;

BB7_45:
	setp.gtu.f32	%p29, %f919, %f771;
	mov.pred 	%p38, 0;
	@%p29 bra 	BB7_47;

	setp.ge.f32	%p38, %f920, %f770;

BB7_47:
	setp.lt.f32	%p30, %f919, %f770;
	setp.geu.f32	%p31, %f919, %f770;
	setp.leu.f32	%p32, %f920, %f771;
	or.pred  	%p33, %p32, %p31;
	selp.f32	%f324, %f920, %f919, %p30;
	setp.ne.s16	%p34, %rs13, 0;
	and.pred  	%p35, %p34, %p38;
	and.pred  	%p36, %p35, %p33;
	@!%p36 bra 	BB7_49;
	bra.uni 	BB7_48;

BB7_48:
	mov.u32 	%r315, 254;
	// inline asm
	call (%r314), _optix_report_intersection_0, (%f324, %r315);
	// inline asm

BB7_49:
	ret;
}

	// .globl	__closesthit__sphere
.visible .entry __closesthit__sphere(

)
{
	.reg .pred 	%p<71>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<2104>;
	.reg .b32 	%r<650>;
	.reg .b64 	%rd<666>;


	// inline asm
	call (%r23), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r24), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r26), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r27), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r28), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r29, %r28, %r24, %r27;
	mad.lo.s32 	%r1, %r29, %r23, %r26;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	@%p1 bra 	BB8_2;

	cvta.to.global.u64 	%rd48, %rd1;
	cvt.u64.u32	%rd49, %r1;
	add.s64 	%rd50, %rd48, %rd49;
	mov.u16 	%rs2, 1;
	st.global.u8 	[%rd50], %rs2;
	bra.uni 	BB8_116;

BB8_2:
	// inline asm
	call (%rd51), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd3, [%rd51+8];
	// inline asm
	call (%f703), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f704), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f1885), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r30), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p2, %r30, 0;
	@%p2 bra 	BB8_3;

	mov.u32 	%r646, 0;
	// inline asm
	call (%f706), _optix_get_ray_time, ();
	// inline asm

BB8_5:
	.pragma "nounroll";
	// inline asm
	call (%rd52), _optix_get_transform_list_handle, (%r646);
	// inline asm
	// inline asm
	call (%r33), _optix_get_transform_type_from_handle, (%rd52);
	// inline asm
	and.b32  	%r34, %r33, -2;
	setp.eq.s32	%p3, %r34, 2;
	@%p3 bra 	BB8_11;
	bra.uni 	BB8_6;

BB8_11:
	setp.eq.s32	%p6, %r33, 2;
	@%p6 bra 	BB8_15;
	bra.uni 	BB8_12;

BB8_15:
	// inline asm
	call (%rd126), _optix_get_matrix_motion_transform_from_handle, (%rd52);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd128, %rd126;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd128];
	// inline asm
	mov.b32	{%rs5, %rs6}, %r124;
	add.s64 	%rd132, %rd126, 16;
	// inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd131];
	// inline asm
	add.s64 	%rd135, %rd126, 32;
	// inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd134];
	// inline asm
	add.s64 	%rd138, %rd126, 48;
	// inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd137];
	// inline asm
	add.s64 	%rd141, %rd126, 64;
	// inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd140];
	// inline asm
	add.s64 	%rd144, %rd126, 80;
	// inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd143];
	// inline asm
	add.s64 	%rd147, %rd126, 96;
	// inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd146];
	// inline asm
	add.s64 	%rd150, %rd126, 112;
	// inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r150,%r151,%r152,%r153}, [%rd149];
	// inline asm
	mov.b32 	 %f833, %r125;
	mov.b32 	 %f834, %r126;
	cvt.u32.u16	%r166, %rs5;
	add.s32 	%r167, %r166, -1;
	cvt.rn.f32.s32	%f835, %r167;
	sub.f32 	%f836, %f706, %f833;
	mul.f32 	%f837, %f836, %f835;
	sub.f32 	%f838, %f834, %f833;
	div.rn.f32 	%f839, %f837, %f838;
	min.f32 	%f840, %f835, %f839;
	mov.f32 	%f841, 0f00000000;
	max.f32 	%f842, %f841, %f840;
	cvt.rmi.f32.f32	%f843, %f842;
	cvt.rzi.s32.f32	%r168, %f843;
	mul.wide.s32 	%rd161, %r168, 48;
	add.s64 	%rd153, %rd135, %rd161;
	// inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r154,%r155,%r156,%r157}, [%rd152];
	// inline asm
	mov.b32 	 %f1852, %r154;
	mov.b32 	 %f1851, %r155;
	mov.b32 	 %f1850, %r156;
	mov.b32 	 %f1849, %r157;
	add.s64 	%rd156, %rd153, 16;
	// inline asm
	cvta.to.global.u64 %rd155, %rd156;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r158,%r159,%r160,%r161}, [%rd155];
	// inline asm
	mov.b32 	 %f1856, %r158;
	mov.b32 	 %f1855, %r159;
	mov.b32 	 %f1854, %r160;
	mov.b32 	 %f1853, %r161;
	add.s64 	%rd159, %rd153, 32;
	// inline asm
	cvta.to.global.u64 %rd158, %rd159;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r162,%r163,%r164,%r165}, [%rd158];
	// inline asm
	sub.f32 	%f98, %f842, %f843;
	mov.b32 	 %f1860, %r162;
	mov.b32 	 %f1859, %r163;
	mov.b32 	 %f1858, %r164;
	mov.b32 	 %f1857, %r165;
	setp.leu.f32	%p8, %f98, 0f00000000;
	@%p8 bra 	BB8_17;

	cvt.rmi.f32.f32	%f1820, %f842;
	cvt.rzi.s32.f32	%r645, %f1820;
	cvt.s64.s32	%rd661, %r645;
	mul.lo.s64 	%rd171, %rd661, 48;
	add.s64 	%rd172, %rd126, %rd171;
	add.s64 	%rd163, %rd172, 80;
	// inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd162];
	// inline asm
	mov.b32 	 %f844, %r169;
	mov.b32 	 %f845, %r170;
	mov.b32 	 %f846, %r171;
	mov.b32 	 %f847, %r172;
	add.s64 	%rd166, %rd172, 96;
	// inline asm
	cvta.to.global.u64 %rd165, %rd166;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd165];
	// inline asm
	mov.b32 	 %f848, %r173;
	mov.b32 	 %f849, %r174;
	mov.b32 	 %f850, %r175;
	mov.b32 	 %f851, %r176;
	add.s64 	%rd169, %rd172, 112;
	// inline asm
	cvta.to.global.u64 %rd168, %rd169;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd168];
	// inline asm
	mov.f32 	%f852, 0f3F800000;
	sub.f32 	%f853, %f852, %f98;
	mul.f32 	%f854, %f98, %f844;
	mul.f32 	%f855, %f98, %f845;
	mul.f32 	%f856, %f98, %f846;
	mul.f32 	%f857, %f98, %f847;
	fma.rn.f32 	%f1852, %f853, %f1852, %f854;
	fma.rn.f32 	%f1851, %f853, %f1851, %f855;
	fma.rn.f32 	%f1850, %f853, %f1850, %f856;
	fma.rn.f32 	%f1849, %f853, %f1849, %f857;
	mul.f32 	%f858, %f98, %f848;
	mul.f32 	%f859, %f98, %f849;
	mul.f32 	%f860, %f98, %f850;
	mul.f32 	%f861, %f98, %f851;
	fma.rn.f32 	%f1856, %f853, %f1856, %f858;
	fma.rn.f32 	%f1855, %f853, %f1855, %f859;
	fma.rn.f32 	%f1854, %f853, %f1854, %f860;
	fma.rn.f32 	%f1853, %f853, %f1853, %f861;
	mov.b32 	 %f862, %r177;
	mov.b32 	 %f863, %r178;
	mov.b32 	 %f864, %r179;
	mov.b32 	 %f865, %r180;
	mul.f32 	%f866, %f98, %f862;
	mul.f32 	%f867, %f98, %f863;
	mul.f32 	%f868, %f98, %f864;
	mul.f32 	%f869, %f98, %f865;
	fma.rn.f32 	%f1860, %f853, %f1860, %f866;
	fma.rn.f32 	%f1859, %f853, %f1859, %f867;
	fma.rn.f32 	%f1858, %f853, %f1858, %f868;
	fma.rn.f32 	%f1857, %f853, %f1857, %f869;
	bra.uni 	BB8_17;

BB8_6:
	mov.f32 	%f1861, 0f00000000;
	mov.f32 	%f1864, 0f3F800000;
	setp.eq.s32	%p4, %r33, 4;
	@%p4 bra 	BB8_9;
	bra.uni 	BB8_7;

BB8_9:
	// inline asm
	call (%rd662), _optix_get_instance_inverse_transform_from_handle, (%rd52);
	// inline asm
	bra.uni 	BB8_10;

BB8_12:
	// inline asm
	call (%rd67), _optix_get_srt_motion_transform_from_handle, (%rd52);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd69, %rd67;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd69];
	// inline asm
	mov.b32	{%rs3, %rs4}, %r49;
	add.s64 	%rd73, %rd67, 16;
	// inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd72];
	// inline asm
	add.s64 	%rd76, %rd67, 32;
	// inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd75];
	// inline asm
	add.s64 	%rd79, %rd67, 48;
	// inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd78];
	// inline asm
	add.s64 	%rd82, %rd67, 64;
	// inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd81];
	// inline asm
	add.s64 	%rd85, %rd67, 80;
	// inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd84];
	// inline asm
	add.s64 	%rd88, %rd67, 96;
	// inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd87];
	// inline asm
	add.s64 	%rd91, %rd67, 112;
	// inline asm
	cvta.to.global.u64 %rd90, %rd91;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd90];
	// inline asm
	add.s64 	%rd94, %rd67, 128;
	// inline asm
	cvta.to.global.u64 %rd93, %rd94;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd93];
	// inline asm
	add.s64 	%rd97, %rd67, 144;
	// inline asm
	cvta.to.global.u64 %rd96, %rd97;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd96];
	// inline asm
	mov.b32 	 %f720, %r50;
	mov.b32 	 %f721, %r51;
	cvt.u32.u16	%r103, %rs3;
	add.s32 	%r104, %r103, -1;
	cvt.rn.f32.s32	%f722, %r104;
	sub.f32 	%f723, %f706, %f720;
	mul.f32 	%f724, %f723, %f722;
	sub.f32 	%f725, %f721, %f720;
	div.rn.f32 	%f726, %f724, %f725;
	min.f32 	%f727, %f722, %f726;
	mov.f32 	%f728, 0f00000000;
	max.f32 	%f729, %f728, %f727;
	cvt.rmi.f32.f32	%f730, %f729;
	cvt.rzi.s32.f32	%r105, %f730;
	mul.wide.s32 	%rd111, %r105, 64;
	add.s64 	%rd100, %rd76, %rd111;
	// inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r87,%r88,%r89,%r90}, [%rd99];
	// inline asm
	mov.b32 	 %f1833, %r87;
	mov.b32 	 %f1834, %r88;
	mov.b32 	 %f1835, %r89;
	mov.b32 	 %f1836, %r90;
	add.s64 	%rd103, %rd100, 16;
	// inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r91,%r92,%r93,%r94}, [%rd102];
	// inline asm
	mov.b32 	 %f1837, %r91;
	mov.b32 	 %f1838, %r92;
	mov.b32 	 %f1839, %r93;
	mov.b32 	 %f1840, %r94;
	add.s64 	%rd106, %rd100, 32;
	// inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r95,%r96,%r97,%r98}, [%rd105];
	// inline asm
	sub.f32 	%f37, %f729, %f730;
	mov.b32 	 %f1841, %r95;
	mov.b32 	 %f1842, %r96;
	mov.b32 	 %f1843, %r97;
	mov.b32 	 %f1844, %r98;
	add.s64 	%rd109, %rd100, 48;
	// inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r99,%r100,%r101,%r102}, [%rd108];
	// inline asm
	mov.b32 	 %f1845, %r99;
	mov.b32 	 %f1846, %r100;
	mov.b32 	 %f1847, %r101;
	mov.b32 	 %f1848, %r102;
	setp.leu.f32	%p7, %f37, 0f00000000;
	@%p7 bra 	BB8_14;

	cvt.rmi.f32.f32	%f1819, %f729;
	cvt.rzi.s32.f32	%r644, %f1819;
	cvt.s64.s32	%rd660, %r644;
	shl.b64 	%rd124, %rd660, 6;
	add.s64 	%rd125, %rd124, %rd67;
	add.s64 	%rd113, %rd125, 96;
	// inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd112];
	// inline asm
	mov.b32 	 %f731, %r106;
	mov.b32 	 %f732, %r107;
	mov.b32 	 %f733, %r108;
	mov.b32 	 %f734, %r109;
	add.s64 	%rd116, %rd125, 112;
	// inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd115];
	// inline asm
	mov.b32 	 %f735, %r110;
	mov.b32 	 %f736, %r111;
	mov.b32 	 %f737, %r112;
	mov.b32 	 %f738, %r113;
	add.s64 	%rd119, %rd125, 128;
	// inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd118];
	// inline asm
	mov.b32 	 %f739, %r114;
	mov.b32 	 %f740, %r115;
	mov.b32 	 %f741, %r116;
	mov.b32 	 %f742, %r117;
	add.s64 	%rd122, %rd125, 144;
	// inline asm
	cvta.to.global.u64 %rd121, %rd122;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd121];
	// inline asm
	mov.f32 	%f743, 0f3F800000;
	sub.f32 	%f744, %f743, %f37;
	mul.f32 	%f745, %f37, %f731;
	mul.f32 	%f746, %f37, %f732;
	mul.f32 	%f747, %f37, %f733;
	mul.f32 	%f748, %f37, %f734;
	fma.rn.f32 	%f1833, %f744, %f1833, %f745;
	fma.rn.f32 	%f1834, %f744, %f1834, %f746;
	fma.rn.f32 	%f1835, %f744, %f1835, %f747;
	fma.rn.f32 	%f1836, %f744, %f1836, %f748;
	mul.f32 	%f749, %f37, %f735;
	mul.f32 	%f750, %f37, %f736;
	mul.f32 	%f751, %f37, %f737;
	mul.f32 	%f752, %f37, %f738;
	fma.rn.f32 	%f1837, %f744, %f1837, %f749;
	fma.rn.f32 	%f1838, %f744, %f1838, %f750;
	fma.rn.f32 	%f1839, %f744, %f1839, %f751;
	fma.rn.f32 	%f1840, %f744, %f1840, %f752;
	mul.f32 	%f753, %f37, %f739;
	mul.f32 	%f754, %f37, %f740;
	mul.f32 	%f755, %f37, %f741;
	mul.f32 	%f756, %f37, %f742;
	fma.rn.f32 	%f1841, %f744, %f1841, %f753;
	fma.rn.f32 	%f757, %f744, %f1842, %f754;
	fma.rn.f32 	%f758, %f744, %f1843, %f755;
	fma.rn.f32 	%f759, %f744, %f1844, %f756;
	mov.b32 	 %f760, %r118;
	mov.b32 	 %f761, %r119;
	mov.b32 	 %f762, %r120;
	mov.b32 	 %f763, %r121;
	mul.f32 	%f764, %f37, %f760;
	mul.f32 	%f765, %f37, %f761;
	mul.f32 	%f766, %f37, %f762;
	mul.f32 	%f767, %f37, %f763;
	fma.rn.f32 	%f768, %f744, %f1845, %f764;
	fma.rn.f32 	%f1846, %f744, %f1846, %f765;
	fma.rn.f32 	%f1847, %f744, %f1847, %f766;
	fma.rn.f32 	%f1848, %f744, %f1848, %f767;
	mul.f32 	%f769, %f758, %f758;
	fma.rn.f32 	%f770, %f757, %f757, %f769;
	fma.rn.f32 	%f771, %f759, %f759, %f770;
	fma.rn.f32 	%f772, %f768, %f768, %f771;
	sqrt.rn.f32 	%f773, %f772;
	rcp.rn.f32 	%f774, %f773;
	mul.f32 	%f1842, %f757, %f774;
	mul.f32 	%f1843, %f758, %f774;
	mul.f32 	%f1844, %f759, %f774;
	mul.f32 	%f1845, %f768, %f774;

BB8_14:
	mul.f32 	%f775, %f1843, %f1843;
	fma.rn.f32 	%f776, %f1842, %f1842, %f775;
	fma.rn.f32 	%f777, %f1844, %f1844, %f776;
	fma.rn.f32 	%f778, %f1845, %f1845, %f777;
	rcp.rn.f32 	%f779, %f778;
	mul.f32 	%f780, %f1842, %f779;
	mul.f32 	%f781, %f1843, %f779;
	mul.f32 	%f782, %f1844, %f779;
	mul.f32 	%f783, %f1845, %f779;
	mul.f32 	%f784, %f1842, %f780;
	mul.f32 	%f785, %f1843, %f781;
	mul.f32 	%f786, %f1844, %f782;
	mul.f32 	%f787, %f1842, %f781;
	mul.f32 	%f788, %f1844, %f783;
	mul.f32 	%f789, %f1842, %f782;
	mul.f32 	%f790, %f1843, %f783;
	mul.f32 	%f791, %f1843, %f782;
	mul.f32 	%f792, %f1842, %f783;
	sub.f32 	%f793, %f784, %f785;
	sub.f32 	%f794, %f793, %f786;
	fma.rn.f32 	%f795, %f1845, %f783, %f794;
	sub.f32 	%f796, %f787, %f788;
	add.f32 	%f797, %f796, %f796;
	add.f32 	%f798, %f789, %f790;
	add.f32 	%f799, %f798, %f798;
	add.f32 	%f800, %f787, %f788;
	add.f32 	%f801, %f800, %f800;
	sub.f32 	%f802, %f785, %f784;
	sub.f32 	%f803, %f802, %f786;
	fma.rn.f32 	%f804, %f1845, %f783, %f803;
	sub.f32 	%f805, %f791, %f792;
	add.f32 	%f806, %f805, %f805;
	sub.f32 	%f807, %f789, %f790;
	add.f32 	%f808, %f807, %f807;
	add.f32 	%f809, %f791, %f792;
	add.f32 	%f810, %f809, %f809;
	neg.f32 	%f811, %f784;
	sub.f32 	%f812, %f811, %f785;
	add.f32 	%f813, %f786, %f812;
	fma.rn.f32 	%f814, %f1845, %f783, %f813;
	mul.f32 	%f815, %f1836, %f795;
	fma.rn.f32 	%f816, %f1839, %f797, %f815;
	fma.rn.f32 	%f817, %f1841, %f799, %f816;
	sub.f32 	%f1849, %f1846, %f817;
	mul.f32 	%f818, %f1839, %f804;
	fma.rn.f32 	%f819, %f1836, %f801, %f818;
	fma.rn.f32 	%f820, %f1841, %f806, %f819;
	sub.f32 	%f1853, %f1847, %f820;
	mul.f32 	%f821, %f1839, %f810;
	fma.rn.f32 	%f822, %f1836, %f808, %f821;
	fma.rn.f32 	%f823, %f1841, %f814, %f822;
	sub.f32 	%f1857, %f1848, %f823;
	mul.f32 	%f824, %f1835, %f795;
	fma.rn.f32 	%f825, %f1838, %f797, %f824;
	fma.rn.f32 	%f1850, %f1840, %f799, %f825;
	mul.f32 	%f826, %f1838, %f804;
	fma.rn.f32 	%f827, %f1835, %f801, %f826;
	fma.rn.f32 	%f1854, %f1840, %f806, %f827;
	mul.f32 	%f828, %f1838, %f810;
	fma.rn.f32 	%f829, %f1835, %f808, %f828;
	fma.rn.f32 	%f1858, %f1840, %f814, %f829;
	mul.f32 	%f830, %f1834, %f795;
	fma.rn.f32 	%f1851, %f1837, %f797, %f830;
	mul.f32 	%f831, %f1837, %f804;
	fma.rn.f32 	%f1855, %f1834, %f801, %f831;
	mul.f32 	%f832, %f1837, %f810;
	fma.rn.f32 	%f1859, %f1834, %f808, %f832;
	mul.f32 	%f1852, %f1833, %f795;
	mul.f32 	%f1856, %f1833, %f801;
	mul.f32 	%f1860, %f1833, %f808;

BB8_17:
	mul.f32 	%f870, %f1854, %f1859;
	mul.f32 	%f871, %f1855, %f1858;
	sub.f32 	%f872, %f871, %f870;
	mul.f32 	%f873, %f1852, %f872;
	mul.f32 	%f874, %f1854, %f1860;
	mul.f32 	%f875, %f1856, %f1858;
	sub.f32 	%f876, %f875, %f874;
	mul.f32 	%f877, %f1851, %f876;
	sub.f32 	%f878, %f873, %f877;
	mul.f32 	%f879, %f1855, %f1860;
	mul.f32 	%f880, %f1856, %f1859;
	sub.f32 	%f881, %f880, %f879;
	fma.rn.f32 	%f882, %f1850, %f881, %f878;
	rcp.rn.f32 	%f883, %f882;
	mul.f32 	%f1864, %f883, %f872;
	mul.f32 	%f884, %f1851, %f1858;
	mul.f32 	%f885, %f1850, %f1859;
	sub.f32 	%f886, %f885, %f884;
	mul.f32 	%f1863, %f883, %f886;
	mul.f32 	%f887, %f1850, %f1855;
	mul.f32 	%f888, %f1851, %f1854;
	sub.f32 	%f889, %f888, %f887;
	mul.f32 	%f1862, %f889, %f883;
	sub.f32 	%f890, %f874, %f875;
	mul.f32 	%f1868, %f883, %f890;
	mul.f32 	%f891, %f1850, %f1860;
	mul.f32 	%f892, %f1852, %f1858;
	sub.f32 	%f893, %f892, %f891;
	mul.f32 	%f1867, %f883, %f893;
	mul.f32 	%f894, %f1852, %f1854;
	mul.f32 	%f895, %f1850, %f1856;
	sub.f32 	%f896, %f895, %f894;
	mul.f32 	%f1866, %f896, %f883;
	mul.f32 	%f1872, %f883, %f881;
	mul.f32 	%f897, %f1852, %f1859;
	mul.f32 	%f898, %f1851, %f1860;
	sub.f32 	%f899, %f898, %f897;
	mul.f32 	%f1871, %f883, %f899;
	mul.f32 	%f900, %f1851, %f1856;
	mul.f32 	%f901, %f1852, %f1855;
	sub.f32 	%f902, %f901, %f900;
	mul.f32 	%f1870, %f902, %f883;
	mul.f32 	%f903, %f1849, %f1864;
	neg.f32 	%f904, %f903;
	mul.f32 	%f905, %f1853, %f1863;
	sub.f32 	%f906, %f904, %f905;
	mul.f32 	%f907, %f1857, %f1862;
	sub.f32 	%f1861, %f906, %f907;
	mul.f32 	%f908, %f1849, %f1868;
	neg.f32 	%f909, %f908;
	mul.f32 	%f910, %f1853, %f1867;
	sub.f32 	%f911, %f909, %f910;
	mul.f32 	%f912, %f1857, %f1866;
	sub.f32 	%f1865, %f911, %f912;
	mul.f32 	%f913, %f1849, %f1872;
	neg.f32 	%f914, %f913;
	mul.f32 	%f915, %f1853, %f1871;
	sub.f32 	%f916, %f914, %f915;
	mul.f32 	%f917, %f1857, %f1870;
	sub.f32 	%f1869, %f916, %f917;
	bra.uni 	BB8_18;

BB8_7:
	setp.ne.s32	%p5, %r33, 1;
	mov.f32 	%f1862, %f1861;
	mov.f32 	%f1863, %f1861;
	mov.f32 	%f1865, %f1861;
	mov.f32 	%f1866, %f1861;
	mov.f32 	%f1867, %f1864;
	mov.f32 	%f1868, %f1861;
	mov.f32 	%f1869, %f1861;
	mov.f32 	%f1870, %f1864;
	mov.f32 	%f1871, %f1861;
	mov.f32 	%f1872, %f1861;
	@%p5 bra 	BB8_18;

	// inline asm
	call (%rd54), _optix_get_static_transform_from_handle, (%rd52);
	// inline asm
	add.s64 	%rd662, %rd54, 64;

BB8_10:
	// inline asm
	cvta.to.global.u64 %rd58, %rd662;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd58];
	// inline asm
	mov.b32 	 %f1864, %r35;
	mov.b32 	 %f1863, %r36;
	mov.b32 	 %f1862, %r37;
	mov.b32 	 %f1861, %r38;
	add.s64 	%rd62, %rd662, 16;
	// inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd61];
	// inline asm
	mov.b32 	 %f1868, %r39;
	mov.b32 	 %f1867, %r40;
	mov.b32 	 %f1866, %r41;
	mov.b32 	 %f1865, %r42;
	add.s64 	%rd65, %rd662, 32;
	// inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd64];
	// inline asm
	mov.b32 	 %f1872, %r43;
	mov.b32 	 %f1871, %r44;
	mov.b32 	 %f1870, %r45;
	mov.b32 	 %f1869, %r46;

BB8_18:
	setp.eq.s32	%p9, %r646, 0;
	@%p9 bra 	BB8_19;
	bra.uni 	BB8_20;

BB8_19:
	mov.f32 	%f1832, %f1861;
	mov.f32 	%f1831, %f1862;
	mov.f32 	%f1830, %f1863;
	mov.f32 	%f1829, %f1864;
	mov.f32 	%f1828, %f1865;
	mov.f32 	%f1827, %f1866;
	mov.f32 	%f1826, %f1867;
	mov.f32 	%f1825, %f1868;
	mov.f32 	%f1824, %f1869;
	mov.f32 	%f1823, %f1870;
	mov.f32 	%f1822, %f1871;
	mov.f32 	%f1821, %f1872;
	bra.uni 	BB8_21;

BB8_20:
	mul.f32 	%f918, %f1829, %f1864;
	fma.rn.f32 	%f919, %f1825, %f1863, %f918;
	fma.rn.f32 	%f151, %f1821, %f1862, %f919;
	mul.f32 	%f920, %f1830, %f1864;
	fma.rn.f32 	%f921, %f1826, %f1863, %f920;
	fma.rn.f32 	%f152, %f1822, %f1862, %f921;
	mul.f32 	%f922, %f1831, %f1864;
	fma.rn.f32 	%f923, %f1827, %f1863, %f922;
	fma.rn.f32 	%f153, %f1823, %f1862, %f923;
	mul.f32 	%f924, %f1832, %f1864;
	fma.rn.f32 	%f925, %f1828, %f1863, %f924;
	fma.rn.f32 	%f926, %f1824, %f1862, %f925;
	add.f32 	%f154, %f1861, %f926;
	mul.f32 	%f927, %f1829, %f1868;
	fma.rn.f32 	%f928, %f1825, %f1867, %f927;
	fma.rn.f32 	%f155, %f1821, %f1866, %f928;
	mul.f32 	%f929, %f1830, %f1868;
	fma.rn.f32 	%f930, %f1826, %f1867, %f929;
	fma.rn.f32 	%f156, %f1822, %f1866, %f930;
	mul.f32 	%f931, %f1831, %f1868;
	fma.rn.f32 	%f932, %f1827, %f1867, %f931;
	fma.rn.f32 	%f157, %f1823, %f1866, %f932;
	mul.f32 	%f933, %f1832, %f1868;
	fma.rn.f32 	%f934, %f1828, %f1867, %f933;
	fma.rn.f32 	%f935, %f1824, %f1866, %f934;
	add.f32 	%f158, %f1865, %f935;
	mul.f32 	%f936, %f1829, %f1872;
	fma.rn.f32 	%f937, %f1825, %f1871, %f936;
	fma.rn.f32 	%f1821, %f1821, %f1870, %f937;
	mul.f32 	%f938, %f1830, %f1872;
	fma.rn.f32 	%f939, %f1826, %f1871, %f938;
	fma.rn.f32 	%f1822, %f1822, %f1870, %f939;
	mul.f32 	%f940, %f1831, %f1872;
	fma.rn.f32 	%f941, %f1827, %f1871, %f940;
	fma.rn.f32 	%f1823, %f1823, %f1870, %f941;
	mul.f32 	%f942, %f1832, %f1872;
	fma.rn.f32 	%f943, %f1828, %f1871, %f942;
	fma.rn.f32 	%f944, %f1824, %f1870, %f943;
	add.f32 	%f1824, %f1869, %f944;
	mov.f32 	%f1832, %f154;
	mov.f32 	%f1831, %f153;
	mov.f32 	%f1830, %f152;
	mov.f32 	%f1829, %f151;
	mov.f32 	%f1828, %f158;
	mov.f32 	%f1827, %f157;
	mov.f32 	%f1826, %f156;
	mov.f32 	%f1825, %f155;

BB8_21:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32	%p10, %r646, %r30;
	@%p10 bra 	BB8_5;

	mul.f32 	%f945, %f703, %f1829;
	fma.rn.f32 	%f946, %f704, %f1830, %f945;
	fma.rn.f32 	%f947, %f1885, %f1831, %f946;
	add.f32 	%f1887, %f1832, %f947;
	mul.f32 	%f948, %f703, %f1825;
	fma.rn.f32 	%f949, %f704, %f1826, %f948;
	fma.rn.f32 	%f950, %f1885, %f1827, %f949;
	add.f32 	%f1886, %f1828, %f950;
	mul.f32 	%f951, %f703, %f1821;
	fma.rn.f32 	%f952, %f704, %f1822, %f951;
	fma.rn.f32 	%f953, %f1885, %f1823, %f952;
	add.f32 	%f1885, %f1824, %f953;
	bra.uni 	BB8_23;

BB8_3:
	mov.f32 	%f1886, %f704;
	mov.f32 	%f1887, %f703;

BB8_23:
	// inline asm
	call (%f954), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f955), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1936), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f957), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r647, 0;
	@%p2 bra 	BB8_24;

BB8_25:
	.pragma "nounroll";
	// inline asm
	call (%rd173), _optix_get_transform_list_handle, (%r647);
	// inline asm
	// inline asm
	call (%r183), _optix_get_transform_type_from_handle, (%rd173);
	// inline asm
	and.b32  	%r184, %r183, -2;
	setp.eq.s32	%p12, %r184, 2;
	@%p12 bra 	BB8_31;
	bra.uni 	BB8_26;

BB8_31:
	setp.eq.s32	%p15, %r183, 2;
	@%p15 bra 	BB8_35;
	bra.uni 	BB8_32;

BB8_35:
	// inline asm
	call (%rd247), _optix_get_matrix_motion_transform_from_handle, (%rd173);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd249, %rd247;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd249];
	// inline asm
	mov.b32	{%rs9, %rs10}, %r274;
	add.s64 	%rd253, %rd247, 16;
	// inline asm
	cvta.to.global.u64 %rd252, %rd253;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd252];
	// inline asm
	add.s64 	%rd256, %rd247, 32;
	// inline asm
	cvta.to.global.u64 %rd255, %rd256;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd255];
	// inline asm
	add.s64 	%rd259, %rd247, 48;
	// inline asm
	cvta.to.global.u64 %rd258, %rd259;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd258];
	// inline asm
	add.s64 	%rd262, %rd247, 64;
	// inline asm
	cvta.to.global.u64 %rd261, %rd262;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd261];
	// inline asm
	add.s64 	%rd265, %rd247, 80;
	// inline asm
	cvta.to.global.u64 %rd264, %rd265;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd264];
	// inline asm
	add.s64 	%rd268, %rd247, 96;
	// inline asm
	cvta.to.global.u64 %rd267, %rd268;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd267];
	// inline asm
	add.s64 	%rd271, %rd247, 112;
	// inline asm
	cvta.to.global.u64 %rd270, %rd271;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r300,%r301,%r302,%r303}, [%rd270];
	// inline asm
	mov.b32 	 %f1060, %r275;
	mov.b32 	 %f1061, %r276;
	cvt.u32.u16	%r316, %rs9;
	add.s32 	%r317, %r316, -1;
	cvt.rn.f32.s32	%f1062, %r317;
	sub.f32 	%f1063, %f957, %f1060;
	mul.f32 	%f1064, %f1063, %f1062;
	sub.f32 	%f1065, %f1061, %f1060;
	div.rn.f32 	%f1066, %f1064, %f1065;
	min.f32 	%f1067, %f1062, %f1066;
	mov.f32 	%f1068, 0f00000000;
	max.f32 	%f1069, %f1068, %f1067;
	cvt.rmi.f32.f32	%f1070, %f1069;
	cvt.rzi.s32.f32	%r318, %f1070;
	cvt.s64.s32	%rd19, %r318;
	mul.wide.s32 	%rd282, %r318, 48;
	add.s64 	%rd274, %rd256, %rd282;
	// inline asm
	cvta.to.global.u64 %rd273, %rd274;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r304,%r305,%r306,%r307}, [%rd273];
	// inline asm
	mov.b32 	 %f1913, %r304;
	mov.b32 	 %f1914, %r305;
	mov.b32 	 %f1915, %r306;
	add.s64 	%rd277, %rd274, 16;
	// inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r308,%r309,%r310,%r311}, [%rd276];
	// inline asm
	mov.b32 	 %f1910, %r308;
	mov.b32 	 %f1911, %r309;
	mov.b32 	 %f1912, %r310;
	add.s64 	%rd280, %rd274, 32;
	// inline asm
	cvta.to.global.u64 %rd279, %rd280;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r312,%r313,%r314,%r315}, [%rd279];
	// inline asm
	sub.f32 	%f249, %f1069, %f1070;
	mov.b32 	 %f1907, %r312;
	mov.b32 	 %f1908, %r313;
	mov.b32 	 %f1909, %r314;
	setp.leu.f32	%p17, %f249, 0f00000000;
	@%p17 bra 	BB8_37;

	mul.lo.s64 	%rd292, %rd19, 48;
	add.s64 	%rd293, %rd247, %rd292;
	add.s64 	%rd284, %rd293, 80;
	// inline asm
	cvta.to.global.u64 %rd283, %rd284;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd283];
	// inline asm
	mov.b32 	 %f1071, %r319;
	mov.b32 	 %f1072, %r320;
	mov.b32 	 %f1073, %r321;
	add.s64 	%rd287, %rd293, 96;
	// inline asm
	cvta.to.global.u64 %rd286, %rd287;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r323,%r324,%r325,%r326}, [%rd286];
	// inline asm
	mov.b32 	 %f1074, %r323;
	mov.b32 	 %f1075, %r324;
	mov.b32 	 %f1076, %r325;
	add.s64 	%rd290, %rd293, 112;
	// inline asm
	cvta.to.global.u64 %rd289, %rd290;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r327,%r328,%r329,%r330}, [%rd289];
	// inline asm
	mov.f32 	%f1077, 0f3F800000;
	sub.f32 	%f1078, %f1077, %f249;
	mul.f32 	%f1079, %f249, %f1071;
	mul.f32 	%f1080, %f249, %f1072;
	mul.f32 	%f1081, %f249, %f1073;
	fma.rn.f32 	%f1913, %f1078, %f1913, %f1079;
	fma.rn.f32 	%f1914, %f1078, %f1914, %f1080;
	fma.rn.f32 	%f1915, %f1078, %f1915, %f1081;
	mul.f32 	%f1082, %f249, %f1074;
	mul.f32 	%f1083, %f249, %f1075;
	mul.f32 	%f1084, %f249, %f1076;
	fma.rn.f32 	%f1910, %f1078, %f1910, %f1082;
	fma.rn.f32 	%f1911, %f1078, %f1911, %f1083;
	fma.rn.f32 	%f1912, %f1078, %f1912, %f1084;
	mov.b32 	 %f1085, %r327;
	mov.b32 	 %f1086, %r328;
	mov.b32 	 %f1087, %r329;
	mul.f32 	%f1088, %f249, %f1085;
	mul.f32 	%f1089, %f249, %f1086;
	mul.f32 	%f1090, %f249, %f1087;
	fma.rn.f32 	%f1907, %f1078, %f1907, %f1088;
	fma.rn.f32 	%f1908, %f1078, %f1908, %f1089;
	fma.rn.f32 	%f1909, %f1078, %f1909, %f1090;
	bra.uni 	BB8_37;

BB8_26:
	mov.f32 	%f1916, 0f00000000;
	mov.f32 	%f1918, 0f3F800000;
	setp.eq.s32	%p13, %r183, 4;
	@%p13 bra 	BB8_29;
	bra.uni 	BB8_27;

BB8_29:
	// inline asm
	call (%rd663), _optix_get_instance_inverse_transform_from_handle, (%rd173);
	// inline asm
	bra.uni 	BB8_30;

BB8_32:
	// inline asm
	call (%rd188), _optix_get_srt_motion_transform_from_handle, (%rd173);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd190, %rd188;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd190];
	// inline asm
	mov.b32	{%rs7, %rs8}, %r199;
	add.s64 	%rd194, %rd188, 16;
	// inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd193];
	// inline asm
	add.s64 	%rd197, %rd188, 32;
	// inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd196];
	// inline asm
	add.s64 	%rd200, %rd188, 48;
	// inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd199];
	// inline asm
	add.s64 	%rd203, %rd188, 64;
	// inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd202];
	// inline asm
	add.s64 	%rd206, %rd188, 80;
	// inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd205];
	// inline asm
	add.s64 	%rd209, %rd188, 96;
	// inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd208];
	// inline asm
	add.s64 	%rd212, %rd188, 112;
	// inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd211];
	// inline asm
	add.s64 	%rd215, %rd188, 128;
	// inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd214];
	// inline asm
	add.s64 	%rd218, %rd188, 144;
	// inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd217];
	// inline asm
	mov.b32 	 %f968, %r200;
	mov.b32 	 %f969, %r201;
	cvt.u32.u16	%r253, %rs7;
	add.s32 	%r254, %r253, -1;
	cvt.rn.f32.s32	%f970, %r254;
	sub.f32 	%f971, %f957, %f968;
	mul.f32 	%f972, %f971, %f970;
	sub.f32 	%f973, %f969, %f968;
	div.rn.f32 	%f974, %f972, %f973;
	min.f32 	%f975, %f970, %f974;
	mov.f32 	%f976, 0f00000000;
	max.f32 	%f977, %f976, %f975;
	cvt.rmi.f32.f32	%f978, %f977;
	cvt.rzi.s32.f32	%r255, %f978;
	cvt.s64.s32	%rd17, %r255;
	mul.wide.s32 	%rd232, %r255, 64;
	add.s64 	%rd221, %rd197, %rd232;
	// inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r237,%r238,%r239,%r240}, [%rd220];
	// inline asm
	mov.b32 	 %f1897, %r237;
	mov.b32 	 %f1898, %r238;
	mov.b32 	 %f1899, %r239;
	add.s64 	%rd224, %rd221, 16;
	// inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r241,%r242,%r243,%r244}, [%rd223];
	// inline asm
	mov.b32 	 %f1900, %r241;
	mov.b32 	 %f1901, %r242;
	mov.b32 	 %f1902, %r244;
	add.s64 	%rd227, %rd221, 32;
	// inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r245,%r246,%r247,%r248}, [%rd226];
	// inline asm
	sub.f32 	%f209, %f977, %f978;
	mov.b32 	 %f1903, %r246;
	mov.b32 	 %f1904, %r247;
	mov.b32 	 %f1905, %r248;
	add.s64 	%rd230, %rd221, 48;
	// inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r249,%r250,%r251,%r252}, [%rd229];
	// inline asm
	mov.b32 	 %f1906, %r249;
	setp.leu.f32	%p16, %f209, 0f00000000;
	@%p16 bra 	BB8_34;

	shl.b64 	%rd245, %rd17, 6;
	add.s64 	%rd246, %rd245, %rd188;
	add.s64 	%rd234, %rd246, 96;
	// inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd233];
	// inline asm
	mov.b32 	 %f979, %r256;
	mov.b32 	 %f980, %r257;
	mov.b32 	 %f981, %r258;
	add.s64 	%rd237, %rd246, 112;
	// inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd236];
	// inline asm
	mov.b32 	 %f982, %r260;
	mov.b32 	 %f983, %r261;
	mov.b32 	 %f984, %r263;
	add.s64 	%rd240, %rd246, 128;
	// inline asm
	cvta.to.global.u64 %rd239, %rd240;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd239];
	// inline asm
	mov.b32 	 %f985, %r265;
	mov.b32 	 %f986, %r266;
	mov.b32 	 %f987, %r267;
	add.s64 	%rd243, %rd246, 144;
	// inline asm
	cvta.to.global.u64 %rd242, %rd243;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd242];
	// inline asm
	mov.f32 	%f988, 0f3F800000;
	sub.f32 	%f989, %f988, %f209;
	mul.f32 	%f990, %f209, %f979;
	mul.f32 	%f991, %f209, %f980;
	mul.f32 	%f992, %f209, %f981;
	fma.rn.f32 	%f1897, %f989, %f1897, %f990;
	fma.rn.f32 	%f1898, %f989, %f1898, %f991;
	fma.rn.f32 	%f1899, %f989, %f1899, %f992;
	mul.f32 	%f993, %f209, %f982;
	mul.f32 	%f994, %f209, %f983;
	mul.f32 	%f995, %f209, %f984;
	fma.rn.f32 	%f1900, %f989, %f1900, %f993;
	fma.rn.f32 	%f1901, %f989, %f1901, %f994;
	fma.rn.f32 	%f1902, %f989, %f1902, %f995;
	mul.f32 	%f996, %f209, %f985;
	mul.f32 	%f997, %f209, %f986;
	mul.f32 	%f998, %f209, %f987;
	fma.rn.f32 	%f999, %f989, %f1903, %f996;
	fma.rn.f32 	%f1000, %f989, %f1904, %f997;
	fma.rn.f32 	%f1001, %f989, %f1905, %f998;
	mov.b32 	 %f1002, %r268;
	mul.f32 	%f1003, %f209, %f1002;
	fma.rn.f32 	%f1004, %f989, %f1906, %f1003;
	mul.f32 	%f1005, %f1000, %f1000;
	fma.rn.f32 	%f1006, %f999, %f999, %f1005;
	fma.rn.f32 	%f1007, %f1001, %f1001, %f1006;
	fma.rn.f32 	%f1008, %f1004, %f1004, %f1007;
	sqrt.rn.f32 	%f1009, %f1008;
	rcp.rn.f32 	%f1010, %f1009;
	mul.f32 	%f1903, %f999, %f1010;
	mul.f32 	%f1904, %f1000, %f1010;
	mul.f32 	%f1905, %f1001, %f1010;
	mul.f32 	%f1906, %f1004, %f1010;

BB8_34:
	mul.f32 	%f1011, %f1904, %f1904;
	fma.rn.f32 	%f1012, %f1903, %f1903, %f1011;
	fma.rn.f32 	%f1013, %f1905, %f1905, %f1012;
	fma.rn.f32 	%f1014, %f1906, %f1906, %f1013;
	rcp.rn.f32 	%f1015, %f1014;
	mul.f32 	%f1016, %f1903, %f1015;
	mul.f32 	%f1017, %f1904, %f1015;
	mul.f32 	%f1018, %f1905, %f1015;
	mul.f32 	%f1019, %f1906, %f1015;
	mul.f32 	%f1020, %f1903, %f1016;
	mul.f32 	%f1021, %f1904, %f1017;
	mul.f32 	%f1022, %f1905, %f1018;
	mul.f32 	%f1023, %f1903, %f1017;
	mul.f32 	%f1024, %f1905, %f1019;
	mul.f32 	%f1025, %f1903, %f1018;
	mul.f32 	%f1026, %f1904, %f1019;
	mul.f32 	%f1027, %f1904, %f1018;
	mul.f32 	%f1028, %f1903, %f1019;
	sub.f32 	%f1029, %f1020, %f1021;
	sub.f32 	%f1030, %f1029, %f1022;
	fma.rn.f32 	%f1031, %f1906, %f1019, %f1030;
	sub.f32 	%f1032, %f1023, %f1024;
	add.f32 	%f1033, %f1032, %f1032;
	add.f32 	%f1034, %f1025, %f1026;
	add.f32 	%f1035, %f1034, %f1034;
	add.f32 	%f1036, %f1023, %f1024;
	add.f32 	%f1037, %f1036, %f1036;
	sub.f32 	%f1038, %f1021, %f1020;
	sub.f32 	%f1039, %f1038, %f1022;
	fma.rn.f32 	%f1040, %f1906, %f1019, %f1039;
	sub.f32 	%f1041, %f1027, %f1028;
	add.f32 	%f1042, %f1041, %f1041;
	sub.f32 	%f1043, %f1025, %f1026;
	add.f32 	%f1044, %f1043, %f1043;
	add.f32 	%f1045, %f1027, %f1028;
	add.f32 	%f1046, %f1045, %f1045;
	neg.f32 	%f1047, %f1020;
	sub.f32 	%f1048, %f1047, %f1021;
	add.f32 	%f1049, %f1022, %f1048;
	fma.rn.f32 	%f1050, %f1906, %f1019, %f1049;
	mul.f32 	%f1051, %f1899, %f1031;
	fma.rn.f32 	%f1052, %f1901, %f1033, %f1051;
	fma.rn.f32 	%f1915, %f1902, %f1035, %f1052;
	mul.f32 	%f1053, %f1901, %f1040;
	fma.rn.f32 	%f1054, %f1899, %f1037, %f1053;
	fma.rn.f32 	%f1912, %f1902, %f1042, %f1054;
	mul.f32 	%f1055, %f1901, %f1046;
	fma.rn.f32 	%f1056, %f1899, %f1044, %f1055;
	fma.rn.f32 	%f1909, %f1902, %f1050, %f1056;
	mul.f32 	%f1057, %f1898, %f1031;
	fma.rn.f32 	%f1914, %f1900, %f1033, %f1057;
	mul.f32 	%f1058, %f1900, %f1040;
	fma.rn.f32 	%f1911, %f1898, %f1037, %f1058;
	mul.f32 	%f1059, %f1900, %f1046;
	fma.rn.f32 	%f1908, %f1898, %f1044, %f1059;
	mul.f32 	%f1913, %f1897, %f1031;
	mul.f32 	%f1910, %f1897, %f1037;
	mul.f32 	%f1907, %f1897, %f1044;

BB8_37:
	mul.f32 	%f1091, %f1908, %f1912;
	mul.f32 	%f1092, %f1909, %f1911;
	sub.f32 	%f1093, %f1092, %f1091;
	mul.f32 	%f1094, %f1913, %f1093;
	mul.f32 	%f1095, %f1907, %f1912;
	mul.f32 	%f1096, %f1909, %f1910;
	sub.f32 	%f1097, %f1096, %f1095;
	mul.f32 	%f1098, %f1097, %f1914;
	sub.f32 	%f1099, %f1094, %f1098;
	mul.f32 	%f1100, %f1907, %f1911;
	mul.f32 	%f1101, %f1908, %f1910;
	sub.f32 	%f1102, %f1101, %f1100;
	fma.rn.f32 	%f1103, %f1102, %f1915, %f1099;
	rcp.rn.f32 	%f1104, %f1103;
	mul.f32 	%f1922, %f1093, %f1104;
	mul.f32 	%f1105, %f1909, %f1914;
	mul.f32 	%f1106, %f1908, %f1915;
	sub.f32 	%f1107, %f1106, %f1105;
	mul.f32 	%f1923, %f1104, %f1107;
	mul.f32 	%f1108, %f1911, %f1915;
	mul.f32 	%f1109, %f1912, %f1914;
	sub.f32 	%f1110, %f1109, %f1108;
	mul.f32 	%f1924, %f1104, %f1110;
	sub.f32 	%f1111, %f1095, %f1096;
	mul.f32 	%f1919, %f1111, %f1104;
	mul.f32 	%f1112, %f1907, %f1915;
	mul.f32 	%f1113, %f1909, %f1913;
	sub.f32 	%f1114, %f1113, %f1112;
	mul.f32 	%f1920, %f1104, %f1114;
	mul.f32 	%f1115, %f1912, %f1913;
	mul.f32 	%f1116, %f1910, %f1915;
	sub.f32 	%f1117, %f1116, %f1115;
	mul.f32 	%f1921, %f1104, %f1117;
	mul.f32 	%f1916, %f1102, %f1104;
	mul.f32 	%f1118, %f1908, %f1913;
	mul.f32 	%f1119, %f1907, %f1914;
	sub.f32 	%f1120, %f1119, %f1118;
	mul.f32 	%f1917, %f1120, %f1104;
	mul.f32 	%f1121, %f1910, %f1914;
	mul.f32 	%f1122, %f1911, %f1913;
	sub.f32 	%f1123, %f1122, %f1121;
	mul.f32 	%f1918, %f1123, %f1104;
	bra.uni 	BB8_38;

BB8_27:
	setp.ne.s32	%p14, %r183, 1;
	mov.f32 	%f1917, %f1916;
	mov.f32 	%f1919, %f1916;
	mov.f32 	%f1920, %f1918;
	mov.f32 	%f1921, %f1916;
	mov.f32 	%f1922, %f1918;
	mov.f32 	%f1923, %f1916;
	mov.f32 	%f1924, %f1916;
	@%p14 bra 	BB8_38;

	// inline asm
	call (%rd175), _optix_get_static_transform_from_handle, (%rd173);
	// inline asm
	add.s64 	%rd663, %rd175, 64;

BB8_30:
	// inline asm
	cvta.to.global.u64 %rd179, %rd663;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd179];
	// inline asm
	mov.b32 	 %f1922, %r185;
	mov.b32 	 %f1923, %r186;
	mov.b32 	 %f1924, %r187;
	add.s64 	%rd183, %rd663, 16;
	// inline asm
	cvta.to.global.u64 %rd182, %rd183;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd182];
	// inline asm
	mov.b32 	 %f1919, %r189;
	mov.b32 	 %f1920, %r190;
	mov.b32 	 %f1921, %r191;
	add.s64 	%rd186, %rd663, 32;
	// inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd185];
	// inline asm
	mov.b32 	 %f1916, %r193;
	mov.b32 	 %f1917, %r194;
	mov.b32 	 %f1918, %r195;

BB8_38:
	setp.eq.s32	%p18, %r647, 0;
	@%p18 bra 	BB8_39;
	bra.uni 	BB8_40;

BB8_39:
	mov.f32 	%f1896, %f1916;
	mov.f32 	%f1895, %f1917;
	mov.f32 	%f1894, %f1918;
	mov.f32 	%f1893, %f1919;
	mov.f32 	%f1892, %f1920;
	mov.f32 	%f1891, %f1921;
	mov.f32 	%f1890, %f1922;
	mov.f32 	%f1889, %f1923;
	mov.f32 	%f1888, %f1924;
	bra.uni 	BB8_41;

BB8_40:
	mul.f32 	%f1124, %f1893, %f1923;
	fma.rn.f32 	%f1125, %f1890, %f1922, %f1124;
	fma.rn.f32 	%f289, %f1896, %f1924, %f1125;
	mul.f32 	%f1126, %f1892, %f1923;
	fma.rn.f32 	%f1127, %f1889, %f1922, %f1126;
	fma.rn.f32 	%f290, %f1895, %f1924, %f1127;
	mul.f32 	%f1128, %f1891, %f1923;
	fma.rn.f32 	%f1129, %f1888, %f1922, %f1128;
	fma.rn.f32 	%f291, %f1894, %f1924, %f1129;
	mul.f32 	%f1130, %f1893, %f1920;
	fma.rn.f32 	%f1131, %f1890, %f1919, %f1130;
	fma.rn.f32 	%f292, %f1896, %f1921, %f1131;
	mul.f32 	%f1132, %f1892, %f1920;
	fma.rn.f32 	%f1133, %f1889, %f1919, %f1132;
	fma.rn.f32 	%f293, %f1895, %f1921, %f1133;
	mul.f32 	%f1134, %f1891, %f1920;
	fma.rn.f32 	%f1135, %f1888, %f1919, %f1134;
	fma.rn.f32 	%f294, %f1894, %f1921, %f1135;
	mul.f32 	%f1136, %f1893, %f1917;
	fma.rn.f32 	%f1137, %f1890, %f1916, %f1136;
	fma.rn.f32 	%f1896, %f1896, %f1918, %f1137;
	mul.f32 	%f1138, %f1892, %f1917;
	fma.rn.f32 	%f1139, %f1889, %f1916, %f1138;
	fma.rn.f32 	%f1895, %f1895, %f1918, %f1139;
	mul.f32 	%f1140, %f1891, %f1917;
	fma.rn.f32 	%f1141, %f1888, %f1916, %f1140;
	fma.rn.f32 	%f1894, %f1894, %f1918, %f1141;
	mov.f32 	%f1893, %f292;
	mov.f32 	%f1892, %f293;
	mov.f32 	%f1891, %f294;
	mov.f32 	%f1890, %f289;
	mov.f32 	%f1889, %f290;
	mov.f32 	%f1888, %f291;

BB8_41:
	add.s32 	%r647, %r647, 1;
	setp.lt.u32	%p19, %r647, %r30;
	@%p19 bra 	BB8_25;

	mul.f32 	%f1142, %f955, %f1889;
	fma.rn.f32 	%f1143, %f954, %f1890, %f1142;
	fma.rn.f32 	%f1934, %f1936, %f1888, %f1143;
	mul.f32 	%f1144, %f955, %f1892;
	fma.rn.f32 	%f1145, %f954, %f1893, %f1144;
	fma.rn.f32 	%f1935, %f1936, %f1891, %f1145;
	mul.f32 	%f1146, %f955, %f1895;
	fma.rn.f32 	%f1147, %f954, %f1896, %f1146;
	fma.rn.f32 	%f1936, %f1936, %f1894, %f1147;
	bra.uni 	BB8_43;

BB8_24:
	mov.f32 	%f1934, %f954;
	mov.f32 	%f1935, %f955;

BB8_43:
	// inline asm
	call (%f1149), _optix_get_ray_tmax, ();
	// inline asm
	ld.const.u64 	%rd294, [params+80];
	setp.eq.s64	%p20, %rd294, 0;
	@%p20 bra 	BB8_48;

	ld.u64 	%rd295, [%rd51];
	ld.const.u64 	%rd296, [params+328];
	cvta.to.global.u64 	%rd297, %rd296;
	cvt.u64.u32	%rd20, %r1;
	mul.wide.u32 	%rd298, %r1, 8;
	add.s64 	%rd299, %rd297, %rd298;
	st.global.u64 	[%rd299], %rd295;
	ld.const.u64 	%rd300, [params+336];
	cvta.to.global.u64 	%rd301, %rd300;
	mul.wide.u32 	%rd302, %r1, 4;
	add.s64 	%rd303, %rd301, %rd302;
	mov.u32 	%r331, 0;
	st.global.u32 	[%rd303], %r331;
	ld.const.u64 	%rd304, [params+344];
	cvta.to.global.u64 	%rd305, %rd304;
	add.s64 	%rd21, %rd305, %rd302;
	ld.global.u32 	%r9, [%rd21];
	setp.eq.s32	%p21, %r9, 0;
	@%p21 bra 	BB8_47;

	// inline asm
	call (%r332), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p22, %r332, %r9;
	@%p22 bra 	BB8_47;

	st.global.u32 	[%rd21], %r332;

BB8_47:
	ld.const.u64 	%rd306, [params+72];
	cvta.to.global.u64 	%rd307, %rd306;
	shl.b64 	%rd308, %rd20, 2;
	add.s64 	%rd309, %rd307, %rd308;
	st.global.f32 	[%rd309], %f1149;
	bra.uni 	BB8_116;

BB8_48:
	fma.rn.f32 	%f1151, %f1149, %f1934, %f1887;
	ld.f32 	%f1152, [%rd3+288];
	sub.f32 	%f1153, %f1151, %f1152;
	ld.f32 	%f1154, [%rd3+292];
	fma.rn.f32 	%f1155, %f1149, %f1935, %f1886;
	sub.f32 	%f1156, %f1155, %f1154;
	ld.f32 	%f1157, [%rd3+296];
	fma.rn.f32 	%f1158, %f1149, %f1936, %f1885;
	sub.f32 	%f1159, %f1158, %f1157;
	mul.f32 	%f1160, %f1153, %f1153;
	fma.rn.f32 	%f1161, %f1156, %f1156, %f1160;
	fma.rn.f32 	%f1162, %f1159, %f1159, %f1161;
	sqrt.rn.f32 	%f1163, %f1162;
	div.rn.f32 	%f1164, %f1153, %f1163;
	div.rn.f32 	%f1165, %f1156, %f1163;
	div.rn.f32 	%f1166, %f1159, %f1163;
	ld.u8 	%rs1, [%rd3+308];
	setp.eq.s16	%p23, %rs1, 0;
	neg.f32 	%f1167, %f1164;
	neg.f32 	%f1168, %f1165;
	neg.f32 	%f1169, %f1166;
	selp.f32	%f2100, %f1166, %f1169, %p23;
	selp.f32	%f2099, %f1165, %f1168, %p23;
	selp.f32	%f2098, %f1164, %f1167, %p23;
	ld.f32 	%f317, [%rd3+304];
	fma.rn.f32 	%f2101, %f317, %f2098, %f1152;
	fma.rn.f32 	%f2102, %f317, %f2099, %f1154;
	fma.rn.f32 	%f2103, %f317, %f2100, %f1157;
	ld.const.u64 	%rd23, [params+96];
	setp.eq.s64	%p24, %rd23, 0;
	@%p24 bra 	BB8_56;

	ld.v4.f32 	{%f1170, %f1171, %f1172, %f1173}, [%rd3+208];
	ld.v4.f32 	{%f1177, %f1178, %f1179, %f1180}, [%rd3+160];
	fma.rn.f32 	%f1182, %f2101, %f1177, %f1170;
	fma.rn.f32 	%f1184, %f2101, %f1178, %f1171;
	fma.rn.f32 	%f1186, %f2101, %f1179, %f1172;
	ld.v4.f32 	{%f1187, %f1188, %f1189, %f1190}, [%rd3+176];
	fma.rn.f32 	%f1192, %f2102, %f1187, %f1182;
	fma.rn.f32 	%f1194, %f2102, %f1188, %f1184;
	fma.rn.f32 	%f1196, %f2102, %f1189, %f1186;
	ld.v4.f32 	{%f1197, %f1198, %f1199, %f1200}, [%rd3+192];
	fma.rn.f32 	%f321, %f2103, %f1197, %f1192;
	fma.rn.f32 	%f322, %f2103, %f1198, %f1194;
	fma.rn.f32 	%f323, %f2103, %f1199, %f1196;
	mul.f32 	%f1204, %f322, %f322;
	fma.rn.f32 	%f324, %f321, %f321, %f1204;
	abs.f32 	%f1205, %f323;
	mov.f32 	%f1206, 0f3F800000;
	sub.f32 	%f1207, %f1206, %f1205;
	mul.f32 	%f1208, %f1207, 0f3F000000;
	sqrt.rn.f32 	%f1209, %f1208;
	setp.gt.f32	%p25, %f1205, 0f3F11EB85;
	selp.f32	%f1210, %f1209, %f1205, %p25;
	mul.f32 	%f1211, %f1210, %f1210;
	mov.f32 	%f1212, 0f3C94D2E9;
	mov.f32 	%f1213, 0f3D53F941;
	fma.rn.f32 	%f1214, %f1213, %f1211, %f1212;
	mov.f32 	%f1215, 0f3D3F841F;
	fma.rn.f32 	%f1216, %f1214, %f1211, %f1215;
	mov.f32 	%f1217, 0f3D994929;
	fma.rn.f32 	%f1218, %f1216, %f1211, %f1217;
	mov.f32 	%f1219, 0f3E2AAB94;
	fma.rn.f32 	%f1220, %f1218, %f1211, %f1219;
	mul.f32 	%f1221, %f1211, %f1220;
	fma.rn.f32 	%f1222, %f1221, %f1210, %f1210;
	add.f32 	%f1223, %f1222, %f1222;
	mov.f32 	%f1224, 0f3FC90FDB;
	sub.f32 	%f1225, %f1224, %f1222;
	selp.f32	%f325, %f1223, %f1225, %p25;
	abs.f32 	%f326, %f321;
	abs.f32 	%f327, %f322;
	setp.eq.f32	%p26, %f326, 0f00000000;
	setp.eq.f32	%p27, %f327, 0f00000000;
	and.pred  	%p28, %p26, %p27;
	mov.b32 	 %r11, %f321;
	mov.b32 	 %r333, %f322;
	and.b32  	%r12, %r333, -2147483648;
	@%p28 bra 	BB8_53;
	bra.uni 	BB8_50;

BB8_53:
	shr.s32 	%r340, %r11, 31;
	and.b32  	%r341, %r340, 1078530011;
	or.b32  	%r342, %r341, %r12;
	mov.b32 	 %f1937, %r342;
	bra.uni 	BB8_54;

BB8_50:
	setp.eq.f32	%p29, %f326, 0f7F800000;
	setp.eq.f32	%p30, %f327, 0f7F800000;
	and.pred  	%p31, %p29, %p30;
	@%p31 bra 	BB8_52;
	bra.uni 	BB8_51;

BB8_52:
	shr.s32 	%r336, %r11, 31;
	and.b32  	%r337, %r336, 13483017;
	add.s32 	%r338, %r337, 1061752795;
	or.b32  	%r339, %r338, %r12;
	mov.b32 	 %f1937, %r339;
	bra.uni 	BB8_54;

BB8_51:
	max.f32 	%f1226, %f327, %f326;
	min.f32 	%f1227, %f327, %f326;
	div.rn.f32 	%f1228, %f1227, %f1226;
	mul.rn.f32 	%f1229, %f1228, %f1228;
	mov.f32 	%f1230, 0fC0B59883;
	mov.f32 	%f1231, 0fBF52C7EA;
	fma.rn.f32 	%f1232, %f1229, %f1231, %f1230;
	mov.f32 	%f1233, 0fC0D21907;
	fma.rn.f32 	%f1234, %f1232, %f1229, %f1233;
	mul.f32 	%f1235, %f1229, %f1234;
	mul.f32 	%f1236, %f1228, %f1235;
	add.f32 	%f1237, %f1229, 0f41355DC0;
	mov.f32 	%f1238, 0f41E6BD60;
	fma.rn.f32 	%f1239, %f1237, %f1229, %f1238;
	mov.f32 	%f1240, 0f419D92C8;
	fma.rn.f32 	%f1241, %f1239, %f1229, %f1240;
	rcp.rn.f32 	%f1242, %f1241;
	fma.rn.f32 	%f1243, %f1236, %f1242, %f1228;
	sub.f32 	%f1245, %f1224, %f1243;
	setp.gt.f32	%p32, %f327, %f326;
	selp.f32	%f1246, %f1245, %f1243, %p32;
	mov.f32 	%f1247, 0f40490FDB;
	sub.f32 	%f1248, %f1247, %f1246;
	setp.lt.s32	%p33, %r11, 0;
	selp.f32	%f1249, %f1248, %f1246, %p33;
	mov.b32 	 %r334, %f1249;
	or.b32  	%r335, %r334, %r12;
	mov.b32 	 %f1250, %r335;
	add.f32 	%f1251, %f326, %f327;
	setp.gtu.f32	%p34, %f1251, 0f7F800000;
	selp.f32	%f1937, %f1251, %f1250, %p34;

BB8_54:
	add.f32 	%f1253, %f1937, 0f40C90FDB;
	setp.lt.f32	%p35, %f1937, 0f00000000;
	selp.f32	%f1254, %f1253, %f1937, %p35;
	mul.f32 	%f1945, %f1254, 0f3E22F983;
	mov.f32 	%f1255, 0f40490FDB;
	sub.f32 	%f1256, %f1255, %f325;
	setp.lt.f32	%p36, %f323, 0f00000000;
	selp.f32	%f1257, %f1256, %f325, %p36;
	mul.f32 	%f1944, %f1257, 0f3EA2F983;
	ld.const.u64 	%rd310, [params+184];
	setp.eq.s64	%p37, %rd310, 0;
	@%p37 bra 	BB8_56;

	neg.f32 	%f1258, %f322;
	sqrt.rn.f32 	%f1259, %f324;
	rcp.rn.f32 	%f1260, %f1259;
	mul.f32 	%f1261, %f321, %f1260;
	mul.f32 	%f1262, %f322, %f1260;
	mul.f32 	%f1263, %f323, %f1261;
	mul.f32 	%f1264, %f323, %f1262;
	neg.f32 	%f1265, %f1259;
	setp.eq.f32	%p38, %f1259, 0f00000000;
	selp.f32	%f1266, 0f00000000, %f1265, %p38;
	selp.f32	%f1267, 0f00000000, %f1264, %p38;
	selp.f32	%f1268, 0f3F800000, %f1263, %p38;
	ld.v4.f32 	{%f1269, %f1270, %f1271, %f1272}, [%rd3+32];
	mul.f32 	%f1276, %f1269, %f1258;
	mul.f32 	%f1277, %f1270, %f1258;
	mul.f32 	%f1278, %f1271, %f1258;
	ld.v4.f32 	{%f1279, %f1280, %f1281, %f1282}, [%rd3+48];
	fma.rn.f32 	%f1286, %f321, %f1279, %f1276;
	fma.rn.f32 	%f1287, %f321, %f1280, %f1277;
	fma.rn.f32 	%f1288, %f321, %f1281, %f1278;
	ld.v4.f32 	{%f1289, %f1290, %f1291, %f1292}, [%rd3+64];
	mov.f32 	%f1294, 0f00000000;
	fma.rn.f32 	%f1295, %f1294, %f1289, %f1286;
	fma.rn.f32 	%f1297, %f1294, %f1290, %f1287;
	fma.rn.f32 	%f1299, %f1294, %f1291, %f1288;
	mul.f32 	%f342, %f1295, 0f40C90FDB;
	mul.f32 	%f341, %f1297, 0f40C90FDB;
	mul.f32 	%f340, %f1299, 0f40C90FDB;
	mul.f32 	%f1300, %f1268, %f1269;
	mul.f32 	%f1301, %f1268, %f1270;
	mul.f32 	%f1302, %f1268, %f1271;
	fma.rn.f32 	%f1303, %f1267, %f1279, %f1300;
	fma.rn.f32 	%f1304, %f1267, %f1280, %f1301;
	fma.rn.f32 	%f1305, %f1267, %f1281, %f1302;
	fma.rn.f32 	%f1306, %f1266, %f1289, %f1303;
	fma.rn.f32 	%f1307, %f1266, %f1290, %f1304;
	fma.rn.f32 	%f1308, %f1266, %f1291, %f1305;
	mul.f32 	%f345, %f1306, 0f40490FDB;
	mul.f32 	%f344, %f1307, 0f40490FDB;
	mul.f32 	%f343, %f1308, 0f40490FDB;

BB8_56:
	selp.f32	%f1309, 0f3F800000, 0fBF800000, %p23;
	div.rn.f32 	%f1310, %f1309, %f317;
	mul.f32 	%f2086, %f342, %f1310;
	mul.f32 	%f2087, %f341, %f1310;
	mul.f32 	%f2088, %f340, %f1310;
	mul.f32 	%f2083, %f345, %f1310;
	mul.f32 	%f2084, %f344, %f1310;
	mul.f32 	%f2085, %f343, %f1310;
	ld.u64 	%rd24, [%rd51];
	ld.const.u64 	%rd311, [params+344];
	cvta.to.global.u64 	%rd312, %rd311;
	cvt.u64.u32	%rd25, %r1;
	mul.wide.u32 	%rd313, %r1, 4;
	add.s64 	%rd26, %rd312, %rd313;
	ld.global.u32 	%r13, [%rd26];
	setp.eq.s32	%p40, %r13, 0;
	@%p40 bra 	BB8_57;

	// inline asm
	call (%r343), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p41, %r343, %r13;
	@%p41 bra 	BB8_57;

	mov.f32 	%f2011, 0f00000000;
	mov.f32 	%f2012, 0f3F800000;
	mov.f32 	%f1949, %f2012;
	mov.f32 	%f1948, %f2011;
	mov.f32 	%f1947, %f2011;
	mov.f32 	%f1946, %f2011;
	mov.f32 	%f1953, %f2011;
	mov.f32 	%f1952, %f2012;
	mov.f32 	%f1951, %f2011;
	mov.f32 	%f1950, %f2011;
	mov.f32 	%f1957, %f2011;
	mov.f32 	%f1956, %f2011;
	mov.f32 	%f1955, %f2012;
	mov.f32 	%f1954, %f2011;
	@%p2 bra 	BB8_77;

	add.s32 	%r648, %r30, -1;
	setp.lt.s32	%p43, %r648, 0;
	@%p43 bra 	BB8_77;

BB8_61:
	.pragma "nounroll";
	// inline asm
	call (%rd314), _optix_get_transform_list_handle, (%r648);
	// inline asm
	// inline asm
	call (%r345), _optix_get_transform_type_from_handle, (%rd314);
	// inline asm
	and.b32  	%r346, %r345, -2;
	setp.eq.s32	%p44, %r346, 2;
	@%p44 bra 	BB8_67;
	bra.uni 	BB8_62;

BB8_67:
	setp.eq.s32	%p47, %r345, 2;
	@%p47 bra 	BB8_71;
	bra.uni 	BB8_68;

BB8_71:
	// inline asm
	call (%rd388), _optix_get_matrix_motion_transform_from_handle, (%rd314);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd390, %rd388;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd390];
	// inline asm
	mov.b32	{%rs13, %rs14}, %r436;
	add.s64 	%rd394, %rd388, 16;
	// inline asm
	cvta.to.global.u64 %rd393, %rd394;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd393];
	// inline asm
	add.s64 	%rd397, %rd388, 32;
	// inline asm
	cvta.to.global.u64 %rd396, %rd397;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd396];
	// inline asm
	add.s64 	%rd400, %rd388, 48;
	// inline asm
	cvta.to.global.u64 %rd399, %rd400;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd399];
	// inline asm
	add.s64 	%rd403, %rd388, 64;
	// inline asm
	cvta.to.global.u64 %rd402, %rd403;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd402];
	// inline asm
	add.s64 	%rd406, %rd388, 80;
	// inline asm
	cvta.to.global.u64 %rd405, %rd406;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd405];
	// inline asm
	add.s64 	%rd409, %rd388, 96;
	// inline asm
	cvta.to.global.u64 %rd408, %rd409;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd408];
	// inline asm
	add.s64 	%rd412, %rd388, 112;
	// inline asm
	cvta.to.global.u64 %rd411, %rd412;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd411];
	// inline asm
	mov.b32 	 %f1449, %r437;
	mov.b32 	 %f1450, %r438;
	cvt.u32.u16	%r478, %rs13;
	add.s32 	%r479, %r478, -1;
	cvt.rn.f32.s32	%f1451, %r479;
	sub.f32 	%f1452, %f957, %f1449;
	mul.f32 	%f1453, %f1452, %f1451;
	sub.f32 	%f1454, %f1450, %f1449;
	div.rn.f32 	%f1455, %f1453, %f1454;
	min.f32 	%f1456, %f1451, %f1455;
	mov.f32 	%f1457, 0f00000000;
	max.f32 	%f1458, %f1457, %f1456;
	cvt.rmi.f32.f32	%f1459, %f1458;
	cvt.rzi.s32.f32	%r480, %f1459;
	cvt.s64.s32	%rd34, %r480;
	mul.wide.s32 	%rd423, %r480, 48;
	add.s64 	%rd415, %rd397, %rd423;
	// inline asm
	cvta.to.global.u64 %rd414, %rd415;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd414];
	// inline asm
	mov.b32 	 %f1982, %r466;
	mov.b32 	 %f1983, %r467;
	mov.b32 	 %f1984, %r468;
	mov.b32 	 %f1985, %r469;
	add.s64 	%rd418, %rd415, 16;
	// inline asm
	cvta.to.global.u64 %rd417, %rd418;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd417];
	// inline asm
	mov.b32 	 %f1978, %r470;
	mov.b32 	 %f1979, %r471;
	mov.b32 	 %f1980, %r472;
	mov.b32 	 %f1981, %r473;
	add.s64 	%rd421, %rd415, 32;
	// inline asm
	cvta.to.global.u64 %rd420, %rd421;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd420];
	// inline asm
	sub.f32 	%f447, %f1458, %f1459;
	mov.b32 	 %f1974, %r474;
	mov.b32 	 %f1975, %r475;
	mov.b32 	 %f1976, %r476;
	mov.b32 	 %f1977, %r477;
	setp.leu.f32	%p49, %f447, 0f00000000;
	@%p49 bra 	BB8_73;

	mul.lo.s64 	%rd433, %rd34, 48;
	add.s64 	%rd434, %rd388, %rd433;
	add.s64 	%rd425, %rd434, 80;
	// inline asm
	cvta.to.global.u64 %rd424, %rd425;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r481,%r482,%r483,%r484}, [%rd424];
	// inline asm
	mov.b32 	 %f1460, %r481;
	mov.b32 	 %f1461, %r482;
	mov.b32 	 %f1462, %r483;
	mov.b32 	 %f1463, %r484;
	add.s64 	%rd428, %rd434, 96;
	// inline asm
	cvta.to.global.u64 %rd427, %rd428;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r485,%r486,%r487,%r488}, [%rd427];
	// inline asm
	mov.b32 	 %f1464, %r485;
	mov.b32 	 %f1465, %r486;
	mov.b32 	 %f1466, %r487;
	mov.b32 	 %f1467, %r488;
	add.s64 	%rd431, %rd434, 112;
	// inline asm
	cvta.to.global.u64 %rd430, %rd431;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd430];
	// inline asm
	mov.f32 	%f1468, 0f3F800000;
	sub.f32 	%f1469, %f1468, %f447;
	mul.f32 	%f1470, %f447, %f1460;
	mul.f32 	%f1471, %f447, %f1461;
	mul.f32 	%f1472, %f447, %f1462;
	mul.f32 	%f1473, %f447, %f1463;
	fma.rn.f32 	%f1982, %f1469, %f1982, %f1470;
	fma.rn.f32 	%f1983, %f1469, %f1983, %f1471;
	fma.rn.f32 	%f1984, %f1469, %f1984, %f1472;
	fma.rn.f32 	%f1985, %f1469, %f1985, %f1473;
	mul.f32 	%f1474, %f447, %f1464;
	mul.f32 	%f1475, %f447, %f1465;
	mul.f32 	%f1476, %f447, %f1466;
	mul.f32 	%f1477, %f447, %f1467;
	fma.rn.f32 	%f1978, %f1469, %f1978, %f1474;
	fma.rn.f32 	%f1979, %f1469, %f1979, %f1475;
	fma.rn.f32 	%f1980, %f1469, %f1980, %f1476;
	fma.rn.f32 	%f1981, %f1469, %f1981, %f1477;
	mov.b32 	 %f1478, %r489;
	mov.b32 	 %f1479, %r490;
	mov.b32 	 %f1480, %r491;
	mov.b32 	 %f1481, %r492;
	mul.f32 	%f1482, %f447, %f1478;
	mul.f32 	%f1483, %f447, %f1479;
	mul.f32 	%f1484, %f447, %f1480;
	mul.f32 	%f1485, %f447, %f1481;
	fma.rn.f32 	%f1974, %f1469, %f1974, %f1482;
	fma.rn.f32 	%f1975, %f1469, %f1975, %f1483;
	fma.rn.f32 	%f1976, %f1469, %f1976, %f1484;
	fma.rn.f32 	%f1977, %f1469, %f1977, %f1485;
	bra.uni 	BB8_73;

BB8_62:
	mov.f32 	%f1974, 0f00000000;
	mov.f32 	%f1976, 0f3F800000;
	setp.eq.s32	%p45, %r345, 4;
	@%p45 bra 	BB8_65;
	bra.uni 	BB8_63;

BB8_65:
	// inline asm
	call (%rd664), _optix_get_instance_transform_from_handle, (%rd314);
	// inline asm
	bra.uni 	BB8_66;

BB8_68:
	// inline asm
	call (%rd329), _optix_get_srt_motion_transform_from_handle, (%rd314);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd331, %rd329;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd331];
	// inline asm
	mov.b32	{%rs11, %rs12}, %r361;
	add.s64 	%rd335, %rd329, 16;
	// inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd334];
	// inline asm
	add.s64 	%rd338, %rd329, 32;
	// inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd337];
	// inline asm
	add.s64 	%rd341, %rd329, 48;
	// inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd340];
	// inline asm
	add.s64 	%rd344, %rd329, 64;
	// inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd343];
	// inline asm
	add.s64 	%rd347, %rd329, 80;
	// inline asm
	cvta.to.global.u64 %rd346, %rd347;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd346];
	// inline asm
	add.s64 	%rd350, %rd329, 96;
	// inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd349];
	// inline asm
	add.s64 	%rd353, %rd329, 112;
	// inline asm
	cvta.to.global.u64 %rd352, %rd353;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd352];
	// inline asm
	add.s64 	%rd356, %rd329, 128;
	// inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd355];
	// inline asm
	add.s64 	%rd359, %rd329, 144;
	// inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd358];
	// inline asm
	mov.b32 	 %f1336, %r362;
	mov.b32 	 %f1337, %r363;
	cvt.u32.u16	%r415, %rs11;
	add.s32 	%r416, %r415, -1;
	cvt.rn.f32.s32	%f1338, %r416;
	sub.f32 	%f1339, %f957, %f1336;
	mul.f32 	%f1340, %f1339, %f1338;
	sub.f32 	%f1341, %f1337, %f1336;
	div.rn.f32 	%f1342, %f1340, %f1341;
	min.f32 	%f1343, %f1338, %f1342;
	mov.f32 	%f1344, 0f00000000;
	max.f32 	%f1345, %f1344, %f1343;
	cvt.rmi.f32.f32	%f1346, %f1345;
	cvt.rzi.s32.f32	%r417, %f1346;
	cvt.s64.s32	%rd32, %r417;
	mul.wide.s32 	%rd373, %r417, 64;
	add.s64 	%rd362, %rd338, %rd373;
	// inline asm
	cvta.to.global.u64 %rd361, %rd362;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd361];
	// inline asm
	mov.b32 	 %f1958, %r399;
	mov.b32 	 %f1959, %r400;
	mov.b32 	 %f1960, %r401;
	mov.b32 	 %f1961, %r402;
	add.s64 	%rd365, %rd362, 16;
	// inline asm
	cvta.to.global.u64 %rd364, %rd365;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd364];
	// inline asm
	mov.b32 	 %f1962, %r403;
	mov.b32 	 %f1963, %r404;
	mov.b32 	 %f1964, %r405;
	mov.b32 	 %f1965, %r406;
	add.s64 	%rd368, %rd362, 32;
	// inline asm
	cvta.to.global.u64 %rd367, %rd368;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd367];
	// inline asm
	sub.f32 	%f386, %f1345, %f1346;
	mov.b32 	 %f1966, %r407;
	mov.b32 	 %f1967, %r408;
	mov.b32 	 %f1968, %r409;
	mov.b32 	 %f1969, %r410;
	add.s64 	%rd371, %rd362, 48;
	// inline asm
	cvta.to.global.u64 %rd370, %rd371;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd370];
	// inline asm
	mov.b32 	 %f1970, %r411;
	mov.b32 	 %f1971, %r412;
	mov.b32 	 %f1972, %r413;
	mov.b32 	 %f1973, %r414;
	setp.leu.f32	%p48, %f386, 0f00000000;
	@%p48 bra 	BB8_70;

	shl.b64 	%rd386, %rd32, 6;
	add.s64 	%rd387, %rd386, %rd329;
	add.s64 	%rd375, %rd387, 96;
	// inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r418,%r419,%r420,%r421}, [%rd374];
	// inline asm
	mov.b32 	 %f1347, %r418;
	mov.b32 	 %f1348, %r419;
	mov.b32 	 %f1349, %r420;
	mov.b32 	 %f1350, %r421;
	add.s64 	%rd378, %rd387, 112;
	// inline asm
	cvta.to.global.u64 %rd377, %rd378;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r422,%r423,%r424,%r425}, [%rd377];
	// inline asm
	mov.b32 	 %f1351, %r422;
	mov.b32 	 %f1352, %r423;
	mov.b32 	 %f1353, %r424;
	mov.b32 	 %f1354, %r425;
	add.s64 	%rd381, %rd387, 128;
	// inline asm
	cvta.to.global.u64 %rd380, %rd381;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd380];
	// inline asm
	mov.b32 	 %f1355, %r426;
	mov.b32 	 %f1356, %r427;
	mov.b32 	 %f1357, %r428;
	mov.b32 	 %f1358, %r429;
	add.s64 	%rd384, %rd387, 144;
	// inline asm
	cvta.to.global.u64 %rd383, %rd384;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd383];
	// inline asm
	mov.f32 	%f1359, 0f3F800000;
	sub.f32 	%f1360, %f1359, %f386;
	mul.f32 	%f1361, %f386, %f1347;
	mul.f32 	%f1362, %f386, %f1348;
	mul.f32 	%f1363, %f386, %f1349;
	mul.f32 	%f1364, %f386, %f1350;
	fma.rn.f32 	%f1958, %f1360, %f1958, %f1361;
	fma.rn.f32 	%f1959, %f1360, %f1959, %f1362;
	fma.rn.f32 	%f1960, %f1360, %f1960, %f1363;
	fma.rn.f32 	%f1961, %f1360, %f1961, %f1364;
	mul.f32 	%f1365, %f386, %f1351;
	mul.f32 	%f1366, %f386, %f1352;
	mul.f32 	%f1367, %f386, %f1353;
	mul.f32 	%f1368, %f386, %f1354;
	fma.rn.f32 	%f1962, %f1360, %f1962, %f1365;
	fma.rn.f32 	%f1963, %f1360, %f1963, %f1366;
	fma.rn.f32 	%f1964, %f1360, %f1964, %f1367;
	fma.rn.f32 	%f1965, %f1360, %f1965, %f1368;
	mul.f32 	%f1369, %f386, %f1355;
	mul.f32 	%f1370, %f386, %f1356;
	mul.f32 	%f1371, %f386, %f1357;
	mul.f32 	%f1372, %f386, %f1358;
	fma.rn.f32 	%f1966, %f1360, %f1966, %f1369;
	fma.rn.f32 	%f1373, %f1360, %f1967, %f1370;
	fma.rn.f32 	%f1374, %f1360, %f1968, %f1371;
	fma.rn.f32 	%f1375, %f1360, %f1969, %f1372;
	mov.b32 	 %f1376, %r430;
	mov.b32 	 %f1377, %r431;
	mov.b32 	 %f1378, %r432;
	mov.b32 	 %f1379, %r433;
	mul.f32 	%f1380, %f386, %f1376;
	mul.f32 	%f1381, %f386, %f1377;
	mul.f32 	%f1382, %f386, %f1378;
	mul.f32 	%f1383, %f386, %f1379;
	fma.rn.f32 	%f1384, %f1360, %f1970, %f1380;
	fma.rn.f32 	%f1971, %f1360, %f1971, %f1381;
	fma.rn.f32 	%f1972, %f1360, %f1972, %f1382;
	fma.rn.f32 	%f1973, %f1360, %f1973, %f1383;
	mul.f32 	%f1385, %f1374, %f1374;
	fma.rn.f32 	%f1386, %f1373, %f1373, %f1385;
	fma.rn.f32 	%f1387, %f1375, %f1375, %f1386;
	fma.rn.f32 	%f1388, %f1384, %f1384, %f1387;
	sqrt.rn.f32 	%f1389, %f1388;
	rcp.rn.f32 	%f1390, %f1389;
	mul.f32 	%f1967, %f1373, %f1390;
	mul.f32 	%f1968, %f1374, %f1390;
	mul.f32 	%f1969, %f1375, %f1390;
	mul.f32 	%f1970, %f1384, %f1390;

BB8_70:
	mul.f32 	%f1391, %f1968, %f1968;
	fma.rn.f32 	%f1392, %f1967, %f1967, %f1391;
	fma.rn.f32 	%f1393, %f1969, %f1969, %f1392;
	fma.rn.f32 	%f1394, %f1970, %f1970, %f1393;
	rcp.rn.f32 	%f1395, %f1394;
	mul.f32 	%f1396, %f1967, %f1395;
	mul.f32 	%f1397, %f1968, %f1395;
	mul.f32 	%f1398, %f1969, %f1395;
	mul.f32 	%f1399, %f1970, %f1395;
	mul.f32 	%f1400, %f1967, %f1396;
	mul.f32 	%f1401, %f1968, %f1397;
	mul.f32 	%f1402, %f1969, %f1398;
	mul.f32 	%f1403, %f1967, %f1397;
	mul.f32 	%f1404, %f1969, %f1399;
	mul.f32 	%f1405, %f1967, %f1398;
	mul.f32 	%f1406, %f1968, %f1399;
	mul.f32 	%f1407, %f1968, %f1398;
	mul.f32 	%f1408, %f1967, %f1399;
	sub.f32 	%f1409, %f1400, %f1401;
	sub.f32 	%f1410, %f1409, %f1402;
	fma.rn.f32 	%f1411, %f1970, %f1399, %f1410;
	sub.f32 	%f1412, %f1403, %f1404;
	add.f32 	%f1413, %f1412, %f1412;
	add.f32 	%f1414, %f1405, %f1406;
	add.f32 	%f1415, %f1414, %f1414;
	add.f32 	%f1416, %f1403, %f1404;
	add.f32 	%f1417, %f1416, %f1416;
	sub.f32 	%f1418, %f1401, %f1400;
	sub.f32 	%f1419, %f1418, %f1402;
	fma.rn.f32 	%f1420, %f1970, %f1399, %f1419;
	sub.f32 	%f1421, %f1407, %f1408;
	add.f32 	%f1422, %f1421, %f1421;
	sub.f32 	%f1423, %f1405, %f1406;
	add.f32 	%f1424, %f1423, %f1423;
	add.f32 	%f1425, %f1407, %f1408;
	add.f32 	%f1426, %f1425, %f1425;
	neg.f32 	%f1427, %f1400;
	sub.f32 	%f1428, %f1427, %f1401;
	add.f32 	%f1429, %f1402, %f1428;
	fma.rn.f32 	%f1430, %f1970, %f1399, %f1429;
	mul.f32 	%f1431, %f1961, %f1411;
	fma.rn.f32 	%f1432, %f1964, %f1413, %f1431;
	fma.rn.f32 	%f1433, %f1966, %f1415, %f1432;
	sub.f32 	%f1985, %f1971, %f1433;
	mul.f32 	%f1434, %f1964, %f1420;
	fma.rn.f32 	%f1435, %f1961, %f1417, %f1434;
	fma.rn.f32 	%f1436, %f1966, %f1422, %f1435;
	sub.f32 	%f1981, %f1972, %f1436;
	mul.f32 	%f1437, %f1964, %f1426;
	fma.rn.f32 	%f1438, %f1961, %f1424, %f1437;
	fma.rn.f32 	%f1439, %f1966, %f1430, %f1438;
	sub.f32 	%f1977, %f1973, %f1439;
	mul.f32 	%f1440, %f1960, %f1411;
	fma.rn.f32 	%f1441, %f1963, %f1413, %f1440;
	fma.rn.f32 	%f1984, %f1965, %f1415, %f1441;
	mul.f32 	%f1442, %f1963, %f1420;
	fma.rn.f32 	%f1443, %f1960, %f1417, %f1442;
	fma.rn.f32 	%f1980, %f1965, %f1422, %f1443;
	mul.f32 	%f1444, %f1963, %f1426;
	fma.rn.f32 	%f1445, %f1960, %f1424, %f1444;
	fma.rn.f32 	%f1976, %f1965, %f1430, %f1445;
	mul.f32 	%f1446, %f1959, %f1411;
	fma.rn.f32 	%f1983, %f1962, %f1413, %f1446;
	mul.f32 	%f1447, %f1962, %f1420;
	fma.rn.f32 	%f1979, %f1959, %f1417, %f1447;
	mul.f32 	%f1448, %f1962, %f1426;
	fma.rn.f32 	%f1975, %f1959, %f1424, %f1448;
	mul.f32 	%f1982, %f1958, %f1411;
	mul.f32 	%f1978, %f1958, %f1417;
	mul.f32 	%f1974, %f1958, %f1424;
	bra.uni 	BB8_73;

BB8_63:
	setp.ne.s32	%p46, %r345, 1;
	mov.f32 	%f1975, %f1974;
	mov.f32 	%f1977, %f1974;
	mov.f32 	%f1978, %f1974;
	mov.f32 	%f1979, %f1976;
	mov.f32 	%f1980, %f1974;
	mov.f32 	%f1981, %f1974;
	mov.f32 	%f1982, %f1976;
	mov.f32 	%f1983, %f1974;
	mov.f32 	%f1984, %f1974;
	mov.f32 	%f1985, %f1974;
	@%p46 bra 	BB8_73;

	// inline asm
	call (%rd316), _optix_get_static_transform_from_handle, (%rd314);
	// inline asm
	add.s64 	%rd664, %rd316, 16;

BB8_66:
	// inline asm
	cvta.to.global.u64 %rd320, %rd664;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r347,%r348,%r349,%r350}, [%rd320];
	// inline asm
	mov.b32 	 %f1982, %r347;
	mov.b32 	 %f1983, %r348;
	mov.b32 	 %f1984, %r349;
	mov.b32 	 %f1985, %r350;
	add.s64 	%rd324, %rd664, 16;
	// inline asm
	cvta.to.global.u64 %rd323, %rd324;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r351,%r352,%r353,%r354}, [%rd323];
	// inline asm
	mov.b32 	 %f1978, %r351;
	mov.b32 	 %f1979, %r352;
	mov.b32 	 %f1980, %r353;
	mov.b32 	 %f1981, %r354;
	add.s64 	%rd327, %rd664, 32;
	// inline asm
	cvta.to.global.u64 %rd326, %rd327;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd326];
	// inline asm
	mov.b32 	 %f1974, %r355;
	mov.b32 	 %f1975, %r356;
	mov.b32 	 %f1976, %r357;
	mov.b32 	 %f1977, %r358;

BB8_73:
	add.s32 	%r18, %r648, 1;
	setp.eq.s32	%p50, %r18, %r30;
	@%p50 bra 	BB8_74;
	bra.uni 	BB8_75;

BB8_74:
	mov.f32 	%f1957, %f1974;
	mov.f32 	%f1956, %f1975;
	mov.f32 	%f1955, %f1976;
	mov.f32 	%f1954, %f1977;
	mov.f32 	%f1953, %f1978;
	mov.f32 	%f1952, %f1979;
	mov.f32 	%f1951, %f1980;
	mov.f32 	%f1950, %f1981;
	mov.f32 	%f1949, %f1982;
	mov.f32 	%f1948, %f1983;
	mov.f32 	%f1947, %f1984;
	mov.f32 	%f1946, %f1985;
	bra.uni 	BB8_76;

BB8_75:
	mul.f32 	%f1486, %f1953, %f1983;
	fma.rn.f32 	%f1487, %f1949, %f1982, %f1486;
	fma.rn.f32 	%f476, %f1957, %f1984, %f1487;
	mul.f32 	%f1488, %f1952, %f1983;
	fma.rn.f32 	%f1489, %f1948, %f1982, %f1488;
	fma.rn.f32 	%f477, %f1956, %f1984, %f1489;
	mul.f32 	%f1490, %f1951, %f1983;
	fma.rn.f32 	%f1491, %f1947, %f1982, %f1490;
	fma.rn.f32 	%f478, %f1955, %f1984, %f1491;
	mul.f32 	%f1492, %f1950, %f1983;
	fma.rn.f32 	%f1493, %f1946, %f1982, %f1492;
	fma.rn.f32 	%f1494, %f1954, %f1984, %f1493;
	add.f32 	%f479, %f1985, %f1494;
	mul.f32 	%f1495, %f1953, %f1979;
	fma.rn.f32 	%f1496, %f1949, %f1978, %f1495;
	fma.rn.f32 	%f480, %f1957, %f1980, %f1496;
	mul.f32 	%f1497, %f1952, %f1979;
	fma.rn.f32 	%f1498, %f1948, %f1978, %f1497;
	fma.rn.f32 	%f481, %f1956, %f1980, %f1498;
	mul.f32 	%f1499, %f1951, %f1979;
	fma.rn.f32 	%f1500, %f1947, %f1978, %f1499;
	fma.rn.f32 	%f482, %f1955, %f1980, %f1500;
	mul.f32 	%f1501, %f1950, %f1979;
	fma.rn.f32 	%f1502, %f1946, %f1978, %f1501;
	fma.rn.f32 	%f1503, %f1954, %f1980, %f1502;
	add.f32 	%f483, %f1981, %f1503;
	mul.f32 	%f1504, %f1953, %f1975;
	fma.rn.f32 	%f1505, %f1949, %f1974, %f1504;
	fma.rn.f32 	%f1957, %f1957, %f1976, %f1505;
	mul.f32 	%f1506, %f1952, %f1975;
	fma.rn.f32 	%f1507, %f1948, %f1974, %f1506;
	fma.rn.f32 	%f1956, %f1956, %f1976, %f1507;
	mul.f32 	%f1508, %f1951, %f1975;
	fma.rn.f32 	%f1509, %f1947, %f1974, %f1508;
	fma.rn.f32 	%f1955, %f1955, %f1976, %f1509;
	mul.f32 	%f1510, %f1950, %f1975;
	fma.rn.f32 	%f1511, %f1946, %f1974, %f1510;
	fma.rn.f32 	%f1512, %f1954, %f1976, %f1511;
	add.f32 	%f1954, %f1977, %f1512;
	mov.f32 	%f1953, %f480;
	mov.f32 	%f1952, %f481;
	mov.f32 	%f1951, %f482;
	mov.f32 	%f1950, %f483;
	mov.f32 	%f1949, %f476;
	mov.f32 	%f1948, %f477;
	mov.f32 	%f1947, %f478;
	mov.f32 	%f1946, %f479;

BB8_76:
	add.s32 	%r648, %r18, -2;
	setp.gt.s32	%p51, %r648, -1;
	@%p51 bra 	BB8_61;

BB8_77:
	mov.u32 	%r649, 0;
	mov.f32 	%f2010, %f2011;
	mov.f32 	%f2015, %f2011;
	mov.f32 	%f2014, %f2012;
	mov.f32 	%f2013, %f2011;
	mov.f32 	%f2018, %f2011;
	mov.f32 	%f2017, %f2011;
	mov.f32 	%f2016, %f2012;
	@%p2 bra 	BB8_95;

BB8_78:
	.pragma "nounroll";
	// inline asm
	call (%rd435), _optix_get_transform_list_handle, (%r649);
	// inline asm
	// inline asm
	call (%r495), _optix_get_transform_type_from_handle, (%rd435);
	// inline asm
	and.b32  	%r496, %r495, -2;
	setp.eq.s32	%p53, %r496, 2;
	@%p53 bra 	BB8_84;
	bra.uni 	BB8_79;

BB8_84:
	setp.eq.s32	%p56, %r495, 2;
	@%p56 bra 	BB8_88;
	bra.uni 	BB8_85;

BB8_88:
	// inline asm
	call (%rd509), _optix_get_matrix_motion_transform_from_handle, (%rd435);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd511, %rd509;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd511];
	// inline asm
	mov.b32	{%rs17, %rs18}, %r586;
	add.s64 	%rd515, %rd509, 16;
	// inline asm
	cvta.to.global.u64 %rd514, %rd515;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd514];
	// inline asm
	add.s64 	%rd518, %rd509, 32;
	// inline asm
	cvta.to.global.u64 %rd517, %rd518;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd517];
	// inline asm
	add.s64 	%rd521, %rd509, 48;
	// inline asm
	cvta.to.global.u64 %rd520, %rd521;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd520];
	// inline asm
	add.s64 	%rd524, %rd509, 64;
	// inline asm
	cvta.to.global.u64 %rd523, %rd524;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd523];
	// inline asm
	add.s64 	%rd527, %rd509, 80;
	// inline asm
	cvta.to.global.u64 %rd526, %rd527;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd526];
	// inline asm
	add.s64 	%rd530, %rd509, 96;
	// inline asm
	cvta.to.global.u64 %rd529, %rd530;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd529];
	// inline asm
	add.s64 	%rd533, %rd509, 112;
	// inline asm
	cvta.to.global.u64 %rd532, %rd533;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd532];
	// inline asm
	mov.b32 	 %f1624, %r587;
	mov.b32 	 %f1625, %r588;
	cvt.u32.u16	%r628, %rs17;
	add.s32 	%r629, %r628, -1;
	cvt.rn.f32.s32	%f1626, %r629;
	sub.f32 	%f1627, %f957, %f1624;
	mul.f32 	%f1628, %f1627, %f1626;
	sub.f32 	%f1629, %f1625, %f1624;
	div.rn.f32 	%f1630, %f1628, %f1629;
	min.f32 	%f1631, %f1626, %f1630;
	mov.f32 	%f1632, 0f00000000;
	max.f32 	%f1633, %f1632, %f1631;
	cvt.rmi.f32.f32	%f1634, %f1633;
	cvt.rzi.s32.f32	%r630, %f1634;
	cvt.s64.s32	%rd42, %r630;
	mul.wide.s32 	%rd544, %r630, 48;
	add.s64 	%rd536, %rd518, %rd544;
	// inline asm
	cvta.to.global.u64 %rd535, %rd536;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd535];
	// inline asm
	mov.b32 	 %f2035, %r616;
	mov.b32 	 %f2036, %r617;
	mov.b32 	 %f2037, %r618;
	add.s64 	%rd539, %rd536, 16;
	// inline asm
	cvta.to.global.u64 %rd538, %rd539;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd538];
	// inline asm
	mov.b32 	 %f2032, %r620;
	mov.b32 	 %f2033, %r621;
	mov.b32 	 %f2034, %r622;
	add.s64 	%rd542, %rd536, 32;
	// inline asm
	cvta.to.global.u64 %rd541, %rd542;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd541];
	// inline asm
	sub.f32 	%f576, %f1633, %f1634;
	mov.b32 	 %f2029, %r624;
	mov.b32 	 %f2030, %r625;
	mov.b32 	 %f2031, %r626;
	setp.leu.f32	%p58, %f576, 0f00000000;
	@%p58 bra 	BB8_90;

	mul.lo.s64 	%rd554, %rd42, 48;
	add.s64 	%rd555, %rd509, %rd554;
	add.s64 	%rd546, %rd555, 80;
	// inline asm
	cvta.to.global.u64 %rd545, %rd546;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd545];
	// inline asm
	mov.b32 	 %f1635, %r631;
	mov.b32 	 %f1636, %r632;
	mov.b32 	 %f1637, %r633;
	add.s64 	%rd549, %rd555, 96;
	// inline asm
	cvta.to.global.u64 %rd548, %rd549;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd548];
	// inline asm
	mov.b32 	 %f1638, %r635;
	mov.b32 	 %f1639, %r636;
	mov.b32 	 %f1640, %r637;
	add.s64 	%rd552, %rd555, 112;
	// inline asm
	cvta.to.global.u64 %rd551, %rd552;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd551];
	// inline asm
	mov.f32 	%f1641, 0f3F800000;
	sub.f32 	%f1642, %f1641, %f576;
	mul.f32 	%f1643, %f576, %f1635;
	mul.f32 	%f1644, %f576, %f1636;
	mul.f32 	%f1645, %f576, %f1637;
	fma.rn.f32 	%f2035, %f1642, %f2035, %f1643;
	fma.rn.f32 	%f2036, %f1642, %f2036, %f1644;
	fma.rn.f32 	%f2037, %f1642, %f2037, %f1645;
	mul.f32 	%f1646, %f576, %f1638;
	mul.f32 	%f1647, %f576, %f1639;
	mul.f32 	%f1648, %f576, %f1640;
	fma.rn.f32 	%f2032, %f1642, %f2032, %f1646;
	fma.rn.f32 	%f2033, %f1642, %f2033, %f1647;
	fma.rn.f32 	%f2034, %f1642, %f2034, %f1648;
	mov.b32 	 %f1649, %r639;
	mov.b32 	 %f1650, %r640;
	mov.b32 	 %f1651, %r641;
	mul.f32 	%f1652, %f576, %f1649;
	mul.f32 	%f1653, %f576, %f1650;
	mul.f32 	%f1654, %f576, %f1651;
	fma.rn.f32 	%f2029, %f1642, %f2029, %f1652;
	fma.rn.f32 	%f2030, %f1642, %f2030, %f1653;
	fma.rn.f32 	%f2031, %f1642, %f2031, %f1654;
	bra.uni 	BB8_90;

BB8_79:
	mov.f32 	%f2038, 0f00000000;
	mov.f32 	%f2040, 0f3F800000;
	setp.eq.s32	%p54, %r495, 4;
	@%p54 bra 	BB8_82;
	bra.uni 	BB8_80;

BB8_82:
	// inline asm
	call (%rd665), _optix_get_instance_inverse_transform_from_handle, (%rd435);
	// inline asm
	bra.uni 	BB8_83;

BB8_85:
	// inline asm
	call (%rd450), _optix_get_srt_motion_transform_from_handle, (%rd435);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd452, %rd450;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd452];
	// inline asm
	mov.b32	{%rs15, %rs16}, %r511;
	add.s64 	%rd456, %rd450, 16;
	// inline asm
	cvta.to.global.u64 %rd455, %rd456;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd455];
	// inline asm
	add.s64 	%rd459, %rd450, 32;
	// inline asm
	cvta.to.global.u64 %rd458, %rd459;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd458];
	// inline asm
	add.s64 	%rd462, %rd450, 48;
	// inline asm
	cvta.to.global.u64 %rd461, %rd462;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd461];
	// inline asm
	add.s64 	%rd465, %rd450, 64;
	// inline asm
	cvta.to.global.u64 %rd464, %rd465;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd464];
	// inline asm
	add.s64 	%rd468, %rd450, 80;
	// inline asm
	cvta.to.global.u64 %rd467, %rd468;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd467];
	// inline asm
	add.s64 	%rd471, %rd450, 96;
	// inline asm
	cvta.to.global.u64 %rd470, %rd471;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd470];
	// inline asm
	add.s64 	%rd474, %rd450, 112;
	// inline asm
	cvta.to.global.u64 %rd473, %rd474;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd473];
	// inline asm
	add.s64 	%rd477, %rd450, 128;
	// inline asm
	cvta.to.global.u64 %rd476, %rd477;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd476];
	// inline asm
	add.s64 	%rd480, %rd450, 144;
	// inline asm
	cvta.to.global.u64 %rd479, %rd480;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd479];
	// inline asm
	mov.b32 	 %f1532, %r512;
	mov.b32 	 %f1533, %r513;
	cvt.u32.u16	%r565, %rs15;
	add.s32 	%r566, %r565, -1;
	cvt.rn.f32.s32	%f1534, %r566;
	sub.f32 	%f1535, %f957, %f1532;
	mul.f32 	%f1536, %f1535, %f1534;
	sub.f32 	%f1537, %f1533, %f1532;
	div.rn.f32 	%f1538, %f1536, %f1537;
	min.f32 	%f1539, %f1534, %f1538;
	mov.f32 	%f1540, 0f00000000;
	max.f32 	%f1541, %f1540, %f1539;
	cvt.rmi.f32.f32	%f1542, %f1541;
	cvt.rzi.s32.f32	%r567, %f1542;
	cvt.s64.s32	%rd40, %r567;
	mul.wide.s32 	%rd494, %r567, 64;
	add.s64 	%rd483, %rd459, %rd494;
	// inline asm
	cvta.to.global.u64 %rd482, %rd483;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd482];
	// inline asm
	mov.b32 	 %f2019, %r549;
	mov.b32 	 %f2020, %r550;
	mov.b32 	 %f2021, %r551;
	add.s64 	%rd486, %rd483, 16;
	// inline asm
	cvta.to.global.u64 %rd485, %rd486;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd485];
	// inline asm
	mov.b32 	 %f2022, %r553;
	mov.b32 	 %f2023, %r554;
	mov.b32 	 %f2024, %r556;
	add.s64 	%rd489, %rd483, 32;
	// inline asm
	cvta.to.global.u64 %rd488, %rd489;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd488];
	// inline asm
	sub.f32 	%f536, %f1541, %f1542;
	mov.b32 	 %f2025, %r558;
	mov.b32 	 %f2026, %r559;
	mov.b32 	 %f2027, %r560;
	add.s64 	%rd492, %rd483, 48;
	// inline asm
	cvta.to.global.u64 %rd491, %rd492;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r561,%r562,%r563,%r564}, [%rd491];
	// inline asm
	mov.b32 	 %f2028, %r561;
	setp.leu.f32	%p57, %f536, 0f00000000;
	@%p57 bra 	BB8_87;

	shl.b64 	%rd507, %rd40, 6;
	add.s64 	%rd508, %rd507, %rd450;
	add.s64 	%rd496, %rd508, 96;
	// inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd495];
	// inline asm
	mov.b32 	 %f1543, %r568;
	mov.b32 	 %f1544, %r569;
	mov.b32 	 %f1545, %r570;
	add.s64 	%rd499, %rd508, 112;
	// inline asm
	cvta.to.global.u64 %rd498, %rd499;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd498];
	// inline asm
	mov.b32 	 %f1546, %r572;
	mov.b32 	 %f1547, %r573;
	mov.b32 	 %f1548, %r575;
	add.s64 	%rd502, %rd508, 128;
	// inline asm
	cvta.to.global.u64 %rd501, %rd502;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd501];
	// inline asm
	mov.b32 	 %f1549, %r577;
	mov.b32 	 %f1550, %r578;
	mov.b32 	 %f1551, %r579;
	add.s64 	%rd505, %rd508, 144;
	// inline asm
	cvta.to.global.u64 %rd504, %rd505;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd504];
	// inline asm
	mov.f32 	%f1552, 0f3F800000;
	sub.f32 	%f1553, %f1552, %f536;
	mul.f32 	%f1554, %f536, %f1543;
	mul.f32 	%f1555, %f536, %f1544;
	mul.f32 	%f1556, %f536, %f1545;
	fma.rn.f32 	%f2019, %f1553, %f2019, %f1554;
	fma.rn.f32 	%f2020, %f1553, %f2020, %f1555;
	fma.rn.f32 	%f2021, %f1553, %f2021, %f1556;
	mul.f32 	%f1557, %f536, %f1546;
	mul.f32 	%f1558, %f536, %f1547;
	mul.f32 	%f1559, %f536, %f1548;
	fma.rn.f32 	%f2022, %f1553, %f2022, %f1557;
	fma.rn.f32 	%f2023, %f1553, %f2023, %f1558;
	fma.rn.f32 	%f2024, %f1553, %f2024, %f1559;
	mul.f32 	%f1560, %f536, %f1549;
	mul.f32 	%f1561, %f536, %f1550;
	mul.f32 	%f1562, %f536, %f1551;
	fma.rn.f32 	%f1563, %f1553, %f2025, %f1560;
	fma.rn.f32 	%f1564, %f1553, %f2026, %f1561;
	fma.rn.f32 	%f1565, %f1553, %f2027, %f1562;
	mov.b32 	 %f1566, %r580;
	mul.f32 	%f1567, %f536, %f1566;
	fma.rn.f32 	%f1568, %f1553, %f2028, %f1567;
	mul.f32 	%f1569, %f1564, %f1564;
	fma.rn.f32 	%f1570, %f1563, %f1563, %f1569;
	fma.rn.f32 	%f1571, %f1565, %f1565, %f1570;
	fma.rn.f32 	%f1572, %f1568, %f1568, %f1571;
	sqrt.rn.f32 	%f1573, %f1572;
	rcp.rn.f32 	%f1574, %f1573;
	mul.f32 	%f2025, %f1563, %f1574;
	mul.f32 	%f2026, %f1564, %f1574;
	mul.f32 	%f2027, %f1565, %f1574;
	mul.f32 	%f2028, %f1568, %f1574;

BB8_87:
	mul.f32 	%f1575, %f2026, %f2026;
	fma.rn.f32 	%f1576, %f2025, %f2025, %f1575;
	fma.rn.f32 	%f1577, %f2027, %f2027, %f1576;
	fma.rn.f32 	%f1578, %f2028, %f2028, %f1577;
	rcp.rn.f32 	%f1579, %f1578;
	mul.f32 	%f1580, %f2025, %f1579;
	mul.f32 	%f1581, %f2026, %f1579;
	mul.f32 	%f1582, %f2027, %f1579;
	mul.f32 	%f1583, %f2028, %f1579;
	mul.f32 	%f1584, %f2025, %f1580;
	mul.f32 	%f1585, %f2026, %f1581;
	mul.f32 	%f1586, %f2027, %f1582;
	mul.f32 	%f1587, %f2025, %f1581;
	mul.f32 	%f1588, %f2027, %f1583;
	mul.f32 	%f1589, %f2025, %f1582;
	mul.f32 	%f1590, %f2026, %f1583;
	mul.f32 	%f1591, %f2026, %f1582;
	mul.f32 	%f1592, %f2025, %f1583;
	sub.f32 	%f1593, %f1584, %f1585;
	sub.f32 	%f1594, %f1593, %f1586;
	fma.rn.f32 	%f1595, %f2028, %f1583, %f1594;
	sub.f32 	%f1596, %f1587, %f1588;
	add.f32 	%f1597, %f1596, %f1596;
	add.f32 	%f1598, %f1589, %f1590;
	add.f32 	%f1599, %f1598, %f1598;
	add.f32 	%f1600, %f1587, %f1588;
	add.f32 	%f1601, %f1600, %f1600;
	sub.f32 	%f1602, %f1585, %f1584;
	sub.f32 	%f1603, %f1602, %f1586;
	fma.rn.f32 	%f1604, %f2028, %f1583, %f1603;
	sub.f32 	%f1605, %f1591, %f1592;
	add.f32 	%f1606, %f1605, %f1605;
	sub.f32 	%f1607, %f1589, %f1590;
	add.f32 	%f1608, %f1607, %f1607;
	add.f32 	%f1609, %f1591, %f1592;
	add.f32 	%f1610, %f1609, %f1609;
	neg.f32 	%f1611, %f1584;
	sub.f32 	%f1612, %f1611, %f1585;
	add.f32 	%f1613, %f1586, %f1612;
	fma.rn.f32 	%f1614, %f2028, %f1583, %f1613;
	mul.f32 	%f1615, %f2021, %f1595;
	fma.rn.f32 	%f1616, %f2023, %f1597, %f1615;
	fma.rn.f32 	%f2037, %f2024, %f1599, %f1616;
	mul.f32 	%f1617, %f2023, %f1604;
	fma.rn.f32 	%f1618, %f2021, %f1601, %f1617;
	fma.rn.f32 	%f2034, %f2024, %f1606, %f1618;
	mul.f32 	%f1619, %f2023, %f1610;
	fma.rn.f32 	%f1620, %f2021, %f1608, %f1619;
	fma.rn.f32 	%f2031, %f2024, %f1614, %f1620;
	mul.f32 	%f1621, %f2020, %f1595;
	fma.rn.f32 	%f2036, %f2022, %f1597, %f1621;
	mul.f32 	%f1622, %f2022, %f1604;
	fma.rn.f32 	%f2033, %f2020, %f1601, %f1622;
	mul.f32 	%f1623, %f2022, %f1610;
	fma.rn.f32 	%f2030, %f2020, %f1608, %f1623;
	mul.f32 	%f2035, %f2019, %f1595;
	mul.f32 	%f2032, %f2019, %f1601;
	mul.f32 	%f2029, %f2019, %f1608;

BB8_90:
	mul.f32 	%f1655, %f2030, %f2034;
	mul.f32 	%f1656, %f2031, %f2033;
	sub.f32 	%f1657, %f1656, %f1655;
	mul.f32 	%f1658, %f2035, %f1657;
	mul.f32 	%f1659, %f2029, %f2034;
	mul.f32 	%f1660, %f2031, %f2032;
	sub.f32 	%f1661, %f1660, %f1659;
	mul.f32 	%f1662, %f1661, %f2036;
	sub.f32 	%f1663, %f1658, %f1662;
	mul.f32 	%f1664, %f2029, %f2033;
	mul.f32 	%f1665, %f2030, %f2032;
	sub.f32 	%f1666, %f1665, %f1664;
	fma.rn.f32 	%f1667, %f1666, %f2037, %f1663;
	rcp.rn.f32 	%f1668, %f1667;
	mul.f32 	%f2044, %f1657, %f1668;
	mul.f32 	%f1669, %f2031, %f2036;
	mul.f32 	%f1670, %f2030, %f2037;
	sub.f32 	%f1671, %f1670, %f1669;
	mul.f32 	%f2045, %f1668, %f1671;
	mul.f32 	%f1672, %f2033, %f2037;
	mul.f32 	%f1673, %f2034, %f2036;
	sub.f32 	%f1674, %f1673, %f1672;
	mul.f32 	%f2046, %f1668, %f1674;
	sub.f32 	%f1675, %f1659, %f1660;
	mul.f32 	%f2041, %f1675, %f1668;
	mul.f32 	%f1676, %f2029, %f2037;
	mul.f32 	%f1677, %f2031, %f2035;
	sub.f32 	%f1678, %f1677, %f1676;
	mul.f32 	%f2042, %f1668, %f1678;
	mul.f32 	%f1679, %f2034, %f2035;
	mul.f32 	%f1680, %f2032, %f2037;
	sub.f32 	%f1681, %f1680, %f1679;
	mul.f32 	%f2043, %f1668, %f1681;
	mul.f32 	%f2038, %f1666, %f1668;
	mul.f32 	%f1682, %f2030, %f2035;
	mul.f32 	%f1683, %f2029, %f2036;
	sub.f32 	%f1684, %f1683, %f1682;
	mul.f32 	%f2039, %f1684, %f1668;
	mul.f32 	%f1685, %f2032, %f2036;
	mul.f32 	%f1686, %f2033, %f2035;
	sub.f32 	%f1687, %f1686, %f1685;
	mul.f32 	%f2040, %f1687, %f1668;
	bra.uni 	BB8_91;

BB8_80:
	setp.ne.s32	%p55, %r495, 1;
	mov.f32 	%f2039, %f2038;
	mov.f32 	%f2041, %f2038;
	mov.f32 	%f2042, %f2040;
	mov.f32 	%f2043, %f2038;
	mov.f32 	%f2044, %f2040;
	mov.f32 	%f2045, %f2038;
	mov.f32 	%f2046, %f2038;
	@%p55 bra 	BB8_91;

	// inline asm
	call (%rd437), _optix_get_static_transform_from_handle, (%rd435);
	// inline asm
	add.s64 	%rd665, %rd437, 64;

BB8_83:
	// inline asm
	cvta.to.global.u64 %rd441, %rd665;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd441];
	// inline asm
	mov.b32 	 %f2044, %r497;
	mov.b32 	 %f2045, %r498;
	mov.b32 	 %f2046, %r499;
	add.s64 	%rd445, %rd665, 16;
	// inline asm
	cvta.to.global.u64 %rd444, %rd445;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd444];
	// inline asm
	mov.b32 	 %f2041, %r501;
	mov.b32 	 %f2042, %r502;
	mov.b32 	 %f2043, %r503;
	add.s64 	%rd448, %rd665, 32;
	// inline asm
	cvta.to.global.u64 %rd447, %rd448;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd447];
	// inline asm
	mov.b32 	 %f2038, %r505;
	mov.b32 	 %f2039, %r506;
	mov.b32 	 %f2040, %r507;

BB8_91:
	setp.eq.s32	%p59, %r649, 0;
	@%p59 bra 	BB8_92;
	bra.uni 	BB8_93;

BB8_92:
	mov.f32 	%f2018, %f2038;
	mov.f32 	%f2017, %f2039;
	mov.f32 	%f2016, %f2040;
	mov.f32 	%f2015, %f2041;
	mov.f32 	%f2014, %f2042;
	mov.f32 	%f2013, %f2043;
	mov.f32 	%f2012, %f2044;
	mov.f32 	%f2011, %f2045;
	mov.f32 	%f2010, %f2046;
	bra.uni 	BB8_94;

BB8_93:
	mul.f32 	%f1688, %f2015, %f2045;
	fma.rn.f32 	%f1689, %f2012, %f2044, %f1688;
	fma.rn.f32 	%f616, %f2018, %f2046, %f1689;
	mul.f32 	%f1690, %f2014, %f2045;
	fma.rn.f32 	%f1691, %f2011, %f2044, %f1690;
	fma.rn.f32 	%f617, %f2017, %f2046, %f1691;
	mul.f32 	%f1692, %f2013, %f2045;
	fma.rn.f32 	%f1693, %f2010, %f2044, %f1692;
	fma.rn.f32 	%f618, %f2016, %f2046, %f1693;
	mul.f32 	%f1694, %f2015, %f2042;
	fma.rn.f32 	%f1695, %f2012, %f2041, %f1694;
	fma.rn.f32 	%f619, %f2018, %f2043, %f1695;
	mul.f32 	%f1696, %f2014, %f2042;
	fma.rn.f32 	%f1697, %f2011, %f2041, %f1696;
	fma.rn.f32 	%f620, %f2017, %f2043, %f1697;
	mul.f32 	%f1698, %f2013, %f2042;
	fma.rn.f32 	%f1699, %f2010, %f2041, %f1698;
	fma.rn.f32 	%f621, %f2016, %f2043, %f1699;
	mul.f32 	%f1700, %f2015, %f2039;
	fma.rn.f32 	%f1701, %f2012, %f2038, %f1700;
	fma.rn.f32 	%f2018, %f2018, %f2040, %f1701;
	mul.f32 	%f1702, %f2014, %f2039;
	fma.rn.f32 	%f1703, %f2011, %f2038, %f1702;
	fma.rn.f32 	%f2017, %f2017, %f2040, %f1703;
	mul.f32 	%f1704, %f2013, %f2039;
	fma.rn.f32 	%f1705, %f2010, %f2038, %f1704;
	fma.rn.f32 	%f2016, %f2016, %f2040, %f1705;
	mov.f32 	%f2015, %f619;
	mov.f32 	%f2014, %f620;
	mov.f32 	%f2013, %f621;
	mov.f32 	%f2012, %f616;
	mov.f32 	%f2011, %f617;
	mov.f32 	%f2010, %f618;

BB8_94:
	add.s32 	%r649, %r649, 1;
	setp.lt.u32	%p60, %r649, %r30;
	@%p60 bra 	BB8_78;

BB8_95:
	fma.rn.f32 	%f1706, %f2101, %f1949, %f1946;
	fma.rn.f32 	%f1707, %f2102, %f1948, %f1706;
	fma.rn.f32 	%f1708, %f2101, %f1953, %f1950;
	fma.rn.f32 	%f1709, %f2102, %f1952, %f1708;
	fma.rn.f32 	%f1710, %f2101, %f1957, %f1954;
	fma.rn.f32 	%f1711, %f2102, %f1956, %f1710;
	fma.rn.f32 	%f2101, %f2103, %f1947, %f1707;
	fma.rn.f32 	%f2102, %f2103, %f1951, %f1709;
	fma.rn.f32 	%f2103, %f2103, %f1955, %f1711;
	ld.const.u64 	%rd556, [params+112];
	setp.eq.s64	%p61, %rd556, 0;
	mov.f32 	%f2095, %f2098;
	mov.f32 	%f2096, %f2099;
	mov.f32 	%f2097, %f2100;
	@%p61 bra 	BB8_97;

	mul.f32 	%f1712, %f2098, %f2012;
	fma.rn.f32 	%f1713, %f2099, %f2015, %f1712;
	mul.f32 	%f1714, %f2098, %f2011;
	fma.rn.f32 	%f1715, %f2099, %f2014, %f1714;
	mul.f32 	%f1716, %f2098, %f2010;
	fma.rn.f32 	%f1717, %f2099, %f2013, %f1716;
	fma.rn.f32 	%f1718, %f2100, %f2018, %f1713;
	fma.rn.f32 	%f1719, %f2100, %f2017, %f1715;
	fma.rn.f32 	%f1720, %f2100, %f2016, %f1717;
	mul.f32 	%f1721, %f1718, %f1718;
	fma.rn.f32 	%f1722, %f1719, %f1719, %f1721;
	fma.rn.f32 	%f1723, %f1720, %f1720, %f1722;
	sqrt.rn.f32 	%f1724, %f1723;
	div.rn.f32 	%f2095, %f1718, %f1724;
	div.rn.f32 	%f2096, %f1719, %f1724;
	div.rn.f32 	%f2097, %f1720, %f1724;

BB8_97:
	ld.const.u64 	%rd557, [params+136];
	setp.eq.s64	%p62, %rd557, 0;
	@%p62 bra 	BB8_99;

	mul.f32 	%f1725, %f2098, %f2012;
	fma.rn.f32 	%f1726, %f2099, %f2015, %f1725;
	mul.f32 	%f1727, %f2098, %f2011;
	fma.rn.f32 	%f1728, %f2099, %f2014, %f1727;
	mul.f32 	%f1729, %f2098, %f2010;
	fma.rn.f32 	%f1730, %f2099, %f2013, %f1729;
	fma.rn.f32 	%f1731, %f2100, %f2018, %f1726;
	fma.rn.f32 	%f1732, %f2100, %f2017, %f1728;
	fma.rn.f32 	%f1733, %f2100, %f2016, %f1730;
	mul.f32 	%f1734, %f1731, %f1731;
	fma.rn.f32 	%f1735, %f1732, %f1732, %f1734;
	fma.rn.f32 	%f1736, %f1733, %f1733, %f1735;
	sqrt.rn.f32 	%f1737, %f1736;
	div.rn.f32 	%f2098, %f1731, %f1737;
	div.rn.f32 	%f2099, %f1732, %f1737;
	div.rn.f32 	%f2100, %f1733, %f1737;

BB8_99:
	ld.const.u64 	%rd558, [params+184];
	setp.eq.s64	%p63, %rd558, 0;
	@%p63 bra 	BB8_101;

	mul.f32 	%f1738, %f342, %f1949;
	fma.rn.f32 	%f1739, %f341, %f1948, %f1738;
	mul.f32 	%f1740, %f342, %f1953;
	fma.rn.f32 	%f1741, %f341, %f1952, %f1740;
	mul.f32 	%f1742, %f342, %f1957;
	fma.rn.f32 	%f1743, %f341, %f1956, %f1742;
	fma.rn.f32 	%f342, %f340, %f1947, %f1739;
	fma.rn.f32 	%f341, %f340, %f1951, %f1741;
	fma.rn.f32 	%f340, %f340, %f1955, %f1743;
	mul.f32 	%f1744, %f345, %f1949;
	fma.rn.f32 	%f1745, %f344, %f1948, %f1744;
	mul.f32 	%f1746, %f345, %f1953;
	fma.rn.f32 	%f1747, %f344, %f1952, %f1746;
	mul.f32 	%f1748, %f345, %f1957;
	fma.rn.f32 	%f1749, %f344, %f1956, %f1748;
	fma.rn.f32 	%f345, %f343, %f1947, %f1745;
	fma.rn.f32 	%f344, %f343, %f1951, %f1747;
	fma.rn.f32 	%f343, %f343, %f1955, %f1749;

BB8_101:
	ld.const.u64 	%rd559, [params+280];
	ld.const.u64 	%rd560, [params+232];
	or.b64  	%rd561, %rd559, %rd560;
	setp.eq.s64	%p64, %rd561, 0;
	@%p64 bra 	BB8_103;

	mul.f32 	%f1750, %f2098, %f1949;
	fma.rn.f32 	%f1751, %f2099, %f1953, %f1750;
	mul.f32 	%f1752, %f2098, %f1948;
	fma.rn.f32 	%f1753, %f2099, %f1952, %f1752;
	mul.f32 	%f1754, %f2098, %f1947;
	fma.rn.f32 	%f1755, %f2099, %f1951, %f1754;
	fma.rn.f32 	%f1756, %f2100, %f1957, %f1751;
	fma.rn.f32 	%f1757, %f2100, %f1956, %f1753;
	fma.rn.f32 	%f1758, %f2100, %f1955, %f1755;
	mul.f32 	%f1759, %f1756, %f1756;
	fma.rn.f32 	%f1760, %f1757, %f1757, %f1759;
	fma.rn.f32 	%f1761, %f1758, %f1758, %f1760;
	sqrt.rn.f32 	%f1762, %f1761;
	div.rn.f32 	%f1763, %f1756, %f1762;
	div.rn.f32 	%f1764, %f1757, %f1762;
	div.rn.f32 	%f1765, %f1758, %f1762;
	mul.f32 	%f1766, %f1763, %f2012;
	mul.f32 	%f1767, %f1763, %f2011;
	mul.f32 	%f1768, %f1763, %f2010;
	fma.rn.f32 	%f1769, %f1764, %f2015, %f1766;
	fma.rn.f32 	%f1770, %f1764, %f2014, %f1767;
	fma.rn.f32 	%f1771, %f1764, %f2013, %f1768;
	fma.rn.f32 	%f1772, %f1765, %f2018, %f1769;
	fma.rn.f32 	%f1773, %f1765, %f2017, %f1770;
	fma.rn.f32 	%f1774, %f1765, %f2016, %f1771;
	mul.f32 	%f1775, %f1772, %f1772;
	fma.rn.f32 	%f1776, %f1773, %f1773, %f1775;
	fma.rn.f32 	%f1777, %f1774, %f1774, %f1776;
	sqrt.rn.f32 	%f1778, %f1777;
	rcp.rn.f32 	%f1779, %f1778;
	mul.f32 	%f1780, %f1779, %f1772;
	mul.f32 	%f1781, %f1779, %f1773;
	mul.f32 	%f1782, %f1779, %f1774;
	mul.f32 	%f1783, %f2086, %f2012;
	fma.rn.f32 	%f1784, %f2087, %f2015, %f1783;
	mul.f32 	%f1785, %f2086, %f2011;
	fma.rn.f32 	%f1786, %f2087, %f2014, %f1785;
	mul.f32 	%f1787, %f2086, %f2010;
	fma.rn.f32 	%f1788, %f2087, %f2013, %f1787;
	fma.rn.f32 	%f1789, %f2088, %f2018, %f1784;
	fma.rn.f32 	%f1790, %f2088, %f2017, %f1786;
	fma.rn.f32 	%f1791, %f2088, %f2016, %f1788;
	mul.f32 	%f1792, %f1789, %f1779;
	mul.f32 	%f1793, %f1790, %f1779;
	mul.f32 	%f1794, %f1791, %f1779;
	mul.f32 	%f1795, %f2083, %f2012;
	fma.rn.f32 	%f1796, %f2084, %f2015, %f1795;
	mul.f32 	%f1797, %f2083, %f2011;
	fma.rn.f32 	%f1798, %f2084, %f2014, %f1797;
	mul.f32 	%f1799, %f2083, %f2010;
	fma.rn.f32 	%f1800, %f2084, %f2013, %f1799;
	fma.rn.f32 	%f1801, %f2085, %f2018, %f1796;
	fma.rn.f32 	%f1802, %f2085, %f2017, %f1798;
	fma.rn.f32 	%f1803, %f2085, %f2016, %f1800;
	mul.f32 	%f1804, %f1801, %f1779;
	mul.f32 	%f1805, %f1802, %f1779;
	mul.f32 	%f1806, %f1803, %f1779;
	mul.f32 	%f1807, %f1780, %f1792;
	fma.rn.f32 	%f1808, %f1781, %f1793, %f1807;
	fma.rn.f32 	%f1809, %f1782, %f1794, %f1808;
	mul.f32 	%f1810, %f1780, %f1809;
	mul.f32 	%f1811, %f1781, %f1809;
	mul.f32 	%f1812, %f1782, %f1809;
	sub.f32 	%f2086, %f1792, %f1810;
	sub.f32 	%f2087, %f1793, %f1811;
	sub.f32 	%f2088, %f1794, %f1812;
	mul.f32 	%f1813, %f1780, %f1804;
	fma.rn.f32 	%f1814, %f1781, %f1805, %f1813;
	fma.rn.f32 	%f1815, %f1782, %f1806, %f1814;
	mul.f32 	%f1816, %f1780, %f1815;
	mul.f32 	%f1817, %f1781, %f1815;
	mul.f32 	%f1818, %f1782, %f1815;
	sub.f32 	%f2083, %f1804, %f1816;
	sub.f32 	%f2084, %f1805, %f1817;
	sub.f32 	%f2085, %f1806, %f1818;

BB8_103:
	st.global.u32 	[%rd26], %r343;
	bra.uni 	BB8_104;

BB8_57:
	mov.f32 	%f2095, %f2098;
	mov.f32 	%f2096, %f2099;
	mov.f32 	%f2097, %f2100;

BB8_104:
	ld.const.u64 	%rd562, [params+328];
	cvta.to.global.u64 	%rd563, %rd562;
	shl.b64 	%rd564, %rd25, 3;
	add.s64 	%rd565, %rd563, %rd564;
	st.global.u64 	[%rd565], %rd24;
	ld.const.u64 	%rd566, [params+336];
	cvta.to.global.u64 	%rd567, %rd566;
	shl.b64 	%rd568, %rd25, 2;
	add.s64 	%rd569, %rd567, %rd568;
	mov.u32 	%r643, 0;
	st.global.u32 	[%rd569], %r643;
	ld.const.u64 	%rd570, [params+160];
	cvta.to.global.u64 	%rd571, %rd570;
	add.s64 	%rd572, %rd571, %rd568;
	st.global.f32 	[%rd572], %f2101;
	ld.const.u64 	%rd573, [params+168];
	cvta.to.global.u64 	%rd574, %rd573;
	add.s64 	%rd575, %rd574, %rd568;
	st.global.f32 	[%rd575], %f2102;
	ld.const.u64 	%rd576, [params+176];
	cvta.to.global.u64 	%rd577, %rd576;
	add.s64 	%rd578, %rd577, %rd568;
	st.global.f32 	[%rd578], %f2103;
	ld.const.u64 	%rd579, [params+72];
	cvta.to.global.u64 	%rd580, %rd579;
	add.s64 	%rd581, %rd580, %rd568;
	st.global.f32 	[%rd581], %f1149;
	@%p24 bra 	BB8_106;

	cvta.to.global.u64 	%rd582, %rd23;
	add.s64 	%rd584, %rd582, %rd568;
	st.global.f32 	[%rd584], %f1945;
	ld.const.u64 	%rd585, [params+104];
	cvta.to.global.u64 	%rd586, %rd585;
	add.s64 	%rd587, %rd586, %rd568;
	st.global.f32 	[%rd587], %f1944;

BB8_106:
	ld.const.u64 	%rd43, [params+112];
	setp.eq.s64	%p66, %rd43, 0;
	@%p66 bra 	BB8_108;

	cvta.to.global.u64 	%rd588, %rd43;
	add.s64 	%rd590, %rd588, %rd568;
	st.global.f32 	[%rd590], %f2095;
	ld.const.u64 	%rd591, [params+120];
	cvta.to.global.u64 	%rd592, %rd591;
	add.s64 	%rd593, %rd592, %rd568;
	st.global.f32 	[%rd593], %f2096;
	ld.const.u64 	%rd594, [params+128];
	cvta.to.global.u64 	%rd595, %rd594;
	add.s64 	%rd596, %rd595, %rd568;
	st.global.f32 	[%rd596], %f2097;

BB8_108:
	ld.const.u64 	%rd44, [params+136];
	setp.eq.s64	%p67, %rd44, 0;
	@%p67 bra 	BB8_110;

	cvta.to.global.u64 	%rd597, %rd44;
	add.s64 	%rd599, %rd597, %rd568;
	st.global.f32 	[%rd599], %f2098;
	ld.const.u64 	%rd600, [params+144];
	cvta.to.global.u64 	%rd601, %rd600;
	add.s64 	%rd602, %rd601, %rd568;
	st.global.f32 	[%rd602], %f2099;
	ld.const.u64 	%rd603, [params+152];
	cvta.to.global.u64 	%rd604, %rd603;
	add.s64 	%rd605, %rd604, %rd568;
	st.global.f32 	[%rd605], %f2100;

BB8_110:
	ld.const.u64 	%rd45, [params+184];
	setp.eq.s64	%p68, %rd45, 0;
	@%p68 bra 	BB8_112;

	cvta.to.global.u64 	%rd606, %rd45;
	add.s64 	%rd608, %rd606, %rd568;
	st.global.f32 	[%rd608], %f342;
	ld.const.u64 	%rd609, [params+192];
	cvta.to.global.u64 	%rd610, %rd609;
	add.s64 	%rd611, %rd610, %rd568;
	st.global.f32 	[%rd611], %f341;
	ld.const.u64 	%rd612, [params+200];
	cvta.to.global.u64 	%rd613, %rd612;
	add.s64 	%rd614, %rd613, %rd568;
	st.global.f32 	[%rd614], %f340;
	ld.const.u64 	%rd615, [params+208];
	cvta.to.global.u64 	%rd616, %rd615;
	add.s64 	%rd617, %rd616, %rd568;
	st.global.f32 	[%rd617], %f345;
	ld.const.u64 	%rd618, [params+216];
	cvta.to.global.u64 	%rd619, %rd618;
	add.s64 	%rd620, %rd619, %rd568;
	st.global.f32 	[%rd620], %f344;
	ld.const.u64 	%rd621, [params+224];
	cvta.to.global.u64 	%rd622, %rd621;
	add.s64 	%rd623, %rd622, %rd568;
	st.global.f32 	[%rd623], %f343;

BB8_112:
	ld.const.u64 	%rd46, [params+232];
	setp.eq.s64	%p69, %rd46, 0;
	@%p69 bra 	BB8_114;

	cvta.to.global.u64 	%rd624, %rd46;
	add.s64 	%rd626, %rd624, %rd568;
	st.global.f32 	[%rd626], %f2086;
	ld.const.u64 	%rd627, [params+240];
	cvta.to.global.u64 	%rd628, %rd627;
	add.s64 	%rd629, %rd628, %rd568;
	st.global.f32 	[%rd629], %f2087;
	ld.const.u64 	%rd630, [params+248];
	cvta.to.global.u64 	%rd631, %rd630;
	add.s64 	%rd632, %rd631, %rd568;
	st.global.f32 	[%rd632], %f2088;
	ld.const.u64 	%rd633, [params+256];
	cvta.to.global.u64 	%rd634, %rd633;
	add.s64 	%rd635, %rd634, %rd568;
	st.global.f32 	[%rd635], %f2083;
	ld.const.u64 	%rd636, [params+264];
	cvta.to.global.u64 	%rd637, %rd636;
	add.s64 	%rd638, %rd637, %rd568;
	st.global.f32 	[%rd638], %f2084;
	ld.const.u64 	%rd639, [params+272];
	cvta.to.global.u64 	%rd640, %rd639;
	add.s64 	%rd641, %rd640, %rd568;
	st.global.f32 	[%rd641], %f2085;

BB8_114:
	ld.const.u64 	%rd47, [params+280];
	setp.eq.s64	%p70, %rd47, 0;
	@%p70 bra 	BB8_116;

	cvta.to.global.u64 	%rd642, %rd47;
	add.s64 	%rd644, %rd642, %rd568;
	st.global.f32 	[%rd644], %f2086;
	ld.const.u64 	%rd645, [params+288];
	cvta.to.global.u64 	%rd646, %rd645;
	add.s64 	%rd647, %rd646, %rd568;
	st.global.f32 	[%rd647], %f2087;
	ld.const.u64 	%rd648, [params+296];
	cvta.to.global.u64 	%rd649, %rd648;
	add.s64 	%rd650, %rd649, %rd568;
	st.global.f32 	[%rd650], %f2088;
	ld.const.u64 	%rd651, [params+304];
	cvta.to.global.u64 	%rd652, %rd651;
	add.s64 	%rd653, %rd652, %rd568;
	st.global.f32 	[%rd653], %f2083;
	ld.const.u64 	%rd654, [params+312];
	cvta.to.global.u64 	%rd655, %rd654;
	add.s64 	%rd656, %rd655, %rd568;
	st.global.f32 	[%rd656], %f2084;
	ld.const.u64 	%rd657, [params+320];
	cvta.to.global.u64 	%rd658, %rd657;
	add.s64 	%rd659, %rd658, %rd568;
	st.global.f32 	[%rd659], %f2085;

BB8_116:
	ret;
}

	// .globl	__intersection__asphsurf
.visible .entry __intersection__asphsurf(

)
{
	.reg .pred 	%p<516>;
	.reg .b16 	%rs<18>;
	.reg .f32 	%f<1018>;
	.reg .b32 	%r<904>;
	.reg .f64 	%fd<482>;
	.reg .b64 	%rd<271>;


	// inline asm
	call (%rd22), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd1, [%rd22+8];
	// inline asm
	call (%f357), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f358), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f965), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r32), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p23, %r32, 0;
	@%p23 bra 	BB9_1;

	mov.u32 	%r902, 0;
	// inline asm
	call (%f360), _optix_get_ray_time, ();
	// inline asm

BB9_3:
	.pragma "nounroll";
	// inline asm
	call (%rd23), _optix_get_transform_list_handle, (%r902);
	// inline asm
	// inline asm
	call (%r35), _optix_get_transform_type_from_handle, (%rd23);
	// inline asm
	and.b32  	%r36, %r35, -2;
	setp.eq.s32	%p24, %r36, 2;
	@%p24 bra 	BB9_9;
	bra.uni 	BB9_4;

BB9_9:
	setp.eq.s32	%p27, %r35, 2;
	@%p27 bra 	BB9_13;
	bra.uni 	BB9_10;

BB9_13:
	// inline asm
	call (%rd97), _optix_get_matrix_motion_transform_from_handle, (%rd23);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd99, %rd97;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd99];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r126;
	add.s64 	%rd103, %rd97, 16;
	// inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd102];
	// inline asm
	add.s64 	%rd106, %rd97, 32;
	// inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd105];
	// inline asm
	add.s64 	%rd109, %rd97, 48;
	// inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd108];
	// inline asm
	add.s64 	%rd112, %rd97, 64;
	// inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd111];
	// inline asm
	add.s64 	%rd115, %rd97, 80;
	// inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r144,%r145,%r146,%r147}, [%rd114];
	// inline asm
	add.s64 	%rd118, %rd97, 96;
	// inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r148,%r149,%r150,%r151}, [%rd117];
	// inline asm
	add.s64 	%rd121, %rd97, 112;
	// inline asm
	cvta.to.global.u64 %rd120, %rd121;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r152,%r153,%r154,%r155}, [%rd120];
	// inline asm
	mov.b32 	 %f487, %r127;
	mov.b32 	 %f488, %r128;
	cvt.u32.u16	%r168, %rs4;
	add.s32 	%r169, %r168, -1;
	cvt.rn.f32.s32	%f489, %r169;
	sub.f32 	%f490, %f360, %f487;
	mul.f32 	%f491, %f490, %f489;
	sub.f32 	%f492, %f488, %f487;
	div.rn.f32 	%f493, %f491, %f492;
	min.f32 	%f494, %f489, %f493;
	mov.f32 	%f495, 0f00000000;
	max.f32 	%f496, %f495, %f494;
	cvt.rmi.f32.f32	%f497, %f496;
	cvt.rzi.s32.f32	%r170, %f497;
	mul.wide.s32 	%rd132, %r170, 48;
	add.s64 	%rd124, %rd106, %rd132;
	// inline asm
	cvta.to.global.u64 %rd123, %rd124;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r156,%r157,%r158,%r159}, [%rd123];
	// inline asm
	mov.b32 	 %f937, %r156;
	mov.b32 	 %f938, %r157;
	mov.b32 	 %f939, %r158;
	mov.b32 	 %f940, %r159;
	add.s64 	%rd127, %rd124, 16;
	// inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r160,%r161,%r162,%r163}, [%rd126];
	// inline asm
	mov.b32 	 %f933, %r160;
	mov.b32 	 %f934, %r161;
	mov.b32 	 %f935, %r162;
	mov.b32 	 %f936, %r163;
	add.s64 	%rd130, %rd124, 32;
	// inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r164,%r165,%r166,%r167}, [%rd129];
	// inline asm
	sub.f32 	%f98, %f496, %f497;
	mov.b32 	 %f929, %r164;
	mov.b32 	 %f930, %r165;
	mov.b32 	 %f931, %r166;
	mov.b32 	 %f932, %r167;
	setp.leu.f32	%p29, %f98, 0f00000000;
	@%p29 bra 	BB9_15;

	cvt.rmi.f32.f32	%f900, %f496;
	cvt.rzi.s32.f32	%r901, %f900;
	cvt.s64.s32	%rd268, %r901;
	mul.lo.s64 	%rd142, %rd268, 48;
	add.s64 	%rd143, %rd97, %rd142;
	add.s64 	%rd134, %rd143, 80;
	// inline asm
	cvta.to.global.u64 %rd133, %rd134;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd133];
	// inline asm
	mov.b32 	 %f498, %r171;
	mov.b32 	 %f499, %r172;
	mov.b32 	 %f500, %r173;
	mov.b32 	 %f501, %r174;
	add.s64 	%rd137, %rd143, 96;
	// inline asm
	cvta.to.global.u64 %rd136, %rd137;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd136];
	// inline asm
	mov.b32 	 %f502, %r175;
	mov.b32 	 %f503, %r176;
	mov.b32 	 %f504, %r177;
	mov.b32 	 %f505, %r178;
	add.s64 	%rd140, %rd143, 112;
	// inline asm
	cvta.to.global.u64 %rd139, %rd140;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd139];
	// inline asm
	mov.f32 	%f506, 0f3F800000;
	sub.f32 	%f507, %f506, %f98;
	mul.f32 	%f508, %f98, %f498;
	mul.f32 	%f509, %f98, %f499;
	mul.f32 	%f510, %f98, %f500;
	mul.f32 	%f511, %f98, %f501;
	fma.rn.f32 	%f937, %f507, %f937, %f508;
	fma.rn.f32 	%f938, %f507, %f938, %f509;
	fma.rn.f32 	%f939, %f507, %f939, %f510;
	fma.rn.f32 	%f940, %f507, %f940, %f511;
	mul.f32 	%f512, %f98, %f502;
	mul.f32 	%f513, %f98, %f503;
	mul.f32 	%f514, %f98, %f504;
	mul.f32 	%f515, %f98, %f505;
	fma.rn.f32 	%f933, %f507, %f933, %f512;
	fma.rn.f32 	%f934, %f507, %f934, %f513;
	fma.rn.f32 	%f935, %f507, %f935, %f514;
	fma.rn.f32 	%f936, %f507, %f936, %f515;
	mov.b32 	 %f516, %r179;
	mov.b32 	 %f517, %r180;
	mov.b32 	 %f518, %r181;
	mov.b32 	 %f519, %r182;
	mul.f32 	%f520, %f98, %f516;
	mul.f32 	%f521, %f98, %f517;
	mul.f32 	%f522, %f98, %f518;
	mul.f32 	%f523, %f98, %f519;
	fma.rn.f32 	%f929, %f507, %f929, %f520;
	fma.rn.f32 	%f930, %f507, %f930, %f521;
	fma.rn.f32 	%f931, %f507, %f931, %f522;
	fma.rn.f32 	%f932, %f507, %f932, %f523;
	bra.uni 	BB9_15;

BB9_4:
	mov.f32 	%f941, 0f00000000;
	mov.f32 	%f943, 0f3F800000;
	setp.eq.s32	%p25, %r35, 4;
	@%p25 bra 	BB9_7;
	bra.uni 	BB9_5;

BB9_7:
	// inline asm
	call (%rd269), _optix_get_instance_inverse_transform_from_handle, (%rd23);
	// inline asm
	bra.uni 	BB9_8;

BB9_10:
	// inline asm
	call (%rd38), _optix_get_srt_motion_transform_from_handle, (%rd23);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd40, %rd38;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd40];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r51;
	add.s64 	%rd44, %rd38, 16;
	// inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd43];
	// inline asm
	add.s64 	%rd47, %rd38, 32;
	// inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd46];
	// inline asm
	add.s64 	%rd50, %rd38, 48;
	// inline asm
	cvta.to.global.u64 %rd49, %rd50;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd49];
	// inline asm
	add.s64 	%rd53, %rd38, 64;
	// inline asm
	cvta.to.global.u64 %rd52, %rd53;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd52];
	// inline asm
	add.s64 	%rd56, %rd38, 80;
	// inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd55];
	// inline asm
	add.s64 	%rd59, %rd38, 96;
	// inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd58];
	// inline asm
	add.s64 	%rd62, %rd38, 112;
	// inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd61];
	// inline asm
	add.s64 	%rd65, %rd38, 128;
	// inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r81,%r82,%r83,%r84}, [%rd64];
	// inline asm
	add.s64 	%rd68, %rd38, 144;
	// inline asm
	cvta.to.global.u64 %rd67, %rd68;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r85,%r86,%r87,%r88}, [%rd67];
	// inline asm
	mov.b32 	 %f374, %r52;
	mov.b32 	 %f375, %r53;
	cvt.u32.u16	%r105, %rs2;
	add.s32 	%r106, %r105, -1;
	cvt.rn.f32.s32	%f376, %r106;
	sub.f32 	%f377, %f360, %f374;
	mul.f32 	%f378, %f377, %f376;
	sub.f32 	%f379, %f375, %f374;
	div.rn.f32 	%f380, %f378, %f379;
	min.f32 	%f381, %f376, %f380;
	mov.f32 	%f382, 0f00000000;
	max.f32 	%f383, %f382, %f381;
	cvt.rmi.f32.f32	%f384, %f383;
	cvt.rzi.s32.f32	%r107, %f384;
	mul.wide.s32 	%rd82, %r107, 64;
	add.s64 	%rd71, %rd47, %rd82;
	// inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r89,%r90,%r91,%r92}, [%rd70];
	// inline asm
	mov.b32 	 %f913, %r89;
	mov.b32 	 %f914, %r90;
	mov.b32 	 %f915, %r91;
	mov.b32 	 %f916, %r92;
	add.s64 	%rd74, %rd71, 16;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r93,%r94,%r95,%r96}, [%rd73];
	// inline asm
	mov.b32 	 %f917, %r93;
	mov.b32 	 %f918, %r94;
	mov.b32 	 %f919, %r95;
	mov.b32 	 %f920, %r96;
	add.s64 	%rd77, %rd71, 32;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r97,%r98,%r99,%r100}, [%rd76];
	// inline asm
	sub.f32 	%f37, %f383, %f384;
	mov.b32 	 %f921, %r97;
	mov.b32 	 %f922, %r98;
	mov.b32 	 %f923, %r99;
	mov.b32 	 %f924, %r100;
	add.s64 	%rd80, %rd71, 48;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r101,%r102,%r103,%r104}, [%rd79];
	// inline asm
	mov.b32 	 %f925, %r101;
	mov.b32 	 %f926, %r102;
	mov.b32 	 %f927, %r103;
	mov.b32 	 %f928, %r104;
	setp.leu.f32	%p28, %f37, 0f00000000;
	@%p28 bra 	BB9_12;

	cvt.rmi.f32.f32	%f899, %f383;
	cvt.rzi.s32.f32	%r900, %f899;
	cvt.s64.s32	%rd267, %r900;
	shl.b64 	%rd95, %rd267, 6;
	add.s64 	%rd96, %rd95, %rd38;
	add.s64 	%rd84, %rd96, 96;
	// inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd83];
	// inline asm
	mov.b32 	 %f385, %r108;
	mov.b32 	 %f386, %r109;
	mov.b32 	 %f387, %r110;
	mov.b32 	 %f388, %r111;
	add.s64 	%rd87, %rd96, 112;
	// inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd86];
	// inline asm
	mov.b32 	 %f389, %r112;
	mov.b32 	 %f390, %r113;
	mov.b32 	 %f391, %r114;
	mov.b32 	 %f392, %r115;
	add.s64 	%rd90, %rd96, 128;
	// inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd89];
	// inline asm
	mov.b32 	 %f393, %r116;
	mov.b32 	 %f394, %r117;
	mov.b32 	 %f395, %r118;
	mov.b32 	 %f396, %r119;
	add.s64 	%rd93, %rd96, 144;
	// inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd92];
	// inline asm
	mov.f32 	%f397, 0f3F800000;
	sub.f32 	%f398, %f397, %f37;
	mul.f32 	%f399, %f37, %f385;
	mul.f32 	%f400, %f37, %f386;
	mul.f32 	%f401, %f37, %f387;
	mul.f32 	%f402, %f37, %f388;
	fma.rn.f32 	%f913, %f398, %f913, %f399;
	fma.rn.f32 	%f914, %f398, %f914, %f400;
	fma.rn.f32 	%f915, %f398, %f915, %f401;
	fma.rn.f32 	%f916, %f398, %f916, %f402;
	mul.f32 	%f403, %f37, %f389;
	mul.f32 	%f404, %f37, %f390;
	mul.f32 	%f405, %f37, %f391;
	mul.f32 	%f406, %f37, %f392;
	fma.rn.f32 	%f917, %f398, %f917, %f403;
	fma.rn.f32 	%f918, %f398, %f918, %f404;
	fma.rn.f32 	%f919, %f398, %f919, %f405;
	fma.rn.f32 	%f920, %f398, %f920, %f406;
	mul.f32 	%f407, %f37, %f393;
	mul.f32 	%f408, %f37, %f394;
	mul.f32 	%f409, %f37, %f395;
	mul.f32 	%f410, %f37, %f396;
	fma.rn.f32 	%f921, %f398, %f921, %f407;
	fma.rn.f32 	%f411, %f398, %f922, %f408;
	fma.rn.f32 	%f412, %f398, %f923, %f409;
	fma.rn.f32 	%f413, %f398, %f924, %f410;
	mov.b32 	 %f414, %r120;
	mov.b32 	 %f415, %r121;
	mov.b32 	 %f416, %r122;
	mov.b32 	 %f417, %r123;
	mul.f32 	%f418, %f37, %f414;
	mul.f32 	%f419, %f37, %f415;
	mul.f32 	%f420, %f37, %f416;
	mul.f32 	%f421, %f37, %f417;
	fma.rn.f32 	%f422, %f398, %f925, %f418;
	fma.rn.f32 	%f926, %f398, %f926, %f419;
	fma.rn.f32 	%f927, %f398, %f927, %f420;
	fma.rn.f32 	%f928, %f398, %f928, %f421;
	mul.f32 	%f423, %f412, %f412;
	fma.rn.f32 	%f424, %f411, %f411, %f423;
	fma.rn.f32 	%f425, %f413, %f413, %f424;
	fma.rn.f32 	%f426, %f422, %f422, %f425;
	sqrt.rn.f32 	%f427, %f426;
	rcp.rn.f32 	%f428, %f427;
	mul.f32 	%f922, %f411, %f428;
	mul.f32 	%f923, %f412, %f428;
	mul.f32 	%f924, %f413, %f428;
	mul.f32 	%f925, %f422, %f428;

BB9_12:
	mul.f32 	%f429, %f923, %f923;
	fma.rn.f32 	%f430, %f922, %f922, %f429;
	fma.rn.f32 	%f431, %f924, %f924, %f430;
	fma.rn.f32 	%f432, %f925, %f925, %f431;
	rcp.rn.f32 	%f433, %f432;
	mul.f32 	%f434, %f922, %f433;
	mul.f32 	%f435, %f923, %f433;
	mul.f32 	%f436, %f924, %f433;
	mul.f32 	%f437, %f925, %f433;
	mul.f32 	%f438, %f922, %f434;
	mul.f32 	%f439, %f923, %f435;
	mul.f32 	%f440, %f924, %f436;
	mul.f32 	%f441, %f922, %f435;
	mul.f32 	%f442, %f924, %f437;
	mul.f32 	%f443, %f922, %f436;
	mul.f32 	%f444, %f923, %f437;
	mul.f32 	%f445, %f923, %f436;
	mul.f32 	%f446, %f922, %f437;
	sub.f32 	%f447, %f438, %f439;
	sub.f32 	%f448, %f447, %f440;
	fma.rn.f32 	%f449, %f925, %f437, %f448;
	sub.f32 	%f450, %f441, %f442;
	add.f32 	%f451, %f450, %f450;
	add.f32 	%f452, %f443, %f444;
	add.f32 	%f453, %f452, %f452;
	add.f32 	%f454, %f441, %f442;
	add.f32 	%f455, %f454, %f454;
	sub.f32 	%f456, %f439, %f438;
	sub.f32 	%f457, %f456, %f440;
	fma.rn.f32 	%f458, %f925, %f437, %f457;
	sub.f32 	%f459, %f445, %f446;
	add.f32 	%f460, %f459, %f459;
	sub.f32 	%f461, %f443, %f444;
	add.f32 	%f462, %f461, %f461;
	add.f32 	%f463, %f445, %f446;
	add.f32 	%f464, %f463, %f463;
	neg.f32 	%f465, %f438;
	sub.f32 	%f466, %f465, %f439;
	add.f32 	%f467, %f440, %f466;
	fma.rn.f32 	%f468, %f925, %f437, %f467;
	mul.f32 	%f469, %f916, %f449;
	fma.rn.f32 	%f470, %f919, %f451, %f469;
	fma.rn.f32 	%f471, %f921, %f453, %f470;
	sub.f32 	%f940, %f926, %f471;
	mul.f32 	%f472, %f919, %f458;
	fma.rn.f32 	%f473, %f916, %f455, %f472;
	fma.rn.f32 	%f474, %f921, %f460, %f473;
	sub.f32 	%f936, %f927, %f474;
	mul.f32 	%f475, %f919, %f464;
	fma.rn.f32 	%f476, %f916, %f462, %f475;
	fma.rn.f32 	%f477, %f921, %f468, %f476;
	sub.f32 	%f932, %f928, %f477;
	mul.f32 	%f478, %f915, %f449;
	fma.rn.f32 	%f479, %f918, %f451, %f478;
	fma.rn.f32 	%f939, %f920, %f453, %f479;
	mul.f32 	%f480, %f918, %f458;
	fma.rn.f32 	%f481, %f915, %f455, %f480;
	fma.rn.f32 	%f935, %f920, %f460, %f481;
	mul.f32 	%f482, %f918, %f464;
	fma.rn.f32 	%f483, %f915, %f462, %f482;
	fma.rn.f32 	%f931, %f920, %f468, %f483;
	mul.f32 	%f484, %f914, %f449;
	fma.rn.f32 	%f938, %f917, %f451, %f484;
	mul.f32 	%f485, %f917, %f458;
	fma.rn.f32 	%f934, %f914, %f455, %f485;
	mul.f32 	%f486, %f917, %f464;
	fma.rn.f32 	%f930, %f914, %f462, %f486;
	mul.f32 	%f937, %f913, %f449;
	mul.f32 	%f933, %f913, %f455;
	mul.f32 	%f929, %f913, %f462;

BB9_15:
	mul.f32 	%f524, %f930, %f935;
	mul.f32 	%f525, %f931, %f934;
	sub.f32 	%f526, %f525, %f524;
	mul.f32 	%f527, %f937, %f526;
	mul.f32 	%f528, %f929, %f935;
	mul.f32 	%f529, %f931, %f933;
	sub.f32 	%f530, %f529, %f528;
	mul.f32 	%f531, %f530, %f938;
	sub.f32 	%f532, %f527, %f531;
	mul.f32 	%f533, %f929, %f934;
	mul.f32 	%f534, %f930, %f933;
	sub.f32 	%f535, %f534, %f533;
	fma.rn.f32 	%f536, %f535, %f939, %f532;
	rcp.rn.f32 	%f537, %f536;
	mul.f32 	%f949, %f526, %f537;
	mul.f32 	%f538, %f931, %f938;
	mul.f32 	%f539, %f930, %f939;
	sub.f32 	%f540, %f539, %f538;
	mul.f32 	%f950, %f537, %f540;
	mul.f32 	%f541, %f934, %f939;
	mul.f32 	%f542, %f935, %f938;
	sub.f32 	%f543, %f542, %f541;
	mul.f32 	%f951, %f537, %f543;
	sub.f32 	%f544, %f528, %f529;
	mul.f32 	%f945, %f544, %f537;
	mul.f32 	%f545, %f929, %f939;
	mul.f32 	%f546, %f931, %f937;
	sub.f32 	%f547, %f546, %f545;
	mul.f32 	%f946, %f537, %f547;
	mul.f32 	%f548, %f935, %f937;
	mul.f32 	%f549, %f933, %f939;
	sub.f32 	%f550, %f549, %f548;
	mul.f32 	%f947, %f537, %f550;
	mul.f32 	%f941, %f535, %f537;
	mul.f32 	%f551, %f930, %f937;
	mul.f32 	%f552, %f929, %f938;
	sub.f32 	%f553, %f552, %f551;
	mul.f32 	%f942, %f553, %f537;
	mul.f32 	%f554, %f933, %f938;
	mul.f32 	%f555, %f934, %f937;
	sub.f32 	%f556, %f555, %f554;
	mul.f32 	%f943, %f556, %f537;
	mul.f32 	%f557, %f940, %f949;
	neg.f32 	%f558, %f557;
	mul.f32 	%f559, %f936, %f950;
	sub.f32 	%f560, %f558, %f559;
	mul.f32 	%f561, %f932, %f951;
	sub.f32 	%f952, %f560, %f561;
	mul.f32 	%f562, %f940, %f945;
	neg.f32 	%f563, %f562;
	mul.f32 	%f564, %f936, %f946;
	sub.f32 	%f565, %f563, %f564;
	mul.f32 	%f566, %f932, %f947;
	sub.f32 	%f948, %f565, %f566;
	mul.f32 	%f567, %f940, %f941;
	neg.f32 	%f568, %f567;
	mul.f32 	%f569, %f936, %f942;
	sub.f32 	%f570, %f568, %f569;
	mul.f32 	%f571, %f932, %f943;
	sub.f32 	%f944, %f570, %f571;
	bra.uni 	BB9_16;

BB9_5:
	setp.ne.s32	%p26, %r35, 1;
	mov.f32 	%f942, %f941;
	mov.f32 	%f944, %f941;
	mov.f32 	%f945, %f941;
	mov.f32 	%f946, %f943;
	mov.f32 	%f947, %f941;
	mov.f32 	%f948, %f941;
	mov.f32 	%f949, %f943;
	mov.f32 	%f950, %f941;
	mov.f32 	%f951, %f941;
	mov.f32 	%f952, %f941;
	@%p26 bra 	BB9_16;

	// inline asm
	call (%rd25), _optix_get_static_transform_from_handle, (%rd23);
	// inline asm
	add.s64 	%rd269, %rd25, 64;

BB9_8:
	// inline asm
	cvta.to.global.u64 %rd29, %rd269;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd29];
	// inline asm
	mov.b32 	 %f949, %r37;
	mov.b32 	 %f950, %r38;
	mov.b32 	 %f951, %r39;
	mov.b32 	 %f952, %r40;
	add.s64 	%rd33, %rd269, 16;
	// inline asm
	cvta.to.global.u64 %rd32, %rd33;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd32];
	// inline asm
	mov.b32 	 %f945, %r41;
	mov.b32 	 %f946, %r42;
	mov.b32 	 %f947, %r43;
	mov.b32 	 %f948, %r44;
	add.s64 	%rd36, %rd269, 32;
	// inline asm
	cvta.to.global.u64 %rd35, %rd36;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd35];
	// inline asm
	mov.b32 	 %f941, %r45;
	mov.b32 	 %f942, %r46;
	mov.b32 	 %f943, %r47;
	mov.b32 	 %f944, %r48;

BB9_16:
	setp.eq.s32	%p30, %r902, 0;
	@%p30 bra 	BB9_17;
	bra.uni 	BB9_18;

BB9_17:
	mov.f32 	%f912, %f952;
	mov.f32 	%f911, %f951;
	mov.f32 	%f910, %f950;
	mov.f32 	%f909, %f949;
	mov.f32 	%f908, %f948;
	mov.f32 	%f907, %f947;
	mov.f32 	%f906, %f946;
	mov.f32 	%f905, %f945;
	mov.f32 	%f904, %f944;
	mov.f32 	%f903, %f943;
	mov.f32 	%f902, %f942;
	mov.f32 	%f901, %f941;
	bra.uni 	BB9_19;

BB9_18:
	mul.f32 	%f572, %f905, %f950;
	fma.rn.f32 	%f573, %f909, %f949, %f572;
	fma.rn.f32 	%f151, %f901, %f951, %f573;
	mul.f32 	%f574, %f906, %f950;
	fma.rn.f32 	%f575, %f910, %f949, %f574;
	fma.rn.f32 	%f152, %f902, %f951, %f575;
	mul.f32 	%f576, %f907, %f950;
	fma.rn.f32 	%f577, %f911, %f949, %f576;
	fma.rn.f32 	%f153, %f903, %f951, %f577;
	mul.f32 	%f578, %f908, %f950;
	fma.rn.f32 	%f579, %f912, %f949, %f578;
	fma.rn.f32 	%f580, %f904, %f951, %f579;
	add.f32 	%f154, %f952, %f580;
	mul.f32 	%f581, %f905, %f946;
	fma.rn.f32 	%f582, %f909, %f945, %f581;
	fma.rn.f32 	%f155, %f901, %f947, %f582;
	mul.f32 	%f583, %f906, %f946;
	fma.rn.f32 	%f584, %f910, %f945, %f583;
	fma.rn.f32 	%f156, %f902, %f947, %f584;
	mul.f32 	%f585, %f907, %f946;
	fma.rn.f32 	%f586, %f911, %f945, %f585;
	fma.rn.f32 	%f157, %f903, %f947, %f586;
	mul.f32 	%f587, %f908, %f946;
	fma.rn.f32 	%f588, %f912, %f945, %f587;
	fma.rn.f32 	%f589, %f904, %f947, %f588;
	add.f32 	%f158, %f948, %f589;
	mul.f32 	%f590, %f905, %f942;
	fma.rn.f32 	%f591, %f909, %f941, %f590;
	fma.rn.f32 	%f901, %f901, %f943, %f591;
	mul.f32 	%f592, %f906, %f942;
	fma.rn.f32 	%f593, %f910, %f941, %f592;
	fma.rn.f32 	%f902, %f902, %f943, %f593;
	mul.f32 	%f594, %f907, %f942;
	fma.rn.f32 	%f595, %f911, %f941, %f594;
	fma.rn.f32 	%f903, %f903, %f943, %f595;
	mul.f32 	%f596, %f908, %f942;
	fma.rn.f32 	%f597, %f912, %f941, %f596;
	fma.rn.f32 	%f598, %f904, %f943, %f597;
	add.f32 	%f904, %f944, %f598;
	mov.f32 	%f912, %f154;
	mov.f32 	%f911, %f153;
	mov.f32 	%f910, %f152;
	mov.f32 	%f909, %f151;
	mov.f32 	%f908, %f158;
	mov.f32 	%f907, %f157;
	mov.f32 	%f906, %f156;
	mov.f32 	%f905, %f155;

BB9_19:
	add.s32 	%r902, %r902, 1;
	setp.lt.u32	%p31, %r902, %r32;
	@%p31 bra 	BB9_3;

	mul.f32 	%f599, %f357, %f909;
	fma.rn.f32 	%f600, %f358, %f910, %f599;
	fma.rn.f32 	%f601, %f965, %f911, %f600;
	add.f32 	%f967, %f912, %f601;
	mul.f32 	%f602, %f357, %f905;
	fma.rn.f32 	%f603, %f358, %f906, %f602;
	fma.rn.f32 	%f604, %f965, %f907, %f603;
	add.f32 	%f966, %f908, %f604;
	mul.f32 	%f605, %f357, %f901;
	fma.rn.f32 	%f606, %f358, %f902, %f605;
	fma.rn.f32 	%f607, %f965, %f903, %f606;
	add.f32 	%f965, %f904, %f607;
	bra.uni 	BB9_21;

BB9_1:
	mov.f32 	%f966, %f358;
	mov.f32 	%f967, %f357;

BB9_21:
	setp.eq.s32	%p515, %r32, 0;
	// inline asm
	call (%f608), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f609), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1016), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f611), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r903, 0;
	@%p515 bra 	BB9_22;

BB9_23:
	.pragma "nounroll";
	// inline asm
	call (%rd144), _optix_get_transform_list_handle, (%r903);
	// inline asm
	// inline asm
	call (%r185), _optix_get_transform_type_from_handle, (%rd144);
	// inline asm
	and.b32  	%r186, %r185, -2;
	setp.eq.s32	%p33, %r186, 2;
	@%p33 bra 	BB9_29;
	bra.uni 	BB9_24;

BB9_29:
	setp.eq.s32	%p36, %r185, 2;
	@%p36 bra 	BB9_33;
	bra.uni 	BB9_30;

BB9_33:
	// inline asm
	call (%rd218), _optix_get_matrix_motion_transform_from_handle, (%rd144);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd220, %rd218;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd220];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r276;
	add.s64 	%rd224, %rd218, 16;
	// inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd223];
	// inline asm
	add.s64 	%rd227, %rd218, 32;
	// inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd226];
	// inline asm
	add.s64 	%rd230, %rd218, 48;
	// inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd229];
	// inline asm
	add.s64 	%rd233, %rd218, 64;
	// inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd232];
	// inline asm
	add.s64 	%rd236, %rd218, 80;
	// inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd235];
	// inline asm
	add.s64 	%rd239, %rd218, 96;
	// inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r298,%r299,%r300,%r301}, [%rd238];
	// inline asm
	add.s64 	%rd242, %rd218, 112;
	// inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r302,%r303,%r304,%r305}, [%rd241];
	// inline asm
	mov.b32 	 %f714, %r277;
	mov.b32 	 %f715, %r278;
	cvt.u32.u16	%r318, %rs8;
	add.s32 	%r319, %r318, -1;
	cvt.rn.f32.s32	%f716, %r319;
	sub.f32 	%f717, %f611, %f714;
	mul.f32 	%f718, %f717, %f716;
	sub.f32 	%f719, %f715, %f714;
	div.rn.f32 	%f720, %f718, %f719;
	min.f32 	%f721, %f716, %f720;
	mov.f32 	%f722, 0f00000000;
	max.f32 	%f723, %f722, %f721;
	cvt.rmi.f32.f32	%f724, %f723;
	cvt.rzi.s32.f32	%r320, %f724;
	cvt.s64.s32	%rd17, %r320;
	mul.wide.s32 	%rd253, %r320, 48;
	add.s64 	%rd245, %rd227, %rd253;
	// inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r306,%r307,%r308,%r309}, [%rd244];
	// inline asm
	mov.b32 	 %f993, %r306;
	mov.b32 	 %f994, %r307;
	mov.b32 	 %f995, %r308;
	add.s64 	%rd248, %rd245, 16;
	// inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r310,%r311,%r312,%r313}, [%rd247];
	// inline asm
	mov.b32 	 %f990, %r310;
	mov.b32 	 %f991, %r311;
	mov.b32 	 %f992, %r312;
	add.s64 	%rd251, %rd245, 32;
	// inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r314,%r315,%r316,%r317}, [%rd250];
	// inline asm
	sub.f32 	%f249, %f723, %f724;
	mov.b32 	 %f987, %r314;
	mov.b32 	 %f988, %r315;
	mov.b32 	 %f989, %r316;
	setp.leu.f32	%p38, %f249, 0f00000000;
	@%p38 bra 	BB9_35;

	mul.lo.s64 	%rd263, %rd17, 48;
	add.s64 	%rd264, %rd218, %rd263;
	add.s64 	%rd255, %rd264, 80;
	// inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r321,%r322,%r323,%r324}, [%rd254];
	// inline asm
	mov.b32 	 %f725, %r321;
	mov.b32 	 %f726, %r322;
	mov.b32 	 %f727, %r323;
	add.s64 	%rd258, %rd264, 96;
	// inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r325,%r326,%r327,%r328}, [%rd257];
	// inline asm
	mov.b32 	 %f728, %r325;
	mov.b32 	 %f729, %r326;
	mov.b32 	 %f730, %r327;
	add.s64 	%rd261, %rd264, 112;
	// inline asm
	cvta.to.global.u64 %rd260, %rd261;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r329,%r330,%r331,%r332}, [%rd260];
	// inline asm
	mov.f32 	%f731, 0f3F800000;
	sub.f32 	%f732, %f731, %f249;
	mul.f32 	%f733, %f249, %f725;
	mul.f32 	%f734, %f249, %f726;
	mul.f32 	%f735, %f249, %f727;
	fma.rn.f32 	%f993, %f732, %f993, %f733;
	fma.rn.f32 	%f994, %f732, %f994, %f734;
	fma.rn.f32 	%f995, %f732, %f995, %f735;
	mul.f32 	%f736, %f249, %f728;
	mul.f32 	%f737, %f249, %f729;
	mul.f32 	%f738, %f249, %f730;
	fma.rn.f32 	%f990, %f732, %f990, %f736;
	fma.rn.f32 	%f991, %f732, %f991, %f737;
	fma.rn.f32 	%f992, %f732, %f992, %f738;
	mov.b32 	 %f739, %r329;
	mov.b32 	 %f740, %r330;
	mov.b32 	 %f741, %r331;
	mul.f32 	%f742, %f249, %f739;
	mul.f32 	%f743, %f249, %f740;
	mul.f32 	%f744, %f249, %f741;
	fma.rn.f32 	%f987, %f732, %f987, %f742;
	fma.rn.f32 	%f988, %f732, %f988, %f743;
	fma.rn.f32 	%f989, %f732, %f989, %f744;
	bra.uni 	BB9_35;

BB9_24:
	mov.f32 	%f996, 0f00000000;
	mov.f32 	%f998, 0f3F800000;
	setp.eq.s32	%p34, %r185, 4;
	@%p34 bra 	BB9_27;
	bra.uni 	BB9_25;

BB9_27:
	// inline asm
	call (%rd270), _optix_get_instance_inverse_transform_from_handle, (%rd144);
	// inline asm
	bra.uni 	BB9_28;

BB9_30:
	// inline asm
	call (%rd159), _optix_get_srt_motion_transform_from_handle, (%rd144);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd161, %rd159;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd161];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r201;
	add.s64 	%rd165, %rd159, 16;
	// inline asm
	cvta.to.global.u64 %rd164, %rd165;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd164];
	// inline asm
	add.s64 	%rd168, %rd159, 32;
	// inline asm
	cvta.to.global.u64 %rd167, %rd168;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd167];
	// inline asm
	add.s64 	%rd171, %rd159, 48;
	// inline asm
	cvta.to.global.u64 %rd170, %rd171;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd170];
	// inline asm
	add.s64 	%rd174, %rd159, 64;
	// inline asm
	cvta.to.global.u64 %rd173, %rd174;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd173];
	// inline asm
	add.s64 	%rd177, %rd159, 80;
	// inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd176];
	// inline asm
	add.s64 	%rd180, %rd159, 96;
	// inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd179];
	// inline asm
	add.s64 	%rd183, %rd159, 112;
	// inline asm
	cvta.to.global.u64 %rd182, %rd183;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd182];
	// inline asm
	add.s64 	%rd186, %rd159, 128;
	// inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd185];
	// inline asm
	add.s64 	%rd189, %rd159, 144;
	// inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r235,%r236,%r237,%r238}, [%rd188];
	// inline asm
	mov.b32 	 %f622, %r202;
	mov.b32 	 %f623, %r203;
	cvt.u32.u16	%r255, %rs6;
	add.s32 	%r256, %r255, -1;
	cvt.rn.f32.s32	%f624, %r256;
	sub.f32 	%f625, %f611, %f622;
	mul.f32 	%f626, %f625, %f624;
	sub.f32 	%f627, %f623, %f622;
	div.rn.f32 	%f628, %f626, %f627;
	min.f32 	%f629, %f624, %f628;
	mov.f32 	%f630, 0f00000000;
	max.f32 	%f631, %f630, %f629;
	cvt.rmi.f32.f32	%f632, %f631;
	cvt.rzi.s32.f32	%r257, %f632;
	cvt.s64.s32	%rd15, %r257;
	mul.wide.s32 	%rd203, %r257, 64;
	add.s64 	%rd192, %rd168, %rd203;
	// inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r239,%r240,%r241,%r242}, [%rd191];
	// inline asm
	mov.b32 	 %f977, %r239;
	mov.b32 	 %f978, %r240;
	mov.b32 	 %f979, %r241;
	add.s64 	%rd195, %rd192, 16;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r243,%r244,%r245,%r246}, [%rd194];
	// inline asm
	mov.b32 	 %f980, %r243;
	mov.b32 	 %f981, %r244;
	mov.b32 	 %f982, %r246;
	add.s64 	%rd198, %rd192, 32;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r247,%r248,%r249,%r250}, [%rd197];
	// inline asm
	sub.f32 	%f209, %f631, %f632;
	mov.b32 	 %f983, %r248;
	mov.b32 	 %f984, %r249;
	mov.b32 	 %f985, %r250;
	add.s64 	%rd201, %rd192, 48;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r251,%r252,%r253,%r254}, [%rd200];
	// inline asm
	mov.b32 	 %f986, %r251;
	setp.leu.f32	%p37, %f209, 0f00000000;
	@%p37 bra 	BB9_32;

	shl.b64 	%rd216, %rd15, 6;
	add.s64 	%rd217, %rd216, %rd159;
	add.s64 	%rd205, %rd217, 96;
	// inline asm
	cvta.to.global.u64 %rd204, %rd205;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd204];
	// inline asm
	mov.b32 	 %f633, %r258;
	mov.b32 	 %f634, %r259;
	mov.b32 	 %f635, %r260;
	add.s64 	%rd208, %rd217, 112;
	// inline asm
	cvta.to.global.u64 %rd207, %rd208;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd207];
	// inline asm
	mov.b32 	 %f636, %r262;
	mov.b32 	 %f637, %r263;
	mov.b32 	 %f638, %r265;
	add.s64 	%rd211, %rd217, 128;
	// inline asm
	cvta.to.global.u64 %rd210, %rd211;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd210];
	// inline asm
	mov.b32 	 %f639, %r267;
	mov.b32 	 %f640, %r268;
	mov.b32 	 %f641, %r269;
	add.s64 	%rd214, %rd217, 144;
	// inline asm
	cvta.to.global.u64 %rd213, %rd214;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd213];
	// inline asm
	mov.f32 	%f642, 0f3F800000;
	sub.f32 	%f643, %f642, %f209;
	mul.f32 	%f644, %f209, %f633;
	mul.f32 	%f645, %f209, %f634;
	mul.f32 	%f646, %f209, %f635;
	fma.rn.f32 	%f977, %f643, %f977, %f644;
	fma.rn.f32 	%f978, %f643, %f978, %f645;
	fma.rn.f32 	%f979, %f643, %f979, %f646;
	mul.f32 	%f647, %f209, %f636;
	mul.f32 	%f648, %f209, %f637;
	mul.f32 	%f649, %f209, %f638;
	fma.rn.f32 	%f980, %f643, %f980, %f647;
	fma.rn.f32 	%f981, %f643, %f981, %f648;
	fma.rn.f32 	%f982, %f643, %f982, %f649;
	mul.f32 	%f650, %f209, %f639;
	mul.f32 	%f651, %f209, %f640;
	mul.f32 	%f652, %f209, %f641;
	fma.rn.f32 	%f653, %f643, %f983, %f650;
	fma.rn.f32 	%f654, %f643, %f984, %f651;
	fma.rn.f32 	%f655, %f643, %f985, %f652;
	mov.b32 	 %f656, %r270;
	mul.f32 	%f657, %f209, %f656;
	fma.rn.f32 	%f658, %f643, %f986, %f657;
	mul.f32 	%f659, %f654, %f654;
	fma.rn.f32 	%f660, %f653, %f653, %f659;
	fma.rn.f32 	%f661, %f655, %f655, %f660;
	fma.rn.f32 	%f662, %f658, %f658, %f661;
	sqrt.rn.f32 	%f663, %f662;
	rcp.rn.f32 	%f664, %f663;
	mul.f32 	%f983, %f653, %f664;
	mul.f32 	%f984, %f654, %f664;
	mul.f32 	%f985, %f655, %f664;
	mul.f32 	%f986, %f658, %f664;

BB9_32:
	mul.f32 	%f665, %f984, %f984;
	fma.rn.f32 	%f666, %f983, %f983, %f665;
	fma.rn.f32 	%f667, %f985, %f985, %f666;
	fma.rn.f32 	%f668, %f986, %f986, %f667;
	rcp.rn.f32 	%f669, %f668;
	mul.f32 	%f670, %f983, %f669;
	mul.f32 	%f671, %f984, %f669;
	mul.f32 	%f672, %f985, %f669;
	mul.f32 	%f673, %f986, %f669;
	mul.f32 	%f674, %f983, %f670;
	mul.f32 	%f675, %f984, %f671;
	mul.f32 	%f676, %f985, %f672;
	mul.f32 	%f677, %f983, %f671;
	mul.f32 	%f678, %f985, %f673;
	mul.f32 	%f679, %f983, %f672;
	mul.f32 	%f680, %f984, %f673;
	mul.f32 	%f681, %f984, %f672;
	mul.f32 	%f682, %f983, %f673;
	sub.f32 	%f683, %f674, %f675;
	sub.f32 	%f684, %f683, %f676;
	fma.rn.f32 	%f685, %f986, %f673, %f684;
	sub.f32 	%f686, %f677, %f678;
	add.f32 	%f687, %f686, %f686;
	add.f32 	%f688, %f679, %f680;
	add.f32 	%f689, %f688, %f688;
	add.f32 	%f690, %f677, %f678;
	add.f32 	%f691, %f690, %f690;
	sub.f32 	%f692, %f675, %f674;
	sub.f32 	%f693, %f692, %f676;
	fma.rn.f32 	%f694, %f986, %f673, %f693;
	sub.f32 	%f695, %f681, %f682;
	add.f32 	%f696, %f695, %f695;
	sub.f32 	%f697, %f679, %f680;
	add.f32 	%f698, %f697, %f697;
	add.f32 	%f699, %f681, %f682;
	add.f32 	%f700, %f699, %f699;
	neg.f32 	%f701, %f674;
	sub.f32 	%f702, %f701, %f675;
	add.f32 	%f703, %f676, %f702;
	fma.rn.f32 	%f704, %f986, %f673, %f703;
	mul.f32 	%f705, %f979, %f685;
	fma.rn.f32 	%f706, %f981, %f687, %f705;
	fma.rn.f32 	%f995, %f982, %f689, %f706;
	mul.f32 	%f707, %f981, %f694;
	fma.rn.f32 	%f708, %f979, %f691, %f707;
	fma.rn.f32 	%f992, %f982, %f696, %f708;
	mul.f32 	%f709, %f981, %f700;
	fma.rn.f32 	%f710, %f979, %f698, %f709;
	fma.rn.f32 	%f989, %f982, %f704, %f710;
	mul.f32 	%f711, %f978, %f685;
	fma.rn.f32 	%f994, %f980, %f687, %f711;
	mul.f32 	%f712, %f980, %f694;
	fma.rn.f32 	%f991, %f978, %f691, %f712;
	mul.f32 	%f713, %f980, %f700;
	fma.rn.f32 	%f988, %f978, %f698, %f713;
	mul.f32 	%f993, %f977, %f685;
	mul.f32 	%f990, %f977, %f691;
	mul.f32 	%f987, %f977, %f698;

BB9_35:
	mul.f32 	%f745, %f988, %f992;
	mul.f32 	%f746, %f989, %f991;
	sub.f32 	%f747, %f746, %f745;
	mul.f32 	%f748, %f993, %f747;
	mul.f32 	%f749, %f987, %f992;
	mul.f32 	%f750, %f989, %f990;
	sub.f32 	%f751, %f750, %f749;
	mul.f32 	%f752, %f751, %f994;
	sub.f32 	%f753, %f748, %f752;
	mul.f32 	%f754, %f987, %f991;
	mul.f32 	%f755, %f988, %f990;
	sub.f32 	%f756, %f755, %f754;
	fma.rn.f32 	%f757, %f756, %f995, %f753;
	rcp.rn.f32 	%f758, %f757;
	mul.f32 	%f1002, %f747, %f758;
	mul.f32 	%f759, %f989, %f994;
	mul.f32 	%f760, %f988, %f995;
	sub.f32 	%f761, %f760, %f759;
	mul.f32 	%f1003, %f758, %f761;
	mul.f32 	%f762, %f991, %f995;
	mul.f32 	%f763, %f992, %f994;
	sub.f32 	%f764, %f763, %f762;
	mul.f32 	%f1004, %f758, %f764;
	sub.f32 	%f765, %f749, %f750;
	mul.f32 	%f999, %f765, %f758;
	mul.f32 	%f766, %f987, %f995;
	mul.f32 	%f767, %f989, %f993;
	sub.f32 	%f768, %f767, %f766;
	mul.f32 	%f1000, %f758, %f768;
	mul.f32 	%f769, %f992, %f993;
	mul.f32 	%f770, %f990, %f995;
	sub.f32 	%f771, %f770, %f769;
	mul.f32 	%f1001, %f758, %f771;
	mul.f32 	%f996, %f756, %f758;
	mul.f32 	%f772, %f988, %f993;
	mul.f32 	%f773, %f987, %f994;
	sub.f32 	%f774, %f773, %f772;
	mul.f32 	%f997, %f774, %f758;
	mul.f32 	%f775, %f990, %f994;
	mul.f32 	%f776, %f991, %f993;
	sub.f32 	%f777, %f776, %f775;
	mul.f32 	%f998, %f777, %f758;
	bra.uni 	BB9_36;

BB9_25:
	setp.ne.s32	%p35, %r185, 1;
	mov.f32 	%f997, %f996;
	mov.f32 	%f999, %f996;
	mov.f32 	%f1000, %f998;
	mov.f32 	%f1001, %f996;
	mov.f32 	%f1002, %f998;
	mov.f32 	%f1003, %f996;
	mov.f32 	%f1004, %f996;
	@%p35 bra 	BB9_36;

	// inline asm
	call (%rd146), _optix_get_static_transform_from_handle, (%rd144);
	// inline asm
	add.s64 	%rd270, %rd146, 64;

BB9_28:
	// inline asm
	cvta.to.global.u64 %rd150, %rd270;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd150];
	// inline asm
	mov.b32 	 %f1002, %r187;
	mov.b32 	 %f1003, %r188;
	mov.b32 	 %f1004, %r189;
	add.s64 	%rd154, %rd270, 16;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd153];
	// inline asm
	mov.b32 	 %f999, %r191;
	mov.b32 	 %f1000, %r192;
	mov.b32 	 %f1001, %r193;
	add.s64 	%rd157, %rd270, 32;
	// inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd156];
	// inline asm
	mov.b32 	 %f996, %r195;
	mov.b32 	 %f997, %r196;
	mov.b32 	 %f998, %r197;

BB9_36:
	setp.eq.s32	%p39, %r903, 0;
	@%p39 bra 	BB9_37;
	bra.uni 	BB9_38;

BB9_37:
	mov.f32 	%f976, %f996;
	mov.f32 	%f975, %f997;
	mov.f32 	%f974, %f998;
	mov.f32 	%f973, %f999;
	mov.f32 	%f972, %f1000;
	mov.f32 	%f971, %f1001;
	mov.f32 	%f970, %f1002;
	mov.f32 	%f969, %f1003;
	mov.f32 	%f968, %f1004;
	bra.uni 	BB9_39;

BB9_38:
	mul.f32 	%f778, %f973, %f1003;
	fma.rn.f32 	%f779, %f970, %f1002, %f778;
	fma.rn.f32 	%f289, %f976, %f1004, %f779;
	mul.f32 	%f780, %f972, %f1003;
	fma.rn.f32 	%f781, %f969, %f1002, %f780;
	fma.rn.f32 	%f290, %f975, %f1004, %f781;
	mul.f32 	%f782, %f971, %f1003;
	fma.rn.f32 	%f783, %f968, %f1002, %f782;
	fma.rn.f32 	%f291, %f974, %f1004, %f783;
	mul.f32 	%f784, %f973, %f1000;
	fma.rn.f32 	%f785, %f970, %f999, %f784;
	fma.rn.f32 	%f292, %f976, %f1001, %f785;
	mul.f32 	%f786, %f972, %f1000;
	fma.rn.f32 	%f787, %f969, %f999, %f786;
	fma.rn.f32 	%f293, %f975, %f1001, %f787;
	mul.f32 	%f788, %f971, %f1000;
	fma.rn.f32 	%f789, %f968, %f999, %f788;
	fma.rn.f32 	%f294, %f974, %f1001, %f789;
	mul.f32 	%f790, %f973, %f997;
	fma.rn.f32 	%f791, %f970, %f996, %f790;
	fma.rn.f32 	%f976, %f976, %f998, %f791;
	mul.f32 	%f792, %f972, %f997;
	fma.rn.f32 	%f793, %f969, %f996, %f792;
	fma.rn.f32 	%f975, %f975, %f998, %f793;
	mul.f32 	%f794, %f971, %f997;
	fma.rn.f32 	%f795, %f968, %f996, %f794;
	fma.rn.f32 	%f974, %f974, %f998, %f795;
	mov.f32 	%f973, %f292;
	mov.f32 	%f972, %f293;
	mov.f32 	%f971, %f294;
	mov.f32 	%f970, %f289;
	mov.f32 	%f969, %f290;
	mov.f32 	%f968, %f291;

BB9_39:
	add.s32 	%r903, %r903, 1;
	setp.lt.u32	%p40, %r903, %r32;
	@%p40 bra 	BB9_23;

	mul.f32 	%f796, %f609, %f969;
	fma.rn.f32 	%f797, %f608, %f970, %f796;
	fma.rn.f32 	%f1014, %f1016, %f968, %f797;
	mul.f32 	%f798, %f609, %f972;
	fma.rn.f32 	%f799, %f608, %f973, %f798;
	fma.rn.f32 	%f1015, %f1016, %f971, %f799;
	mul.f32 	%f800, %f609, %f975;
	fma.rn.f32 	%f801, %f608, %f976, %f800;
	fma.rn.f32 	%f1016, %f1016, %f974, %f801;
	bra.uni 	BB9_41;

BB9_22:
	mov.f32 	%f1014, %f608;
	mov.f32 	%f1015, %f609;

BB9_41:
	// inline asm
	call (%f802), _optix_get_ray_tmin, ();
	// inline asm
	// inline asm
	call (%f803), _optix_get_ray_tmax, ();
	// inline asm
	ld.u8 	%rs10, [%rd1+324];
	setp.eq.s16	%p41, %rs10, 0;
	cvt.f64.f32	%fd1, %f1016;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r8}, %fd1;
	}
	mov.f64 	%fd292, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd292;
	}
	bfe.u32 	%r333, %r9, 20, 11;
	add.s32 	%r334, %r333, -1012;
	cvt.u64.u32	%rd19, %r334;
	mov.u64 	%rd265, 4611686018427387904;
	shl.b64 	%rd20, %rd265, %r334;
	setp.eq.s64	%p42, %rd20, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd413, [retval0+0];
	
	//{
	}// Callseq End 0
	setp.lt.s32	%p43, %r8, 0;
	and.pred  	%p1, %p43, %p42;
	@%p41 bra 	BB9_189;

	ld.v2.f32 	{%f804, %f805}, [%rd1+312];
	ld.v2.f32 	{%f807, %f808}, [%rd1+288];
	ld.f32 	%f809, [%rd1+296];
	fma.rn.f32 	%f317, %f805, 0fC0000000, %f809;
	ld.f32 	%f810, [%rd1+308];
	add.f32 	%f320, %f810, 0f3F800000;
	neg.f32 	%f319, %f320;
	cvt.f64.f32	%fd4, %f320;
	@!%p1 bra 	BB9_44;
	bra.uni 	BB9_43;

BB9_43:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r335}, %fd413;
	}
	xor.b32  	%r336, %r335, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r337, %temp}, %fd413;
	}
	mov.b64 	%fd413, {%r337, %r336};

BB9_44:
	setp.eq.f32	%p44, %f1016, 0f00000000;
	@%p44 bra 	BB9_47;
	bra.uni 	BB9_45;

BB9_47:
	selp.b32	%r338, %r8, 0, %p42;
	mov.u32 	%r339, 0;
	or.b32  	%r340, %r338, 2146435072;
	setp.lt.s32	%p48, %r9, 0;
	selp.b32	%r341, %r340, %r338, %p48;
	mov.b64 	%fd413, {%r339, %r341};
	bra.uni 	BB9_48;

BB9_189:
	ld.v4.f32 	{%f844, %f845, %f846, %f847}, [%rd1+288];
	ld.f32 	%f336, [%rd1+312];
	ld.f32 	%f848, [%rd1+308];
	add.f32 	%f338, %f848, 0f3F800000;
	neg.f32 	%f337, %f338;
	cvt.f64.f32	%fd116, %f338;
	@!%p1 bra 	BB9_191;
	bra.uni 	BB9_190;

BB9_190:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r556}, %fd413;
	}
	xor.b32  	%r557, %r556, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r558, %temp}, %fd413;
	}
	mov.b64 	%fd413, {%r558, %r557};

BB9_191:
	setp.eq.f32	%p226, %f1016, 0f00000000;
	@%p226 bra 	BB9_194;
	bra.uni 	BB9_192;

BB9_194:
	selp.b32	%r559, %r8, 0, %p42;
	mov.u32 	%r560, 0;
	or.b32  	%r561, %r559, 2146435072;
	setp.lt.s32	%p230, %r9, 0;
	selp.b32	%r562, %r561, %r559, %p230;
	mov.b64 	%fd413, {%r560, %r562};
	bra.uni 	BB9_195;

BB9_45:
	setp.gt.s32	%p45, %r8, -1;
	@%p45 bra 	BB9_48;

	cvt.rzi.f64.f64	%fd294, %fd292;
	setp.neu.f64	%p46, %fd294, 0d4000000000000000;
	selp.f64	%fd413, 0dFFF8000000000000, %fd413, %p46;

BB9_48:
	add.f64 	%fd415, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r342}, %fd415;
	}
	and.b32  	%r343, %r342, 2146435072;
	setp.ne.s32	%p49, %r343, 2146435072;
	@%p49 bra 	BB9_49;

	setp.gtu.f64	%p50, %fd2, 0d7FF0000000000000;
	@%p50 bra 	BB9_58;

	and.b32  	%r344, %r9, 2147483647;
	setp.ne.s32	%p51, %r344, 2146435072;
	@%p51 bra 	BB9_53;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd292;
	}
	setp.eq.s32	%p52, %r345, 0;
	@%p52 bra 	BB9_57;

BB9_53:
	and.b32  	%r346, %r8, 2147483647;
	setp.ne.s32	%p53, %r346, 2146435072;
	@%p53 bra 	BB9_54;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r347, %temp}, %fd1;
	}
	setp.ne.s32	%p54, %r347, 0;
	mov.f64 	%fd415, %fd413;
	@%p54 bra 	BB9_58;

	shr.s32 	%r348, %r9, 31;
	and.b32  	%r349, %r348, -2146435072;
	add.s32 	%r350, %r349, 2146435072;
	or.b32  	%r351, %r350, -2147483648;
	selp.b32	%r352, %r351, %r350, %p1;
	mov.u32 	%r353, 0;
	mov.b64 	%fd415, {%r353, %r352};
	bra.uni 	BB9_58;

BB9_49:
	mov.f64 	%fd415, %fd413;
	bra.uni 	BB9_58;

BB9_192:
	setp.gt.s32	%p227, %r8, -1;
	@%p227 bra 	BB9_195;

	cvt.rzi.f64.f64	%fd343, %fd292;
	setp.neu.f64	%p228, %fd343, 0d4000000000000000;
	selp.f64	%fd413, 0dFFF8000000000000, %fd413, %p228;

BB9_195:
	add.f64 	%fd442, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r563}, %fd442;
	}
	and.b32  	%r564, %r563, 2146435072;
	setp.ne.s32	%p231, %r564, 2146435072;
	@%p231 bra 	BB9_196;

	setp.gtu.f64	%p232, %fd2, 0d7FF0000000000000;
	@%p232 bra 	BB9_205;

	and.b32  	%r565, %r9, 2147483647;
	setp.ne.s32	%p233, %r565, 2146435072;
	@%p233 bra 	BB9_200;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r566, %temp}, %fd292;
	}
	setp.eq.s32	%p234, %r566, 0;
	@%p234 bra 	BB9_204;

BB9_200:
	and.b32  	%r567, %r8, 2147483647;
	setp.ne.s32	%p235, %r567, 2146435072;
	@%p235 bra 	BB9_201;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r568, %temp}, %fd1;
	}
	setp.ne.s32	%p236, %r568, 0;
	mov.f64 	%fd442, %fd413;
	@%p236 bra 	BB9_205;

	shr.s32 	%r569, %r9, 31;
	and.b32  	%r570, %r569, -2146435072;
	add.s32 	%r571, %r570, 2146435072;
	or.b32  	%r572, %r571, -2147483648;
	selp.b32	%r573, %r572, %r571, %p1;
	mov.u32 	%r574, 0;
	mov.b64 	%fd442, {%r574, %r573};
	bra.uni 	BB9_205;

BB9_196:
	mov.f64 	%fd442, %fd413;
	bra.uni 	BB9_205;

BB9_54:
	mov.f64 	%fd415, %fd413;
	bra.uni 	BB9_58;

BB9_201:
	mov.f64 	%fd442, %fd413;
	bra.uni 	BB9_205;

BB9_57:
	setp.gt.f64	%p55, %fd2, 0d3FF0000000000000;
	selp.b32	%r354, 2146435072, 0, %p55;
	mov.u32 	%r355, 0;
	xor.b32  	%r356, %r354, 2146435072;
	setp.lt.s32	%p56, %r9, 0;
	selp.b32	%r357, %r356, %r354, %p56;
	setp.eq.f32	%p57, %f1016, 0fBF800000;
	selp.b32	%r358, 1072693248, %r357, %p57;
	mov.b64 	%fd415, {%r355, %r358};

BB9_58:
	cvt.f64.f32	%fd14, %f1014;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r10}, %fd14;
	}
	abs.f64 	%fd15, %fd14;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd417, [retval0+0];
	
	//{
	}// Callseq End 1
	setp.gt.s32	%p58, %r10, -1;
	setp.lt.s32	%p59, %r10, 0;
	setp.ne.s64	%p60, %rd20, -9223372036854775808;
	and.pred  	%p2, %p59, %p42;
	or.pred  	%p62, %p58, %p60;
	@%p62 bra 	BB9_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r359}, %fd417;
	}
	xor.b32  	%r360, %r359, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r361, %temp}, %fd417;
	}
	mov.b64 	%fd417, {%r361, %r360};

BB9_60:
	setp.eq.f32	%p63, %f1014, 0f00000000;
	@%p63 bra 	BB9_63;
	bra.uni 	BB9_61;

BB9_63:
	selp.b32	%r362, %r10, 0, %p42;
	mov.u32 	%r363, 0;
	or.b32  	%r364, %r362, 2146435072;
	setp.lt.s32	%p67, %r9, 0;
	selp.b32	%r365, %r364, %r362, %p67;
	mov.b64 	%fd417, {%r363, %r365};
	bra.uni 	BB9_64;

BB9_61:
	@%p58 bra 	BB9_64;

	cvt.rzi.f64.f64	%fd297, %fd292;
	setp.neu.f64	%p65, %fd297, 0d4000000000000000;
	selp.f64	%fd417, 0dFFF8000000000000, %fd417, %p65;

BB9_64:
	add.f64 	%fd418, %fd14, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r366}, %fd418;
	}
	and.b32  	%r367, %r366, 2146435072;
	setp.ne.s32	%p68, %r367, 2146435072;
	@%p68 bra 	BB9_65;

	setp.gtu.f64	%p69, %fd15, 0d7FF0000000000000;
	@%p69 bra 	BB9_74;

	and.b32  	%r368, %r9, 2147483647;
	setp.ne.s32	%p70, %r368, 2146435072;
	@%p70 bra 	BB9_69;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r369, %temp}, %fd292;
	}
	setp.eq.s32	%p71, %r369, 0;
	@%p71 bra 	BB9_73;

BB9_69:
	and.b32  	%r370, %r10, 2147483647;
	setp.ne.s32	%p72, %r370, 2146435072;
	@%p72 bra 	BB9_70;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r371, %temp}, %fd14;
	}
	setp.ne.s32	%p73, %r371, 0;
	mov.f64 	%fd418, %fd417;
	@%p73 bra 	BB9_74;

	shr.s32 	%r372, %r9, 31;
	and.b32  	%r373, %r372, -2146435072;
	add.s32 	%r374, %r373, 2146435072;
	or.b32  	%r375, %r374, -2147483648;
	selp.b32	%r376, %r375, %r374, %p2;
	mov.u32 	%r377, 0;
	mov.b64 	%fd418, {%r377, %r376};
	bra.uni 	BB9_74;

BB9_65:
	mov.f64 	%fd418, %fd417;
	bra.uni 	BB9_74;

BB9_70:
	mov.f64 	%fd418, %fd417;
	bra.uni 	BB9_74;

BB9_73:
	setp.gt.f64	%p74, %fd15, 0d3FF0000000000000;
	selp.b32	%r378, 2146435072, 0, %p74;
	mov.u32 	%r379, 0;
	xor.b32  	%r380, %r378, 2146435072;
	setp.lt.s32	%p75, %r9, 0;
	selp.b32	%r381, %r380, %r378, %p75;
	setp.eq.f32	%p76, %f1014, 0fBF800000;
	selp.b32	%r382, 1072693248, %r381, %p76;
	mov.b64 	%fd418, {%r379, %r382};

BB9_74:
	setp.eq.f32	%p77, %f1014, 0f3F800000;
	selp.f64	%fd299, 0d3FF0000000000000, %fd418, %p77;
	setp.eq.f32	%p78, %f1016, 0f3F800000;
	selp.f64	%fd300, 0d3FF0000000000000, %fd415, %p78;
	fma.rn.f64 	%fd26, %fd4, %fd300, %fd299;
	cvt.f64.f32	%fd27, %f1015;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd27;
	}
	abs.f64 	%fd28, %fd27;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd28;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd420, [retval0+0];
	
	//{
	}// Callseq End 2
	setp.gt.s32	%p79, %r11, -1;
	setp.lt.s32	%p80, %r11, 0;
	and.pred  	%p3, %p80, %p42;
	or.pred  	%p83, %p79, %p60;
	@%p83 bra 	BB9_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r383}, %fd420;
	}
	xor.b32  	%r384, %r383, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r385, %temp}, %fd420;
	}
	mov.b64 	%fd420, {%r385, %r384};

BB9_76:
	setp.eq.f32	%p84, %f1015, 0f00000000;
	@%p84 bra 	BB9_79;
	bra.uni 	BB9_77;

BB9_79:
	selp.b32	%r386, %r11, 0, %p42;
	mov.u32 	%r387, 0;
	or.b32  	%r388, %r386, 2146435072;
	setp.lt.s32	%p88, %r9, 0;
	selp.b32	%r389, %r388, %r386, %p88;
	mov.b64 	%fd420, {%r387, %r389};
	bra.uni 	BB9_80;

BB9_77:
	@%p79 bra 	BB9_80;

	cvt.rzi.f64.f64	%fd302, %fd292;
	setp.neu.f64	%p86, %fd302, 0d4000000000000000;
	selp.f64	%fd420, 0dFFF8000000000000, %fd420, %p86;

BB9_80:
	add.f64 	%fd421, %fd27, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r390}, %fd421;
	}
	and.b32  	%r391, %r390, 2146435072;
	setp.ne.s32	%p89, %r391, 2146435072;
	@%p89 bra 	BB9_81;

	setp.gtu.f64	%p90, %fd28, 0d7FF0000000000000;
	@%p90 bra 	BB9_90;

	and.b32  	%r392, %r9, 2147483647;
	setp.ne.s32	%p91, %r392, 2146435072;
	@%p91 bra 	BB9_85;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r393, %temp}, %fd292;
	}
	setp.eq.s32	%p92, %r393, 0;
	@%p92 bra 	BB9_89;

BB9_85:
	and.b32  	%r394, %r11, 2147483647;
	setp.ne.s32	%p93, %r394, 2146435072;
	@%p93 bra 	BB9_86;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r395, %temp}, %fd27;
	}
	setp.ne.s32	%p94, %r395, 0;
	mov.f64 	%fd421, %fd420;
	@%p94 bra 	BB9_90;

	shr.s32 	%r396, %r9, 31;
	and.b32  	%r397, %r396, -2146435072;
	add.s32 	%r398, %r397, 2146435072;
	or.b32  	%r399, %r398, -2147483648;
	selp.b32	%r400, %r399, %r398, %p3;
	mov.u32 	%r401, 0;
	mov.b64 	%fd421, {%r401, %r400};
	bra.uni 	BB9_90;

BB9_81:
	mov.f64 	%fd421, %fd420;
	bra.uni 	BB9_90;

BB9_86:
	mov.f64 	%fd421, %fd420;
	bra.uni 	BB9_90;

BB9_89:
	setp.gt.f64	%p95, %fd28, 0d3FF0000000000000;
	selp.b32	%r402, 2146435072, 0, %p95;
	mov.u32 	%r403, 0;
	xor.b32  	%r404, %r402, 2146435072;
	setp.lt.s32	%p96, %r9, 0;
	selp.b32	%r405, %r404, %r402, %p96;
	setp.eq.f32	%p97, %f1015, 0fBF800000;
	selp.b32	%r406, 1072693248, %r405, %p97;
	mov.b64 	%fd421, {%r403, %r406};

BB9_90:
	setp.eq.f32	%p98, %f1015, 0f3F800000;
	selp.f64	%fd304, 0d3FF0000000000000, %fd421, %p98;
	add.f64 	%fd305, %fd26, %fd304;
	cvt.rn.f32.f64	%f321, %fd305;
	add.f32 	%f811, %f320, %f320;
	mul.f32 	%f812, %f965, %f811;
	mul.f32 	%f813, %f1016, %f812;
	add.f32 	%f814, %f319, %f319;
	mul.f32 	%f322, %f317, %f814;
	fma.rn.f32 	%f815, %f1016, %f322, %f813;
	add.f32 	%f816, %f967, %f967;
	fma.rn.f32 	%f817, %f1014, %f816, %f815;
	add.f32 	%f323, %f807, %f807;
	mul.f32 	%f818, %f323, %f1014;
	sub.f32 	%f819, %f817, %f818;
	add.f32 	%f820, %f966, %f966;
	fma.rn.f32 	%f821, %f1015, %f820, %f819;
	add.f32 	%f324, %f808, %f808;
	mul.f32 	%f822, %f324, %f1015;
	sub.f32 	%f823, %f821, %f822;
	add.f32 	%f824, %f1016, %f1016;
	div.rn.f32 	%f825, %f824, %f804;
	sub.f32 	%f325, %f823, %f825;
	cvt.f64.f32	%fd39, %f965;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd39;
	}
	abs.f64 	%fd40, %fd39;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd423, [retval0+0];
	
	//{
	}// Callseq End 3
	setp.gt.s32	%p99, %r12, -1;
	setp.lt.s32	%p100, %r12, 0;
	and.pred  	%p4, %p100, %p42;
	or.pred  	%p103, %p99, %p60;
	@%p103 bra 	BB9_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r407}, %fd423;
	}
	xor.b32  	%r408, %r407, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd423;
	}
	mov.b64 	%fd423, {%r409, %r408};

BB9_92:
	setp.eq.f32	%p104, %f965, 0f00000000;
	@%p104 bra 	BB9_95;
	bra.uni 	BB9_93;

BB9_95:
	selp.b32	%r410, %r12, 0, %p42;
	mov.u32 	%r411, 0;
	or.b32  	%r412, %r410, 2146435072;
	setp.lt.s32	%p108, %r9, 0;
	selp.b32	%r413, %r412, %r410, %p108;
	mov.b64 	%fd423, {%r411, %r413};
	bra.uni 	BB9_96;

BB9_93:
	@%p99 bra 	BB9_96;

	cvt.rzi.f64.f64	%fd307, %fd292;
	setp.neu.f64	%p106, %fd307, 0d4000000000000000;
	selp.f64	%fd423, 0dFFF8000000000000, %fd423, %p106;

BB9_96:
	add.f64 	%fd424, %fd39, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r414}, %fd424;
	}
	and.b32  	%r415, %r414, 2146435072;
	setp.ne.s32	%p109, %r415, 2146435072;
	@%p109 bra 	BB9_97;

	setp.gtu.f64	%p110, %fd40, 0d7FF0000000000000;
	@%p110 bra 	BB9_106;

	and.b32  	%r416, %r9, 2147483647;
	setp.ne.s32	%p111, %r416, 2146435072;
	@%p111 bra 	BB9_101;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r417, %temp}, %fd292;
	}
	setp.eq.s32	%p112, %r417, 0;
	@%p112 bra 	BB9_105;

BB9_101:
	and.b32  	%r418, %r12, 2147483647;
	setp.ne.s32	%p113, %r418, 2146435072;
	@%p113 bra 	BB9_102;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r419, %temp}, %fd39;
	}
	setp.ne.s32	%p114, %r419, 0;
	mov.f64 	%fd424, %fd423;
	@%p114 bra 	BB9_106;

	shr.s32 	%r420, %r9, 31;
	and.b32  	%r421, %r420, -2146435072;
	add.s32 	%r422, %r421, 2146435072;
	or.b32  	%r423, %r422, -2147483648;
	selp.b32	%r424, %r423, %r422, %p4;
	mov.u32 	%r425, 0;
	mov.b64 	%fd424, {%r425, %r424};
	bra.uni 	BB9_106;

BB9_97:
	mov.f64 	%fd424, %fd423;
	bra.uni 	BB9_106;

BB9_102:
	mov.f64 	%fd424, %fd423;
	bra.uni 	BB9_106;

BB9_105:
	setp.gt.f64	%p115, %fd40, 0d3FF0000000000000;
	selp.b32	%r426, 2146435072, 0, %p115;
	mov.u32 	%r427, 0;
	xor.b32  	%r428, %r426, 2146435072;
	setp.lt.s32	%p116, %r9, 0;
	selp.b32	%r429, %r428, %r426, %p116;
	setp.eq.f32	%p117, %f965, 0fBF800000;
	selp.b32	%r430, 1072693248, %r429, %p117;
	mov.b64 	%fd424, {%r427, %r430};

BB9_106:
	setp.eq.f32	%p118, %f965, 0f3F800000;
	selp.f64	%fd309, 0d3FF0000000000000, %fd424, %p118;
	mul.f32 	%f826, %f965, %f322;
	cvt.f64.f32	%fd310, %f826;
	fma.rn.f64 	%fd51, %fd4, %fd309, %fd310;
	neg.f32 	%f326, %f317;
	cvt.f64.f32	%fd52, %f326;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd52;
	}
	abs.f64 	%fd53, %fd52;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd53;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd426, [retval0+0];
	
	//{
	}// Callseq End 4
	setp.gt.s32	%p119, %r13, -1;
	setp.lt.s32	%p120, %r13, 0;
	and.pred  	%p5, %p120, %p42;
	or.pred  	%p123, %p119, %p60;
	@%p123 bra 	BB9_108;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r431}, %fd426;
	}
	xor.b32  	%r432, %r431, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r433, %temp}, %fd426;
	}
	mov.b64 	%fd426, {%r433, %r432};

BB9_108:
	setp.eq.f32	%p124, %f326, 0f00000000;
	@%p124 bra 	BB9_111;
	bra.uni 	BB9_109;

BB9_111:
	selp.b32	%r434, %r13, 0, %p42;
	mov.u32 	%r435, 0;
	or.b32  	%r436, %r434, 2146435072;
	setp.lt.s32	%p128, %r9, 0;
	selp.b32	%r437, %r436, %r434, %p128;
	mov.b64 	%fd426, {%r435, %r437};
	bra.uni 	BB9_112;

BB9_109:
	@%p119 bra 	BB9_112;

	cvt.rzi.f64.f64	%fd312, %fd292;
	setp.neu.f64	%p126, %fd312, 0d4000000000000000;
	selp.f64	%fd426, 0dFFF8000000000000, %fd426, %p126;

BB9_112:
	add.f64 	%fd427, %fd52, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r438}, %fd427;
	}
	and.b32  	%r439, %r438, 2146435072;
	setp.ne.s32	%p129, %r439, 2146435072;
	@%p129 bra 	BB9_113;

	setp.gtu.f64	%p130, %fd53, 0d7FF0000000000000;
	@%p130 bra 	BB9_122;

	and.b32  	%r440, %r9, 2147483647;
	setp.ne.s32	%p131, %r440, 2146435072;
	@%p131 bra 	BB9_117;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r441, %temp}, %fd292;
	}
	setp.eq.s32	%p132, %r441, 0;
	@%p132 bra 	BB9_121;

BB9_117:
	and.b32  	%r442, %r13, 2147483647;
	setp.ne.s32	%p133, %r442, 2146435072;
	@%p133 bra 	BB9_118;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r443, %temp}, %fd52;
	}
	setp.ne.s32	%p134, %r443, 0;
	mov.f64 	%fd427, %fd426;
	@%p134 bra 	BB9_122;

	shr.s32 	%r444, %r9, 31;
	and.b32  	%r445, %r444, -2146435072;
	add.s32 	%r446, %r445, 2146435072;
	or.b32  	%r447, %r446, -2147483648;
	selp.b32	%r448, %r447, %r446, %p5;
	mov.u32 	%r449, 0;
	mov.b64 	%fd427, {%r449, %r448};
	bra.uni 	BB9_122;

BB9_113:
	mov.f64 	%fd427, %fd426;
	bra.uni 	BB9_122;

BB9_118:
	mov.f64 	%fd427, %fd426;
	bra.uni 	BB9_122;

BB9_121:
	setp.gt.f64	%p135, %fd53, 0d3FF0000000000000;
	selp.b32	%r450, 2146435072, 0, %p135;
	mov.u32 	%r451, 0;
	xor.b32  	%r452, %r450, 2146435072;
	setp.lt.s32	%p136, %r9, 0;
	selp.b32	%r453, %r452, %r450, %p136;
	setp.eq.f32	%p137, %f326, 0fBF800000;
	selp.b32	%r454, 1072693248, %r453, %p137;
	mov.b64 	%fd427, {%r451, %r454};

BB9_122:
	setp.eq.f32	%p138, %f326, 0f3F800000;
	selp.f64	%fd314, 0d3FF0000000000000, %fd427, %p138;
	cvt.f64.f32	%fd315, %f319;
	mul.f64 	%fd316, %fd315, %fd314;
	sub.f64 	%fd64, %fd51, %fd316;
	cvt.f64.f32	%fd65, %f967;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd65;
	}
	abs.f64 	%fd66, %fd65;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd66;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd429, [retval0+0];
	
	//{
	}// Callseq End 5
	setp.gt.s32	%p139, %r14, -1;
	setp.lt.s32	%p140, %r14, 0;
	and.pred  	%p6, %p140, %p42;
	or.pred  	%p143, %p139, %p60;
	@%p143 bra 	BB9_124;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r455}, %fd429;
	}
	xor.b32  	%r456, %r455, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r457, %temp}, %fd429;
	}
	mov.b64 	%fd429, {%r457, %r456};

BB9_124:
	setp.eq.f32	%p144, %f967, 0f00000000;
	@%p144 bra 	BB9_127;
	bra.uni 	BB9_125;

BB9_127:
	selp.b32	%r458, %r14, 0, %p42;
	mov.u32 	%r459, 0;
	or.b32  	%r460, %r458, 2146435072;
	setp.lt.s32	%p148, %r9, 0;
	selp.b32	%r461, %r460, %r458, %p148;
	mov.b64 	%fd429, {%r459, %r461};
	bra.uni 	BB9_128;

BB9_125:
	@%p139 bra 	BB9_128;

	cvt.rzi.f64.f64	%fd318, %fd292;
	setp.neu.f64	%p146, %fd318, 0d4000000000000000;
	selp.f64	%fd429, 0dFFF8000000000000, %fd429, %p146;

BB9_128:
	add.f64 	%fd430, %fd65, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r462}, %fd430;
	}
	and.b32  	%r463, %r462, 2146435072;
	setp.ne.s32	%p149, %r463, 2146435072;
	@%p149 bra 	BB9_129;

	setp.gtu.f64	%p150, %fd66, 0d7FF0000000000000;
	@%p150 bra 	BB9_138;

	and.b32  	%r464, %r9, 2147483647;
	setp.ne.s32	%p151, %r464, 2146435072;
	@%p151 bra 	BB9_133;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r465, %temp}, %fd292;
	}
	setp.eq.s32	%p152, %r465, 0;
	@%p152 bra 	BB9_137;

BB9_133:
	and.b32  	%r466, %r14, 2147483647;
	setp.ne.s32	%p153, %r466, 2146435072;
	@%p153 bra 	BB9_134;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r467, %temp}, %fd65;
	}
	setp.ne.s32	%p154, %r467, 0;
	mov.f64 	%fd430, %fd429;
	@%p154 bra 	BB9_138;

	shr.s32 	%r468, %r9, 31;
	and.b32  	%r469, %r468, -2146435072;
	add.s32 	%r470, %r469, 2146435072;
	or.b32  	%r471, %r470, -2147483648;
	selp.b32	%r472, %r471, %r470, %p6;
	mov.u32 	%r473, 0;
	mov.b64 	%fd430, {%r473, %r472};
	bra.uni 	BB9_138;

BB9_129:
	mov.f64 	%fd430, %fd429;
	bra.uni 	BB9_138;

BB9_134:
	mov.f64 	%fd430, %fd429;
	bra.uni 	BB9_138;

BB9_137:
	setp.gt.f64	%p155, %fd66, 0d3FF0000000000000;
	selp.b32	%r474, 2146435072, 0, %p155;
	mov.u32 	%r475, 0;
	xor.b32  	%r476, %r474, 2146435072;
	setp.lt.s32	%p156, %r9, 0;
	selp.b32	%r477, %r476, %r474, %p156;
	setp.eq.f32	%p157, %f967, 0fBF800000;
	selp.b32	%r478, 1072693248, %r477, %p157;
	mov.b64 	%fd430, {%r475, %r478};

BB9_138:
	setp.eq.f32	%p158, %f967, 0f3F800000;
	selp.f64	%fd320, 0d3FF0000000000000, %fd430, %p158;
	add.f64 	%fd321, %fd64, %fd320;
	mul.f32 	%f827, %f323, %f967;
	cvt.f64.f32	%fd322, %f827;
	sub.f64 	%fd77, %fd321, %fd322;
	neg.f32 	%f327, %f807;
	cvt.f64.f32	%fd78, %f327;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd78;
	}
	abs.f64 	%fd79, %fd78;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd79;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd432, [retval0+0];
	
	//{
	}// Callseq End 6
	setp.gt.s32	%p159, %r15, -1;
	setp.lt.s32	%p160, %r15, 0;
	and.pred  	%p7, %p160, %p42;
	or.pred  	%p163, %p159, %p60;
	@%p163 bra 	BB9_140;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r479}, %fd432;
	}
	xor.b32  	%r480, %r479, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r481, %temp}, %fd432;
	}
	mov.b64 	%fd432, {%r481, %r480};

BB9_140:
	setp.eq.f32	%p164, %f327, 0f00000000;
	@%p164 bra 	BB9_143;
	bra.uni 	BB9_141;

BB9_143:
	selp.b32	%r482, %r15, 0, %p42;
	mov.u32 	%r483, 0;
	or.b32  	%r484, %r482, 2146435072;
	setp.lt.s32	%p168, %r9, 0;
	selp.b32	%r485, %r484, %r482, %p168;
	mov.b64 	%fd432, {%r483, %r485};
	bra.uni 	BB9_144;

BB9_141:
	@%p159 bra 	BB9_144;

	cvt.rzi.f64.f64	%fd324, %fd292;
	setp.neu.f64	%p166, %fd324, 0d4000000000000000;
	selp.f64	%fd432, 0dFFF8000000000000, %fd432, %p166;

BB9_144:
	add.f64 	%fd433, %fd78, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r486}, %fd433;
	}
	and.b32  	%r487, %r486, 2146435072;
	setp.ne.s32	%p169, %r487, 2146435072;
	@%p169 bra 	BB9_145;

	setp.gtu.f64	%p170, %fd79, 0d7FF0000000000000;
	@%p170 bra 	BB9_154;

	and.b32  	%r488, %r9, 2147483647;
	setp.ne.s32	%p171, %r488, 2146435072;
	@%p171 bra 	BB9_149;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r489, %temp}, %fd292;
	}
	setp.eq.s32	%p172, %r489, 0;
	@%p172 bra 	BB9_153;

BB9_149:
	and.b32  	%r490, %r15, 2147483647;
	setp.ne.s32	%p173, %r490, 2146435072;
	@%p173 bra 	BB9_150;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r491, %temp}, %fd78;
	}
	setp.ne.s32	%p174, %r491, 0;
	mov.f64 	%fd433, %fd432;
	@%p174 bra 	BB9_154;

	shr.s32 	%r492, %r9, 31;
	and.b32  	%r493, %r492, -2146435072;
	add.s32 	%r494, %r493, 2146435072;
	or.b32  	%r495, %r494, -2147483648;
	selp.b32	%r496, %r495, %r494, %p7;
	mov.u32 	%r497, 0;
	mov.b64 	%fd433, {%r497, %r496};
	bra.uni 	BB9_154;

BB9_145:
	mov.f64 	%fd433, %fd432;
	bra.uni 	BB9_154;

BB9_150:
	mov.f64 	%fd433, %fd432;
	bra.uni 	BB9_154;

BB9_153:
	setp.gt.f64	%p175, %fd79, 0d3FF0000000000000;
	selp.b32	%r498, 2146435072, 0, %p175;
	mov.u32 	%r499, 0;
	xor.b32  	%r500, %r498, 2146435072;
	setp.lt.s32	%p176, %r9, 0;
	selp.b32	%r501, %r500, %r498, %p176;
	setp.eq.f32	%p177, %f327, 0fBF800000;
	selp.b32	%r502, 1072693248, %r501, %p177;
	mov.b64 	%fd433, {%r499, %r502};

BB9_154:
	setp.eq.f32	%p178, %f327, 0f3F800000;
	selp.f64	%fd326, 0d3FF0000000000000, %fd433, %p178;
	add.f64 	%fd90, %fd77, %fd326;
	cvt.f64.f32	%fd91, %f966;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r16}, %fd91;
	}
	abs.f64 	%fd92, %fd91;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd92;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd435, [retval0+0];
	
	//{
	}// Callseq End 7
	setp.gt.s32	%p179, %r16, -1;
	setp.lt.s32	%p180, %r16, 0;
	and.pred  	%p8, %p180, %p42;
	or.pred  	%p183, %p179, %p60;
	@%p183 bra 	BB9_156;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r503}, %fd435;
	}
	xor.b32  	%r504, %r503, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r505, %temp}, %fd435;
	}
	mov.b64 	%fd435, {%r505, %r504};

BB9_156:
	setp.eq.f32	%p184, %f966, 0f00000000;
	@%p184 bra 	BB9_159;
	bra.uni 	BB9_157;

BB9_159:
	selp.b32	%r506, %r16, 0, %p42;
	mov.u32 	%r507, 0;
	or.b32  	%r508, %r506, 2146435072;
	setp.lt.s32	%p188, %r9, 0;
	selp.b32	%r509, %r508, %r506, %p188;
	mov.b64 	%fd435, {%r507, %r509};
	bra.uni 	BB9_160;

BB9_157:
	@%p179 bra 	BB9_160;

	cvt.rzi.f64.f64	%fd328, %fd292;
	setp.neu.f64	%p186, %fd328, 0d4000000000000000;
	selp.f64	%fd435, 0dFFF8000000000000, %fd435, %p186;

BB9_160:
	add.f64 	%fd436, %fd91, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r510}, %fd436;
	}
	and.b32  	%r511, %r510, 2146435072;
	setp.ne.s32	%p189, %r511, 2146435072;
	@%p189 bra 	BB9_161;

	setp.gtu.f64	%p190, %fd92, 0d7FF0000000000000;
	@%p190 bra 	BB9_170;

	and.b32  	%r512, %r9, 2147483647;
	setp.ne.s32	%p191, %r512, 2146435072;
	@%p191 bra 	BB9_165;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r513, %temp}, %fd292;
	}
	setp.eq.s32	%p192, %r513, 0;
	@%p192 bra 	BB9_169;

BB9_165:
	and.b32  	%r514, %r16, 2147483647;
	setp.ne.s32	%p193, %r514, 2146435072;
	@%p193 bra 	BB9_166;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r515, %temp}, %fd91;
	}
	setp.ne.s32	%p194, %r515, 0;
	mov.f64 	%fd436, %fd435;
	@%p194 bra 	BB9_170;

	shr.s32 	%r516, %r9, 31;
	and.b32  	%r517, %r516, -2146435072;
	add.s32 	%r518, %r517, 2146435072;
	or.b32  	%r519, %r518, -2147483648;
	selp.b32	%r520, %r519, %r518, %p8;
	mov.u32 	%r521, 0;
	mov.b64 	%fd436, {%r521, %r520};
	bra.uni 	BB9_170;

BB9_161:
	mov.f64 	%fd436, %fd435;
	bra.uni 	BB9_170;

BB9_166:
	mov.f64 	%fd436, %fd435;
	bra.uni 	BB9_170;

BB9_169:
	setp.gt.f64	%p195, %fd92, 0d3FF0000000000000;
	selp.b32	%r522, 2146435072, 0, %p195;
	mov.u32 	%r523, 0;
	xor.b32  	%r524, %r522, 2146435072;
	setp.lt.s32	%p196, %r9, 0;
	selp.b32	%r525, %r524, %r522, %p196;
	setp.eq.f32	%p197, %f966, 0fBF800000;
	selp.b32	%r526, 1072693248, %r525, %p197;
	mov.b64 	%fd436, {%r523, %r526};

BB9_170:
	setp.eq.f32	%p198, %f966, 0f3F800000;
	selp.f64	%fd330, 0d3FF0000000000000, %fd436, %p198;
	add.f64 	%fd331, %fd90, %fd330;
	mul.f32 	%f828, %f324, %f966;
	cvt.f64.f32	%fd332, %f828;
	sub.f64 	%fd103, %fd331, %fd332;
	neg.f32 	%f328, %f808;
	cvt.f64.f32	%fd104, %f328;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r17}, %fd104;
	}
	abs.f64 	%fd105, %fd104;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd105;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd438, [retval0+0];
	
	//{
	}// Callseq End 8
	setp.gt.s32	%p199, %r17, -1;
	setp.lt.s32	%p200, %r17, 0;
	and.pred  	%p9, %p200, %p42;
	or.pred  	%p203, %p199, %p60;
	@%p203 bra 	BB9_172;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r527}, %fd438;
	}
	xor.b32  	%r528, %r527, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r529, %temp}, %fd438;
	}
	mov.b64 	%fd438, {%r529, %r528};

BB9_172:
	setp.eq.f32	%p204, %f328, 0f00000000;
	@%p204 bra 	BB9_175;
	bra.uni 	BB9_173;

BB9_175:
	selp.b32	%r530, %r17, 0, %p42;
	mov.u32 	%r531, 0;
	or.b32  	%r532, %r530, 2146435072;
	setp.lt.s32	%p208, %r9, 0;
	selp.b32	%r533, %r532, %r530, %p208;
	mov.b64 	%fd438, {%r531, %r533};
	bra.uni 	BB9_176;

BB9_173:
	@%p199 bra 	BB9_176;

	cvt.rzi.f64.f64	%fd334, %fd292;
	setp.neu.f64	%p206, %fd334, 0d4000000000000000;
	selp.f64	%fd438, 0dFFF8000000000000, %fd438, %p206;

BB9_176:
	add.f64 	%fd439, %fd104, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r534}, %fd439;
	}
	and.b32  	%r535, %r534, 2146435072;
	setp.ne.s32	%p209, %r535, 2146435072;
	@%p209 bra 	BB9_177;

	setp.gtu.f64	%p210, %fd105, 0d7FF0000000000000;
	@%p210 bra 	BB9_186;

	and.b32  	%r536, %r9, 2147483647;
	setp.ne.s32	%p211, %r536, 2146435072;
	@%p211 bra 	BB9_181;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r537, %temp}, %fd292;
	}
	setp.eq.s32	%p212, %r537, 0;
	@%p212 bra 	BB9_185;

BB9_181:
	and.b32  	%r538, %r17, 2147483647;
	setp.ne.s32	%p213, %r538, 2146435072;
	@%p213 bra 	BB9_182;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r539, %temp}, %fd104;
	}
	setp.ne.s32	%p214, %r539, 0;
	mov.f64 	%fd439, %fd438;
	@%p214 bra 	BB9_186;

	shr.s32 	%r540, %r9, 31;
	and.b32  	%r541, %r540, -2146435072;
	add.s32 	%r542, %r541, 2146435072;
	or.b32  	%r543, %r542, -2147483648;
	selp.b32	%r544, %r543, %r542, %p9;
	mov.u32 	%r545, 0;
	mov.b64 	%fd439, {%r545, %r544};
	bra.uni 	BB9_186;

BB9_177:
	mov.f64 	%fd439, %fd438;
	bra.uni 	BB9_186;

BB9_182:
	mov.f64 	%fd439, %fd438;
	bra.uni 	BB9_186;

BB9_185:
	setp.gt.f64	%p215, %fd105, 0d3FF0000000000000;
	selp.b32	%r546, 2146435072, 0, %p215;
	mov.u32 	%r547, 0;
	xor.b32  	%r548, %r546, 2146435072;
	setp.lt.s32	%p216, %r9, 0;
	selp.b32	%r549, %r548, %r546, %p216;
	setp.eq.f32	%p217, %f328, 0fBF800000;
	selp.b32	%r550, 1072693248, %r549, %p217;
	mov.b64 	%fd439, {%r547, %r550};

BB9_186:
	setp.eq.f32	%p218, %f328, 0f3F800000;
	selp.f64	%fd336, 0d3FF0000000000000, %fd439, %p218;
	add.f64 	%fd337, %fd103, %fd336;
	add.f32 	%f830, %f965, %f965;
	div.rn.f32 	%f831, %f830, %f804;
	cvt.f64.f32	%fd338, %f831;
	sub.f64 	%fd339, %fd337, %fd338;
	add.f32 	%f832, %f317, %f317;
	div.rn.f32 	%f833, %f832, %f804;
	cvt.f64.f32	%fd340, %f833;
	add.f64 	%fd341, %fd339, %fd340;
	cvt.rn.f32.f64	%f329, %fd341;
	setp.eq.f32	%p219, %f325, 0f00000000;
	setp.eq.f32	%p220, %f321, 0f00000000;
	and.pred  	%p221, %p220, %p219;
	mov.u16 	%rs17, 0;
	@%p221 bra 	BB9_337;

	neg.f32 	%f834, %f329;
	div.rn.f32 	%f1017, %f834, %f325;
	mul.f32 	%f835, %f321, 0fC0800000;
	mul.f32 	%f836, %f835, %f329;
	fma.rn.f32 	%f331, %f325, %f325, %f836;
	setp.lt.f32	%p222, %f331, 0f00000000;
	setp.neu.f32	%p223, %f321, 0f00000000;
	and.pred  	%p224, %p222, %p223;
	@%p224 bra 	BB9_337;

	mov.b32 	 %r551, %f325;
	and.b32  	%r552, %r551, -2147483648;
	sqrt.rn.f32 	%f837, %f331;
	mov.b32 	 %r553, %f837;
	and.b32  	%r554, %r553, 2147483647;
	or.b32  	%r555, %r554, %r552;
	mov.b32 	 %f838, %r555;
	add.f32 	%f839, %f325, %f838;
	mul.f32 	%f840, %f839, 0fBF000000;
	div.rn.f32 	%f841, %f840, %f321;
	div.rn.f32 	%f842, %f329, %f840;
	max.f32 	%f843, %f841, %f842;
	selp.f32	%f1017, %f1017, %f843, %p220;
	bra.uni 	BB9_336;

BB9_204:
	setp.gt.f64	%p237, %fd2, 0d3FF0000000000000;
	selp.b32	%r575, 2146435072, 0, %p237;
	mov.u32 	%r576, 0;
	xor.b32  	%r577, %r575, 2146435072;
	setp.lt.s32	%p238, %r9, 0;
	selp.b32	%r578, %r577, %r575, %p238;
	setp.eq.f32	%p239, %f1016, 0fBF800000;
	selp.b32	%r579, 1072693248, %r578, %p239;
	mov.b64 	%fd442, {%r576, %r579};

BB9_205:
	cvt.f64.f32	%fd126, %f1014;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r18}, %fd126;
	}
	abs.f64 	%fd127, %fd126;
	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd127;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd444, [retval0+0];
	
	//{
	}// Callseq End 9
	setp.gt.s32	%p240, %r18, -1;
	setp.lt.s32	%p241, %r18, 0;
	setp.ne.s64	%p242, %rd20, -9223372036854775808;
	and.pred  	%p10, %p241, %p42;
	or.pred  	%p244, %p240, %p242;
	@%p244 bra 	BB9_207;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r580}, %fd444;
	}
	xor.b32  	%r581, %r580, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r582, %temp}, %fd444;
	}
	mov.b64 	%fd444, {%r582, %r581};

BB9_207:
	setp.eq.f32	%p245, %f1014, 0f00000000;
	@%p245 bra 	BB9_210;
	bra.uni 	BB9_208;

BB9_210:
	selp.b32	%r583, %r18, 0, %p42;
	mov.u32 	%r584, 0;
	or.b32  	%r585, %r583, 2146435072;
	setp.lt.s32	%p249, %r9, 0;
	selp.b32	%r586, %r585, %r583, %p249;
	mov.b64 	%fd444, {%r584, %r586};
	bra.uni 	BB9_211;

BB9_208:
	@%p240 bra 	BB9_211;

	cvt.rzi.f64.f64	%fd346, %fd292;
	setp.neu.f64	%p247, %fd346, 0d4000000000000000;
	selp.f64	%fd444, 0dFFF8000000000000, %fd444, %p247;

BB9_211:
	add.f64 	%fd445, %fd126, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r587}, %fd445;
	}
	and.b32  	%r588, %r587, 2146435072;
	setp.ne.s32	%p250, %r588, 2146435072;
	@%p250 bra 	BB9_212;

	setp.gtu.f64	%p251, %fd127, 0d7FF0000000000000;
	@%p251 bra 	BB9_221;

	and.b32  	%r589, %r9, 2147483647;
	setp.ne.s32	%p252, %r589, 2146435072;
	@%p252 bra 	BB9_216;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r590, %temp}, %fd292;
	}
	setp.eq.s32	%p253, %r590, 0;
	@%p253 bra 	BB9_220;

BB9_216:
	and.b32  	%r591, %r18, 2147483647;
	setp.ne.s32	%p254, %r591, 2146435072;
	@%p254 bra 	BB9_217;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r592, %temp}, %fd126;
	}
	setp.ne.s32	%p255, %r592, 0;
	mov.f64 	%fd445, %fd444;
	@%p255 bra 	BB9_221;

	shr.s32 	%r593, %r9, 31;
	and.b32  	%r594, %r593, -2146435072;
	add.s32 	%r595, %r594, 2146435072;
	or.b32  	%r596, %r595, -2147483648;
	selp.b32	%r597, %r596, %r595, %p10;
	mov.u32 	%r598, 0;
	mov.b64 	%fd445, {%r598, %r597};
	bra.uni 	BB9_221;

BB9_212:
	mov.f64 	%fd445, %fd444;
	bra.uni 	BB9_221;

BB9_217:
	mov.f64 	%fd445, %fd444;
	bra.uni 	BB9_221;

BB9_220:
	setp.gt.f64	%p256, %fd127, 0d3FF0000000000000;
	selp.b32	%r599, 2146435072, 0, %p256;
	mov.u32 	%r600, 0;
	xor.b32  	%r601, %r599, 2146435072;
	setp.lt.s32	%p257, %r9, 0;
	selp.b32	%r602, %r601, %r599, %p257;
	setp.eq.f32	%p258, %f1014, 0fBF800000;
	selp.b32	%r603, 1072693248, %r602, %p258;
	mov.b64 	%fd445, {%r600, %r603};

BB9_221:
	setp.eq.f32	%p259, %f1014, 0f3F800000;
	selp.f64	%fd348, 0d3FF0000000000000, %fd445, %p259;
	setp.eq.f32	%p260, %f1016, 0f3F800000;
	selp.f64	%fd349, 0d3FF0000000000000, %fd442, %p260;
	fma.rn.f64 	%fd138, %fd116, %fd349, %fd348;
	cvt.f64.f32	%fd139, %f1015;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r19}, %fd139;
	}
	abs.f64 	%fd140, %fd139;
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd140;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd447, [retval0+0];
	
	//{
	}// Callseq End 10
	setp.gt.s32	%p261, %r19, -1;
	setp.lt.s32	%p262, %r19, 0;
	and.pred  	%p11, %p262, %p42;
	or.pred  	%p265, %p261, %p242;
	@%p265 bra 	BB9_223;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r604}, %fd447;
	}
	xor.b32  	%r605, %r604, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r606, %temp}, %fd447;
	}
	mov.b64 	%fd447, {%r606, %r605};

BB9_223:
	setp.eq.f32	%p266, %f1015, 0f00000000;
	@%p266 bra 	BB9_226;
	bra.uni 	BB9_224;

BB9_226:
	selp.b32	%r607, %r19, 0, %p42;
	mov.u32 	%r608, 0;
	or.b32  	%r609, %r607, 2146435072;
	setp.lt.s32	%p270, %r9, 0;
	selp.b32	%r610, %r609, %r607, %p270;
	mov.b64 	%fd447, {%r608, %r610};
	bra.uni 	BB9_227;

BB9_224:
	@%p261 bra 	BB9_227;

	cvt.rzi.f64.f64	%fd351, %fd292;
	setp.neu.f64	%p268, %fd351, 0d4000000000000000;
	selp.f64	%fd447, 0dFFF8000000000000, %fd447, %p268;

BB9_227:
	add.f64 	%fd448, %fd139, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r611}, %fd448;
	}
	and.b32  	%r612, %r611, 2146435072;
	setp.ne.s32	%p271, %r612, 2146435072;
	@%p271 bra 	BB9_228;

	setp.gtu.f64	%p272, %fd140, 0d7FF0000000000000;
	@%p272 bra 	BB9_237;

	and.b32  	%r613, %r9, 2147483647;
	setp.ne.s32	%p273, %r613, 2146435072;
	@%p273 bra 	BB9_232;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r614, %temp}, %fd292;
	}
	setp.eq.s32	%p274, %r614, 0;
	@%p274 bra 	BB9_236;

BB9_232:
	and.b32  	%r615, %r19, 2147483647;
	setp.ne.s32	%p275, %r615, 2146435072;
	@%p275 bra 	BB9_233;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r616, %temp}, %fd139;
	}
	setp.ne.s32	%p276, %r616, 0;
	mov.f64 	%fd448, %fd447;
	@%p276 bra 	BB9_237;

	shr.s32 	%r617, %r9, 31;
	and.b32  	%r618, %r617, -2146435072;
	add.s32 	%r619, %r618, 2146435072;
	or.b32  	%r620, %r619, -2147483648;
	selp.b32	%r621, %r620, %r619, %p11;
	mov.u32 	%r622, 0;
	mov.b64 	%fd448, {%r622, %r621};
	bra.uni 	BB9_237;

BB9_228:
	mov.f64 	%fd448, %fd447;
	bra.uni 	BB9_237;

BB9_233:
	mov.f64 	%fd448, %fd447;
	bra.uni 	BB9_237;

BB9_236:
	setp.gt.f64	%p277, %fd140, 0d3FF0000000000000;
	selp.b32	%r623, 2146435072, 0, %p277;
	mov.u32 	%r624, 0;
	xor.b32  	%r625, %r623, 2146435072;
	setp.lt.s32	%p278, %r9, 0;
	selp.b32	%r626, %r625, %r623, %p278;
	setp.eq.f32	%p279, %f1015, 0fBF800000;
	selp.b32	%r627, 1072693248, %r626, %p279;
	mov.b64 	%fd448, {%r624, %r627};

BB9_237:
	setp.eq.f32	%p280, %f1015, 0f3F800000;
	selp.f64	%fd353, 0d3FF0000000000000, %fd448, %p280;
	add.f64 	%fd354, %fd138, %fd353;
	cvt.rn.f32.f64	%f339, %fd354;
	add.f32 	%f849, %f338, %f338;
	mul.f32 	%f850, %f965, %f849;
	mul.f32 	%f851, %f1016, %f850;
	add.f32 	%f852, %f337, %f337;
	mul.f32 	%f340, %f846, %f852;
	fma.rn.f32 	%f853, %f1016, %f340, %f851;
	add.f32 	%f854, %f967, %f967;
	fma.rn.f32 	%f855, %f1014, %f854, %f853;
	add.f32 	%f341, %f844, %f844;
	mul.f32 	%f856, %f341, %f1014;
	sub.f32 	%f857, %f855, %f856;
	add.f32 	%f858, %f966, %f966;
	fma.rn.f32 	%f859, %f1015, %f858, %f857;
	add.f32 	%f342, %f845, %f845;
	mul.f32 	%f860, %f342, %f1015;
	sub.f32 	%f861, %f859, %f860;
	add.f32 	%f862, %f1016, %f1016;
	div.rn.f32 	%f863, %f862, %f336;
	sub.f32 	%f343, %f861, %f863;
	cvt.f64.f32	%fd151, %f965;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd151;
	}
	abs.f64 	%fd152, %fd151;
	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd152;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd450, [retval0+0];
	
	//{
	}// Callseq End 11
	setp.gt.s32	%p281, %r20, -1;
	setp.lt.s32	%p282, %r20, 0;
	and.pred  	%p12, %p282, %p42;
	or.pred  	%p285, %p281, %p242;
	@%p285 bra 	BB9_239;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r628}, %fd450;
	}
	xor.b32  	%r629, %r628, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r630, %temp}, %fd450;
	}
	mov.b64 	%fd450, {%r630, %r629};

BB9_239:
	setp.eq.f32	%p286, %f965, 0f00000000;
	@%p286 bra 	BB9_242;
	bra.uni 	BB9_240;

BB9_242:
	selp.b32	%r631, %r20, 0, %p42;
	mov.u32 	%r632, 0;
	or.b32  	%r633, %r631, 2146435072;
	setp.lt.s32	%p290, %r9, 0;
	selp.b32	%r634, %r633, %r631, %p290;
	mov.b64 	%fd450, {%r632, %r634};
	bra.uni 	BB9_243;

BB9_240:
	@%p281 bra 	BB9_243;

	cvt.rzi.f64.f64	%fd356, %fd292;
	setp.neu.f64	%p288, %fd356, 0d4000000000000000;
	selp.f64	%fd450, 0dFFF8000000000000, %fd450, %p288;

BB9_243:
	add.f64 	%fd451, %fd151, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r635}, %fd451;
	}
	and.b32  	%r636, %r635, 2146435072;
	setp.ne.s32	%p291, %r636, 2146435072;
	@%p291 bra 	BB9_244;

	setp.gtu.f64	%p292, %fd152, 0d7FF0000000000000;
	@%p292 bra 	BB9_253;

	and.b32  	%r637, %r9, 2147483647;
	setp.ne.s32	%p293, %r637, 2146435072;
	@%p293 bra 	BB9_248;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r638, %temp}, %fd292;
	}
	setp.eq.s32	%p294, %r638, 0;
	@%p294 bra 	BB9_252;

BB9_248:
	and.b32  	%r639, %r20, 2147483647;
	setp.ne.s32	%p295, %r639, 2146435072;
	@%p295 bra 	BB9_249;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r640, %temp}, %fd151;
	}
	setp.ne.s32	%p296, %r640, 0;
	mov.f64 	%fd451, %fd450;
	@%p296 bra 	BB9_253;

	shr.s32 	%r641, %r9, 31;
	and.b32  	%r642, %r641, -2146435072;
	add.s32 	%r643, %r642, 2146435072;
	or.b32  	%r644, %r643, -2147483648;
	selp.b32	%r645, %r644, %r643, %p12;
	mov.u32 	%r646, 0;
	mov.b64 	%fd451, {%r646, %r645};
	bra.uni 	BB9_253;

BB9_244:
	mov.f64 	%fd451, %fd450;
	bra.uni 	BB9_253;

BB9_249:
	mov.f64 	%fd451, %fd450;
	bra.uni 	BB9_253;

BB9_252:
	setp.gt.f64	%p297, %fd152, 0d3FF0000000000000;
	selp.b32	%r647, 2146435072, 0, %p297;
	mov.u32 	%r648, 0;
	xor.b32  	%r649, %r647, 2146435072;
	setp.lt.s32	%p298, %r9, 0;
	selp.b32	%r650, %r649, %r647, %p298;
	setp.eq.f32	%p299, %f965, 0fBF800000;
	selp.b32	%r651, 1072693248, %r650, %p299;
	mov.b64 	%fd451, {%r648, %r651};

BB9_253:
	setp.eq.f32	%p300, %f965, 0f3F800000;
	selp.f64	%fd358, 0d3FF0000000000000, %fd451, %p300;
	mul.f32 	%f864, %f965, %f340;
	cvt.f64.f32	%fd359, %f864;
	fma.rn.f64 	%fd163, %fd116, %fd358, %fd359;
	neg.f32 	%f344, %f846;
	cvt.f64.f32	%fd164, %f344;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd164;
	}
	abs.f64 	%fd165, %fd164;
	// Callseq Start 12
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd165;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd453, [retval0+0];
	
	//{
	}// Callseq End 12
	setp.gt.s32	%p301, %r21, -1;
	setp.lt.s32	%p302, %r21, 0;
	and.pred  	%p13, %p302, %p42;
	or.pred  	%p305, %p301, %p242;
	@%p305 bra 	BB9_255;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r652}, %fd453;
	}
	xor.b32  	%r653, %r652, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r654, %temp}, %fd453;
	}
	mov.b64 	%fd453, {%r654, %r653};

BB9_255:
	setp.eq.f32	%p306, %f344, 0f00000000;
	@%p306 bra 	BB9_258;
	bra.uni 	BB9_256;

BB9_258:
	selp.b32	%r655, %r21, 0, %p42;
	mov.u32 	%r656, 0;
	or.b32  	%r657, %r655, 2146435072;
	setp.lt.s32	%p310, %r9, 0;
	selp.b32	%r658, %r657, %r655, %p310;
	mov.b64 	%fd453, {%r656, %r658};
	bra.uni 	BB9_259;

BB9_256:
	@%p301 bra 	BB9_259;

	cvt.rzi.f64.f64	%fd361, %fd292;
	setp.neu.f64	%p308, %fd361, 0d4000000000000000;
	selp.f64	%fd453, 0dFFF8000000000000, %fd453, %p308;

BB9_259:
	add.f64 	%fd454, %fd164, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r659}, %fd454;
	}
	and.b32  	%r660, %r659, 2146435072;
	setp.ne.s32	%p311, %r660, 2146435072;
	@%p311 bra 	BB9_260;

	setp.gtu.f64	%p312, %fd165, 0d7FF0000000000000;
	@%p312 bra 	BB9_269;

	and.b32  	%r661, %r9, 2147483647;
	setp.ne.s32	%p313, %r661, 2146435072;
	@%p313 bra 	BB9_264;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r662, %temp}, %fd292;
	}
	setp.eq.s32	%p314, %r662, 0;
	@%p314 bra 	BB9_268;

BB9_264:
	and.b32  	%r663, %r21, 2147483647;
	setp.ne.s32	%p315, %r663, 2146435072;
	@%p315 bra 	BB9_265;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r664, %temp}, %fd164;
	}
	setp.ne.s32	%p316, %r664, 0;
	mov.f64 	%fd454, %fd453;
	@%p316 bra 	BB9_269;

	shr.s32 	%r665, %r9, 31;
	and.b32  	%r666, %r665, -2146435072;
	add.s32 	%r667, %r666, 2146435072;
	or.b32  	%r668, %r667, -2147483648;
	selp.b32	%r669, %r668, %r667, %p13;
	mov.u32 	%r670, 0;
	mov.b64 	%fd454, {%r670, %r669};
	bra.uni 	BB9_269;

BB9_260:
	mov.f64 	%fd454, %fd453;
	bra.uni 	BB9_269;

BB9_265:
	mov.f64 	%fd454, %fd453;
	bra.uni 	BB9_269;

BB9_268:
	setp.gt.f64	%p317, %fd165, 0d3FF0000000000000;
	selp.b32	%r671, 2146435072, 0, %p317;
	mov.u32 	%r672, 0;
	xor.b32  	%r673, %r671, 2146435072;
	setp.lt.s32	%p318, %r9, 0;
	selp.b32	%r674, %r673, %r671, %p318;
	setp.eq.f32	%p319, %f344, 0fBF800000;
	selp.b32	%r675, 1072693248, %r674, %p319;
	mov.b64 	%fd454, {%r672, %r675};

BB9_269:
	setp.eq.f32	%p320, %f344, 0f3F800000;
	selp.f64	%fd363, 0d3FF0000000000000, %fd454, %p320;
	cvt.f64.f32	%fd364, %f337;
	mul.f64 	%fd365, %fd364, %fd363;
	sub.f64 	%fd176, %fd163, %fd365;
	cvt.f64.f32	%fd177, %f967;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd177;
	}
	abs.f64 	%fd178, %fd177;
	// Callseq Start 13
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd178;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd456, [retval0+0];
	
	//{
	}// Callseq End 13
	setp.gt.s32	%p321, %r22, -1;
	setp.lt.s32	%p322, %r22, 0;
	and.pred  	%p14, %p322, %p42;
	or.pred  	%p325, %p321, %p242;
	@%p325 bra 	BB9_271;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r676}, %fd456;
	}
	xor.b32  	%r677, %r676, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r678, %temp}, %fd456;
	}
	mov.b64 	%fd456, {%r678, %r677};

BB9_271:
	setp.eq.f32	%p326, %f967, 0f00000000;
	@%p326 bra 	BB9_274;
	bra.uni 	BB9_272;

BB9_274:
	selp.b32	%r679, %r22, 0, %p42;
	mov.u32 	%r680, 0;
	or.b32  	%r681, %r679, 2146435072;
	setp.lt.s32	%p330, %r9, 0;
	selp.b32	%r682, %r681, %r679, %p330;
	mov.b64 	%fd456, {%r680, %r682};
	bra.uni 	BB9_275;

BB9_272:
	@%p321 bra 	BB9_275;

	cvt.rzi.f64.f64	%fd367, %fd292;
	setp.neu.f64	%p328, %fd367, 0d4000000000000000;
	selp.f64	%fd456, 0dFFF8000000000000, %fd456, %p328;

BB9_275:
	add.f64 	%fd457, %fd177, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r683}, %fd457;
	}
	and.b32  	%r684, %r683, 2146435072;
	setp.ne.s32	%p331, %r684, 2146435072;
	@%p331 bra 	BB9_276;

	setp.gtu.f64	%p332, %fd178, 0d7FF0000000000000;
	@%p332 bra 	BB9_285;

	and.b32  	%r685, %r9, 2147483647;
	setp.ne.s32	%p333, %r685, 2146435072;
	@%p333 bra 	BB9_280;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r686, %temp}, %fd292;
	}
	setp.eq.s32	%p334, %r686, 0;
	@%p334 bra 	BB9_284;

BB9_280:
	and.b32  	%r687, %r22, 2147483647;
	setp.ne.s32	%p335, %r687, 2146435072;
	@%p335 bra 	BB9_281;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r688, %temp}, %fd177;
	}
	setp.ne.s32	%p336, %r688, 0;
	mov.f64 	%fd457, %fd456;
	@%p336 bra 	BB9_285;

	shr.s32 	%r689, %r9, 31;
	and.b32  	%r690, %r689, -2146435072;
	add.s32 	%r691, %r690, 2146435072;
	or.b32  	%r692, %r691, -2147483648;
	selp.b32	%r693, %r692, %r691, %p14;
	mov.u32 	%r694, 0;
	mov.b64 	%fd457, {%r694, %r693};
	bra.uni 	BB9_285;

BB9_276:
	mov.f64 	%fd457, %fd456;
	bra.uni 	BB9_285;

BB9_281:
	mov.f64 	%fd457, %fd456;
	bra.uni 	BB9_285;

BB9_284:
	setp.gt.f64	%p337, %fd178, 0d3FF0000000000000;
	selp.b32	%r695, 2146435072, 0, %p337;
	mov.u32 	%r696, 0;
	xor.b32  	%r697, %r695, 2146435072;
	setp.lt.s32	%p338, %r9, 0;
	selp.b32	%r698, %r697, %r695, %p338;
	setp.eq.f32	%p339, %f967, 0fBF800000;
	selp.b32	%r699, 1072693248, %r698, %p339;
	mov.b64 	%fd457, {%r696, %r699};

BB9_285:
	setp.eq.f32	%p340, %f967, 0f3F800000;
	selp.f64	%fd369, 0d3FF0000000000000, %fd457, %p340;
	add.f64 	%fd370, %fd176, %fd369;
	mul.f32 	%f865, %f341, %f967;
	cvt.f64.f32	%fd371, %f865;
	sub.f64 	%fd189, %fd370, %fd371;
	neg.f32 	%f345, %f844;
	cvt.f64.f32	%fd190, %f345;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd190;
	}
	abs.f64 	%fd191, %fd190;
	// Callseq Start 14
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd191;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd459, [retval0+0];
	
	//{
	}// Callseq End 14
	setp.gt.s32	%p341, %r23, -1;
	setp.lt.s32	%p342, %r23, 0;
	and.pred  	%p15, %p342, %p42;
	or.pred  	%p345, %p341, %p242;
	@%p345 bra 	BB9_287;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r700}, %fd459;
	}
	xor.b32  	%r701, %r700, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r702, %temp}, %fd459;
	}
	mov.b64 	%fd459, {%r702, %r701};

BB9_287:
	setp.eq.f32	%p346, %f345, 0f00000000;
	@%p346 bra 	BB9_290;
	bra.uni 	BB9_288;

BB9_290:
	selp.b32	%r703, %r23, 0, %p42;
	mov.u32 	%r704, 0;
	or.b32  	%r705, %r703, 2146435072;
	setp.lt.s32	%p350, %r9, 0;
	selp.b32	%r706, %r705, %r703, %p350;
	mov.b64 	%fd459, {%r704, %r706};
	bra.uni 	BB9_291;

BB9_288:
	@%p341 bra 	BB9_291;

	cvt.rzi.f64.f64	%fd373, %fd292;
	setp.neu.f64	%p348, %fd373, 0d4000000000000000;
	selp.f64	%fd459, 0dFFF8000000000000, %fd459, %p348;

BB9_291:
	add.f64 	%fd460, %fd190, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r707}, %fd460;
	}
	and.b32  	%r708, %r707, 2146435072;
	setp.ne.s32	%p351, %r708, 2146435072;
	@%p351 bra 	BB9_292;

	setp.gtu.f64	%p352, %fd191, 0d7FF0000000000000;
	@%p352 bra 	BB9_301;

	and.b32  	%r709, %r9, 2147483647;
	setp.ne.s32	%p353, %r709, 2146435072;
	@%p353 bra 	BB9_296;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r710, %temp}, %fd292;
	}
	setp.eq.s32	%p354, %r710, 0;
	@%p354 bra 	BB9_300;

BB9_296:
	and.b32  	%r711, %r23, 2147483647;
	setp.ne.s32	%p355, %r711, 2146435072;
	@%p355 bra 	BB9_297;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r712, %temp}, %fd190;
	}
	setp.ne.s32	%p356, %r712, 0;
	mov.f64 	%fd460, %fd459;
	@%p356 bra 	BB9_301;

	shr.s32 	%r713, %r9, 31;
	and.b32  	%r714, %r713, -2146435072;
	add.s32 	%r715, %r714, 2146435072;
	or.b32  	%r716, %r715, -2147483648;
	selp.b32	%r717, %r716, %r715, %p15;
	mov.u32 	%r718, 0;
	mov.b64 	%fd460, {%r718, %r717};
	bra.uni 	BB9_301;

BB9_292:
	mov.f64 	%fd460, %fd459;
	bra.uni 	BB9_301;

BB9_297:
	mov.f64 	%fd460, %fd459;
	bra.uni 	BB9_301;

BB9_300:
	setp.gt.f64	%p357, %fd191, 0d3FF0000000000000;
	selp.b32	%r719, 2146435072, 0, %p357;
	mov.u32 	%r720, 0;
	xor.b32  	%r721, %r719, 2146435072;
	setp.lt.s32	%p358, %r9, 0;
	selp.b32	%r722, %r721, %r719, %p358;
	setp.eq.f32	%p359, %f345, 0fBF800000;
	selp.b32	%r723, 1072693248, %r722, %p359;
	mov.b64 	%fd460, {%r720, %r723};

BB9_301:
	setp.eq.f32	%p360, %f345, 0f3F800000;
	selp.f64	%fd375, 0d3FF0000000000000, %fd460, %p360;
	add.f64 	%fd202, %fd189, %fd375;
	cvt.f64.f32	%fd203, %f966;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r24}, %fd203;
	}
	abs.f64 	%fd204, %fd203;
	// Callseq Start 15
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd204;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd462, [retval0+0];
	
	//{
	}// Callseq End 15
	setp.gt.s32	%p361, %r24, -1;
	setp.lt.s32	%p362, %r24, 0;
	and.pred  	%p16, %p362, %p42;
	or.pred  	%p365, %p361, %p242;
	@%p365 bra 	BB9_303;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r724}, %fd462;
	}
	xor.b32  	%r725, %r724, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r726, %temp}, %fd462;
	}
	mov.b64 	%fd462, {%r726, %r725};

BB9_303:
	setp.eq.f32	%p366, %f966, 0f00000000;
	@%p366 bra 	BB9_306;
	bra.uni 	BB9_304;

BB9_306:
	selp.b32	%r727, %r24, 0, %p42;
	mov.u32 	%r728, 0;
	or.b32  	%r729, %r727, 2146435072;
	setp.lt.s32	%p370, %r9, 0;
	selp.b32	%r730, %r729, %r727, %p370;
	mov.b64 	%fd462, {%r728, %r730};
	bra.uni 	BB9_307;

BB9_304:
	@%p361 bra 	BB9_307;

	cvt.rzi.f64.f64	%fd377, %fd292;
	setp.neu.f64	%p368, %fd377, 0d4000000000000000;
	selp.f64	%fd462, 0dFFF8000000000000, %fd462, %p368;

BB9_307:
	add.f64 	%fd463, %fd203, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r731}, %fd463;
	}
	and.b32  	%r732, %r731, 2146435072;
	setp.ne.s32	%p371, %r732, 2146435072;
	@%p371 bra 	BB9_308;

	setp.gtu.f64	%p372, %fd204, 0d7FF0000000000000;
	@%p372 bra 	BB9_317;

	and.b32  	%r733, %r9, 2147483647;
	setp.ne.s32	%p373, %r733, 2146435072;
	@%p373 bra 	BB9_312;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r734, %temp}, %fd292;
	}
	setp.eq.s32	%p374, %r734, 0;
	@%p374 bra 	BB9_316;

BB9_312:
	and.b32  	%r735, %r24, 2147483647;
	setp.ne.s32	%p375, %r735, 2146435072;
	@%p375 bra 	BB9_313;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r736, %temp}, %fd203;
	}
	setp.ne.s32	%p376, %r736, 0;
	mov.f64 	%fd463, %fd462;
	@%p376 bra 	BB9_317;

	shr.s32 	%r737, %r9, 31;
	and.b32  	%r738, %r737, -2146435072;
	add.s32 	%r739, %r738, 2146435072;
	or.b32  	%r740, %r739, -2147483648;
	selp.b32	%r741, %r740, %r739, %p16;
	mov.u32 	%r742, 0;
	mov.b64 	%fd463, {%r742, %r741};
	bra.uni 	BB9_317;

BB9_308:
	mov.f64 	%fd463, %fd462;
	bra.uni 	BB9_317;

BB9_313:
	mov.f64 	%fd463, %fd462;
	bra.uni 	BB9_317;

BB9_316:
	setp.gt.f64	%p377, %fd204, 0d3FF0000000000000;
	selp.b32	%r743, 2146435072, 0, %p377;
	mov.u32 	%r744, 0;
	xor.b32  	%r745, %r743, 2146435072;
	setp.lt.s32	%p378, %r9, 0;
	selp.b32	%r746, %r745, %r743, %p378;
	setp.eq.f32	%p379, %f966, 0fBF800000;
	selp.b32	%r747, 1072693248, %r746, %p379;
	mov.b64 	%fd463, {%r744, %r747};

BB9_317:
	setp.eq.f32	%p380, %f966, 0f3F800000;
	selp.f64	%fd379, 0d3FF0000000000000, %fd463, %p380;
	add.f64 	%fd380, %fd202, %fd379;
	mul.f32 	%f866, %f342, %f966;
	cvt.f64.f32	%fd381, %f866;
	sub.f64 	%fd215, %fd380, %fd381;
	neg.f32 	%f346, %f845;
	cvt.f64.f32	%fd216, %f346;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd216;
	}
	abs.f64 	%fd217, %fd216;
	// Callseq Start 16
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd217;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd465, [retval0+0];
	
	//{
	}// Callseq End 16
	setp.gt.s32	%p381, %r25, -1;
	setp.lt.s32	%p382, %r25, 0;
	and.pred  	%p17, %p382, %p42;
	or.pred  	%p385, %p381, %p242;
	@%p385 bra 	BB9_319;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r748}, %fd465;
	}
	xor.b32  	%r749, %r748, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r750, %temp}, %fd465;
	}
	mov.b64 	%fd465, {%r750, %r749};

BB9_319:
	setp.eq.f32	%p386, %f346, 0f00000000;
	@%p386 bra 	BB9_322;
	bra.uni 	BB9_320;

BB9_322:
	selp.b32	%r751, %r25, 0, %p42;
	mov.u32 	%r752, 0;
	or.b32  	%r753, %r751, 2146435072;
	setp.lt.s32	%p390, %r9, 0;
	selp.b32	%r754, %r753, %r751, %p390;
	mov.b64 	%fd465, {%r752, %r754};
	bra.uni 	BB9_323;

BB9_320:
	@%p381 bra 	BB9_323;

	cvt.rzi.f64.f64	%fd383, %fd292;
	setp.neu.f64	%p388, %fd383, 0d4000000000000000;
	selp.f64	%fd465, 0dFFF8000000000000, %fd465, %p388;

BB9_323:
	add.f64 	%fd466, %fd216, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r755}, %fd466;
	}
	and.b32  	%r756, %r755, 2146435072;
	setp.ne.s32	%p391, %r756, 2146435072;
	@%p391 bra 	BB9_324;

	setp.gtu.f64	%p392, %fd217, 0d7FF0000000000000;
	@%p392 bra 	BB9_333;

	and.b32  	%r757, %r9, 2147483647;
	setp.ne.s32	%p393, %r757, 2146435072;
	@%p393 bra 	BB9_328;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r758, %temp}, %fd292;
	}
	setp.eq.s32	%p394, %r758, 0;
	@%p394 bra 	BB9_332;

BB9_328:
	and.b32  	%r759, %r25, 2147483647;
	setp.ne.s32	%p395, %r759, 2146435072;
	@%p395 bra 	BB9_329;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r760, %temp}, %fd216;
	}
	setp.ne.s32	%p396, %r760, 0;
	mov.f64 	%fd466, %fd465;
	@%p396 bra 	BB9_333;

	shr.s32 	%r761, %r9, 31;
	and.b32  	%r762, %r761, -2146435072;
	add.s32 	%r763, %r762, 2146435072;
	or.b32  	%r764, %r763, -2147483648;
	selp.b32	%r765, %r764, %r763, %p17;
	mov.u32 	%r766, 0;
	mov.b64 	%fd466, {%r766, %r765};
	bra.uni 	BB9_333;

BB9_324:
	mov.f64 	%fd466, %fd465;
	bra.uni 	BB9_333;

BB9_329:
	mov.f64 	%fd466, %fd465;
	bra.uni 	BB9_333;

BB9_332:
	setp.gt.f64	%p397, %fd217, 0d3FF0000000000000;
	selp.b32	%r767, 2146435072, 0, %p397;
	mov.u32 	%r768, 0;
	xor.b32  	%r769, %r767, 2146435072;
	setp.lt.s32	%p398, %r9, 0;
	selp.b32	%r770, %r769, %r767, %p398;
	setp.eq.f32	%p399, %f346, 0fBF800000;
	selp.b32	%r771, 1072693248, %r770, %p399;
	mov.b64 	%fd466, {%r768, %r771};

BB9_333:
	setp.eq.f32	%p400, %f346, 0f3F800000;
	selp.f64	%fd385, 0d3FF0000000000000, %fd466, %p400;
	add.f64 	%fd386, %fd215, %fd385;
	add.f32 	%f868, %f965, %f965;
	div.rn.f32 	%f869, %f868, %f336;
	cvt.f64.f32	%fd387, %f869;
	sub.f64 	%fd388, %fd386, %fd387;
	add.f32 	%f870, %f846, %f846;
	div.rn.f32 	%f871, %f870, %f336;
	cvt.f64.f32	%fd389, %f871;
	add.f64 	%fd390, %fd388, %fd389;
	cvt.rn.f32.f64	%f347, %fd390;
	setp.eq.f32	%p401, %f343, 0f00000000;
	setp.eq.f32	%p402, %f339, 0f00000000;
	and.pred  	%p403, %p402, %p401;
	mov.u16 	%rs17, 0;
	@%p403 bra 	BB9_337;

	neg.f32 	%f872, %f347;
	div.rn.f32 	%f1017, %f872, %f343;
	mul.f32 	%f873, %f339, 0fC0800000;
	mul.f32 	%f874, %f873, %f347;
	fma.rn.f32 	%f349, %f343, %f343, %f874;
	setp.lt.f32	%p404, %f349, 0f00000000;
	setp.neu.f32	%p405, %f339, 0f00000000;
	and.pred  	%p406, %p404, %p405;
	@%p406 bra 	BB9_337;

	mov.b32 	 %r772, %f343;
	and.b32  	%r773, %r772, -2147483648;
	sqrt.rn.f32 	%f875, %f349;
	mov.b32 	 %r774, %f875;
	and.b32  	%r775, %r774, 2147483647;
	or.b32  	%r776, %r775, %r773;
	mov.b32 	 %f876, %r776;
	add.f32 	%f877, %f343, %f876;
	mul.f32 	%f878, %f877, 0fBF000000;
	div.rn.f32 	%f879, %f878, %f339;
	div.rn.f32 	%f880, %f347, %f878;
	min.f32 	%f881, %f879, %f880;
	selp.f32	%f1017, %f1017, %f881, %p402;

BB9_336:
	mov.u16 	%rs17, 1;

BB9_337:
	ld.v4.f32 	{%f882, %f883, %f884, %f885}, [%rd1+288];
	ld.v4.f32 	{%f889, %f890, %f891, %f892}, [%rd1+320];
	fma.rn.f32 	%f893, %f1017, %f1014, %f967;
	sub.f32 	%f354, %f893, %f882;
	fma.rn.f32 	%f894, %f1017, %f1015, %f966;
	sub.f32 	%f355, %f894, %f883;
	fma.rn.f32 	%f895, %f1017, %f1016, %f965;
	sub.f32 	%f356, %f895, %f884;
	cvt.f64.f32	%fd228, %f354;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd228;
	}
	cvt.u32.u64	%r777, %rd19;
	shl.b64 	%rd21, %rd265, %r777;
	setp.ne.s64	%p408, %rd21, -9223372036854775808;
	setp.eq.s64	%p409, %rd21, -9223372036854775808;
	abs.f64 	%fd229, %fd228;
	// Callseq Start 17
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd229;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd468, [retval0+0];
	
	//{
	}// Callseq End 17
	setp.gt.s32	%p410, %r27, -1;
	setp.lt.s32	%p411, %r27, 0;
	and.pred  	%p18, %p411, %p409;
	or.pred  	%p412, %p410, %p408;
	@%p412 bra 	BB9_339;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r778}, %fd468;
	}
	xor.b32  	%r779, %r778, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r780, %temp}, %fd468;
	}
	mov.b64 	%fd468, {%r780, %r779};

BB9_339:
	setp.eq.f32	%p413, %f354, 0f00000000;
	@%p413 bra 	BB9_342;
	bra.uni 	BB9_340;

BB9_342:
	selp.b32	%r781, %r27, 0, %p409;
	mov.u32 	%r782, 0;
	or.b32  	%r783, %r781, 2146435072;
	setp.lt.s32	%p417, %r9, 0;
	selp.b32	%r784, %r783, %r781, %p417;
	mov.b64 	%fd468, {%r782, %r784};
	bra.uni 	BB9_343;

BB9_340:
	@%p410 bra 	BB9_343;

	cvt.rzi.f64.f64	%fd393, %fd292;
	setp.neu.f64	%p415, %fd393, 0d4000000000000000;
	selp.f64	%fd468, 0dFFF8000000000000, %fd468, %p415;

BB9_343:
	add.f64 	%fd469, %fd228, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r785}, %fd469;
	}
	and.b32  	%r786, %r785, 2146435072;
	setp.ne.s32	%p418, %r786, 2146435072;
	@%p418 bra 	BB9_344;

	setp.gtu.f64	%p419, %fd229, 0d7FF0000000000000;
	@%p419 bra 	BB9_353;

	and.b32  	%r787, %r9, 2147483647;
	setp.ne.s32	%p420, %r787, 2146435072;
	@%p420 bra 	BB9_348;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r788, %temp}, %fd292;
	}
	setp.eq.s32	%p421, %r788, 0;
	@%p421 bra 	BB9_352;

BB9_348:
	and.b32  	%r789, %r27, 2147483647;
	setp.ne.s32	%p422, %r789, 2146435072;
	@%p422 bra 	BB9_349;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r790, %temp}, %fd228;
	}
	setp.ne.s32	%p423, %r790, 0;
	mov.f64 	%fd469, %fd468;
	@%p423 bra 	BB9_353;

	shr.s32 	%r791, %r9, 31;
	and.b32  	%r792, %r791, -2146435072;
	add.s32 	%r793, %r792, 2146435072;
	or.b32  	%r794, %r793, -2147483648;
	selp.b32	%r795, %r794, %r793, %p18;
	mov.u32 	%r796, 0;
	mov.b64 	%fd469, {%r796, %r795};
	bra.uni 	BB9_353;

BB9_344:
	mov.f64 	%fd469, %fd468;
	bra.uni 	BB9_353;

BB9_349:
	mov.f64 	%fd469, %fd468;
	bra.uni 	BB9_353;

BB9_352:
	setp.gt.f64	%p424, %fd229, 0d3FF0000000000000;
	selp.b32	%r797, 2146435072, 0, %p424;
	mov.u32 	%r798, 0;
	xor.b32  	%r799, %r797, 2146435072;
	setp.lt.s32	%p425, %r9, 0;
	selp.b32	%r800, %r799, %r797, %p425;
	setp.eq.f32	%p426, %f354, 0fBF800000;
	selp.b32	%r801, 1072693248, %r800, %p426;
	mov.b64 	%fd469, {%r798, %r801};

BB9_353:
	setp.eq.f32	%p427, %f354, 0f3F800000;
	selp.f64	%fd240, 0d3FF0000000000000, %fd469, %p427;
	cvt.f64.f32	%fd241, %f355;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd241;
	}
	abs.f64 	%fd242, %fd241;
	// Callseq Start 18
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd242;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd471, [retval0+0];
	
	//{
	}// Callseq End 18
	setp.gt.s32	%p428, %r28, -1;
	setp.lt.s32	%p429, %r28, 0;
	and.pred  	%p19, %p429, %p409;
	or.pred  	%p432, %p428, %p408;
	@%p432 bra 	BB9_355;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r802}, %fd471;
	}
	xor.b32  	%r803, %r802, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r804, %temp}, %fd471;
	}
	mov.b64 	%fd471, {%r804, %r803};

BB9_355:
	setp.eq.f32	%p433, %f355, 0f00000000;
	@%p433 bra 	BB9_358;
	bra.uni 	BB9_356;

BB9_358:
	selp.b32	%r805, %r28, 0, %p409;
	mov.u32 	%r806, 0;
	or.b32  	%r807, %r805, 2146435072;
	setp.lt.s32	%p437, %r9, 0;
	selp.b32	%r808, %r807, %r805, %p437;
	mov.b64 	%fd471, {%r806, %r808};
	bra.uni 	BB9_359;

BB9_356:
	@%p428 bra 	BB9_359;

	cvt.rzi.f64.f64	%fd396, %fd292;
	setp.neu.f64	%p435, %fd396, 0d4000000000000000;
	selp.f64	%fd471, 0dFFF8000000000000, %fd471, %p435;

BB9_359:
	add.f64 	%fd472, %fd241, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r809}, %fd472;
	}
	and.b32  	%r810, %r809, 2146435072;
	setp.ne.s32	%p438, %r810, 2146435072;
	@%p438 bra 	BB9_360;

	setp.gtu.f64	%p439, %fd242, 0d7FF0000000000000;
	@%p439 bra 	BB9_369;

	and.b32  	%r811, %r9, 2147483647;
	setp.ne.s32	%p440, %r811, 2146435072;
	@%p440 bra 	BB9_364;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r812, %temp}, %fd292;
	}
	setp.eq.s32	%p441, %r812, 0;
	@%p441 bra 	BB9_368;

BB9_364:
	and.b32  	%r813, %r28, 2147483647;
	setp.ne.s32	%p442, %r813, 2146435072;
	@%p442 bra 	BB9_365;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r814, %temp}, %fd241;
	}
	setp.ne.s32	%p443, %r814, 0;
	mov.f64 	%fd472, %fd471;
	@%p443 bra 	BB9_369;

	shr.s32 	%r815, %r9, 31;
	and.b32  	%r816, %r815, -2146435072;
	add.s32 	%r817, %r816, 2146435072;
	or.b32  	%r818, %r817, -2147483648;
	selp.b32	%r819, %r818, %r817, %p19;
	mov.u32 	%r820, 0;
	mov.b64 	%fd472, {%r820, %r819};
	bra.uni 	BB9_369;

BB9_360:
	mov.f64 	%fd472, %fd471;
	bra.uni 	BB9_369;

BB9_365:
	mov.f64 	%fd472, %fd471;
	bra.uni 	BB9_369;

BB9_368:
	setp.gt.f64	%p444, %fd242, 0d3FF0000000000000;
	selp.b32	%r821, 2146435072, 0, %p444;
	mov.u32 	%r822, 0;
	xor.b32  	%r823, %r821, 2146435072;
	setp.lt.s32	%p445, %r9, 0;
	selp.b32	%r824, %r823, %r821, %p445;
	setp.eq.f32	%p446, %f355, 0fBF800000;
	selp.b32	%r825, 1072693248, %r824, %p446;
	mov.b64 	%fd472, {%r822, %r825};

BB9_369:
	setp.eq.f32	%p447, %f355, 0f3F800000;
	selp.f64	%fd398, 0d3FF0000000000000, %fd472, %p447;
	add.f64 	%fd253, %fd240, %fd398;
	cvt.f64.f32	%fd254, %f356;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd254;
	}
	abs.f64 	%fd255, %fd254;
	// Callseq Start 19
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd255;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd474, [retval0+0];
	
	//{
	}// Callseq End 19
	setp.gt.s32	%p448, %r29, -1;
	setp.lt.s32	%p449, %r29, 0;
	and.pred  	%p20, %p449, %p409;
	or.pred  	%p452, %p448, %p408;
	@%p452 bra 	BB9_371;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r826}, %fd474;
	}
	xor.b32  	%r827, %r826, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r828, %temp}, %fd474;
	}
	mov.b64 	%fd474, {%r828, %r827};

BB9_371:
	setp.eq.f32	%p453, %f356, 0f00000000;
	@%p453 bra 	BB9_374;
	bra.uni 	BB9_372;

BB9_374:
	selp.b32	%r829, %r29, 0, %p409;
	mov.u32 	%r830, 0;
	or.b32  	%r831, %r829, 2146435072;
	setp.lt.s32	%p457, %r9, 0;
	selp.b32	%r832, %r831, %r829, %p457;
	mov.b64 	%fd474, {%r830, %r832};
	bra.uni 	BB9_375;

BB9_372:
	@%p448 bra 	BB9_375;

	cvt.rzi.f64.f64	%fd400, %fd292;
	setp.neu.f64	%p455, %fd400, 0d4000000000000000;
	selp.f64	%fd474, 0dFFF8000000000000, %fd474, %p455;

BB9_375:
	add.f64 	%fd475, %fd254, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r833}, %fd475;
	}
	and.b32  	%r834, %r833, 2146435072;
	setp.ne.s32	%p458, %r834, 2146435072;
	@%p458 bra 	BB9_376;

	setp.gtu.f64	%p459, %fd255, 0d7FF0000000000000;
	@%p459 bra 	BB9_385;

	and.b32  	%r835, %r9, 2147483647;
	setp.ne.s32	%p460, %r835, 2146435072;
	@%p460 bra 	BB9_380;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r836, %temp}, %fd292;
	}
	setp.eq.s32	%p461, %r836, 0;
	@%p461 bra 	BB9_384;

BB9_380:
	and.b32  	%r837, %r29, 2147483647;
	setp.ne.s32	%p462, %r837, 2146435072;
	@%p462 bra 	BB9_381;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r838, %temp}, %fd254;
	}
	setp.ne.s32	%p463, %r838, 0;
	mov.f64 	%fd475, %fd474;
	@%p463 bra 	BB9_385;

	shr.s32 	%r839, %r9, 31;
	and.b32  	%r840, %r839, -2146435072;
	add.s32 	%r841, %r840, 2146435072;
	or.b32  	%r842, %r841, -2147483648;
	selp.b32	%r843, %r842, %r841, %p20;
	mov.u32 	%r844, 0;
	mov.b64 	%fd475, {%r844, %r843};
	bra.uni 	BB9_385;

BB9_376:
	mov.f64 	%fd475, %fd474;
	bra.uni 	BB9_385;

BB9_381:
	mov.f64 	%fd475, %fd474;
	bra.uni 	BB9_385;

BB9_384:
	setp.gt.f64	%p464, %fd255, 0d3FF0000000000000;
	selp.b32	%r845, 2146435072, 0, %p464;
	mov.u32 	%r846, 0;
	xor.b32  	%r847, %r845, 2146435072;
	setp.lt.s32	%p465, %r9, 0;
	selp.b32	%r848, %r847, %r845, %p465;
	setp.eq.f32	%p466, %f356, 0fBF800000;
	selp.b32	%r849, 1072693248, %r848, %p466;
	mov.b64 	%fd475, {%r846, %r849};

BB9_385:
	setp.eq.f32	%p467, %f356, 0f3F800000;
	selp.f64	%fd402, 0d3FF0000000000000, %fd475, %p467;
	add.f64 	%fd403, %fd253, %fd402;
	sqrt.rn.f64 	%fd266, %fd403;
	cvt.f64.f32	%fd267, %f889;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd267;
	}
	abs.f64 	%fd268, %fd267;
	// Callseq Start 20
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd268;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd477, [retval0+0];
	
	//{
	}// Callseq End 20
	setp.gt.s32	%p468, %r30, -1;
	setp.lt.s32	%p469, %r30, 0;
	and.pred  	%p21, %p469, %p409;
	or.pred  	%p472, %p468, %p408;
	@%p472 bra 	BB9_387;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r850}, %fd477;
	}
	xor.b32  	%r851, %r850, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r852, %temp}, %fd477;
	}
	mov.b64 	%fd477, {%r852, %r851};

BB9_387:
	setp.eq.f32	%p473, %f889, 0f00000000;
	@%p473 bra 	BB9_390;
	bra.uni 	BB9_388;

BB9_390:
	selp.b32	%r853, %r30, 0, %p409;
	mov.u32 	%r854, 0;
	or.b32  	%r855, %r853, 2146435072;
	setp.lt.s32	%p477, %r9, 0;
	selp.b32	%r856, %r855, %r853, %p477;
	mov.b64 	%fd477, {%r854, %r856};
	bra.uni 	BB9_391;

BB9_388:
	@%p468 bra 	BB9_391;

	cvt.rzi.f64.f64	%fd405, %fd292;
	setp.neu.f64	%p475, %fd405, 0d4000000000000000;
	selp.f64	%fd477, 0dFFF8000000000000, %fd477, %p475;

BB9_391:
	add.f64 	%fd478, %fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r857}, %fd478;
	}
	and.b32  	%r858, %r857, 2146435072;
	setp.ne.s32	%p478, %r858, 2146435072;
	@%p478 bra 	BB9_392;

	setp.gtu.f64	%p479, %fd268, 0d7FF0000000000000;
	@%p479 bra 	BB9_401;

	and.b32  	%r859, %r9, 2147483647;
	setp.ne.s32	%p480, %r859, 2146435072;
	@%p480 bra 	BB9_396;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r860, %temp}, %fd292;
	}
	setp.eq.s32	%p481, %r860, 0;
	@%p481 bra 	BB9_400;

BB9_396:
	and.b32  	%r861, %r30, 2147483647;
	setp.ne.s32	%p482, %r861, 2146435072;
	@%p482 bra 	BB9_397;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r862, %temp}, %fd267;
	}
	setp.ne.s32	%p483, %r862, 0;
	mov.f64 	%fd478, %fd477;
	@%p483 bra 	BB9_401;

	shr.s32 	%r863, %r9, 31;
	and.b32  	%r864, %r863, -2146435072;
	add.s32 	%r865, %r864, 2146435072;
	or.b32  	%r866, %r865, -2147483648;
	selp.b32	%r867, %r866, %r865, %p21;
	mov.u32 	%r868, 0;
	mov.b64 	%fd478, {%r868, %r867};
	bra.uni 	BB9_401;

BB9_392:
	mov.f64 	%fd478, %fd477;
	bra.uni 	BB9_401;

BB9_397:
	mov.f64 	%fd478, %fd477;
	bra.uni 	BB9_401;

BB9_400:
	setp.gt.f64	%p484, %fd268, 0d3FF0000000000000;
	selp.b32	%r869, 2146435072, 0, %p484;
	mov.u32 	%r870, 0;
	xor.b32  	%r871, %r869, 2146435072;
	setp.lt.s32	%p485, %r9, 0;
	selp.b32	%r872, %r871, %r869, %p485;
	setp.eq.f32	%p486, %f889, 0fBF800000;
	selp.b32	%r873, 1072693248, %r872, %p486;
	mov.b64 	%fd478, {%r870, %r873};

BB9_401:
	setp.eq.f32	%p487, %f889, 0f3F800000;
	selp.f64	%fd279, 0d3FF0000000000000, %fd478, %p487;
	cvt.f64.f32	%fd280, %f891;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd280;
	}
	abs.f64 	%fd281, %fd280;
	// Callseq Start 21
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd281;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd480, [retval0+0];
	
	//{
	}// Callseq End 21
	setp.gt.s32	%p488, %r31, -1;
	setp.lt.s32	%p489, %r31, 0;
	and.pred  	%p22, %p489, %p409;
	or.pred  	%p492, %p488, %p408;
	@%p492 bra 	BB9_403;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r874}, %fd480;
	}
	xor.b32  	%r875, %r874, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r876, %temp}, %fd480;
	}
	mov.b64 	%fd480, {%r876, %r875};

BB9_403:
	setp.eq.f32	%p493, %f891, 0f00000000;
	@%p493 bra 	BB9_406;
	bra.uni 	BB9_404;

BB9_406:
	selp.b32	%r877, %r31, 0, %p409;
	mov.u32 	%r878, 0;
	or.b32  	%r879, %r877, 2146435072;
	setp.lt.s32	%p497, %r9, 0;
	selp.b32	%r880, %r879, %r877, %p497;
	mov.b64 	%fd480, {%r878, %r880};
	bra.uni 	BB9_407;

BB9_404:
	@%p488 bra 	BB9_407;

	cvt.rzi.f64.f64	%fd408, %fd292;
	setp.neu.f64	%p495, %fd408, 0d4000000000000000;
	selp.f64	%fd480, 0dFFF8000000000000, %fd480, %p495;

BB9_407:
	add.f64 	%fd481, %fd280, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r881}, %fd481;
	}
	and.b32  	%r882, %r881, 2146435072;
	setp.ne.s32	%p498, %r882, 2146435072;
	@%p498 bra 	BB9_408;

	setp.gtu.f64	%p499, %fd281, 0d7FF0000000000000;
	@%p499 bra 	BB9_417;

	and.b32  	%r883, %r9, 2147483647;
	setp.ne.s32	%p500, %r883, 2146435072;
	@%p500 bra 	BB9_412;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r884, %temp}, %fd292;
	}
	setp.eq.s32	%p501, %r884, 0;
	@%p501 bra 	BB9_416;

BB9_412:
	and.b32  	%r885, %r31, 2147483647;
	setp.ne.s32	%p502, %r885, 2146435072;
	@%p502 bra 	BB9_413;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r886, %temp}, %fd280;
	}
	setp.ne.s32	%p503, %r886, 0;
	mov.f64 	%fd481, %fd480;
	@%p503 bra 	BB9_417;

	shr.s32 	%r887, %r9, 31;
	and.b32  	%r888, %r887, -2146435072;
	add.s32 	%r889, %r888, 2146435072;
	or.b32  	%r890, %r889, -2147483648;
	selp.b32	%r891, %r890, %r889, %p22;
	mov.u32 	%r892, 0;
	mov.b64 	%fd481, {%r892, %r891};
	bra.uni 	BB9_417;

BB9_408:
	mov.f64 	%fd481, %fd480;
	bra.uni 	BB9_417;

BB9_413:
	mov.f64 	%fd481, %fd480;
	bra.uni 	BB9_417;

BB9_416:
	setp.gt.f64	%p504, %fd281, 0d3FF0000000000000;
	selp.b32	%r893, 2146435072, 0, %p504;
	mov.u32 	%r894, 0;
	xor.b32  	%r895, %r893, 2146435072;
	setp.lt.s32	%p505, %r9, 0;
	selp.b32	%r896, %r895, %r893, %p505;
	setp.eq.f32	%p506, %f891, 0fBF800000;
	selp.b32	%r897, 1072693248, %r896, %p506;
	mov.b64 	%fd481, {%r894, %r897};

BB9_417:
	setp.eq.f32	%p507, %f891, 0f3F800000;
	selp.f64	%fd410, 0d3FF0000000000000, %fd481, %p507;
	add.f64 	%fd411, %fd279, %fd410;
	sqrt.rn.f64 	%fd412, %fd411;
	cvt.rn.f32.f64	%f896, %fd412;
	cvt.rn.f32.f64	%f897, %fd266;
	setp.gtu.f32	%p508, %f897, %f896;
	setp.eq.s16	%p509, %rs17, 0;
	or.pred  	%p510, %p509, %p508;
	setp.ltu.f32	%p511, %f1017, %f802;
	or.pred  	%p512, %p510, %p511;
	setp.geu.f32	%p513, %f1017, %f803;
	or.pred  	%p514, %p513, %p512;
	@%p514 bra 	BB9_419;

	mov.u32 	%r899, 254;
	// inline asm
	call (%r898), _optix_report_intersection_0, (%f1017, %r899);
	// inline asm

BB9_419:
	ret;
}

	// .globl	__closesthit__asphsurf
.visible .entry __closesthit__asphsurf(

)
{
	.reg .pred 	%p<135>;
	.reg .b16 	%rs<21>;
	.reg .f32 	%f<1994>;
	.reg .b32 	%r<738>;
	.reg .f64 	%fd<89>;
	.reg .b64 	%rd<667>;


	// inline asm
	call (%r26), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r27), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r29), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r30), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r31), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r32, %r31, %r27, %r30;
	mad.lo.s32 	%r1, %r32, %r26, %r29;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p4, %rd1, 0;
	@%p4 bra 	BB10_2;

	cvta.to.global.u64 	%rd49, %rd1;
	cvt.u64.u32	%rd50, %r1;
	add.s64 	%rd51, %rd49, %rd50;
	mov.u16 	%rs2, 1;
	st.global.u8 	[%rd51], %rs2;
	bra.uni 	BB10_178;

BB10_2:
	// inline asm
	call (%rd52), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd3, [%rd52+8];
	// inline asm
	call (%f686), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f687), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f1779), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r33), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p5, %r33, 0;
	@%p5 bra 	BB10_3;

	mov.u32 	%r734, 0;
	// inline asm
	call (%f689), _optix_get_ray_time, ();
	// inline asm

BB10_5:
	.pragma "nounroll";
	// inline asm
	call (%rd53), _optix_get_transform_list_handle, (%r734);
	// inline asm
	// inline asm
	call (%r36), _optix_get_transform_type_from_handle, (%rd53);
	// inline asm
	and.b32  	%r37, %r36, -2;
	setp.eq.s32	%p6, %r37, 2;
	@%p6 bra 	BB10_11;
	bra.uni 	BB10_6;

BB10_11:
	setp.eq.s32	%p9, %r36, 2;
	@%p9 bra 	BB10_15;
	bra.uni 	BB10_12;

BB10_15:
	// inline asm
	call (%rd127), _optix_get_matrix_motion_transform_from_handle, (%rd53);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd129, %rd127;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r125,%r126,%r127,%r128}, [%rd129];
	// inline asm
	mov.b32	{%rs5, %rs6}, %r127;
	add.s64 	%rd133, %rd127, 16;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r129,%r130,%r131,%r132}, [%rd132];
	// inline asm
	add.s64 	%rd136, %rd127, 32;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r133,%r134,%r135,%r136}, [%rd135];
	// inline asm
	add.s64 	%rd139, %rd127, 48;
	// inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r137,%r138,%r139,%r140}, [%rd138];
	// inline asm
	add.s64 	%rd142, %rd127, 64;
	// inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r141,%r142,%r143,%r144}, [%rd141];
	// inline asm
	add.s64 	%rd145, %rd127, 80;
	// inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r145,%r146,%r147,%r148}, [%rd144];
	// inline asm
	add.s64 	%rd148, %rd127, 96;
	// inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd147];
	// inline asm
	add.s64 	%rd151, %rd127, 112;
	// inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd150];
	// inline asm
	mov.b32 	 %f816, %r128;
	mov.b32 	 %f817, %r129;
	cvt.u32.u16	%r169, %rs5;
	add.s32 	%r170, %r169, -1;
	cvt.rn.f32.s32	%f818, %r170;
	sub.f32 	%f819, %f689, %f816;
	mul.f32 	%f820, %f819, %f818;
	sub.f32 	%f821, %f817, %f816;
	div.rn.f32 	%f822, %f820, %f821;
	min.f32 	%f823, %f818, %f822;
	mov.f32 	%f824, 0f00000000;
	max.f32 	%f825, %f824, %f823;
	cvt.rmi.f32.f32	%f826, %f825;
	cvt.rzi.s32.f32	%r171, %f826;
	mul.wide.s32 	%rd162, %r171, 48;
	add.s64 	%rd154, %rd136, %rd162;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd153];
	// inline asm
	mov.b32 	 %f1746, %r157;
	mov.b32 	 %f1745, %r158;
	mov.b32 	 %f1744, %r159;
	mov.b32 	 %f1743, %r160;
	add.s64 	%rd157, %rd154, 16;
	// inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd156];
	// inline asm
	mov.b32 	 %f1750, %r161;
	mov.b32 	 %f1749, %r162;
	mov.b32 	 %f1748, %r163;
	mov.b32 	 %f1747, %r164;
	add.s64 	%rd160, %rd154, 32;
	// inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd159];
	// inline asm
	sub.f32 	%f98, %f825, %f826;
	mov.b32 	 %f1754, %r165;
	mov.b32 	 %f1753, %r166;
	mov.b32 	 %f1752, %r167;
	mov.b32 	 %f1751, %r168;
	setp.leu.f32	%p11, %f98, 0f00000000;
	@%p11 bra 	BB10_17;

	cvt.rmi.f32.f32	%f1714, %f825;
	cvt.rzi.s32.f32	%r733, %f1714;
	cvt.s64.s32	%rd662, %r733;
	mul.lo.s64 	%rd172, %rd662, 48;
	add.s64 	%rd173, %rd127, %rd172;
	add.s64 	%rd164, %rd173, 80;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r172,%r173,%r174,%r175}, [%rd163];
	// inline asm
	mov.b32 	 %f827, %r172;
	mov.b32 	 %f828, %r173;
	mov.b32 	 %f829, %r174;
	mov.b32 	 %f830, %r175;
	add.s64 	%rd167, %rd173, 96;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r176,%r177,%r178,%r179}, [%rd166];
	// inline asm
	mov.b32 	 %f831, %r176;
	mov.b32 	 %f832, %r177;
	mov.b32 	 %f833, %r178;
	mov.b32 	 %f834, %r179;
	add.s64 	%rd170, %rd173, 112;
	// inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r180,%r181,%r182,%r183}, [%rd169];
	// inline asm
	mov.f32 	%f835, 0f3F800000;
	sub.f32 	%f836, %f835, %f98;
	mul.f32 	%f837, %f98, %f827;
	mul.f32 	%f838, %f98, %f828;
	mul.f32 	%f839, %f98, %f829;
	mul.f32 	%f840, %f98, %f830;
	fma.rn.f32 	%f1746, %f836, %f1746, %f837;
	fma.rn.f32 	%f1745, %f836, %f1745, %f838;
	fma.rn.f32 	%f1744, %f836, %f1744, %f839;
	fma.rn.f32 	%f1743, %f836, %f1743, %f840;
	mul.f32 	%f841, %f98, %f831;
	mul.f32 	%f842, %f98, %f832;
	mul.f32 	%f843, %f98, %f833;
	mul.f32 	%f844, %f98, %f834;
	fma.rn.f32 	%f1750, %f836, %f1750, %f841;
	fma.rn.f32 	%f1749, %f836, %f1749, %f842;
	fma.rn.f32 	%f1748, %f836, %f1748, %f843;
	fma.rn.f32 	%f1747, %f836, %f1747, %f844;
	mov.b32 	 %f845, %r180;
	mov.b32 	 %f846, %r181;
	mov.b32 	 %f847, %r182;
	mov.b32 	 %f848, %r183;
	mul.f32 	%f849, %f98, %f845;
	mul.f32 	%f850, %f98, %f846;
	mul.f32 	%f851, %f98, %f847;
	mul.f32 	%f852, %f98, %f848;
	fma.rn.f32 	%f1754, %f836, %f1754, %f849;
	fma.rn.f32 	%f1753, %f836, %f1753, %f850;
	fma.rn.f32 	%f1752, %f836, %f1752, %f851;
	fma.rn.f32 	%f1751, %f836, %f1751, %f852;
	bra.uni 	BB10_17;

BB10_6:
	mov.f32 	%f1755, 0f00000000;
	mov.f32 	%f1758, 0f3F800000;
	setp.eq.s32	%p7, %r36, 4;
	@%p7 bra 	BB10_9;
	bra.uni 	BB10_7;

BB10_9:
	// inline asm
	call (%rd663), _optix_get_instance_inverse_transform_from_handle, (%rd53);
	// inline asm
	bra.uni 	BB10_10;

BB10_12:
	// inline asm
	call (%rd68), _optix_get_srt_motion_transform_from_handle, (%rd53);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd70, %rd68;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r50,%r51,%r52,%r53}, [%rd70];
	// inline asm
	mov.b32	{%rs3, %rs4}, %r52;
	add.s64 	%rd74, %rd68, 16;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r54,%r55,%r56,%r57}, [%rd73];
	// inline asm
	add.s64 	%rd77, %rd68, 32;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r58,%r59,%r60,%r61}, [%rd76];
	// inline asm
	add.s64 	%rd80, %rd68, 48;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r62,%r63,%r64,%r65}, [%rd79];
	// inline asm
	add.s64 	%rd83, %rd68, 64;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r66,%r67,%r68,%r69}, [%rd82];
	// inline asm
	add.s64 	%rd86, %rd68, 80;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r70,%r71,%r72,%r73}, [%rd85];
	// inline asm
	add.s64 	%rd89, %rd68, 96;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r74,%r75,%r76,%r77}, [%rd88];
	// inline asm
	add.s64 	%rd92, %rd68, 112;
	// inline asm
	cvta.to.global.u64 %rd91, %rd92;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r78,%r79,%r80,%r81}, [%rd91];
	// inline asm
	add.s64 	%rd95, %rd68, 128;
	// inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r82,%r83,%r84,%r85}, [%rd94];
	// inline asm
	add.s64 	%rd98, %rd68, 144;
	// inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd97];
	// inline asm
	mov.b32 	 %f703, %r53;
	mov.b32 	 %f704, %r54;
	cvt.u32.u16	%r106, %rs3;
	add.s32 	%r107, %r106, -1;
	cvt.rn.f32.s32	%f705, %r107;
	sub.f32 	%f706, %f689, %f703;
	mul.f32 	%f707, %f706, %f705;
	sub.f32 	%f708, %f704, %f703;
	div.rn.f32 	%f709, %f707, %f708;
	min.f32 	%f710, %f705, %f709;
	mov.f32 	%f711, 0f00000000;
	max.f32 	%f712, %f711, %f710;
	cvt.rmi.f32.f32	%f713, %f712;
	cvt.rzi.s32.f32	%r108, %f713;
	mul.wide.s32 	%rd112, %r108, 64;
	add.s64 	%rd101, %rd77, %rd112;
	// inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd100];
	// inline asm
	mov.b32 	 %f1727, %r90;
	mov.b32 	 %f1728, %r91;
	mov.b32 	 %f1729, %r92;
	mov.b32 	 %f1730, %r93;
	add.s64 	%rd104, %rd101, 16;
	// inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd103];
	// inline asm
	mov.b32 	 %f1731, %r94;
	mov.b32 	 %f1732, %r95;
	mov.b32 	 %f1733, %r96;
	mov.b32 	 %f1734, %r97;
	add.s64 	%rd107, %rd101, 32;
	// inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd106];
	// inline asm
	sub.f32 	%f37, %f712, %f713;
	mov.b32 	 %f1735, %r98;
	mov.b32 	 %f1736, %r99;
	mov.b32 	 %f1737, %r100;
	mov.b32 	 %f1738, %r101;
	add.s64 	%rd110, %rd101, 48;
	// inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd109];
	// inline asm
	mov.b32 	 %f1739, %r102;
	mov.b32 	 %f1740, %r103;
	mov.b32 	 %f1741, %r104;
	mov.b32 	 %f1742, %r105;
	setp.leu.f32	%p10, %f37, 0f00000000;
	@%p10 bra 	BB10_14;

	cvt.rmi.f32.f32	%f1713, %f712;
	cvt.rzi.s32.f32	%r732, %f1713;
	cvt.s64.s32	%rd661, %r732;
	shl.b64 	%rd125, %rd661, 6;
	add.s64 	%rd126, %rd125, %rd68;
	add.s64 	%rd114, %rd126, 96;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r109,%r110,%r111,%r112}, [%rd113];
	// inline asm
	mov.b32 	 %f714, %r109;
	mov.b32 	 %f715, %r110;
	mov.b32 	 %f716, %r111;
	mov.b32 	 %f717, %r112;
	add.s64 	%rd117, %rd126, 112;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r113,%r114,%r115,%r116}, [%rd116];
	// inline asm
	mov.b32 	 %f718, %r113;
	mov.b32 	 %f719, %r114;
	mov.b32 	 %f720, %r115;
	mov.b32 	 %f721, %r116;
	add.s64 	%rd120, %rd126, 128;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r117,%r118,%r119,%r120}, [%rd119];
	// inline asm
	mov.b32 	 %f722, %r117;
	mov.b32 	 %f723, %r118;
	mov.b32 	 %f724, %r119;
	mov.b32 	 %f725, %r120;
	add.s64 	%rd123, %rd126, 144;
	// inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r121,%r122,%r123,%r124}, [%rd122];
	// inline asm
	mov.f32 	%f726, 0f3F800000;
	sub.f32 	%f727, %f726, %f37;
	mul.f32 	%f728, %f37, %f714;
	mul.f32 	%f729, %f37, %f715;
	mul.f32 	%f730, %f37, %f716;
	mul.f32 	%f731, %f37, %f717;
	fma.rn.f32 	%f1727, %f727, %f1727, %f728;
	fma.rn.f32 	%f1728, %f727, %f1728, %f729;
	fma.rn.f32 	%f1729, %f727, %f1729, %f730;
	fma.rn.f32 	%f1730, %f727, %f1730, %f731;
	mul.f32 	%f732, %f37, %f718;
	mul.f32 	%f733, %f37, %f719;
	mul.f32 	%f734, %f37, %f720;
	mul.f32 	%f735, %f37, %f721;
	fma.rn.f32 	%f1731, %f727, %f1731, %f732;
	fma.rn.f32 	%f1732, %f727, %f1732, %f733;
	fma.rn.f32 	%f1733, %f727, %f1733, %f734;
	fma.rn.f32 	%f1734, %f727, %f1734, %f735;
	mul.f32 	%f736, %f37, %f722;
	mul.f32 	%f737, %f37, %f723;
	mul.f32 	%f738, %f37, %f724;
	mul.f32 	%f739, %f37, %f725;
	fma.rn.f32 	%f1735, %f727, %f1735, %f736;
	fma.rn.f32 	%f740, %f727, %f1736, %f737;
	fma.rn.f32 	%f741, %f727, %f1737, %f738;
	fma.rn.f32 	%f742, %f727, %f1738, %f739;
	mov.b32 	 %f743, %r121;
	mov.b32 	 %f744, %r122;
	mov.b32 	 %f745, %r123;
	mov.b32 	 %f746, %r124;
	mul.f32 	%f747, %f37, %f743;
	mul.f32 	%f748, %f37, %f744;
	mul.f32 	%f749, %f37, %f745;
	mul.f32 	%f750, %f37, %f746;
	fma.rn.f32 	%f751, %f727, %f1739, %f747;
	fma.rn.f32 	%f1740, %f727, %f1740, %f748;
	fma.rn.f32 	%f1741, %f727, %f1741, %f749;
	fma.rn.f32 	%f1742, %f727, %f1742, %f750;
	mul.f32 	%f752, %f741, %f741;
	fma.rn.f32 	%f753, %f740, %f740, %f752;
	fma.rn.f32 	%f754, %f742, %f742, %f753;
	fma.rn.f32 	%f755, %f751, %f751, %f754;
	sqrt.rn.f32 	%f756, %f755;
	rcp.rn.f32 	%f757, %f756;
	mul.f32 	%f1736, %f740, %f757;
	mul.f32 	%f1737, %f741, %f757;
	mul.f32 	%f1738, %f742, %f757;
	mul.f32 	%f1739, %f751, %f757;

BB10_14:
	mul.f32 	%f758, %f1737, %f1737;
	fma.rn.f32 	%f759, %f1736, %f1736, %f758;
	fma.rn.f32 	%f760, %f1738, %f1738, %f759;
	fma.rn.f32 	%f761, %f1739, %f1739, %f760;
	rcp.rn.f32 	%f762, %f761;
	mul.f32 	%f763, %f1736, %f762;
	mul.f32 	%f764, %f1737, %f762;
	mul.f32 	%f765, %f1738, %f762;
	mul.f32 	%f766, %f1739, %f762;
	mul.f32 	%f767, %f1736, %f763;
	mul.f32 	%f768, %f1737, %f764;
	mul.f32 	%f769, %f1738, %f765;
	mul.f32 	%f770, %f1736, %f764;
	mul.f32 	%f771, %f1738, %f766;
	mul.f32 	%f772, %f1736, %f765;
	mul.f32 	%f773, %f1737, %f766;
	mul.f32 	%f774, %f1737, %f765;
	mul.f32 	%f775, %f1736, %f766;
	sub.f32 	%f776, %f767, %f768;
	sub.f32 	%f777, %f776, %f769;
	fma.rn.f32 	%f778, %f1739, %f766, %f777;
	sub.f32 	%f779, %f770, %f771;
	add.f32 	%f780, %f779, %f779;
	add.f32 	%f781, %f772, %f773;
	add.f32 	%f782, %f781, %f781;
	add.f32 	%f783, %f770, %f771;
	add.f32 	%f784, %f783, %f783;
	sub.f32 	%f785, %f768, %f767;
	sub.f32 	%f786, %f785, %f769;
	fma.rn.f32 	%f787, %f1739, %f766, %f786;
	sub.f32 	%f788, %f774, %f775;
	add.f32 	%f789, %f788, %f788;
	sub.f32 	%f790, %f772, %f773;
	add.f32 	%f791, %f790, %f790;
	add.f32 	%f792, %f774, %f775;
	add.f32 	%f793, %f792, %f792;
	neg.f32 	%f794, %f767;
	sub.f32 	%f795, %f794, %f768;
	add.f32 	%f796, %f769, %f795;
	fma.rn.f32 	%f797, %f1739, %f766, %f796;
	mul.f32 	%f798, %f1730, %f778;
	fma.rn.f32 	%f799, %f1733, %f780, %f798;
	fma.rn.f32 	%f800, %f1735, %f782, %f799;
	sub.f32 	%f1743, %f1740, %f800;
	mul.f32 	%f801, %f1733, %f787;
	fma.rn.f32 	%f802, %f1730, %f784, %f801;
	fma.rn.f32 	%f803, %f1735, %f789, %f802;
	sub.f32 	%f1747, %f1741, %f803;
	mul.f32 	%f804, %f1733, %f793;
	fma.rn.f32 	%f805, %f1730, %f791, %f804;
	fma.rn.f32 	%f806, %f1735, %f797, %f805;
	sub.f32 	%f1751, %f1742, %f806;
	mul.f32 	%f807, %f1729, %f778;
	fma.rn.f32 	%f808, %f1732, %f780, %f807;
	fma.rn.f32 	%f1744, %f1734, %f782, %f808;
	mul.f32 	%f809, %f1732, %f787;
	fma.rn.f32 	%f810, %f1729, %f784, %f809;
	fma.rn.f32 	%f1748, %f1734, %f789, %f810;
	mul.f32 	%f811, %f1732, %f793;
	fma.rn.f32 	%f812, %f1729, %f791, %f811;
	fma.rn.f32 	%f1752, %f1734, %f797, %f812;
	mul.f32 	%f813, %f1728, %f778;
	fma.rn.f32 	%f1745, %f1731, %f780, %f813;
	mul.f32 	%f814, %f1731, %f787;
	fma.rn.f32 	%f1749, %f1728, %f784, %f814;
	mul.f32 	%f815, %f1731, %f793;
	fma.rn.f32 	%f1753, %f1728, %f791, %f815;
	mul.f32 	%f1746, %f1727, %f778;
	mul.f32 	%f1750, %f1727, %f784;
	mul.f32 	%f1754, %f1727, %f791;

BB10_17:
	mul.f32 	%f853, %f1748, %f1753;
	mul.f32 	%f854, %f1749, %f1752;
	sub.f32 	%f855, %f854, %f853;
	mul.f32 	%f856, %f1746, %f855;
	mul.f32 	%f857, %f1748, %f1754;
	mul.f32 	%f858, %f1750, %f1752;
	sub.f32 	%f859, %f858, %f857;
	mul.f32 	%f860, %f1745, %f859;
	sub.f32 	%f861, %f856, %f860;
	mul.f32 	%f862, %f1749, %f1754;
	mul.f32 	%f863, %f1750, %f1753;
	sub.f32 	%f864, %f863, %f862;
	fma.rn.f32 	%f865, %f1744, %f864, %f861;
	rcp.rn.f32 	%f866, %f865;
	mul.f32 	%f1758, %f866, %f855;
	mul.f32 	%f867, %f1745, %f1752;
	mul.f32 	%f868, %f1744, %f1753;
	sub.f32 	%f869, %f868, %f867;
	mul.f32 	%f1757, %f866, %f869;
	mul.f32 	%f870, %f1744, %f1749;
	mul.f32 	%f871, %f1745, %f1748;
	sub.f32 	%f872, %f871, %f870;
	mul.f32 	%f1756, %f872, %f866;
	sub.f32 	%f873, %f857, %f858;
	mul.f32 	%f1762, %f866, %f873;
	mul.f32 	%f874, %f1744, %f1754;
	mul.f32 	%f875, %f1746, %f1752;
	sub.f32 	%f876, %f875, %f874;
	mul.f32 	%f1761, %f866, %f876;
	mul.f32 	%f877, %f1746, %f1748;
	mul.f32 	%f878, %f1744, %f1750;
	sub.f32 	%f879, %f878, %f877;
	mul.f32 	%f1760, %f879, %f866;
	mul.f32 	%f1766, %f866, %f864;
	mul.f32 	%f880, %f1746, %f1753;
	mul.f32 	%f881, %f1745, %f1754;
	sub.f32 	%f882, %f881, %f880;
	mul.f32 	%f1765, %f866, %f882;
	mul.f32 	%f883, %f1745, %f1750;
	mul.f32 	%f884, %f1746, %f1749;
	sub.f32 	%f885, %f884, %f883;
	mul.f32 	%f1764, %f885, %f866;
	mul.f32 	%f886, %f1743, %f1758;
	neg.f32 	%f887, %f886;
	mul.f32 	%f888, %f1747, %f1757;
	sub.f32 	%f889, %f887, %f888;
	mul.f32 	%f890, %f1751, %f1756;
	sub.f32 	%f1755, %f889, %f890;
	mul.f32 	%f891, %f1743, %f1762;
	neg.f32 	%f892, %f891;
	mul.f32 	%f893, %f1747, %f1761;
	sub.f32 	%f894, %f892, %f893;
	mul.f32 	%f895, %f1751, %f1760;
	sub.f32 	%f1759, %f894, %f895;
	mul.f32 	%f896, %f1743, %f1766;
	neg.f32 	%f897, %f896;
	mul.f32 	%f898, %f1747, %f1765;
	sub.f32 	%f899, %f897, %f898;
	mul.f32 	%f900, %f1751, %f1764;
	sub.f32 	%f1763, %f899, %f900;
	bra.uni 	BB10_18;

BB10_7:
	setp.ne.s32	%p8, %r36, 1;
	mov.f32 	%f1756, %f1755;
	mov.f32 	%f1757, %f1755;
	mov.f32 	%f1759, %f1755;
	mov.f32 	%f1760, %f1755;
	mov.f32 	%f1761, %f1758;
	mov.f32 	%f1762, %f1755;
	mov.f32 	%f1763, %f1755;
	mov.f32 	%f1764, %f1758;
	mov.f32 	%f1765, %f1755;
	mov.f32 	%f1766, %f1755;
	@%p8 bra 	BB10_18;

	// inline asm
	call (%rd55), _optix_get_static_transform_from_handle, (%rd53);
	// inline asm
	add.s64 	%rd663, %rd55, 64;

BB10_10:
	// inline asm
	cvta.to.global.u64 %rd59, %rd663;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r38,%r39,%r40,%r41}, [%rd59];
	// inline asm
	mov.b32 	 %f1758, %r38;
	mov.b32 	 %f1757, %r39;
	mov.b32 	 %f1756, %r40;
	mov.b32 	 %f1755, %r41;
	add.s64 	%rd63, %rd663, 16;
	// inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r42,%r43,%r44,%r45}, [%rd62];
	// inline asm
	mov.b32 	 %f1762, %r42;
	mov.b32 	 %f1761, %r43;
	mov.b32 	 %f1760, %r44;
	mov.b32 	 %f1759, %r45;
	add.s64 	%rd66, %rd663, 32;
	// inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r46,%r47,%r48,%r49}, [%rd65];
	// inline asm
	mov.b32 	 %f1766, %r46;
	mov.b32 	 %f1765, %r47;
	mov.b32 	 %f1764, %r48;
	mov.b32 	 %f1763, %r49;

BB10_18:
	setp.eq.s32	%p12, %r734, 0;
	@%p12 bra 	BB10_19;
	bra.uni 	BB10_20;

BB10_19:
	mov.f32 	%f1726, %f1755;
	mov.f32 	%f1725, %f1756;
	mov.f32 	%f1724, %f1757;
	mov.f32 	%f1723, %f1758;
	mov.f32 	%f1722, %f1759;
	mov.f32 	%f1721, %f1760;
	mov.f32 	%f1720, %f1761;
	mov.f32 	%f1719, %f1762;
	mov.f32 	%f1718, %f1763;
	mov.f32 	%f1717, %f1764;
	mov.f32 	%f1716, %f1765;
	mov.f32 	%f1715, %f1766;
	bra.uni 	BB10_21;

BB10_20:
	mul.f32 	%f901, %f1723, %f1758;
	fma.rn.f32 	%f902, %f1719, %f1757, %f901;
	fma.rn.f32 	%f151, %f1715, %f1756, %f902;
	mul.f32 	%f903, %f1724, %f1758;
	fma.rn.f32 	%f904, %f1720, %f1757, %f903;
	fma.rn.f32 	%f152, %f1716, %f1756, %f904;
	mul.f32 	%f905, %f1725, %f1758;
	fma.rn.f32 	%f906, %f1721, %f1757, %f905;
	fma.rn.f32 	%f153, %f1717, %f1756, %f906;
	mul.f32 	%f907, %f1726, %f1758;
	fma.rn.f32 	%f908, %f1722, %f1757, %f907;
	fma.rn.f32 	%f909, %f1718, %f1756, %f908;
	add.f32 	%f154, %f1755, %f909;
	mul.f32 	%f910, %f1723, %f1762;
	fma.rn.f32 	%f911, %f1719, %f1761, %f910;
	fma.rn.f32 	%f155, %f1715, %f1760, %f911;
	mul.f32 	%f912, %f1724, %f1762;
	fma.rn.f32 	%f913, %f1720, %f1761, %f912;
	fma.rn.f32 	%f156, %f1716, %f1760, %f913;
	mul.f32 	%f914, %f1725, %f1762;
	fma.rn.f32 	%f915, %f1721, %f1761, %f914;
	fma.rn.f32 	%f157, %f1717, %f1760, %f915;
	mul.f32 	%f916, %f1726, %f1762;
	fma.rn.f32 	%f917, %f1722, %f1761, %f916;
	fma.rn.f32 	%f918, %f1718, %f1760, %f917;
	add.f32 	%f158, %f1759, %f918;
	mul.f32 	%f919, %f1723, %f1766;
	fma.rn.f32 	%f920, %f1719, %f1765, %f919;
	fma.rn.f32 	%f1715, %f1715, %f1764, %f920;
	mul.f32 	%f921, %f1724, %f1766;
	fma.rn.f32 	%f922, %f1720, %f1765, %f921;
	fma.rn.f32 	%f1716, %f1716, %f1764, %f922;
	mul.f32 	%f923, %f1725, %f1766;
	fma.rn.f32 	%f924, %f1721, %f1765, %f923;
	fma.rn.f32 	%f1717, %f1717, %f1764, %f924;
	mul.f32 	%f925, %f1726, %f1766;
	fma.rn.f32 	%f926, %f1722, %f1765, %f925;
	fma.rn.f32 	%f927, %f1718, %f1764, %f926;
	add.f32 	%f1718, %f1763, %f927;
	mov.f32 	%f1726, %f154;
	mov.f32 	%f1725, %f153;
	mov.f32 	%f1724, %f152;
	mov.f32 	%f1723, %f151;
	mov.f32 	%f1722, %f158;
	mov.f32 	%f1721, %f157;
	mov.f32 	%f1720, %f156;
	mov.f32 	%f1719, %f155;

BB10_21:
	add.s32 	%r734, %r734, 1;
	setp.lt.u32	%p13, %r734, %r33;
	@%p13 bra 	BB10_5;

	mul.f32 	%f928, %f686, %f1723;
	fma.rn.f32 	%f929, %f687, %f1724, %f928;
	fma.rn.f32 	%f930, %f1779, %f1725, %f929;
	add.f32 	%f1781, %f1726, %f930;
	mul.f32 	%f931, %f686, %f1719;
	fma.rn.f32 	%f932, %f687, %f1720, %f931;
	fma.rn.f32 	%f933, %f1779, %f1721, %f932;
	add.f32 	%f1780, %f1722, %f933;
	mul.f32 	%f934, %f686, %f1715;
	fma.rn.f32 	%f935, %f687, %f1716, %f934;
	fma.rn.f32 	%f936, %f1779, %f1717, %f935;
	add.f32 	%f1779, %f1718, %f936;
	bra.uni 	BB10_23;

BB10_3:
	mov.f32 	%f1780, %f687;
	mov.f32 	%f1781, %f686;

BB10_23:
	// inline asm
	call (%f937), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f938), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1830), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f940), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r735, 0;
	@%p5 bra 	BB10_24;

BB10_25:
	.pragma "nounroll";
	// inline asm
	call (%rd174), _optix_get_transform_list_handle, (%r735);
	// inline asm
	// inline asm
	call (%r186), _optix_get_transform_type_from_handle, (%rd174);
	// inline asm
	and.b32  	%r187, %r186, -2;
	setp.eq.s32	%p15, %r187, 2;
	@%p15 bra 	BB10_31;
	bra.uni 	BB10_26;

BB10_31:
	setp.eq.s32	%p18, %r186, 2;
	@%p18 bra 	BB10_35;
	bra.uni 	BB10_32;

BB10_35:
	// inline asm
	call (%rd248), _optix_get_matrix_motion_transform_from_handle, (%rd174);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd250, %rd248;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r275,%r276,%r277,%r278}, [%rd250];
	// inline asm
	mov.b32	{%rs9, %rs10}, %r277;
	add.s64 	%rd254, %rd248, 16;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r279,%r280,%r281,%r282}, [%rd253];
	// inline asm
	add.s64 	%rd257, %rd248, 32;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd256];
	// inline asm
	add.s64 	%rd260, %rd248, 48;
	// inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd259];
	// inline asm
	add.s64 	%rd263, %rd248, 64;
	// inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd262];
	// inline asm
	add.s64 	%rd266, %rd248, 80;
	// inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd265];
	// inline asm
	add.s64 	%rd269, %rd248, 96;
	// inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd268];
	// inline asm
	add.s64 	%rd272, %rd248, 112;
	// inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd271];
	// inline asm
	mov.b32 	 %f1043, %r278;
	mov.b32 	 %f1044, %r279;
	cvt.u32.u16	%r319, %rs9;
	add.s32 	%r320, %r319, -1;
	cvt.rn.f32.s32	%f1045, %r320;
	sub.f32 	%f1046, %f940, %f1043;
	mul.f32 	%f1047, %f1046, %f1045;
	sub.f32 	%f1048, %f1044, %f1043;
	div.rn.f32 	%f1049, %f1047, %f1048;
	min.f32 	%f1050, %f1045, %f1049;
	mov.f32 	%f1051, 0f00000000;
	max.f32 	%f1052, %f1051, %f1050;
	cvt.rmi.f32.f32	%f1053, %f1052;
	cvt.rzi.s32.f32	%r321, %f1053;
	cvt.s64.s32	%rd19, %r321;
	mul.wide.s32 	%rd283, %r321, 48;
	add.s64 	%rd275, %rd257, %rd283;
	// inline asm
	cvta.to.global.u64 %rd274, %rd275;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd274];
	// inline asm
	mov.b32 	 %f1807, %r307;
	mov.b32 	 %f1808, %r308;
	mov.b32 	 %f1809, %r309;
	add.s64 	%rd278, %rd275, 16;
	// inline asm
	cvta.to.global.u64 %rd277, %rd278;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd277];
	// inline asm
	mov.b32 	 %f1804, %r311;
	mov.b32 	 %f1805, %r312;
	mov.b32 	 %f1806, %r313;
	add.s64 	%rd281, %rd275, 32;
	// inline asm
	cvta.to.global.u64 %rd280, %rd281;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd280];
	// inline asm
	sub.f32 	%f249, %f1052, %f1053;
	mov.b32 	 %f1801, %r315;
	mov.b32 	 %f1802, %r316;
	mov.b32 	 %f1803, %r317;
	setp.leu.f32	%p20, %f249, 0f00000000;
	@%p20 bra 	BB10_37;

	mul.lo.s64 	%rd293, %rd19, 48;
	add.s64 	%rd294, %rd248, %rd293;
	add.s64 	%rd285, %rd294, 80;
	// inline asm
	cvta.to.global.u64 %rd284, %rd285;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r322,%r323,%r324,%r325}, [%rd284];
	// inline asm
	mov.b32 	 %f1054, %r322;
	mov.b32 	 %f1055, %r323;
	mov.b32 	 %f1056, %r324;
	add.s64 	%rd288, %rd294, 96;
	// inline asm
	cvta.to.global.u64 %rd287, %rd288;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r326,%r327,%r328,%r329}, [%rd287];
	// inline asm
	mov.b32 	 %f1057, %r326;
	mov.b32 	 %f1058, %r327;
	mov.b32 	 %f1059, %r328;
	add.s64 	%rd291, %rd294, 112;
	// inline asm
	cvta.to.global.u64 %rd290, %rd291;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r330,%r331,%r332,%r333}, [%rd290];
	// inline asm
	mov.f32 	%f1060, 0f3F800000;
	sub.f32 	%f1061, %f1060, %f249;
	mul.f32 	%f1062, %f249, %f1054;
	mul.f32 	%f1063, %f249, %f1055;
	mul.f32 	%f1064, %f249, %f1056;
	fma.rn.f32 	%f1807, %f1061, %f1807, %f1062;
	fma.rn.f32 	%f1808, %f1061, %f1808, %f1063;
	fma.rn.f32 	%f1809, %f1061, %f1809, %f1064;
	mul.f32 	%f1065, %f249, %f1057;
	mul.f32 	%f1066, %f249, %f1058;
	mul.f32 	%f1067, %f249, %f1059;
	fma.rn.f32 	%f1804, %f1061, %f1804, %f1065;
	fma.rn.f32 	%f1805, %f1061, %f1805, %f1066;
	fma.rn.f32 	%f1806, %f1061, %f1806, %f1067;
	mov.b32 	 %f1068, %r330;
	mov.b32 	 %f1069, %r331;
	mov.b32 	 %f1070, %r332;
	mul.f32 	%f1071, %f249, %f1068;
	mul.f32 	%f1072, %f249, %f1069;
	mul.f32 	%f1073, %f249, %f1070;
	fma.rn.f32 	%f1801, %f1061, %f1801, %f1071;
	fma.rn.f32 	%f1802, %f1061, %f1802, %f1072;
	fma.rn.f32 	%f1803, %f1061, %f1803, %f1073;
	bra.uni 	BB10_37;

BB10_26:
	mov.f32 	%f1810, 0f00000000;
	mov.f32 	%f1812, 0f3F800000;
	setp.eq.s32	%p16, %r186, 4;
	@%p16 bra 	BB10_29;
	bra.uni 	BB10_27;

BB10_29:
	// inline asm
	call (%rd664), _optix_get_instance_inverse_transform_from_handle, (%rd174);
	// inline asm
	bra.uni 	BB10_30;

BB10_32:
	// inline asm
	call (%rd189), _optix_get_srt_motion_transform_from_handle, (%rd174);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd191, %rd189;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd191];
	// inline asm
	mov.b32	{%rs7, %rs8}, %r202;
	add.s64 	%rd195, %rd189, 16;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd194];
	// inline asm
	add.s64 	%rd198, %rd189, 32;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd197];
	// inline asm
	add.s64 	%rd201, %rd189, 48;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd200];
	// inline asm
	add.s64 	%rd204, %rd189, 64;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd203];
	// inline asm
	add.s64 	%rd207, %rd189, 80;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd206];
	// inline asm
	add.s64 	%rd210, %rd189, 96;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd209];
	// inline asm
	add.s64 	%rd213, %rd189, 112;
	// inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd212];
	// inline asm
	add.s64 	%rd216, %rd189, 128;
	// inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd215];
	// inline asm
	add.s64 	%rd219, %rd189, 144;
	// inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd218];
	// inline asm
	mov.b32 	 %f951, %r203;
	mov.b32 	 %f952, %r204;
	cvt.u32.u16	%r256, %rs7;
	add.s32 	%r257, %r256, -1;
	cvt.rn.f32.s32	%f953, %r257;
	sub.f32 	%f954, %f940, %f951;
	mul.f32 	%f955, %f954, %f953;
	sub.f32 	%f956, %f952, %f951;
	div.rn.f32 	%f957, %f955, %f956;
	min.f32 	%f958, %f953, %f957;
	mov.f32 	%f959, 0f00000000;
	max.f32 	%f960, %f959, %f958;
	cvt.rmi.f32.f32	%f961, %f960;
	cvt.rzi.s32.f32	%r258, %f961;
	cvt.s64.s32	%rd17, %r258;
	mul.wide.s32 	%rd233, %r258, 64;
	add.s64 	%rd222, %rd198, %rd233;
	// inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd221];
	// inline asm
	mov.b32 	 %f1791, %r240;
	mov.b32 	 %f1792, %r241;
	mov.b32 	 %f1793, %r242;
	add.s64 	%rd225, %rd222, 16;
	// inline asm
	cvta.to.global.u64 %rd224, %rd225;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd224];
	// inline asm
	mov.b32 	 %f1794, %r244;
	mov.b32 	 %f1795, %r245;
	mov.b32 	 %f1796, %r247;
	add.s64 	%rd228, %rd222, 32;
	// inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd227];
	// inline asm
	sub.f32 	%f209, %f960, %f961;
	mov.b32 	 %f1797, %r249;
	mov.b32 	 %f1798, %r250;
	mov.b32 	 %f1799, %r251;
	add.s64 	%rd231, %rd222, 48;
	// inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd230];
	// inline asm
	mov.b32 	 %f1800, %r252;
	setp.leu.f32	%p19, %f209, 0f00000000;
	@%p19 bra 	BB10_34;

	shl.b64 	%rd246, %rd17, 6;
	add.s64 	%rd247, %rd246, %rd189;
	add.s64 	%rd235, %rd247, 96;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r259,%r260,%r261,%r262}, [%rd234];
	// inline asm
	mov.b32 	 %f962, %r259;
	mov.b32 	 %f963, %r260;
	mov.b32 	 %f964, %r261;
	add.s64 	%rd238, %rd247, 112;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r263,%r264,%r265,%r266}, [%rd237];
	// inline asm
	mov.b32 	 %f965, %r263;
	mov.b32 	 %f966, %r264;
	mov.b32 	 %f967, %r266;
	add.s64 	%rd241, %rd247, 128;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r267,%r268,%r269,%r270}, [%rd240];
	// inline asm
	mov.b32 	 %f968, %r268;
	mov.b32 	 %f969, %r269;
	mov.b32 	 %f970, %r270;
	add.s64 	%rd244, %rd247, 144;
	// inline asm
	cvta.to.global.u64 %rd243, %rd244;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r271,%r272,%r273,%r274}, [%rd243];
	// inline asm
	mov.f32 	%f971, 0f3F800000;
	sub.f32 	%f972, %f971, %f209;
	mul.f32 	%f973, %f209, %f962;
	mul.f32 	%f974, %f209, %f963;
	mul.f32 	%f975, %f209, %f964;
	fma.rn.f32 	%f1791, %f972, %f1791, %f973;
	fma.rn.f32 	%f1792, %f972, %f1792, %f974;
	fma.rn.f32 	%f1793, %f972, %f1793, %f975;
	mul.f32 	%f976, %f209, %f965;
	mul.f32 	%f977, %f209, %f966;
	mul.f32 	%f978, %f209, %f967;
	fma.rn.f32 	%f1794, %f972, %f1794, %f976;
	fma.rn.f32 	%f1795, %f972, %f1795, %f977;
	fma.rn.f32 	%f1796, %f972, %f1796, %f978;
	mul.f32 	%f979, %f209, %f968;
	mul.f32 	%f980, %f209, %f969;
	mul.f32 	%f981, %f209, %f970;
	fma.rn.f32 	%f982, %f972, %f1797, %f979;
	fma.rn.f32 	%f983, %f972, %f1798, %f980;
	fma.rn.f32 	%f984, %f972, %f1799, %f981;
	mov.b32 	 %f985, %r271;
	mul.f32 	%f986, %f209, %f985;
	fma.rn.f32 	%f987, %f972, %f1800, %f986;
	mul.f32 	%f988, %f983, %f983;
	fma.rn.f32 	%f989, %f982, %f982, %f988;
	fma.rn.f32 	%f990, %f984, %f984, %f989;
	fma.rn.f32 	%f991, %f987, %f987, %f990;
	sqrt.rn.f32 	%f992, %f991;
	rcp.rn.f32 	%f993, %f992;
	mul.f32 	%f1797, %f982, %f993;
	mul.f32 	%f1798, %f983, %f993;
	mul.f32 	%f1799, %f984, %f993;
	mul.f32 	%f1800, %f987, %f993;

BB10_34:
	mul.f32 	%f994, %f1798, %f1798;
	fma.rn.f32 	%f995, %f1797, %f1797, %f994;
	fma.rn.f32 	%f996, %f1799, %f1799, %f995;
	fma.rn.f32 	%f997, %f1800, %f1800, %f996;
	rcp.rn.f32 	%f998, %f997;
	mul.f32 	%f999, %f1797, %f998;
	mul.f32 	%f1000, %f1798, %f998;
	mul.f32 	%f1001, %f1799, %f998;
	mul.f32 	%f1002, %f1800, %f998;
	mul.f32 	%f1003, %f1797, %f999;
	mul.f32 	%f1004, %f1798, %f1000;
	mul.f32 	%f1005, %f1799, %f1001;
	mul.f32 	%f1006, %f1797, %f1000;
	mul.f32 	%f1007, %f1799, %f1002;
	mul.f32 	%f1008, %f1797, %f1001;
	mul.f32 	%f1009, %f1798, %f1002;
	mul.f32 	%f1010, %f1798, %f1001;
	mul.f32 	%f1011, %f1797, %f1002;
	sub.f32 	%f1012, %f1003, %f1004;
	sub.f32 	%f1013, %f1012, %f1005;
	fma.rn.f32 	%f1014, %f1800, %f1002, %f1013;
	sub.f32 	%f1015, %f1006, %f1007;
	add.f32 	%f1016, %f1015, %f1015;
	add.f32 	%f1017, %f1008, %f1009;
	add.f32 	%f1018, %f1017, %f1017;
	add.f32 	%f1019, %f1006, %f1007;
	add.f32 	%f1020, %f1019, %f1019;
	sub.f32 	%f1021, %f1004, %f1003;
	sub.f32 	%f1022, %f1021, %f1005;
	fma.rn.f32 	%f1023, %f1800, %f1002, %f1022;
	sub.f32 	%f1024, %f1010, %f1011;
	add.f32 	%f1025, %f1024, %f1024;
	sub.f32 	%f1026, %f1008, %f1009;
	add.f32 	%f1027, %f1026, %f1026;
	add.f32 	%f1028, %f1010, %f1011;
	add.f32 	%f1029, %f1028, %f1028;
	neg.f32 	%f1030, %f1003;
	sub.f32 	%f1031, %f1030, %f1004;
	add.f32 	%f1032, %f1005, %f1031;
	fma.rn.f32 	%f1033, %f1800, %f1002, %f1032;
	mul.f32 	%f1034, %f1793, %f1014;
	fma.rn.f32 	%f1035, %f1795, %f1016, %f1034;
	fma.rn.f32 	%f1809, %f1796, %f1018, %f1035;
	mul.f32 	%f1036, %f1795, %f1023;
	fma.rn.f32 	%f1037, %f1793, %f1020, %f1036;
	fma.rn.f32 	%f1806, %f1796, %f1025, %f1037;
	mul.f32 	%f1038, %f1795, %f1029;
	fma.rn.f32 	%f1039, %f1793, %f1027, %f1038;
	fma.rn.f32 	%f1803, %f1796, %f1033, %f1039;
	mul.f32 	%f1040, %f1792, %f1014;
	fma.rn.f32 	%f1808, %f1794, %f1016, %f1040;
	mul.f32 	%f1041, %f1794, %f1023;
	fma.rn.f32 	%f1805, %f1792, %f1020, %f1041;
	mul.f32 	%f1042, %f1794, %f1029;
	fma.rn.f32 	%f1802, %f1792, %f1027, %f1042;
	mul.f32 	%f1807, %f1791, %f1014;
	mul.f32 	%f1804, %f1791, %f1020;
	mul.f32 	%f1801, %f1791, %f1027;

BB10_37:
	mul.f32 	%f1074, %f1802, %f1806;
	mul.f32 	%f1075, %f1803, %f1805;
	sub.f32 	%f1076, %f1075, %f1074;
	mul.f32 	%f1077, %f1807, %f1076;
	mul.f32 	%f1078, %f1801, %f1806;
	mul.f32 	%f1079, %f1803, %f1804;
	sub.f32 	%f1080, %f1079, %f1078;
	mul.f32 	%f1081, %f1080, %f1808;
	sub.f32 	%f1082, %f1077, %f1081;
	mul.f32 	%f1083, %f1801, %f1805;
	mul.f32 	%f1084, %f1802, %f1804;
	sub.f32 	%f1085, %f1084, %f1083;
	fma.rn.f32 	%f1086, %f1085, %f1809, %f1082;
	rcp.rn.f32 	%f1087, %f1086;
	mul.f32 	%f1816, %f1076, %f1087;
	mul.f32 	%f1088, %f1803, %f1808;
	mul.f32 	%f1089, %f1802, %f1809;
	sub.f32 	%f1090, %f1089, %f1088;
	mul.f32 	%f1817, %f1087, %f1090;
	mul.f32 	%f1091, %f1805, %f1809;
	mul.f32 	%f1092, %f1806, %f1808;
	sub.f32 	%f1093, %f1092, %f1091;
	mul.f32 	%f1818, %f1087, %f1093;
	sub.f32 	%f1094, %f1078, %f1079;
	mul.f32 	%f1813, %f1094, %f1087;
	mul.f32 	%f1095, %f1801, %f1809;
	mul.f32 	%f1096, %f1803, %f1807;
	sub.f32 	%f1097, %f1096, %f1095;
	mul.f32 	%f1814, %f1087, %f1097;
	mul.f32 	%f1098, %f1806, %f1807;
	mul.f32 	%f1099, %f1804, %f1809;
	sub.f32 	%f1100, %f1099, %f1098;
	mul.f32 	%f1815, %f1087, %f1100;
	mul.f32 	%f1810, %f1085, %f1087;
	mul.f32 	%f1101, %f1802, %f1807;
	mul.f32 	%f1102, %f1801, %f1808;
	sub.f32 	%f1103, %f1102, %f1101;
	mul.f32 	%f1811, %f1103, %f1087;
	mul.f32 	%f1104, %f1804, %f1808;
	mul.f32 	%f1105, %f1805, %f1807;
	sub.f32 	%f1106, %f1105, %f1104;
	mul.f32 	%f1812, %f1106, %f1087;
	bra.uni 	BB10_38;

BB10_27:
	setp.ne.s32	%p17, %r186, 1;
	mov.f32 	%f1811, %f1810;
	mov.f32 	%f1813, %f1810;
	mov.f32 	%f1814, %f1812;
	mov.f32 	%f1815, %f1810;
	mov.f32 	%f1816, %f1812;
	mov.f32 	%f1817, %f1810;
	mov.f32 	%f1818, %f1810;
	@%p17 bra 	BB10_38;

	// inline asm
	call (%rd176), _optix_get_static_transform_from_handle, (%rd174);
	// inline asm
	add.s64 	%rd664, %rd176, 64;

BB10_30:
	// inline asm
	cvta.to.global.u64 %rd180, %rd664;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r188,%r189,%r190,%r191}, [%rd180];
	// inline asm
	mov.b32 	 %f1816, %r188;
	mov.b32 	 %f1817, %r189;
	mov.b32 	 %f1818, %r190;
	add.s64 	%rd184, %rd664, 16;
	// inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd183];
	// inline asm
	mov.b32 	 %f1813, %r192;
	mov.b32 	 %f1814, %r193;
	mov.b32 	 %f1815, %r194;
	add.s64 	%rd187, %rd664, 32;
	// inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd186];
	// inline asm
	mov.b32 	 %f1810, %r196;
	mov.b32 	 %f1811, %r197;
	mov.b32 	 %f1812, %r198;

BB10_38:
	setp.eq.s32	%p21, %r735, 0;
	@%p21 bra 	BB10_39;
	bra.uni 	BB10_40;

BB10_39:
	mov.f32 	%f1790, %f1810;
	mov.f32 	%f1789, %f1811;
	mov.f32 	%f1788, %f1812;
	mov.f32 	%f1787, %f1813;
	mov.f32 	%f1786, %f1814;
	mov.f32 	%f1785, %f1815;
	mov.f32 	%f1784, %f1816;
	mov.f32 	%f1783, %f1817;
	mov.f32 	%f1782, %f1818;
	bra.uni 	BB10_41;

BB10_40:
	mul.f32 	%f1107, %f1787, %f1817;
	fma.rn.f32 	%f1108, %f1784, %f1816, %f1107;
	fma.rn.f32 	%f289, %f1790, %f1818, %f1108;
	mul.f32 	%f1109, %f1786, %f1817;
	fma.rn.f32 	%f1110, %f1783, %f1816, %f1109;
	fma.rn.f32 	%f290, %f1789, %f1818, %f1110;
	mul.f32 	%f1111, %f1785, %f1817;
	fma.rn.f32 	%f1112, %f1782, %f1816, %f1111;
	fma.rn.f32 	%f291, %f1788, %f1818, %f1112;
	mul.f32 	%f1113, %f1787, %f1814;
	fma.rn.f32 	%f1114, %f1784, %f1813, %f1113;
	fma.rn.f32 	%f292, %f1790, %f1815, %f1114;
	mul.f32 	%f1115, %f1786, %f1814;
	fma.rn.f32 	%f1116, %f1783, %f1813, %f1115;
	fma.rn.f32 	%f293, %f1789, %f1815, %f1116;
	mul.f32 	%f1117, %f1785, %f1814;
	fma.rn.f32 	%f1118, %f1782, %f1813, %f1117;
	fma.rn.f32 	%f294, %f1788, %f1815, %f1118;
	mul.f32 	%f1119, %f1787, %f1811;
	fma.rn.f32 	%f1120, %f1784, %f1810, %f1119;
	fma.rn.f32 	%f1790, %f1790, %f1812, %f1120;
	mul.f32 	%f1121, %f1786, %f1811;
	fma.rn.f32 	%f1122, %f1783, %f1810, %f1121;
	fma.rn.f32 	%f1789, %f1789, %f1812, %f1122;
	mul.f32 	%f1123, %f1785, %f1811;
	fma.rn.f32 	%f1124, %f1782, %f1810, %f1123;
	fma.rn.f32 	%f1788, %f1788, %f1812, %f1124;
	mov.f32 	%f1787, %f292;
	mov.f32 	%f1786, %f293;
	mov.f32 	%f1785, %f294;
	mov.f32 	%f1784, %f289;
	mov.f32 	%f1783, %f290;
	mov.f32 	%f1782, %f291;

BB10_41:
	add.s32 	%r735, %r735, 1;
	setp.lt.u32	%p22, %r735, %r33;
	@%p22 bra 	BB10_25;

	mul.f32 	%f1125, %f938, %f1783;
	fma.rn.f32 	%f1126, %f937, %f1784, %f1125;
	fma.rn.f32 	%f1828, %f1830, %f1782, %f1126;
	mul.f32 	%f1127, %f938, %f1786;
	fma.rn.f32 	%f1128, %f937, %f1787, %f1127;
	fma.rn.f32 	%f1829, %f1830, %f1785, %f1128;
	mul.f32 	%f1129, %f938, %f1789;
	fma.rn.f32 	%f1130, %f937, %f1790, %f1129;
	fma.rn.f32 	%f1830, %f1830, %f1788, %f1130;
	bra.uni 	BB10_43;

BB10_24:
	mov.f32 	%f1828, %f937;
	mov.f32 	%f1829, %f938;

BB10_43:
	// inline asm
	call (%f1132), _optix_get_ray_tmax, ();
	// inline asm
	ld.const.u64 	%rd295, [params+80];
	setp.eq.s64	%p23, %rd295, 0;
	@%p23 bra 	BB10_48;

	ld.u64 	%rd296, [%rd52];
	ld.const.u64 	%rd297, [params+328];
	cvta.to.global.u64 	%rd298, %rd297;
	cvt.u64.u32	%rd20, %r1;
	mul.wide.u32 	%rd299, %r1, 8;
	add.s64 	%rd300, %rd298, %rd299;
	st.global.u64 	[%rd300], %rd296;
	ld.const.u64 	%rd301, [params+336];
	cvta.to.global.u64 	%rd302, %rd301;
	mul.wide.u32 	%rd303, %r1, 4;
	add.s64 	%rd304, %rd302, %rd303;
	mov.u32 	%r334, 0;
	st.global.u32 	[%rd304], %r334;
	ld.const.u64 	%rd305, [params+344];
	cvta.to.global.u64 	%rd306, %rd305;
	add.s64 	%rd21, %rd306, %rd303;
	ld.global.u32 	%r9, [%rd21];
	setp.eq.s32	%p24, %r9, 0;
	@%p24 bra 	BB10_47;

	// inline asm
	call (%r335), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p25, %r335, %r9;
	@%p25 bra 	BB10_47;

	st.global.u32 	[%rd21], %r335;

BB10_47:
	ld.const.u64 	%rd307, [params+72];
	cvta.to.global.u64 	%rd308, %rd307;
	shl.b64 	%rd309, %rd20, 2;
	add.s64 	%rd310, %rd308, %rd309;
	st.global.f32 	[%rd310], %f1132;
	bra.uni 	BB10_178;

BB10_48:
	fma.rn.f32 	%f1991, %f1132, %f1828, %f1781;
	fma.rn.f32 	%f1993, %f1132, %f1830, %f1779;
	ld.v2.f32 	{%f1133, %f1134}, [%rd3+288];
	sub.f32 	%f316, %f1991, %f1133;
	fma.rn.f32 	%f1992, %f1132, %f1829, %f1780;
	sub.f32 	%f318, %f1992, %f1134;
	ld.u8 	%rs1, [%rd3+324];
	ld.f32 	%f319, [%rd3+312];
	ld.f32 	%f320, [%rd3+308];
	cvt.f64.f32	%fd1, %f316;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r11}, %fd1;
	}
	mov.f64 	%fd48, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd48;
	}
	bfe.u32 	%r336, %r12, 20, 11;
	add.s32 	%r337, %r336, -1012;
	mov.u64 	%rd311, 4611686018427387904;
	shl.b64 	%rd23, %rd311, %r337;
	setp.ne.s64	%p26, %rd23, -9223372036854775808;
	setp.eq.s64	%p27, %rd23, -9223372036854775808;
	abs.f64 	%fd2, %fd1;
	// Callseq Start 22
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd78, [retval0+0];
	
	//{
	}// Callseq End 22
	setp.gt.s32	%p28, %r11, -1;
	setp.lt.s32	%p29, %r11, 0;
	and.pred  	%p1, %p29, %p27;
	or.pred  	%p30, %p28, %p26;
	@%p30 bra 	BB10_50;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r338}, %fd78;
	}
	xor.b32  	%r339, %r338, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r340, %temp}, %fd78;
	}
	mov.b64 	%fd78, {%r340, %r339};

BB10_50:
	setp.eq.f32	%p31, %f316, 0f00000000;
	@%p31 bra 	BB10_53;
	bra.uni 	BB10_51;

BB10_53:
	selp.b32	%r341, %r11, 0, %p27;
	mov.u32 	%r342, 0;
	or.b32  	%r343, %r341, 2146435072;
	setp.lt.s32	%p35, %r12, 0;
	selp.b32	%r344, %r343, %r341, %p35;
	mov.b64 	%fd78, {%r342, %r344};
	bra.uni 	BB10_54;

BB10_51:
	@%p28 bra 	BB10_54;

	cvt.rzi.f64.f64	%fd50, %fd48;
	setp.neu.f64	%p33, %fd50, 0d4000000000000000;
	selp.f64	%fd78, 0dFFF8000000000000, %fd78, %p33;

BB10_54:
	add.f64 	%fd79, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r345}, %fd79;
	}
	and.b32  	%r346, %r345, 2146435072;
	setp.ne.s32	%p36, %r346, 2146435072;
	@%p36 bra 	BB10_55;

	setp.gtu.f64	%p37, %fd2, 0d7FF0000000000000;
	@%p37 bra 	BB10_64;

	and.b32  	%r347, %r12, 2147483647;
	setp.ne.s32	%p38, %r347, 2146435072;
	@%p38 bra 	BB10_59;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r348, %temp}, %fd48;
	}
	setp.eq.s32	%p39, %r348, 0;
	@%p39 bra 	BB10_63;

BB10_59:
	and.b32  	%r349, %r11, 2147483647;
	setp.ne.s32	%p40, %r349, 2146435072;
	@%p40 bra 	BB10_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r350, %temp}, %fd1;
	}
	setp.ne.s32	%p41, %r350, 0;
	mov.f64 	%fd79, %fd78;
	@%p41 bra 	BB10_64;

	shr.s32 	%r351, %r12, 31;
	and.b32  	%r352, %r351, -2146435072;
	add.s32 	%r353, %r352, 2146435072;
	or.b32  	%r354, %r353, -2147483648;
	selp.b32	%r355, %r354, %r353, %p1;
	mov.u32 	%r356, 0;
	mov.b64 	%fd79, {%r356, %r355};
	bra.uni 	BB10_64;

BB10_55:
	mov.f64 	%fd79, %fd78;
	bra.uni 	BB10_64;

BB10_60:
	mov.f64 	%fd79, %fd78;
	bra.uni 	BB10_64;

BB10_63:
	setp.gt.f64	%p42, %fd2, 0d3FF0000000000000;
	selp.b32	%r357, 2146435072, 0, %p42;
	mov.u32 	%r358, 0;
	xor.b32  	%r359, %r357, 2146435072;
	setp.lt.s32	%p43, %r12, 0;
	selp.b32	%r360, %r359, %r357, %p43;
	setp.eq.f32	%p44, %f316, 0fBF800000;
	selp.b32	%r361, 1072693248, %r360, %p44;
	mov.b64 	%fd79, {%r358, %r361};

BB10_64:
	cvt.f64.f32	%fd13, %f318;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd13;
	}
	abs.f64 	%fd14, %fd13;
	// Callseq Start 23
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd14;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd81, [retval0+0];
	
	//{
	}// Callseq End 23
	setp.gt.s32	%p45, %r13, -1;
	setp.lt.s32	%p46, %r13, 0;
	and.pred  	%p2, %p46, %p27;
	or.pred  	%p49, %p45, %p26;
	@%p49 bra 	BB10_66;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r362}, %fd81;
	}
	xor.b32  	%r363, %r362, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r364, %temp}, %fd81;
	}
	mov.b64 	%fd81, {%r364, %r363};

BB10_66:
	setp.eq.f32	%p50, %f318, 0f00000000;
	setp.eq.f32	%p51, %f316, 0f3F800000;
	selp.f64	%fd18, 0d3FF0000000000000, %fd79, %p51;
	@%p50 bra 	BB10_69;
	bra.uni 	BB10_67;

BB10_69:
	selp.b32	%r365, %r13, 0, %p27;
	mov.u32 	%r366, 0;
	or.b32  	%r367, %r365, 2146435072;
	setp.lt.s32	%p55, %r12, 0;
	selp.b32	%r368, %r367, %r365, %p55;
	mov.b64 	%fd81, {%r366, %r368};
	bra.uni 	BB10_70;

BB10_67:
	@%p45 bra 	BB10_70;

	cvt.rzi.f64.f64	%fd53, %fd48;
	setp.neu.f64	%p53, %fd53, 0d4000000000000000;
	selp.f64	%fd81, 0dFFF8000000000000, %fd81, %p53;

BB10_70:
	add.f64 	%fd82, %fd13, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r369}, %fd82;
	}
	and.b32  	%r370, %r369, 2146435072;
	setp.ne.s32	%p56, %r370, 2146435072;
	@%p56 bra 	BB10_71;

	setp.gtu.f64	%p57, %fd14, 0d7FF0000000000000;
	@%p57 bra 	BB10_80;

	and.b32  	%r371, %r12, 2147483647;
	setp.ne.s32	%p58, %r371, 2146435072;
	@%p58 bra 	BB10_75;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r372, %temp}, %fd48;
	}
	setp.eq.s32	%p59, %r372, 0;
	@%p59 bra 	BB10_79;

BB10_75:
	and.b32  	%r373, %r13, 2147483647;
	setp.ne.s32	%p60, %r373, 2146435072;
	@%p60 bra 	BB10_76;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r374, %temp}, %fd13;
	}
	setp.ne.s32	%p61, %r374, 0;
	mov.f64 	%fd82, %fd81;
	@%p61 bra 	BB10_80;

	shr.s32 	%r375, %r12, 31;
	and.b32  	%r376, %r375, -2146435072;
	add.s32 	%r377, %r376, 2146435072;
	or.b32  	%r378, %r377, -2147483648;
	selp.b32	%r379, %r378, %r377, %p2;
	mov.u32 	%r380, 0;
	mov.b64 	%fd82, {%r380, %r379};
	bra.uni 	BB10_80;

BB10_71:
	mov.f64 	%fd82, %fd81;
	bra.uni 	BB10_80;

BB10_76:
	mov.f64 	%fd82, %fd81;
	bra.uni 	BB10_80;

BB10_79:
	setp.gt.f64	%p62, %fd14, 0d3FF0000000000000;
	selp.b32	%r381, 2146435072, 0, %p62;
	mov.u32 	%r382, 0;
	xor.b32  	%r383, %r381, 2146435072;
	setp.lt.s32	%p63, %r12, 0;
	selp.b32	%r384, %r383, %r381, %p63;
	setp.eq.f32	%p64, %f318, 0fBF800000;
	selp.b32	%r385, 1072693248, %r384, %p64;
	mov.b64 	%fd82, {%r382, %r385};

BB10_80:
	setp.eq.f32	%p65, %f318, 0f3F800000;
	selp.f64	%fd55, 0d3FF0000000000000, %fd82, %p65;
	add.f64 	%fd56, %fd18, %fd55;
	add.f32 	%f1137, %f320, 0f3F800000;
	cvt.f64.f32	%fd57, %f1137;
	mul.f64 	%fd26, %fd57, %fd56;
	cvt.f64.f32	%fd27, %f319;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd27;
	}
	abs.f64 	%fd28, %fd27;
	// Callseq Start 24
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd28;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd87, [retval0+0];
	
	//{
	}// Callseq End 24
	setp.gt.s32	%p66, %r14, -1;
	setp.lt.s32	%p67, %r14, 0;
	and.pred  	%p3, %p67, %p27;
	or.pred  	%p70, %p66, %p26;
	mov.f64 	%fd84, %fd87;
	@%p70 bra 	BB10_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r386}, %fd87;
	}
	xor.b32  	%r387, %r386, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r388, %temp}, %fd87;
	}
	mov.b64 	%fd84, {%r388, %r387};

BB10_82:
	setp.eq.f32	%p71, %f319, 0f00000000;
	@%p71 bra 	BB10_85;
	bra.uni 	BB10_83;

BB10_85:
	selp.b32	%r389, %r14, 0, %p27;
	mov.u32 	%r390, 0;
	or.b32  	%r391, %r389, 2146435072;
	setp.lt.s32	%p75, %r12, 0;
	selp.b32	%r392, %r391, %r389, %p75;
	mov.b64 	%fd84, {%r390, %r392};
	bra.uni 	BB10_86;

BB10_83:
	@%p66 bra 	BB10_86;

	cvt.rzi.f64.f64	%fd59, %fd48;
	setp.neu.f64	%p73, %fd59, 0d4000000000000000;
	selp.f64	%fd84, 0dFFF8000000000000, %fd84, %p73;

BB10_86:
	add.f64 	%fd88, %fd27, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r393}, %fd88;
	}
	and.b32  	%r15, %r393, 2146435072;
	setp.ne.s32	%p76, %r15, 2146435072;
	@%p76 bra 	BB10_87;

	setp.gtu.f64	%p77, %fd28, 0d7FF0000000000000;
	mov.f64 	%fd85, %fd88;
	@%p77 bra 	BB10_96;

	and.b32  	%r394, %r12, 2147483647;
	setp.ne.s32	%p78, %r394, 2146435072;
	@%p78 bra 	BB10_91;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r395, %temp}, %fd48;
	}
	setp.eq.s32	%p79, %r395, 0;
	@%p79 bra 	BB10_95;

BB10_91:
	and.b32  	%r396, %r14, 2147483647;
	setp.ne.s32	%p80, %r396, 2146435072;
	@%p80 bra 	BB10_92;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r397, %temp}, %fd27;
	}
	setp.ne.s32	%p81, %r397, 0;
	mov.f64 	%fd85, %fd84;
	@%p81 bra 	BB10_96;

	shr.s32 	%r398, %r12, 31;
	and.b32  	%r399, %r398, -2146435072;
	add.s32 	%r400, %r399, 2146435072;
	or.b32  	%r401, %r400, -2147483648;
	selp.b32	%r402, %r401, %r400, %p3;
	mov.u32 	%r403, 0;
	mov.b64 	%fd85, {%r403, %r402};
	bra.uni 	BB10_96;

BB10_87:
	mov.f64 	%fd85, %fd84;
	bra.uni 	BB10_96;

BB10_92:
	mov.f64 	%fd85, %fd84;
	bra.uni 	BB10_96;

BB10_95:
	setp.gt.f64	%p82, %fd28, 0d3FF0000000000000;
	selp.b32	%r404, 2146435072, 0, %p82;
	mov.u32 	%r405, 0;
	xor.b32  	%r406, %r404, 2146435072;
	setp.lt.s32	%p83, %r12, 0;
	selp.b32	%r407, %r406, %r404, %p83;
	setp.eq.f32	%p84, %f319, 0fBF800000;
	selp.b32	%r408, 1072693248, %r407, %p84;
	mov.b64 	%fd85, {%r405, %r408};

BB10_96:
	setp.eq.f32	%p85, %f319, 0f3F800000;
	selp.f64	%fd61, 0d3FF0000000000000, %fd85, %p85;
	mul.f64 	%fd62, %fd26, %fd61;
	mov.f64 	%fd63, 0d3FF0000000000000;
	sub.f64 	%fd64, %fd63, %fd62;
	sqrt.rn.f64 	%fd65, %fd64;
	mul.f32 	%f1138, %f316, %f319;
	cvt.f64.f32	%fd66, %f1138;
	div.rn.f64 	%fd39, %fd66, %fd65;
	@!%p3 bra 	BB10_98;
	bra.uni 	BB10_97;

BB10_97:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r409}, %fd87;
	}
	xor.b32  	%r410, %r409, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r411, %temp}, %fd87;
	}
	mov.b64 	%fd87, {%r411, %r410};

BB10_98:
	@%p71 bra 	BB10_101;
	bra.uni 	BB10_99;

BB10_101:
	selp.b32	%r412, %r14, 0, %p27;
	mov.u32 	%r413, 0;
	or.b32  	%r414, %r412, 2146435072;
	setp.lt.s32	%p90, %r12, 0;
	selp.b32	%r415, %r414, %r412, %p90;
	mov.b64 	%fd87, {%r413, %r415};
	bra.uni 	BB10_102;

BB10_99:
	@%p66 bra 	BB10_102;

	cvt.rzi.f64.f64	%fd68, %fd48;
	setp.neu.f64	%p88, %fd68, 0d4000000000000000;
	selp.f64	%fd87, 0dFFF8000000000000, %fd87, %p88;

BB10_102:
	@%p76 bra 	BB10_103;

	setp.gtu.f64	%p92, %fd28, 0d7FF0000000000000;
	@%p92 bra 	BB10_112;

	and.b32  	%r416, %r12, 2147483647;
	setp.ne.s32	%p93, %r416, 2146435072;
	@%p93 bra 	BB10_107;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r417, %temp}, %fd48;
	}
	setp.eq.s32	%p94, %r417, 0;
	@%p94 bra 	BB10_111;

BB10_107:
	and.b32  	%r418, %r14, 2147483647;
	setp.ne.s32	%p95, %r418, 2146435072;
	@%p95 bra 	BB10_108;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r419, %temp}, %fd27;
	}
	setp.ne.s32	%p96, %r419, 0;
	mov.f64 	%fd88, %fd87;
	@%p96 bra 	BB10_112;

	shr.s32 	%r420, %r12, 31;
	and.b32  	%r421, %r420, -2146435072;
	add.s32 	%r422, %r421, 2146435072;
	or.b32  	%r423, %r422, -2147483648;
	selp.b32	%r424, %r423, %r422, %p3;
	mov.u32 	%r425, 0;
	mov.b64 	%fd88, {%r425, %r424};
	bra.uni 	BB10_112;

BB10_103:
	mov.f64 	%fd88, %fd87;
	bra.uni 	BB10_112;

BB10_108:
	mov.f64 	%fd88, %fd87;
	bra.uni 	BB10_112;

BB10_111:
	setp.gt.f64	%p97, %fd28, 0d3FF0000000000000;
	selp.b32	%r426, 2146435072, 0, %p97;
	mov.u32 	%r427, 0;
	xor.b32  	%r428, %r426, 2146435072;
	setp.lt.s32	%p98, %r12, 0;
	selp.b32	%r429, %r428, %r426, %p98;
	setp.eq.f32	%p99, %f319, 0fBF800000;
	selp.b32	%r430, 1072693248, %r429, %p99;
	mov.b64 	%fd88, {%r427, %r430};

BB10_112:
	selp.f64	%fd70, 0d3FF0000000000000, %fd88, %p85;
	mul.f64 	%fd71, %fd26, %fd70;
	sub.f64 	%fd73, %fd63, %fd71;
	sqrt.rn.f64 	%fd74, %fd73;
	mul.f32 	%f1139, %f318, %f319;
	cvt.f64.f32	%fd75, %f1139;
	div.rn.f64 	%fd76, %fd75, %fd74;
	setp.eq.s16	%p101, %rs1, 0;
	selp.f32	%f321, 0fBF800000, 0f3F800000, %p101;
	cvt.rn.f32.f64	%f1973, %fd76;
	cvt.rn.f32.f64	%f1976, %fd39;
	ld.u8 	%rs12, [%rd3+332];
	setp.eq.s16	%p102, %rs12, 0;
	@%p102 bra 	BB10_114;

	neg.f32 	%f1140, %f1976;
	mul.f32 	%f1141, %f1976, %f1976;
	neg.f32 	%f1142, %f1973;
	fma.rn.f32 	%f1143, %f1142, %f1142, %f1141;
	neg.f32 	%f1144, %f321;
	fma.rn.f32 	%f1145, %f1144, %f1144, %f1143;
	sqrt.rn.f32 	%f1146, %f1145;
	div.rn.f32 	%f1988, %f1140, %f1146;
	div.rn.f32 	%f1989, %f1142, %f1146;
	div.rn.f32 	%f1990, %f1144, %f1146;
	bra.uni 	BB10_115;

BB10_114:
	mul.f32 	%f1147, %f1976, %f1976;
	fma.rn.f32 	%f1148, %f1973, %f1973, %f1147;
	fma.rn.f32 	%f1149, %f321, %f321, %f1148;
	sqrt.rn.f32 	%f1150, %f1149;
	div.rn.f32 	%f1988, %f1976, %f1150;
	div.rn.f32 	%f1989, %f1973, %f1150;
	div.rn.f32 	%f1990, %f321, %f1150;

BB10_115:
	ld.const.u64 	%rd24, [params+96];
	setp.eq.s64	%p103, %rd24, 0;
	@%p103 bra 	BB10_117;

	ld.v4.f32 	{%f1152, %f1153, %f1154, %f1155}, [%rd3+208];
	ld.v2.f32 	{%f1158, %f1159}, [%rd3+160];
	fma.rn.f32 	%f1161, %f1991, %f1158, %f1152;
	fma.rn.f32 	%f1163, %f1991, %f1159, %f1153;
	ld.v2.f32 	{%f1164, %f1165}, [%rd3+176];
	fma.rn.f32 	%f1167, %f1992, %f1164, %f1161;
	fma.rn.f32 	%f1169, %f1992, %f1165, %f1163;
	ld.v2.f32 	{%f1170, %f1171}, [%rd3+192];
	fma.rn.f32 	%f1173, %f1993, %f1170, %f1167;
	fma.rn.f32 	%f1175, %f1993, %f1171, %f1169;
	ld.f32 	%f1176, [%rd3+316];
	div.rn.f32 	%f1834, %f1173, %f1176;
	div.rn.f32 	%f1835, %f1175, %f1176;

BB10_117:
	ld.u64 	%rd25, [%rd52];
	ld.const.u64 	%rd312, [params+344];
	cvta.to.global.u64 	%rd313, %rd312;
	cvt.u64.u32	%rd26, %r1;
	mul.wide.u32 	%rd314, %r1, 4;
	add.s64 	%rd27, %rd313, %rd314;
	ld.global.u32 	%r16, [%rd27];
	setp.eq.s32	%p104, %r16, 0;
	mov.f32 	%f1974, 0f00000000;
	mov.f32 	%f1975, 0f3F800000;
	@%p104 bra 	BB10_118;

	// inline asm
	call (%r431), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p105, %r431, %r16;
	@%p105 bra 	BB10_118;

	mov.f32 	%f1901, 0f00000000;
	mov.f32 	%f1902, 0f3F800000;
	mov.f32 	%f1839, %f1902;
	mov.f32 	%f1838, %f1901;
	mov.f32 	%f1837, %f1901;
	mov.f32 	%f1836, %f1901;
	mov.f32 	%f1843, %f1901;
	mov.f32 	%f1842, %f1902;
	mov.f32 	%f1841, %f1901;
	mov.f32 	%f1840, %f1901;
	mov.f32 	%f1847, %f1901;
	mov.f32 	%f1846, %f1901;
	mov.f32 	%f1845, %f1902;
	mov.f32 	%f1844, %f1901;
	@%p5 bra 	BB10_138;

	add.s32 	%r736, %r33, -1;
	setp.lt.s32	%p107, %r736, 0;
	@%p107 bra 	BB10_138;

BB10_122:
	.pragma "nounroll";
	// inline asm
	call (%rd315), _optix_get_transform_list_handle, (%r736);
	// inline asm
	// inline asm
	call (%r433), _optix_get_transform_type_from_handle, (%rd315);
	// inline asm
	and.b32  	%r434, %r433, -2;
	setp.eq.s32	%p108, %r434, 2;
	@%p108 bra 	BB10_128;
	bra.uni 	BB10_123;

BB10_128:
	setp.eq.s32	%p111, %r433, 2;
	@%p111 bra 	BB10_132;
	bra.uni 	BB10_129;

BB10_132:
	// inline asm
	call (%rd389), _optix_get_matrix_motion_transform_from_handle, (%rd315);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd391, %rd389;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r522,%r523,%r524,%r525}, [%rd391];
	// inline asm
	mov.b32	{%rs15, %rs16}, %r524;
	add.s64 	%rd395, %rd389, 16;
	// inline asm
	cvta.to.global.u64 %rd394, %rd395;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r526,%r527,%r528,%r529}, [%rd394];
	// inline asm
	add.s64 	%rd398, %rd389, 32;
	// inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r530,%r531,%r532,%r533}, [%rd397];
	// inline asm
	add.s64 	%rd401, %rd389, 48;
	// inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r534,%r535,%r536,%r537}, [%rd400];
	// inline asm
	add.s64 	%rd404, %rd389, 64;
	// inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r538,%r539,%r540,%r541}, [%rd403];
	// inline asm
	add.s64 	%rd407, %rd389, 80;
	// inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r542,%r543,%r544,%r545}, [%rd406];
	// inline asm
	add.s64 	%rd410, %rd389, 96;
	// inline asm
	cvta.to.global.u64 %rd409, %rd410;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r546,%r547,%r548,%r549}, [%rd409];
	// inline asm
	add.s64 	%rd413, %rd389, 112;
	// inline asm
	cvta.to.global.u64 %rd412, %rd413;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r550,%r551,%r552,%r553}, [%rd412];
	// inline asm
	mov.b32 	 %f1331, %r525;
	mov.b32 	 %f1332, %r526;
	cvt.u32.u16	%r566, %rs15;
	add.s32 	%r567, %r566, -1;
	cvt.rn.f32.s32	%f1333, %r567;
	sub.f32 	%f1334, %f940, %f1331;
	mul.f32 	%f1335, %f1334, %f1333;
	sub.f32 	%f1336, %f1332, %f1331;
	div.rn.f32 	%f1337, %f1335, %f1336;
	min.f32 	%f1338, %f1333, %f1337;
	mov.f32 	%f1339, 0f00000000;
	max.f32 	%f1340, %f1339, %f1338;
	cvt.rmi.f32.f32	%f1341, %f1340;
	cvt.rzi.s32.f32	%r568, %f1341;
	cvt.s64.s32	%rd35, %r568;
	mul.wide.s32 	%rd424, %r568, 48;
	add.s64 	%rd416, %rd398, %rd424;
	// inline asm
	cvta.to.global.u64 %rd415, %rd416;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r554,%r555,%r556,%r557}, [%rd415];
	// inline asm
	mov.b32 	 %f1872, %r554;
	mov.b32 	 %f1873, %r555;
	mov.b32 	 %f1874, %r556;
	mov.b32 	 %f1875, %r557;
	add.s64 	%rd419, %rd416, 16;
	// inline asm
	cvta.to.global.u64 %rd418, %rd419;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r558,%r559,%r560,%r561}, [%rd418];
	// inline asm
	mov.b32 	 %f1868, %r558;
	mov.b32 	 %f1869, %r559;
	mov.b32 	 %f1870, %r560;
	mov.b32 	 %f1871, %r561;
	add.s64 	%rd422, %rd416, 32;
	// inline asm
	cvta.to.global.u64 %rd421, %rd422;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r562,%r563,%r564,%r565}, [%rd421];
	// inline asm
	sub.f32 	%f430, %f1340, %f1341;
	mov.b32 	 %f1864, %r562;
	mov.b32 	 %f1865, %r563;
	mov.b32 	 %f1866, %r564;
	mov.b32 	 %f1867, %r565;
	setp.leu.f32	%p113, %f430, 0f00000000;
	@%p113 bra 	BB10_134;

	mul.lo.s64 	%rd434, %rd35, 48;
	add.s64 	%rd435, %rd389, %rd434;
	add.s64 	%rd426, %rd435, 80;
	// inline asm
	cvta.to.global.u64 %rd425, %rd426;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r569,%r570,%r571,%r572}, [%rd425];
	// inline asm
	mov.b32 	 %f1342, %r569;
	mov.b32 	 %f1343, %r570;
	mov.b32 	 %f1344, %r571;
	mov.b32 	 %f1345, %r572;
	add.s64 	%rd429, %rd435, 96;
	// inline asm
	cvta.to.global.u64 %rd428, %rd429;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r573,%r574,%r575,%r576}, [%rd428];
	// inline asm
	mov.b32 	 %f1346, %r573;
	mov.b32 	 %f1347, %r574;
	mov.b32 	 %f1348, %r575;
	mov.b32 	 %f1349, %r576;
	add.s64 	%rd432, %rd435, 112;
	// inline asm
	cvta.to.global.u64 %rd431, %rd432;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r577,%r578,%r579,%r580}, [%rd431];
	// inline asm
	mov.f32 	%f1350, 0f3F800000;
	sub.f32 	%f1351, %f1350, %f430;
	mul.f32 	%f1352, %f430, %f1342;
	mul.f32 	%f1353, %f430, %f1343;
	mul.f32 	%f1354, %f430, %f1344;
	mul.f32 	%f1355, %f430, %f1345;
	fma.rn.f32 	%f1872, %f1351, %f1872, %f1352;
	fma.rn.f32 	%f1873, %f1351, %f1873, %f1353;
	fma.rn.f32 	%f1874, %f1351, %f1874, %f1354;
	fma.rn.f32 	%f1875, %f1351, %f1875, %f1355;
	mul.f32 	%f1356, %f430, %f1346;
	mul.f32 	%f1357, %f430, %f1347;
	mul.f32 	%f1358, %f430, %f1348;
	mul.f32 	%f1359, %f430, %f1349;
	fma.rn.f32 	%f1868, %f1351, %f1868, %f1356;
	fma.rn.f32 	%f1869, %f1351, %f1869, %f1357;
	fma.rn.f32 	%f1870, %f1351, %f1870, %f1358;
	fma.rn.f32 	%f1871, %f1351, %f1871, %f1359;
	mov.b32 	 %f1360, %r577;
	mov.b32 	 %f1361, %r578;
	mov.b32 	 %f1362, %r579;
	mov.b32 	 %f1363, %r580;
	mul.f32 	%f1364, %f430, %f1360;
	mul.f32 	%f1365, %f430, %f1361;
	mul.f32 	%f1366, %f430, %f1362;
	mul.f32 	%f1367, %f430, %f1363;
	fma.rn.f32 	%f1864, %f1351, %f1864, %f1364;
	fma.rn.f32 	%f1865, %f1351, %f1865, %f1365;
	fma.rn.f32 	%f1866, %f1351, %f1866, %f1366;
	fma.rn.f32 	%f1867, %f1351, %f1867, %f1367;
	bra.uni 	BB10_134;

BB10_123:
	mov.f32 	%f1864, 0f00000000;
	mov.f32 	%f1866, 0f3F800000;
	setp.eq.s32	%p109, %r433, 4;
	@%p109 bra 	BB10_126;
	bra.uni 	BB10_124;

BB10_126:
	// inline asm
	call (%rd665), _optix_get_instance_transform_from_handle, (%rd315);
	// inline asm
	bra.uni 	BB10_127;

BB10_129:
	// inline asm
	call (%rd330), _optix_get_srt_motion_transform_from_handle, (%rd315);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd332, %rd330;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r447,%r448,%r449,%r450}, [%rd332];
	// inline asm
	mov.b32	{%rs13, %rs14}, %r449;
	add.s64 	%rd336, %rd330, 16;
	// inline asm
	cvta.to.global.u64 %rd335, %rd336;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r451,%r452,%r453,%r454}, [%rd335];
	// inline asm
	add.s64 	%rd339, %rd330, 32;
	// inline asm
	cvta.to.global.u64 %rd338, %rd339;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r455,%r456,%r457,%r458}, [%rd338];
	// inline asm
	add.s64 	%rd342, %rd330, 48;
	// inline asm
	cvta.to.global.u64 %rd341, %rd342;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r459,%r460,%r461,%r462}, [%rd341];
	// inline asm
	add.s64 	%rd345, %rd330, 64;
	// inline asm
	cvta.to.global.u64 %rd344, %rd345;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r463,%r464,%r465,%r466}, [%rd344];
	// inline asm
	add.s64 	%rd348, %rd330, 80;
	// inline asm
	cvta.to.global.u64 %rd347, %rd348;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r467,%r468,%r469,%r470}, [%rd347];
	// inline asm
	add.s64 	%rd351, %rd330, 96;
	// inline asm
	cvta.to.global.u64 %rd350, %rd351;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r471,%r472,%r473,%r474}, [%rd350];
	// inline asm
	add.s64 	%rd354, %rd330, 112;
	// inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r475,%r476,%r477,%r478}, [%rd353];
	// inline asm
	add.s64 	%rd357, %rd330, 128;
	// inline asm
	cvta.to.global.u64 %rd356, %rd357;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd356];
	// inline asm
	add.s64 	%rd360, %rd330, 144;
	// inline asm
	cvta.to.global.u64 %rd359, %rd360;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd359];
	// inline asm
	mov.b32 	 %f1218, %r450;
	mov.b32 	 %f1219, %r451;
	cvt.u32.u16	%r503, %rs13;
	add.s32 	%r504, %r503, -1;
	cvt.rn.f32.s32	%f1220, %r504;
	sub.f32 	%f1221, %f940, %f1218;
	mul.f32 	%f1222, %f1221, %f1220;
	sub.f32 	%f1223, %f1219, %f1218;
	div.rn.f32 	%f1224, %f1222, %f1223;
	min.f32 	%f1225, %f1220, %f1224;
	mov.f32 	%f1226, 0f00000000;
	max.f32 	%f1227, %f1226, %f1225;
	cvt.rmi.f32.f32	%f1228, %f1227;
	cvt.rzi.s32.f32	%r505, %f1228;
	cvt.s64.s32	%rd33, %r505;
	mul.wide.s32 	%rd374, %r505, 64;
	add.s64 	%rd363, %rd339, %rd374;
	// inline asm
	cvta.to.global.u64 %rd362, %rd363;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r487,%r488,%r489,%r490}, [%rd362];
	// inline asm
	mov.b32 	 %f1848, %r487;
	mov.b32 	 %f1849, %r488;
	mov.b32 	 %f1850, %r489;
	mov.b32 	 %f1851, %r490;
	add.s64 	%rd366, %rd363, 16;
	// inline asm
	cvta.to.global.u64 %rd365, %rd366;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r491,%r492,%r493,%r494}, [%rd365];
	// inline asm
	mov.b32 	 %f1852, %r491;
	mov.b32 	 %f1853, %r492;
	mov.b32 	 %f1854, %r493;
	mov.b32 	 %f1855, %r494;
	add.s64 	%rd369, %rd363, 32;
	// inline asm
	cvta.to.global.u64 %rd368, %rd369;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r495,%r496,%r497,%r498}, [%rd368];
	// inline asm
	sub.f32 	%f369, %f1227, %f1228;
	mov.b32 	 %f1856, %r495;
	mov.b32 	 %f1857, %r496;
	mov.b32 	 %f1858, %r497;
	mov.b32 	 %f1859, %r498;
	add.s64 	%rd372, %rd363, 48;
	// inline asm
	cvta.to.global.u64 %rd371, %rd372;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r499,%r500,%r501,%r502}, [%rd371];
	// inline asm
	mov.b32 	 %f1860, %r499;
	mov.b32 	 %f1861, %r500;
	mov.b32 	 %f1862, %r501;
	mov.b32 	 %f1863, %r502;
	setp.leu.f32	%p112, %f369, 0f00000000;
	@%p112 bra 	BB10_131;

	shl.b64 	%rd387, %rd33, 6;
	add.s64 	%rd388, %rd387, %rd330;
	add.s64 	%rd376, %rd388, 96;
	// inline asm
	cvta.to.global.u64 %rd375, %rd376;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r506,%r507,%r508,%r509}, [%rd375];
	// inline asm
	mov.b32 	 %f1229, %r506;
	mov.b32 	 %f1230, %r507;
	mov.b32 	 %f1231, %r508;
	mov.b32 	 %f1232, %r509;
	add.s64 	%rd379, %rd388, 112;
	// inline asm
	cvta.to.global.u64 %rd378, %rd379;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r510,%r511,%r512,%r513}, [%rd378];
	// inline asm
	mov.b32 	 %f1233, %r510;
	mov.b32 	 %f1234, %r511;
	mov.b32 	 %f1235, %r512;
	mov.b32 	 %f1236, %r513;
	add.s64 	%rd382, %rd388, 128;
	// inline asm
	cvta.to.global.u64 %rd381, %rd382;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r514,%r515,%r516,%r517}, [%rd381];
	// inline asm
	mov.b32 	 %f1237, %r514;
	mov.b32 	 %f1238, %r515;
	mov.b32 	 %f1239, %r516;
	mov.b32 	 %f1240, %r517;
	add.s64 	%rd385, %rd388, 144;
	// inline asm
	cvta.to.global.u64 %rd384, %rd385;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r518,%r519,%r520,%r521}, [%rd384];
	// inline asm
	mov.f32 	%f1241, 0f3F800000;
	sub.f32 	%f1242, %f1241, %f369;
	mul.f32 	%f1243, %f369, %f1229;
	mul.f32 	%f1244, %f369, %f1230;
	mul.f32 	%f1245, %f369, %f1231;
	mul.f32 	%f1246, %f369, %f1232;
	fma.rn.f32 	%f1848, %f1242, %f1848, %f1243;
	fma.rn.f32 	%f1849, %f1242, %f1849, %f1244;
	fma.rn.f32 	%f1850, %f1242, %f1850, %f1245;
	fma.rn.f32 	%f1851, %f1242, %f1851, %f1246;
	mul.f32 	%f1247, %f369, %f1233;
	mul.f32 	%f1248, %f369, %f1234;
	mul.f32 	%f1249, %f369, %f1235;
	mul.f32 	%f1250, %f369, %f1236;
	fma.rn.f32 	%f1852, %f1242, %f1852, %f1247;
	fma.rn.f32 	%f1853, %f1242, %f1853, %f1248;
	fma.rn.f32 	%f1854, %f1242, %f1854, %f1249;
	fma.rn.f32 	%f1855, %f1242, %f1855, %f1250;
	mul.f32 	%f1251, %f369, %f1237;
	mul.f32 	%f1252, %f369, %f1238;
	mul.f32 	%f1253, %f369, %f1239;
	mul.f32 	%f1254, %f369, %f1240;
	fma.rn.f32 	%f1856, %f1242, %f1856, %f1251;
	fma.rn.f32 	%f1255, %f1242, %f1857, %f1252;
	fma.rn.f32 	%f1256, %f1242, %f1858, %f1253;
	fma.rn.f32 	%f1257, %f1242, %f1859, %f1254;
	mov.b32 	 %f1258, %r518;
	mov.b32 	 %f1259, %r519;
	mov.b32 	 %f1260, %r520;
	mov.b32 	 %f1261, %r521;
	mul.f32 	%f1262, %f369, %f1258;
	mul.f32 	%f1263, %f369, %f1259;
	mul.f32 	%f1264, %f369, %f1260;
	mul.f32 	%f1265, %f369, %f1261;
	fma.rn.f32 	%f1266, %f1242, %f1860, %f1262;
	fma.rn.f32 	%f1861, %f1242, %f1861, %f1263;
	fma.rn.f32 	%f1862, %f1242, %f1862, %f1264;
	fma.rn.f32 	%f1863, %f1242, %f1863, %f1265;
	mul.f32 	%f1267, %f1256, %f1256;
	fma.rn.f32 	%f1268, %f1255, %f1255, %f1267;
	fma.rn.f32 	%f1269, %f1257, %f1257, %f1268;
	fma.rn.f32 	%f1270, %f1266, %f1266, %f1269;
	sqrt.rn.f32 	%f1271, %f1270;
	rcp.rn.f32 	%f1272, %f1271;
	mul.f32 	%f1857, %f1255, %f1272;
	mul.f32 	%f1858, %f1256, %f1272;
	mul.f32 	%f1859, %f1257, %f1272;
	mul.f32 	%f1860, %f1266, %f1272;

BB10_131:
	mul.f32 	%f1273, %f1858, %f1858;
	fma.rn.f32 	%f1274, %f1857, %f1857, %f1273;
	fma.rn.f32 	%f1275, %f1859, %f1859, %f1274;
	fma.rn.f32 	%f1276, %f1860, %f1860, %f1275;
	rcp.rn.f32 	%f1277, %f1276;
	mul.f32 	%f1278, %f1857, %f1277;
	mul.f32 	%f1279, %f1858, %f1277;
	mul.f32 	%f1280, %f1859, %f1277;
	mul.f32 	%f1281, %f1860, %f1277;
	mul.f32 	%f1282, %f1857, %f1278;
	mul.f32 	%f1283, %f1858, %f1279;
	mul.f32 	%f1284, %f1859, %f1280;
	mul.f32 	%f1285, %f1857, %f1279;
	mul.f32 	%f1286, %f1859, %f1281;
	mul.f32 	%f1287, %f1857, %f1280;
	mul.f32 	%f1288, %f1858, %f1281;
	mul.f32 	%f1289, %f1858, %f1280;
	mul.f32 	%f1290, %f1857, %f1281;
	sub.f32 	%f1291, %f1282, %f1283;
	sub.f32 	%f1292, %f1291, %f1284;
	fma.rn.f32 	%f1293, %f1860, %f1281, %f1292;
	sub.f32 	%f1294, %f1285, %f1286;
	add.f32 	%f1295, %f1294, %f1294;
	add.f32 	%f1296, %f1287, %f1288;
	add.f32 	%f1297, %f1296, %f1296;
	add.f32 	%f1298, %f1285, %f1286;
	add.f32 	%f1299, %f1298, %f1298;
	sub.f32 	%f1300, %f1283, %f1282;
	sub.f32 	%f1301, %f1300, %f1284;
	fma.rn.f32 	%f1302, %f1860, %f1281, %f1301;
	sub.f32 	%f1303, %f1289, %f1290;
	add.f32 	%f1304, %f1303, %f1303;
	sub.f32 	%f1305, %f1287, %f1288;
	add.f32 	%f1306, %f1305, %f1305;
	add.f32 	%f1307, %f1289, %f1290;
	add.f32 	%f1308, %f1307, %f1307;
	neg.f32 	%f1309, %f1282;
	sub.f32 	%f1310, %f1309, %f1283;
	add.f32 	%f1311, %f1284, %f1310;
	fma.rn.f32 	%f1312, %f1860, %f1281, %f1311;
	mul.f32 	%f1313, %f1851, %f1293;
	fma.rn.f32 	%f1314, %f1854, %f1295, %f1313;
	fma.rn.f32 	%f1315, %f1856, %f1297, %f1314;
	sub.f32 	%f1875, %f1861, %f1315;
	mul.f32 	%f1316, %f1854, %f1302;
	fma.rn.f32 	%f1317, %f1851, %f1299, %f1316;
	fma.rn.f32 	%f1318, %f1856, %f1304, %f1317;
	sub.f32 	%f1871, %f1862, %f1318;
	mul.f32 	%f1319, %f1854, %f1308;
	fma.rn.f32 	%f1320, %f1851, %f1306, %f1319;
	fma.rn.f32 	%f1321, %f1856, %f1312, %f1320;
	sub.f32 	%f1867, %f1863, %f1321;
	mul.f32 	%f1322, %f1850, %f1293;
	fma.rn.f32 	%f1323, %f1853, %f1295, %f1322;
	fma.rn.f32 	%f1874, %f1855, %f1297, %f1323;
	mul.f32 	%f1324, %f1853, %f1302;
	fma.rn.f32 	%f1325, %f1850, %f1299, %f1324;
	fma.rn.f32 	%f1870, %f1855, %f1304, %f1325;
	mul.f32 	%f1326, %f1853, %f1308;
	fma.rn.f32 	%f1327, %f1850, %f1306, %f1326;
	fma.rn.f32 	%f1866, %f1855, %f1312, %f1327;
	mul.f32 	%f1328, %f1849, %f1293;
	fma.rn.f32 	%f1873, %f1852, %f1295, %f1328;
	mul.f32 	%f1329, %f1852, %f1302;
	fma.rn.f32 	%f1869, %f1849, %f1299, %f1329;
	mul.f32 	%f1330, %f1852, %f1308;
	fma.rn.f32 	%f1865, %f1849, %f1306, %f1330;
	mul.f32 	%f1872, %f1848, %f1293;
	mul.f32 	%f1868, %f1848, %f1299;
	mul.f32 	%f1864, %f1848, %f1306;
	bra.uni 	BB10_134;

BB10_124:
	setp.ne.s32	%p110, %r433, 1;
	mov.f32 	%f1865, %f1864;
	mov.f32 	%f1867, %f1864;
	mov.f32 	%f1868, %f1864;
	mov.f32 	%f1869, %f1866;
	mov.f32 	%f1870, %f1864;
	mov.f32 	%f1871, %f1864;
	mov.f32 	%f1872, %f1866;
	mov.f32 	%f1873, %f1864;
	mov.f32 	%f1874, %f1864;
	mov.f32 	%f1875, %f1864;
	@%p110 bra 	BB10_134;

	// inline asm
	call (%rd317), _optix_get_static_transform_from_handle, (%rd315);
	// inline asm
	add.s64 	%rd665, %rd317, 16;

BB10_127:
	// inline asm
	cvta.to.global.u64 %rd321, %rd665;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r435,%r436,%r437,%r438}, [%rd321];
	// inline asm
	mov.b32 	 %f1872, %r435;
	mov.b32 	 %f1873, %r436;
	mov.b32 	 %f1874, %r437;
	mov.b32 	 %f1875, %r438;
	add.s64 	%rd325, %rd665, 16;
	// inline asm
	cvta.to.global.u64 %rd324, %rd325;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r439,%r440,%r441,%r442}, [%rd324];
	// inline asm
	mov.b32 	 %f1868, %r439;
	mov.b32 	 %f1869, %r440;
	mov.b32 	 %f1870, %r441;
	mov.b32 	 %f1871, %r442;
	add.s64 	%rd328, %rd665, 32;
	// inline asm
	cvta.to.global.u64 %rd327, %rd328;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r443,%r444,%r445,%r446}, [%rd327];
	// inline asm
	mov.b32 	 %f1864, %r443;
	mov.b32 	 %f1865, %r444;
	mov.b32 	 %f1866, %r445;
	mov.b32 	 %f1867, %r446;

BB10_134:
	add.s32 	%r21, %r736, 1;
	setp.eq.s32	%p114, %r21, %r33;
	@%p114 bra 	BB10_135;
	bra.uni 	BB10_136;

BB10_135:
	mov.f32 	%f1847, %f1864;
	mov.f32 	%f1846, %f1865;
	mov.f32 	%f1845, %f1866;
	mov.f32 	%f1844, %f1867;
	mov.f32 	%f1843, %f1868;
	mov.f32 	%f1842, %f1869;
	mov.f32 	%f1841, %f1870;
	mov.f32 	%f1840, %f1871;
	mov.f32 	%f1839, %f1872;
	mov.f32 	%f1838, %f1873;
	mov.f32 	%f1837, %f1874;
	mov.f32 	%f1836, %f1875;
	bra.uni 	BB10_137;

BB10_136:
	mul.f32 	%f1368, %f1843, %f1873;
	fma.rn.f32 	%f1369, %f1839, %f1872, %f1368;
	fma.rn.f32 	%f459, %f1847, %f1874, %f1369;
	mul.f32 	%f1370, %f1842, %f1873;
	fma.rn.f32 	%f1371, %f1838, %f1872, %f1370;
	fma.rn.f32 	%f460, %f1846, %f1874, %f1371;
	mul.f32 	%f1372, %f1841, %f1873;
	fma.rn.f32 	%f1373, %f1837, %f1872, %f1372;
	fma.rn.f32 	%f461, %f1845, %f1874, %f1373;
	mul.f32 	%f1374, %f1840, %f1873;
	fma.rn.f32 	%f1375, %f1836, %f1872, %f1374;
	fma.rn.f32 	%f1376, %f1844, %f1874, %f1375;
	add.f32 	%f462, %f1875, %f1376;
	mul.f32 	%f1377, %f1843, %f1869;
	fma.rn.f32 	%f1378, %f1839, %f1868, %f1377;
	fma.rn.f32 	%f463, %f1847, %f1870, %f1378;
	mul.f32 	%f1379, %f1842, %f1869;
	fma.rn.f32 	%f1380, %f1838, %f1868, %f1379;
	fma.rn.f32 	%f464, %f1846, %f1870, %f1380;
	mul.f32 	%f1381, %f1841, %f1869;
	fma.rn.f32 	%f1382, %f1837, %f1868, %f1381;
	fma.rn.f32 	%f465, %f1845, %f1870, %f1382;
	mul.f32 	%f1383, %f1840, %f1869;
	fma.rn.f32 	%f1384, %f1836, %f1868, %f1383;
	fma.rn.f32 	%f1385, %f1844, %f1870, %f1384;
	add.f32 	%f466, %f1871, %f1385;
	mul.f32 	%f1386, %f1843, %f1865;
	fma.rn.f32 	%f1387, %f1839, %f1864, %f1386;
	fma.rn.f32 	%f1847, %f1847, %f1866, %f1387;
	mul.f32 	%f1388, %f1842, %f1865;
	fma.rn.f32 	%f1389, %f1838, %f1864, %f1388;
	fma.rn.f32 	%f1846, %f1846, %f1866, %f1389;
	mul.f32 	%f1390, %f1841, %f1865;
	fma.rn.f32 	%f1391, %f1837, %f1864, %f1390;
	fma.rn.f32 	%f1845, %f1845, %f1866, %f1391;
	mul.f32 	%f1392, %f1840, %f1865;
	fma.rn.f32 	%f1393, %f1836, %f1864, %f1392;
	fma.rn.f32 	%f1394, %f1844, %f1866, %f1393;
	add.f32 	%f1844, %f1867, %f1394;
	mov.f32 	%f1843, %f463;
	mov.f32 	%f1842, %f464;
	mov.f32 	%f1841, %f465;
	mov.f32 	%f1840, %f466;
	mov.f32 	%f1839, %f459;
	mov.f32 	%f1838, %f460;
	mov.f32 	%f1837, %f461;
	mov.f32 	%f1836, %f462;

BB10_137:
	add.s32 	%r736, %r21, -2;
	setp.gt.s32	%p115, %r736, -1;
	@%p115 bra 	BB10_122;

BB10_138:
	mov.u32 	%r737, 0;
	mov.f32 	%f1900, %f1901;
	mov.f32 	%f1905, %f1901;
	mov.f32 	%f1904, %f1902;
	mov.f32 	%f1903, %f1901;
	mov.f32 	%f1908, %f1901;
	mov.f32 	%f1907, %f1901;
	mov.f32 	%f1906, %f1902;
	@%p5 bra 	BB10_156;

BB10_139:
	.pragma "nounroll";
	// inline asm
	call (%rd436), _optix_get_transform_list_handle, (%r737);
	// inline asm
	// inline asm
	call (%r583), _optix_get_transform_type_from_handle, (%rd436);
	// inline asm
	and.b32  	%r584, %r583, -2;
	setp.eq.s32	%p117, %r584, 2;
	@%p117 bra 	BB10_145;
	bra.uni 	BB10_140;

BB10_145:
	setp.eq.s32	%p120, %r583, 2;
	@%p120 bra 	BB10_149;
	bra.uni 	BB10_146;

BB10_149:
	// inline asm
	call (%rd510), _optix_get_matrix_motion_transform_from_handle, (%rd436);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd512, %rd510;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r672,%r673,%r674,%r675}, [%rd512];
	// inline asm
	mov.b32	{%rs19, %rs20}, %r674;
	add.s64 	%rd516, %rd510, 16;
	// inline asm
	cvta.to.global.u64 %rd515, %rd516;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r676,%r677,%r678,%r679}, [%rd515];
	// inline asm
	add.s64 	%rd519, %rd510, 32;
	// inline asm
	cvta.to.global.u64 %rd518, %rd519;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r680,%r681,%r682,%r683}, [%rd518];
	// inline asm
	add.s64 	%rd522, %rd510, 48;
	// inline asm
	cvta.to.global.u64 %rd521, %rd522;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r684,%r685,%r686,%r687}, [%rd521];
	// inline asm
	add.s64 	%rd525, %rd510, 64;
	// inline asm
	cvta.to.global.u64 %rd524, %rd525;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r688,%r689,%r690,%r691}, [%rd524];
	// inline asm
	add.s64 	%rd528, %rd510, 80;
	// inline asm
	cvta.to.global.u64 %rd527, %rd528;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r692,%r693,%r694,%r695}, [%rd527];
	// inline asm
	add.s64 	%rd531, %rd510, 96;
	// inline asm
	cvta.to.global.u64 %rd530, %rd531;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r696,%r697,%r698,%r699}, [%rd530];
	// inline asm
	add.s64 	%rd534, %rd510, 112;
	// inline asm
	cvta.to.global.u64 %rd533, %rd534;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r700,%r701,%r702,%r703}, [%rd533];
	// inline asm
	mov.b32 	 %f1506, %r675;
	mov.b32 	 %f1507, %r676;
	cvt.u32.u16	%r716, %rs19;
	add.s32 	%r717, %r716, -1;
	cvt.rn.f32.s32	%f1508, %r717;
	sub.f32 	%f1509, %f940, %f1506;
	mul.f32 	%f1510, %f1509, %f1508;
	sub.f32 	%f1511, %f1507, %f1506;
	div.rn.f32 	%f1512, %f1510, %f1511;
	min.f32 	%f1513, %f1508, %f1512;
	mov.f32 	%f1514, 0f00000000;
	max.f32 	%f1515, %f1514, %f1513;
	cvt.rmi.f32.f32	%f1516, %f1515;
	cvt.rzi.s32.f32	%r718, %f1516;
	cvt.s64.s32	%rd43, %r718;
	mul.wide.s32 	%rd545, %r718, 48;
	add.s64 	%rd537, %rd519, %rd545;
	// inline asm
	cvta.to.global.u64 %rd536, %rd537;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r704,%r705,%r706,%r707}, [%rd536];
	// inline asm
	mov.b32 	 %f1925, %r704;
	mov.b32 	 %f1926, %r705;
	mov.b32 	 %f1927, %r706;
	add.s64 	%rd540, %rd537, 16;
	// inline asm
	cvta.to.global.u64 %rd539, %rd540;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r708,%r709,%r710,%r711}, [%rd539];
	// inline asm
	mov.b32 	 %f1922, %r708;
	mov.b32 	 %f1923, %r709;
	mov.b32 	 %f1924, %r710;
	add.s64 	%rd543, %rd537, 32;
	// inline asm
	cvta.to.global.u64 %rd542, %rd543;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r712,%r713,%r714,%r715}, [%rd542];
	// inline asm
	sub.f32 	%f559, %f1515, %f1516;
	mov.b32 	 %f1919, %r712;
	mov.b32 	 %f1920, %r713;
	mov.b32 	 %f1921, %r714;
	setp.leu.f32	%p122, %f559, 0f00000000;
	@%p122 bra 	BB10_151;

	mul.lo.s64 	%rd555, %rd43, 48;
	add.s64 	%rd556, %rd510, %rd555;
	add.s64 	%rd547, %rd556, 80;
	// inline asm
	cvta.to.global.u64 %rd546, %rd547;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r719,%r720,%r721,%r722}, [%rd546];
	// inline asm
	mov.b32 	 %f1517, %r719;
	mov.b32 	 %f1518, %r720;
	mov.b32 	 %f1519, %r721;
	add.s64 	%rd550, %rd556, 96;
	// inline asm
	cvta.to.global.u64 %rd549, %rd550;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r723,%r724,%r725,%r726}, [%rd549];
	// inline asm
	mov.b32 	 %f1520, %r723;
	mov.b32 	 %f1521, %r724;
	mov.b32 	 %f1522, %r725;
	add.s64 	%rd553, %rd556, 112;
	// inline asm
	cvta.to.global.u64 %rd552, %rd553;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r727,%r728,%r729,%r730}, [%rd552];
	// inline asm
	mov.f32 	%f1523, 0f3F800000;
	sub.f32 	%f1524, %f1523, %f559;
	mul.f32 	%f1525, %f559, %f1517;
	mul.f32 	%f1526, %f559, %f1518;
	mul.f32 	%f1527, %f559, %f1519;
	fma.rn.f32 	%f1925, %f1524, %f1925, %f1525;
	fma.rn.f32 	%f1926, %f1524, %f1926, %f1526;
	fma.rn.f32 	%f1927, %f1524, %f1927, %f1527;
	mul.f32 	%f1528, %f559, %f1520;
	mul.f32 	%f1529, %f559, %f1521;
	mul.f32 	%f1530, %f559, %f1522;
	fma.rn.f32 	%f1922, %f1524, %f1922, %f1528;
	fma.rn.f32 	%f1923, %f1524, %f1923, %f1529;
	fma.rn.f32 	%f1924, %f1524, %f1924, %f1530;
	mov.b32 	 %f1531, %r727;
	mov.b32 	 %f1532, %r728;
	mov.b32 	 %f1533, %r729;
	mul.f32 	%f1534, %f559, %f1531;
	mul.f32 	%f1535, %f559, %f1532;
	mul.f32 	%f1536, %f559, %f1533;
	fma.rn.f32 	%f1919, %f1524, %f1919, %f1534;
	fma.rn.f32 	%f1920, %f1524, %f1920, %f1535;
	fma.rn.f32 	%f1921, %f1524, %f1921, %f1536;
	bra.uni 	BB10_151;

BB10_140:
	mov.f32 	%f1928, 0f00000000;
	mov.f32 	%f1930, 0f3F800000;
	setp.eq.s32	%p118, %r583, 4;
	@%p118 bra 	BB10_143;
	bra.uni 	BB10_141;

BB10_143:
	// inline asm
	call (%rd666), _optix_get_instance_inverse_transform_from_handle, (%rd436);
	// inline asm
	bra.uni 	BB10_144;

BB10_146:
	// inline asm
	call (%rd451), _optix_get_srt_motion_transform_from_handle, (%rd436);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd453, %rd451;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r597,%r598,%r599,%r600}, [%rd453];
	// inline asm
	mov.b32	{%rs17, %rs18}, %r599;
	add.s64 	%rd457, %rd451, 16;
	// inline asm
	cvta.to.global.u64 %rd456, %rd457;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r601,%r602,%r603,%r604}, [%rd456];
	// inline asm
	add.s64 	%rd460, %rd451, 32;
	// inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r605,%r606,%r607,%r608}, [%rd459];
	// inline asm
	add.s64 	%rd463, %rd451, 48;
	// inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r609,%r610,%r611,%r612}, [%rd462];
	// inline asm
	add.s64 	%rd466, %rd451, 64;
	// inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r613,%r614,%r615,%r616}, [%rd465];
	// inline asm
	add.s64 	%rd469, %rd451, 80;
	// inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r617,%r618,%r619,%r620}, [%rd468];
	// inline asm
	add.s64 	%rd472, %rd451, 96;
	// inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r621,%r622,%r623,%r624}, [%rd471];
	// inline asm
	add.s64 	%rd475, %rd451, 112;
	// inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r625,%r626,%r627,%r628}, [%rd474];
	// inline asm
	add.s64 	%rd478, %rd451, 128;
	// inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r629,%r630,%r631,%r632}, [%rd477];
	// inline asm
	add.s64 	%rd481, %rd451, 144;
	// inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r633,%r634,%r635,%r636}, [%rd480];
	// inline asm
	mov.b32 	 %f1414, %r600;
	mov.b32 	 %f1415, %r601;
	cvt.u32.u16	%r653, %rs17;
	add.s32 	%r654, %r653, -1;
	cvt.rn.f32.s32	%f1416, %r654;
	sub.f32 	%f1417, %f940, %f1414;
	mul.f32 	%f1418, %f1417, %f1416;
	sub.f32 	%f1419, %f1415, %f1414;
	div.rn.f32 	%f1420, %f1418, %f1419;
	min.f32 	%f1421, %f1416, %f1420;
	mov.f32 	%f1422, 0f00000000;
	max.f32 	%f1423, %f1422, %f1421;
	cvt.rmi.f32.f32	%f1424, %f1423;
	cvt.rzi.s32.f32	%r655, %f1424;
	cvt.s64.s32	%rd41, %r655;
	mul.wide.s32 	%rd495, %r655, 64;
	add.s64 	%rd484, %rd460, %rd495;
	// inline asm
	cvta.to.global.u64 %rd483, %rd484;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r637,%r638,%r639,%r640}, [%rd483];
	// inline asm
	mov.b32 	 %f1909, %r637;
	mov.b32 	 %f1910, %r638;
	mov.b32 	 %f1911, %r639;
	add.s64 	%rd487, %rd484, 16;
	// inline asm
	cvta.to.global.u64 %rd486, %rd487;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r641,%r642,%r643,%r644}, [%rd486];
	// inline asm
	mov.b32 	 %f1912, %r641;
	mov.b32 	 %f1913, %r642;
	mov.b32 	 %f1914, %r644;
	add.s64 	%rd490, %rd484, 32;
	// inline asm
	cvta.to.global.u64 %rd489, %rd490;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r645,%r646,%r647,%r648}, [%rd489];
	// inline asm
	sub.f32 	%f519, %f1423, %f1424;
	mov.b32 	 %f1915, %r646;
	mov.b32 	 %f1916, %r647;
	mov.b32 	 %f1917, %r648;
	add.s64 	%rd493, %rd484, 48;
	// inline asm
	cvta.to.global.u64 %rd492, %rd493;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r649,%r650,%r651,%r652}, [%rd492];
	// inline asm
	mov.b32 	 %f1918, %r649;
	setp.leu.f32	%p121, %f519, 0f00000000;
	@%p121 bra 	BB10_148;

	shl.b64 	%rd508, %rd41, 6;
	add.s64 	%rd509, %rd508, %rd451;
	add.s64 	%rd497, %rd509, 96;
	// inline asm
	cvta.to.global.u64 %rd496, %rd497;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r656,%r657,%r658,%r659}, [%rd496];
	// inline asm
	mov.b32 	 %f1425, %r656;
	mov.b32 	 %f1426, %r657;
	mov.b32 	 %f1427, %r658;
	add.s64 	%rd500, %rd509, 112;
	// inline asm
	cvta.to.global.u64 %rd499, %rd500;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r660,%r661,%r662,%r663}, [%rd499];
	// inline asm
	mov.b32 	 %f1428, %r660;
	mov.b32 	 %f1429, %r661;
	mov.b32 	 %f1430, %r663;
	add.s64 	%rd503, %rd509, 128;
	// inline asm
	cvta.to.global.u64 %rd502, %rd503;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r664,%r665,%r666,%r667}, [%rd502];
	// inline asm
	mov.b32 	 %f1431, %r665;
	mov.b32 	 %f1432, %r666;
	mov.b32 	 %f1433, %r667;
	add.s64 	%rd506, %rd509, 144;
	// inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r668,%r669,%r670,%r671}, [%rd505];
	// inline asm
	mov.f32 	%f1434, 0f3F800000;
	sub.f32 	%f1435, %f1434, %f519;
	mul.f32 	%f1436, %f519, %f1425;
	mul.f32 	%f1437, %f519, %f1426;
	mul.f32 	%f1438, %f519, %f1427;
	fma.rn.f32 	%f1909, %f1435, %f1909, %f1436;
	fma.rn.f32 	%f1910, %f1435, %f1910, %f1437;
	fma.rn.f32 	%f1911, %f1435, %f1911, %f1438;
	mul.f32 	%f1439, %f519, %f1428;
	mul.f32 	%f1440, %f519, %f1429;
	mul.f32 	%f1441, %f519, %f1430;
	fma.rn.f32 	%f1912, %f1435, %f1912, %f1439;
	fma.rn.f32 	%f1913, %f1435, %f1913, %f1440;
	fma.rn.f32 	%f1914, %f1435, %f1914, %f1441;
	mul.f32 	%f1442, %f519, %f1431;
	mul.f32 	%f1443, %f519, %f1432;
	mul.f32 	%f1444, %f519, %f1433;
	fma.rn.f32 	%f1445, %f1435, %f1915, %f1442;
	fma.rn.f32 	%f1446, %f1435, %f1916, %f1443;
	fma.rn.f32 	%f1447, %f1435, %f1917, %f1444;
	mov.b32 	 %f1448, %r668;
	mul.f32 	%f1449, %f519, %f1448;
	fma.rn.f32 	%f1450, %f1435, %f1918, %f1449;
	mul.f32 	%f1451, %f1446, %f1446;
	fma.rn.f32 	%f1452, %f1445, %f1445, %f1451;
	fma.rn.f32 	%f1453, %f1447, %f1447, %f1452;
	fma.rn.f32 	%f1454, %f1450, %f1450, %f1453;
	sqrt.rn.f32 	%f1455, %f1454;
	rcp.rn.f32 	%f1456, %f1455;
	mul.f32 	%f1915, %f1445, %f1456;
	mul.f32 	%f1916, %f1446, %f1456;
	mul.f32 	%f1917, %f1447, %f1456;
	mul.f32 	%f1918, %f1450, %f1456;

BB10_148:
	mul.f32 	%f1457, %f1916, %f1916;
	fma.rn.f32 	%f1458, %f1915, %f1915, %f1457;
	fma.rn.f32 	%f1459, %f1917, %f1917, %f1458;
	fma.rn.f32 	%f1460, %f1918, %f1918, %f1459;
	rcp.rn.f32 	%f1461, %f1460;
	mul.f32 	%f1462, %f1915, %f1461;
	mul.f32 	%f1463, %f1916, %f1461;
	mul.f32 	%f1464, %f1917, %f1461;
	mul.f32 	%f1465, %f1918, %f1461;
	mul.f32 	%f1466, %f1915, %f1462;
	mul.f32 	%f1467, %f1916, %f1463;
	mul.f32 	%f1468, %f1917, %f1464;
	mul.f32 	%f1469, %f1915, %f1463;
	mul.f32 	%f1470, %f1917, %f1465;
	mul.f32 	%f1471, %f1915, %f1464;
	mul.f32 	%f1472, %f1916, %f1465;
	mul.f32 	%f1473, %f1916, %f1464;
	mul.f32 	%f1474, %f1915, %f1465;
	sub.f32 	%f1475, %f1466, %f1467;
	sub.f32 	%f1476, %f1475, %f1468;
	fma.rn.f32 	%f1477, %f1918, %f1465, %f1476;
	sub.f32 	%f1478, %f1469, %f1470;
	add.f32 	%f1479, %f1478, %f1478;
	add.f32 	%f1480, %f1471, %f1472;
	add.f32 	%f1481, %f1480, %f1480;
	add.f32 	%f1482, %f1469, %f1470;
	add.f32 	%f1483, %f1482, %f1482;
	sub.f32 	%f1484, %f1467, %f1466;
	sub.f32 	%f1485, %f1484, %f1468;
	fma.rn.f32 	%f1486, %f1918, %f1465, %f1485;
	sub.f32 	%f1487, %f1473, %f1474;
	add.f32 	%f1488, %f1487, %f1487;
	sub.f32 	%f1489, %f1471, %f1472;
	add.f32 	%f1490, %f1489, %f1489;
	add.f32 	%f1491, %f1473, %f1474;
	add.f32 	%f1492, %f1491, %f1491;
	neg.f32 	%f1493, %f1466;
	sub.f32 	%f1494, %f1493, %f1467;
	add.f32 	%f1495, %f1468, %f1494;
	fma.rn.f32 	%f1496, %f1918, %f1465, %f1495;
	mul.f32 	%f1497, %f1911, %f1477;
	fma.rn.f32 	%f1498, %f1913, %f1479, %f1497;
	fma.rn.f32 	%f1927, %f1914, %f1481, %f1498;
	mul.f32 	%f1499, %f1913, %f1486;
	fma.rn.f32 	%f1500, %f1911, %f1483, %f1499;
	fma.rn.f32 	%f1924, %f1914, %f1488, %f1500;
	mul.f32 	%f1501, %f1913, %f1492;
	fma.rn.f32 	%f1502, %f1911, %f1490, %f1501;
	fma.rn.f32 	%f1921, %f1914, %f1496, %f1502;
	mul.f32 	%f1503, %f1910, %f1477;
	fma.rn.f32 	%f1926, %f1912, %f1479, %f1503;
	mul.f32 	%f1504, %f1912, %f1486;
	fma.rn.f32 	%f1923, %f1910, %f1483, %f1504;
	mul.f32 	%f1505, %f1912, %f1492;
	fma.rn.f32 	%f1920, %f1910, %f1490, %f1505;
	mul.f32 	%f1925, %f1909, %f1477;
	mul.f32 	%f1922, %f1909, %f1483;
	mul.f32 	%f1919, %f1909, %f1490;

BB10_151:
	mul.f32 	%f1537, %f1920, %f1924;
	mul.f32 	%f1538, %f1921, %f1923;
	sub.f32 	%f1539, %f1538, %f1537;
	mul.f32 	%f1540, %f1925, %f1539;
	mul.f32 	%f1541, %f1919, %f1924;
	mul.f32 	%f1542, %f1921, %f1922;
	sub.f32 	%f1543, %f1542, %f1541;
	mul.f32 	%f1544, %f1543, %f1926;
	sub.f32 	%f1545, %f1540, %f1544;
	mul.f32 	%f1546, %f1919, %f1923;
	mul.f32 	%f1547, %f1920, %f1922;
	sub.f32 	%f1548, %f1547, %f1546;
	fma.rn.f32 	%f1549, %f1548, %f1927, %f1545;
	rcp.rn.f32 	%f1550, %f1549;
	mul.f32 	%f1934, %f1539, %f1550;
	mul.f32 	%f1551, %f1921, %f1926;
	mul.f32 	%f1552, %f1920, %f1927;
	sub.f32 	%f1553, %f1552, %f1551;
	mul.f32 	%f1935, %f1550, %f1553;
	mul.f32 	%f1554, %f1923, %f1927;
	mul.f32 	%f1555, %f1924, %f1926;
	sub.f32 	%f1556, %f1555, %f1554;
	mul.f32 	%f1936, %f1550, %f1556;
	sub.f32 	%f1557, %f1541, %f1542;
	mul.f32 	%f1931, %f1557, %f1550;
	mul.f32 	%f1558, %f1919, %f1927;
	mul.f32 	%f1559, %f1921, %f1925;
	sub.f32 	%f1560, %f1559, %f1558;
	mul.f32 	%f1932, %f1550, %f1560;
	mul.f32 	%f1561, %f1924, %f1925;
	mul.f32 	%f1562, %f1922, %f1927;
	sub.f32 	%f1563, %f1562, %f1561;
	mul.f32 	%f1933, %f1550, %f1563;
	mul.f32 	%f1928, %f1548, %f1550;
	mul.f32 	%f1564, %f1920, %f1925;
	mul.f32 	%f1565, %f1919, %f1926;
	sub.f32 	%f1566, %f1565, %f1564;
	mul.f32 	%f1929, %f1566, %f1550;
	mul.f32 	%f1567, %f1922, %f1926;
	mul.f32 	%f1568, %f1923, %f1925;
	sub.f32 	%f1569, %f1568, %f1567;
	mul.f32 	%f1930, %f1569, %f1550;
	bra.uni 	BB10_152;

BB10_141:
	setp.ne.s32	%p119, %r583, 1;
	mov.f32 	%f1929, %f1928;
	mov.f32 	%f1931, %f1928;
	mov.f32 	%f1932, %f1930;
	mov.f32 	%f1933, %f1928;
	mov.f32 	%f1934, %f1930;
	mov.f32 	%f1935, %f1928;
	mov.f32 	%f1936, %f1928;
	@%p119 bra 	BB10_152;

	// inline asm
	call (%rd438), _optix_get_static_transform_from_handle, (%rd436);
	// inline asm
	add.s64 	%rd666, %rd438, 64;

BB10_144:
	// inline asm
	cvta.to.global.u64 %rd442, %rd666;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r585,%r586,%r587,%r588}, [%rd442];
	// inline asm
	mov.b32 	 %f1934, %r585;
	mov.b32 	 %f1935, %r586;
	mov.b32 	 %f1936, %r587;
	add.s64 	%rd446, %rd666, 16;
	// inline asm
	cvta.to.global.u64 %rd445, %rd446;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r589,%r590,%r591,%r592}, [%rd445];
	// inline asm
	mov.b32 	 %f1931, %r589;
	mov.b32 	 %f1932, %r590;
	mov.b32 	 %f1933, %r591;
	add.s64 	%rd449, %rd666, 32;
	// inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r593,%r594,%r595,%r596}, [%rd448];
	// inline asm
	mov.b32 	 %f1928, %r593;
	mov.b32 	 %f1929, %r594;
	mov.b32 	 %f1930, %r595;

BB10_152:
	setp.eq.s32	%p123, %r737, 0;
	@%p123 bra 	BB10_153;
	bra.uni 	BB10_154;

BB10_153:
	mov.f32 	%f1908, %f1928;
	mov.f32 	%f1907, %f1929;
	mov.f32 	%f1906, %f1930;
	mov.f32 	%f1905, %f1931;
	mov.f32 	%f1904, %f1932;
	mov.f32 	%f1903, %f1933;
	mov.f32 	%f1902, %f1934;
	mov.f32 	%f1901, %f1935;
	mov.f32 	%f1900, %f1936;
	bra.uni 	BB10_155;

BB10_154:
	mul.f32 	%f1570, %f1905, %f1935;
	fma.rn.f32 	%f1571, %f1902, %f1934, %f1570;
	fma.rn.f32 	%f599, %f1908, %f1936, %f1571;
	mul.f32 	%f1572, %f1904, %f1935;
	fma.rn.f32 	%f1573, %f1901, %f1934, %f1572;
	fma.rn.f32 	%f600, %f1907, %f1936, %f1573;
	mul.f32 	%f1574, %f1903, %f1935;
	fma.rn.f32 	%f1575, %f1900, %f1934, %f1574;
	fma.rn.f32 	%f601, %f1906, %f1936, %f1575;
	mul.f32 	%f1576, %f1905, %f1932;
	fma.rn.f32 	%f1577, %f1902, %f1931, %f1576;
	fma.rn.f32 	%f602, %f1908, %f1933, %f1577;
	mul.f32 	%f1578, %f1904, %f1932;
	fma.rn.f32 	%f1579, %f1901, %f1931, %f1578;
	fma.rn.f32 	%f603, %f1907, %f1933, %f1579;
	mul.f32 	%f1580, %f1903, %f1932;
	fma.rn.f32 	%f1581, %f1900, %f1931, %f1580;
	fma.rn.f32 	%f604, %f1906, %f1933, %f1581;
	mul.f32 	%f1582, %f1905, %f1929;
	fma.rn.f32 	%f1583, %f1902, %f1928, %f1582;
	fma.rn.f32 	%f1908, %f1908, %f1930, %f1583;
	mul.f32 	%f1584, %f1904, %f1929;
	fma.rn.f32 	%f1585, %f1901, %f1928, %f1584;
	fma.rn.f32 	%f1907, %f1907, %f1930, %f1585;
	mul.f32 	%f1586, %f1903, %f1929;
	fma.rn.f32 	%f1587, %f1900, %f1928, %f1586;
	fma.rn.f32 	%f1906, %f1906, %f1930, %f1587;
	mov.f32 	%f1905, %f602;
	mov.f32 	%f1904, %f603;
	mov.f32 	%f1903, %f604;
	mov.f32 	%f1902, %f599;
	mov.f32 	%f1901, %f600;
	mov.f32 	%f1900, %f601;

BB10_155:
	add.s32 	%r737, %r737, 1;
	setp.lt.u32	%p124, %r737, %r33;
	@%p124 bra 	BB10_139;

BB10_156:
	fma.rn.f32 	%f1588, %f1991, %f1839, %f1836;
	fma.rn.f32 	%f1589, %f1992, %f1838, %f1588;
	fma.rn.f32 	%f1590, %f1991, %f1843, %f1840;
	fma.rn.f32 	%f1591, %f1992, %f1842, %f1590;
	fma.rn.f32 	%f1592, %f1991, %f1847, %f1844;
	fma.rn.f32 	%f1593, %f1992, %f1846, %f1592;
	fma.rn.f32 	%f1991, %f1993, %f1837, %f1589;
	fma.rn.f32 	%f1992, %f1993, %f1841, %f1591;
	fma.rn.f32 	%f1993, %f1993, %f1845, %f1593;
	ld.const.u64 	%rd557, [params+112];
	setp.eq.s64	%p125, %rd557, 0;
	mov.f32 	%f1985, %f1988;
	mov.f32 	%f1986, %f1989;
	mov.f32 	%f1987, %f1990;
	@%p125 bra 	BB10_158;

	mul.f32 	%f1594, %f1988, %f1902;
	fma.rn.f32 	%f1595, %f1989, %f1905, %f1594;
	mul.f32 	%f1596, %f1988, %f1901;
	fma.rn.f32 	%f1597, %f1989, %f1904, %f1596;
	mul.f32 	%f1598, %f1988, %f1900;
	fma.rn.f32 	%f1599, %f1989, %f1903, %f1598;
	fma.rn.f32 	%f1600, %f1990, %f1908, %f1595;
	fma.rn.f32 	%f1601, %f1990, %f1907, %f1597;
	fma.rn.f32 	%f1602, %f1990, %f1906, %f1599;
	mul.f32 	%f1603, %f1600, %f1600;
	fma.rn.f32 	%f1604, %f1601, %f1601, %f1603;
	fma.rn.f32 	%f1605, %f1602, %f1602, %f1604;
	sqrt.rn.f32 	%f1606, %f1605;
	div.rn.f32 	%f1985, %f1600, %f1606;
	div.rn.f32 	%f1986, %f1601, %f1606;
	div.rn.f32 	%f1987, %f1602, %f1606;

BB10_158:
	ld.const.u64 	%rd558, [params+136];
	setp.eq.s64	%p126, %rd558, 0;
	@%p126 bra 	BB10_160;

	mul.f32 	%f1607, %f1988, %f1902;
	fma.rn.f32 	%f1608, %f1989, %f1905, %f1607;
	mul.f32 	%f1609, %f1988, %f1901;
	fma.rn.f32 	%f1610, %f1989, %f1904, %f1609;
	mul.f32 	%f1611, %f1988, %f1900;
	fma.rn.f32 	%f1612, %f1989, %f1903, %f1611;
	fma.rn.f32 	%f1613, %f1990, %f1908, %f1608;
	fma.rn.f32 	%f1614, %f1990, %f1907, %f1610;
	fma.rn.f32 	%f1615, %f1990, %f1906, %f1612;
	mul.f32 	%f1616, %f1613, %f1613;
	fma.rn.f32 	%f1617, %f1614, %f1614, %f1616;
	fma.rn.f32 	%f1618, %f1615, %f1615, %f1617;
	sqrt.rn.f32 	%f1619, %f1618;
	div.rn.f32 	%f1988, %f1613, %f1619;
	div.rn.f32 	%f1989, %f1614, %f1619;
	div.rn.f32 	%f1990, %f1615, %f1619;

BB10_160:
	ld.const.u64 	%rd559, [params+184];
	setp.eq.s64	%p127, %rd559, 0;
	mov.f32 	%f1974, 0f00000000;
	mov.f32 	%f1975, 0f3F800000;
	mov.f32 	%f1979, %f1973;
	mov.f32 	%f1980, %f1974;
	mov.f32 	%f1981, %f1975;
	mov.f32 	%f1982, %f1976;
	mov.f32 	%f1983, %f1975;
	mov.f32 	%f1984, %f1974;
	@%p127 bra 	BB10_162;

	mul.f32 	%f1624, %f1976, %f1839;
	mov.f32 	%f1625, 0f3F800000;
	fma.rn.f32 	%f1626, %f1625, %f1838, %f1624;
	mul.f32 	%f1627, %f1976, %f1843;
	fma.rn.f32 	%f1628, %f1625, %f1842, %f1627;
	mul.f32 	%f1629, %f1976, %f1847;
	fma.rn.f32 	%f1630, %f1625, %f1846, %f1629;
	mov.f32 	%f1631, 0f00000000;
	fma.rn.f32 	%f1982, %f1631, %f1837, %f1626;
	fma.rn.f32 	%f1983, %f1631, %f1841, %f1628;
	fma.rn.f32 	%f1984, %f1631, %f1845, %f1630;
	mul.f32 	%f1632, %f1973, %f1839;
	fma.rn.f32 	%f1633, %f1631, %f1838, %f1632;
	mul.f32 	%f1634, %f1973, %f1843;
	fma.rn.f32 	%f1635, %f1631, %f1842, %f1634;
	mul.f32 	%f1636, %f1973, %f1847;
	fma.rn.f32 	%f1637, %f1631, %f1846, %f1636;
	fma.rn.f32 	%f1979, %f1625, %f1837, %f1633;
	fma.rn.f32 	%f1980, %f1625, %f1841, %f1635;
	fma.rn.f32 	%f1981, %f1625, %f1845, %f1637;

BB10_162:
	ld.const.u64 	%rd560, [params+280];
	ld.const.u64 	%rd561, [params+232];
	or.b64  	%rd562, %rd560, %rd561;
	setp.eq.s64	%p128, %rd562, 0;
	@%p128 bra 	BB10_163;

	mul.f32 	%f1642, %f1988, %f1839;
	fma.rn.f32 	%f1643, %f1989, %f1843, %f1642;
	mul.f32 	%f1644, %f1988, %f1838;
	fma.rn.f32 	%f1645, %f1989, %f1842, %f1644;
	mul.f32 	%f1646, %f1988, %f1837;
	fma.rn.f32 	%f1647, %f1989, %f1841, %f1646;
	fma.rn.f32 	%f1648, %f1990, %f1847, %f1643;
	fma.rn.f32 	%f1649, %f1990, %f1846, %f1645;
	fma.rn.f32 	%f1650, %f1990, %f1845, %f1647;
	mul.f32 	%f1651, %f1648, %f1648;
	fma.rn.f32 	%f1652, %f1649, %f1649, %f1651;
	fma.rn.f32 	%f1653, %f1650, %f1650, %f1652;
	sqrt.rn.f32 	%f1654, %f1653;
	div.rn.f32 	%f1655, %f1648, %f1654;
	div.rn.f32 	%f1656, %f1649, %f1654;
	div.rn.f32 	%f1657, %f1650, %f1654;
	mul.f32 	%f1658, %f1655, %f1902;
	mul.f32 	%f1659, %f1655, %f1901;
	mul.f32 	%f1660, %f1655, %f1900;
	fma.rn.f32 	%f1661, %f1656, %f1905, %f1658;
	fma.rn.f32 	%f1662, %f1656, %f1904, %f1659;
	fma.rn.f32 	%f1663, %f1656, %f1903, %f1660;
	fma.rn.f32 	%f1664, %f1657, %f1908, %f1661;
	fma.rn.f32 	%f1665, %f1657, %f1907, %f1662;
	fma.rn.f32 	%f1666, %f1657, %f1906, %f1663;
	mul.f32 	%f1667, %f1664, %f1664;
	fma.rn.f32 	%f1668, %f1665, %f1665, %f1667;
	fma.rn.f32 	%f1669, %f1666, %f1666, %f1668;
	sqrt.rn.f32 	%f1670, %f1669;
	rcp.rn.f32 	%f1671, %f1670;
	mul.f32 	%f1672, %f1671, %f1664;
	mul.f32 	%f1673, %f1671, %f1665;
	mul.f32 	%f1674, %f1671, %f1666;
	mul.f32 	%f1675, %f1976, %f1902;
	mov.f32 	%f1676, 0f3F800000;
	fma.rn.f32 	%f1677, %f1676, %f1905, %f1675;
	mul.f32 	%f1678, %f1976, %f1901;
	fma.rn.f32 	%f1679, %f1676, %f1904, %f1678;
	mul.f32 	%f1680, %f1976, %f1900;
	fma.rn.f32 	%f1681, %f1676, %f1903, %f1680;
	mov.f32 	%f1682, 0f00000000;
	fma.rn.f32 	%f1683, %f1682, %f1908, %f1677;
	fma.rn.f32 	%f1684, %f1682, %f1907, %f1679;
	fma.rn.f32 	%f1685, %f1682, %f1906, %f1681;
	mul.f32 	%f1686, %f1683, %f1671;
	mul.f32 	%f1687, %f1684, %f1671;
	mul.f32 	%f1688, %f1685, %f1671;
	mul.f32 	%f1689, %f1973, %f1902;
	fma.rn.f32 	%f1690, %f1682, %f1905, %f1689;
	mul.f32 	%f1691, %f1973, %f1901;
	fma.rn.f32 	%f1692, %f1682, %f1904, %f1691;
	mul.f32 	%f1693, %f1973, %f1900;
	fma.rn.f32 	%f1694, %f1682, %f1903, %f1693;
	fma.rn.f32 	%f1695, %f1676, %f1908, %f1690;
	fma.rn.f32 	%f1696, %f1676, %f1907, %f1692;
	fma.rn.f32 	%f1697, %f1676, %f1906, %f1694;
	mul.f32 	%f1698, %f1695, %f1671;
	mul.f32 	%f1699, %f1696, %f1671;
	mul.f32 	%f1700, %f1697, %f1671;
	mul.f32 	%f1701, %f1672, %f1686;
	fma.rn.f32 	%f1702, %f1673, %f1687, %f1701;
	fma.rn.f32 	%f1703, %f1674, %f1688, %f1702;
	mul.f32 	%f1704, %f1672, %f1703;
	mul.f32 	%f1705, %f1673, %f1703;
	mul.f32 	%f1706, %f1674, %f1703;
	sub.f32 	%f1976, %f1686, %f1704;
	sub.f32 	%f1977, %f1687, %f1705;
	sub.f32 	%f1978, %f1688, %f1706;
	mul.f32 	%f1707, %f1672, %f1698;
	fma.rn.f32 	%f1708, %f1673, %f1699, %f1707;
	fma.rn.f32 	%f1709, %f1674, %f1700, %f1708;
	mul.f32 	%f1710, %f1672, %f1709;
	mul.f32 	%f1711, %f1673, %f1709;
	mul.f32 	%f1712, %f1674, %f1709;
	sub.f32 	%f1973, %f1698, %f1710;
	sub.f32 	%f1974, %f1699, %f1711;
	sub.f32 	%f1975, %f1700, %f1712;
	bra.uni 	BB10_165;

BB10_118:
	mov.f32 	%f1977, %f1975;
	mov.f32 	%f1978, %f1974;
	mov.f32 	%f1979, %f1973;
	mov.f32 	%f1980, %f1974;
	mov.f32 	%f1981, %f1975;
	mov.f32 	%f1982, %f1976;
	mov.f32 	%f1983, %f1975;
	mov.f32 	%f1984, %f1974;
	mov.f32 	%f1985, %f1988;
	mov.f32 	%f1986, %f1989;
	mov.f32 	%f1987, %f1990;
	bra.uni 	BB10_166;

BB10_163:
	mov.f32 	%f1977, %f1975;
	mov.f32 	%f1978, %f1974;

BB10_165:
	st.global.u32 	[%rd27], %r431;

BB10_166:
	ld.const.u64 	%rd563, [params+328];
	cvta.to.global.u64 	%rd564, %rd563;
	shl.b64 	%rd565, %rd26, 3;
	add.s64 	%rd566, %rd564, %rd565;
	st.global.u64 	[%rd566], %rd25;
	ld.const.u64 	%rd567, [params+336];
	cvta.to.global.u64 	%rd568, %rd567;
	shl.b64 	%rd569, %rd26, 2;
	add.s64 	%rd570, %rd568, %rd569;
	mov.u32 	%r731, 0;
	st.global.u32 	[%rd570], %r731;
	ld.const.u64 	%rd571, [params+160];
	cvta.to.global.u64 	%rd572, %rd571;
	add.s64 	%rd573, %rd572, %rd569;
	st.global.f32 	[%rd573], %f1991;
	ld.const.u64 	%rd574, [params+168];
	cvta.to.global.u64 	%rd575, %rd574;
	add.s64 	%rd576, %rd575, %rd569;
	st.global.f32 	[%rd576], %f1992;
	ld.const.u64 	%rd577, [params+176];
	cvta.to.global.u64 	%rd578, %rd577;
	add.s64 	%rd579, %rd578, %rd569;
	st.global.f32 	[%rd579], %f1993;
	ld.const.u64 	%rd580, [params+72];
	cvta.to.global.u64 	%rd581, %rd580;
	add.s64 	%rd582, %rd581, %rd569;
	st.global.f32 	[%rd582], %f1132;
	@%p103 bra 	BB10_168;

	cvta.to.global.u64 	%rd583, %rd24;
	add.s64 	%rd585, %rd583, %rd569;
	st.global.f32 	[%rd585], %f1834;
	ld.const.u64 	%rd586, [params+104];
	cvta.to.global.u64 	%rd587, %rd586;
	add.s64 	%rd588, %rd587, %rd569;
	st.global.f32 	[%rd588], %f1835;

BB10_168:
	ld.const.u64 	%rd44, [params+112];
	setp.eq.s64	%p130, %rd44, 0;
	@%p130 bra 	BB10_170;

	cvta.to.global.u64 	%rd589, %rd44;
	add.s64 	%rd591, %rd589, %rd569;
	st.global.f32 	[%rd591], %f1985;
	ld.const.u64 	%rd592, [params+120];
	cvta.to.global.u64 	%rd593, %rd592;
	add.s64 	%rd594, %rd593, %rd569;
	st.global.f32 	[%rd594], %f1986;
	ld.const.u64 	%rd595, [params+128];
	cvta.to.global.u64 	%rd596, %rd595;
	add.s64 	%rd597, %rd596, %rd569;
	st.global.f32 	[%rd597], %f1987;

BB10_170:
	ld.const.u64 	%rd45, [params+136];
	setp.eq.s64	%p131, %rd45, 0;
	@%p131 bra 	BB10_172;

	cvta.to.global.u64 	%rd598, %rd45;
	add.s64 	%rd600, %rd598, %rd569;
	st.global.f32 	[%rd600], %f1988;
	ld.const.u64 	%rd601, [params+144];
	cvta.to.global.u64 	%rd602, %rd601;
	add.s64 	%rd603, %rd602, %rd569;
	st.global.f32 	[%rd603], %f1989;
	ld.const.u64 	%rd604, [params+152];
	cvta.to.global.u64 	%rd605, %rd604;
	add.s64 	%rd606, %rd605, %rd569;
	st.global.f32 	[%rd606], %f1990;

BB10_172:
	ld.const.u64 	%rd46, [params+184];
	setp.eq.s64	%p132, %rd46, 0;
	@%p132 bra 	BB10_174;

	cvta.to.global.u64 	%rd607, %rd46;
	add.s64 	%rd609, %rd607, %rd569;
	st.global.f32 	[%rd609], %f1982;
	ld.const.u64 	%rd610, [params+192];
	cvta.to.global.u64 	%rd611, %rd610;
	add.s64 	%rd612, %rd611, %rd569;
	st.global.f32 	[%rd612], %f1983;
	ld.const.u64 	%rd613, [params+200];
	cvta.to.global.u64 	%rd614, %rd613;
	add.s64 	%rd615, %rd614, %rd569;
	st.global.f32 	[%rd615], %f1984;
	ld.const.u64 	%rd616, [params+208];
	cvta.to.global.u64 	%rd617, %rd616;
	add.s64 	%rd618, %rd617, %rd569;
	st.global.f32 	[%rd618], %f1979;
	ld.const.u64 	%rd619, [params+216];
	cvta.to.global.u64 	%rd620, %rd619;
	add.s64 	%rd621, %rd620, %rd569;
	st.global.f32 	[%rd621], %f1980;
	ld.const.u64 	%rd622, [params+224];
	cvta.to.global.u64 	%rd623, %rd622;
	add.s64 	%rd624, %rd623, %rd569;
	st.global.f32 	[%rd624], %f1981;

BB10_174:
	ld.const.u64 	%rd47, [params+232];
	setp.eq.s64	%p133, %rd47, 0;
	@%p133 bra 	BB10_176;

	cvta.to.global.u64 	%rd625, %rd47;
	add.s64 	%rd627, %rd625, %rd569;
	st.global.f32 	[%rd627], %f1976;
	ld.const.u64 	%rd628, [params+240];
	cvta.to.global.u64 	%rd629, %rd628;
	add.s64 	%rd630, %rd629, %rd569;
	st.global.f32 	[%rd630], %f1977;
	ld.const.u64 	%rd631, [params+248];
	cvta.to.global.u64 	%rd632, %rd631;
	add.s64 	%rd633, %rd632, %rd569;
	st.global.f32 	[%rd633], %f1978;
	ld.const.u64 	%rd634, [params+256];
	cvta.to.global.u64 	%rd635, %rd634;
	add.s64 	%rd636, %rd635, %rd569;
	st.global.f32 	[%rd636], %f1973;
	ld.const.u64 	%rd637, [params+264];
	cvta.to.global.u64 	%rd638, %rd637;
	add.s64 	%rd639, %rd638, %rd569;
	st.global.f32 	[%rd639], %f1974;
	ld.const.u64 	%rd640, [params+272];
	cvta.to.global.u64 	%rd641, %rd640;
	add.s64 	%rd642, %rd641, %rd569;
	st.global.f32 	[%rd642], %f1975;

BB10_176:
	ld.const.u64 	%rd48, [params+280];
	setp.eq.s64	%p134, %rd48, 0;
	@%p134 bra 	BB10_178;

	cvta.to.global.u64 	%rd643, %rd48;
	add.s64 	%rd645, %rd643, %rd569;
	st.global.f32 	[%rd645], %f1976;
	ld.const.u64 	%rd646, [params+288];
	cvta.to.global.u64 	%rd647, %rd646;
	add.s64 	%rd648, %rd647, %rd569;
	st.global.f32 	[%rd648], %f1977;
	ld.const.u64 	%rd649, [params+296];
	cvta.to.global.u64 	%rd650, %rd649;
	add.s64 	%rd651, %rd650, %rd569;
	st.global.f32 	[%rd651], %f1978;
	ld.const.u64 	%rd652, [params+304];
	cvta.to.global.u64 	%rd653, %rd652;
	add.s64 	%rd654, %rd653, %rd569;
	st.global.f32 	[%rd654], %f1973;
	ld.const.u64 	%rd655, [params+312];
	cvta.to.global.u64 	%rd656, %rd655;
	add.s64 	%rd657, %rd656, %rd569;
	st.global.f32 	[%rd657], %f1974;
	ld.const.u64 	%rd658, [params+320];
	cvta.to.global.u64 	%rd659, %rd658;
	add.s64 	%rd660, %rd659, %rd569;
	st.global.f32 	[%rd660], %f1975;

BB10_178:
	ret;
}

	// .globl	__intersection__cylhollow
.visible .entry __intersection__cylhollow(

)
{
	.reg .pred 	%p<334>;
	.reg .b16 	%rs<27>;
	.reg .f32 	%f<2395>;
	.reg .b32 	%r<427>;
	.reg .b64 	%rd<266>;


	// inline asm
	call (%rd19), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd1, [%rd19+8];
	// inline asm
	call (%f571), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f572), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f2292), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r14), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p11, %r14, 0;
	@%p11 bra 	BB11_1;

	mov.u32 	%r425, 0;
	// inline asm
	call (%f574), _optix_get_ray_time, ();
	// inline asm

BB11_3:
	.pragma "nounroll";
	// inline asm
	call (%rd20), _optix_get_transform_list_handle, (%r425);
	// inline asm
	// inline asm
	call (%r17), _optix_get_transform_type_from_handle, (%rd20);
	// inline asm
	and.b32  	%r18, %r17, -2;
	setp.eq.s32	%p12, %r18, 2;
	@%p12 bra 	BB11_9;
	bra.uni 	BB11_4;

BB11_9:
	setp.eq.s32	%p15, %r17, 2;
	@%p15 bra 	BB11_13;
	bra.uni 	BB11_10;

BB11_13:
	// inline asm
	call (%rd94), _optix_get_matrix_motion_transform_from_handle, (%rd20);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd96, %rd94;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd96];
	// inline asm
	mov.b32	{%rs9, %rs10}, %r108;
	add.s64 	%rd100, %rd94, 16;
	// inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd99];
	// inline asm
	add.s64 	%rd103, %rd94, 32;
	// inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd102];
	// inline asm
	add.s64 	%rd106, %rd94, 48;
	// inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd105];
	// inline asm
	add.s64 	%rd109, %rd94, 64;
	// inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd108];
	// inline asm
	add.s64 	%rd112, %rd94, 80;
	// inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd111];
	// inline asm
	add.s64 	%rd115, %rd94, 96;
	// inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd114];
	// inline asm
	add.s64 	%rd118, %rd94, 112;
	// inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd117];
	// inline asm
	mov.b32 	 %f701, %r109;
	mov.b32 	 %f702, %r110;
	cvt.u32.u16	%r150, %rs9;
	add.s32 	%r151, %r150, -1;
	cvt.rn.f32.s32	%f703, %r151;
	sub.f32 	%f704, %f574, %f701;
	mul.f32 	%f705, %f704, %f703;
	sub.f32 	%f706, %f702, %f701;
	div.rn.f32 	%f707, %f705, %f706;
	min.f32 	%f708, %f703, %f707;
	mov.f32 	%f709, 0f00000000;
	max.f32 	%f710, %f709, %f708;
	cvt.rmi.f32.f32	%f711, %f710;
	cvt.rzi.s32.f32	%r152, %f711;
	mul.wide.s32 	%rd129, %r152, 48;
	add.s64 	%rd121, %rd103, %rd129;
	// inline asm
	cvta.to.global.u64 %rd120, %rd121;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd120];
	// inline asm
	mov.b32 	 %f2264, %r138;
	mov.b32 	 %f2265, %r139;
	mov.b32 	 %f2266, %r140;
	mov.b32 	 %f2267, %r141;
	add.s64 	%rd124, %rd121, 16;
	// inline asm
	cvta.to.global.u64 %rd123, %rd124;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd123];
	// inline asm
	mov.b32 	 %f2260, %r142;
	mov.b32 	 %f2261, %r143;
	mov.b32 	 %f2262, %r144;
	mov.b32 	 %f2263, %r145;
	add.s64 	%rd127, %rd121, 32;
	// inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd126];
	// inline asm
	sub.f32 	%f98, %f710, %f711;
	mov.b32 	 %f2256, %r146;
	mov.b32 	 %f2257, %r147;
	mov.b32 	 %f2258, %r148;
	mov.b32 	 %f2259, %r149;
	setp.leu.f32	%p17, %f98, 0f00000000;
	@%p17 bra 	BB11_15;

	cvt.rmi.f32.f32	%f2210, %f710;
	cvt.rzi.s32.f32	%r424, %f2210;
	cvt.s64.s32	%rd263, %r424;
	mul.lo.s64 	%rd139, %rd263, 48;
	add.s64 	%rd140, %rd94, %rd139;
	add.s64 	%rd131, %rd140, 80;
	// inline asm
	cvta.to.global.u64 %rd130, %rd131;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd130];
	// inline asm
	mov.b32 	 %f712, %r153;
	mov.b32 	 %f713, %r154;
	mov.b32 	 %f714, %r155;
	mov.b32 	 %f715, %r156;
	add.s64 	%rd134, %rd140, 96;
	// inline asm
	cvta.to.global.u64 %rd133, %rd134;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd133];
	// inline asm
	mov.b32 	 %f716, %r157;
	mov.b32 	 %f717, %r158;
	mov.b32 	 %f718, %r159;
	mov.b32 	 %f719, %r160;
	add.s64 	%rd137, %rd140, 112;
	// inline asm
	cvta.to.global.u64 %rd136, %rd137;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd136];
	// inline asm
	mov.f32 	%f720, 0f3F800000;
	sub.f32 	%f721, %f720, %f98;
	mul.f32 	%f722, %f98, %f712;
	mul.f32 	%f723, %f98, %f713;
	mul.f32 	%f724, %f98, %f714;
	mul.f32 	%f725, %f98, %f715;
	fma.rn.f32 	%f2264, %f721, %f2264, %f722;
	fma.rn.f32 	%f2265, %f721, %f2265, %f723;
	fma.rn.f32 	%f2266, %f721, %f2266, %f724;
	fma.rn.f32 	%f2267, %f721, %f2267, %f725;
	mul.f32 	%f726, %f98, %f716;
	mul.f32 	%f727, %f98, %f717;
	mul.f32 	%f728, %f98, %f718;
	mul.f32 	%f729, %f98, %f719;
	fma.rn.f32 	%f2260, %f721, %f2260, %f726;
	fma.rn.f32 	%f2261, %f721, %f2261, %f727;
	fma.rn.f32 	%f2262, %f721, %f2262, %f728;
	fma.rn.f32 	%f2263, %f721, %f2263, %f729;
	mov.b32 	 %f730, %r161;
	mov.b32 	 %f731, %r162;
	mov.b32 	 %f732, %r163;
	mov.b32 	 %f733, %r164;
	mul.f32 	%f734, %f98, %f730;
	mul.f32 	%f735, %f98, %f731;
	mul.f32 	%f736, %f98, %f732;
	mul.f32 	%f737, %f98, %f733;
	fma.rn.f32 	%f2256, %f721, %f2256, %f734;
	fma.rn.f32 	%f2257, %f721, %f2257, %f735;
	fma.rn.f32 	%f2258, %f721, %f2258, %f736;
	fma.rn.f32 	%f2259, %f721, %f2259, %f737;
	bra.uni 	BB11_15;

BB11_4:
	mov.f32 	%f2268, 0f00000000;
	mov.f32 	%f2270, 0f3F800000;
	setp.eq.s32	%p13, %r17, 4;
	@%p13 bra 	BB11_7;
	bra.uni 	BB11_5;

BB11_7:
	// inline asm
	call (%rd264), _optix_get_instance_inverse_transform_from_handle, (%rd20);
	// inline asm
	bra.uni 	BB11_8;

BB11_10:
	// inline asm
	call (%rd35), _optix_get_srt_motion_transform_from_handle, (%rd20);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd37, %rd35;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd37];
	// inline asm
	mov.b32	{%rs7, %rs8}, %r33;
	add.s64 	%rd41, %rd35, 16;
	// inline asm
	cvta.to.global.u64 %rd40, %rd41;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd40];
	// inline asm
	add.s64 	%rd44, %rd35, 32;
	// inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd43];
	// inline asm
	add.s64 	%rd47, %rd35, 48;
	// inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd46];
	// inline asm
	add.s64 	%rd50, %rd35, 64;
	// inline asm
	cvta.to.global.u64 %rd49, %rd50;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd49];
	// inline asm
	add.s64 	%rd53, %rd35, 80;
	// inline asm
	cvta.to.global.u64 %rd52, %rd53;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd52];
	// inline asm
	add.s64 	%rd56, %rd35, 96;
	// inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd55];
	// inline asm
	add.s64 	%rd59, %rd35, 112;
	// inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd58];
	// inline asm
	add.s64 	%rd62, %rd35, 128;
	// inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd61];
	// inline asm
	add.s64 	%rd65, %rd35, 144;
	// inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd64];
	// inline asm
	mov.b32 	 %f588, %r34;
	mov.b32 	 %f589, %r35;
	cvt.u32.u16	%r87, %rs7;
	add.s32 	%r88, %r87, -1;
	cvt.rn.f32.s32	%f590, %r88;
	sub.f32 	%f591, %f574, %f588;
	mul.f32 	%f592, %f591, %f590;
	sub.f32 	%f593, %f589, %f588;
	div.rn.f32 	%f594, %f592, %f593;
	min.f32 	%f595, %f590, %f594;
	mov.f32 	%f596, 0f00000000;
	max.f32 	%f597, %f596, %f595;
	cvt.rmi.f32.f32	%f598, %f597;
	cvt.rzi.s32.f32	%r89, %f598;
	mul.wide.s32 	%rd79, %r89, 64;
	add.s64 	%rd68, %rd44, %rd79;
	// inline asm
	cvta.to.global.u64 %rd67, %rd68;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd67];
	// inline asm
	mov.b32 	 %f2240, %r71;
	mov.b32 	 %f2241, %r72;
	mov.b32 	 %f2242, %r73;
	mov.b32 	 %f2243, %r74;
	add.s64 	%rd71, %rd68, 16;
	// inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd70];
	// inline asm
	mov.b32 	 %f2244, %r75;
	mov.b32 	 %f2245, %r76;
	mov.b32 	 %f2246, %r77;
	mov.b32 	 %f2247, %r78;
	add.s64 	%rd74, %rd68, 32;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd73];
	// inline asm
	sub.f32 	%f37, %f597, %f598;
	mov.b32 	 %f2248, %r79;
	mov.b32 	 %f2249, %r80;
	mov.b32 	 %f2250, %r81;
	mov.b32 	 %f2251, %r82;
	add.s64 	%rd77, %rd68, 48;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd76];
	// inline asm
	mov.b32 	 %f2252, %r83;
	mov.b32 	 %f2253, %r84;
	mov.b32 	 %f2254, %r85;
	mov.b32 	 %f2255, %r86;
	setp.leu.f32	%p16, %f37, 0f00000000;
	@%p16 bra 	BB11_12;

	cvt.rmi.f32.f32	%f2209, %f597;
	cvt.rzi.s32.f32	%r423, %f2209;
	cvt.s64.s32	%rd262, %r423;
	shl.b64 	%rd92, %rd262, 6;
	add.s64 	%rd93, %rd92, %rd35;
	add.s64 	%rd81, %rd93, 96;
	// inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd80];
	// inline asm
	mov.b32 	 %f599, %r90;
	mov.b32 	 %f600, %r91;
	mov.b32 	 %f601, %r92;
	mov.b32 	 %f602, %r93;
	add.s64 	%rd84, %rd93, 112;
	// inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd83];
	// inline asm
	mov.b32 	 %f603, %r94;
	mov.b32 	 %f604, %r95;
	mov.b32 	 %f605, %r96;
	mov.b32 	 %f606, %r97;
	add.s64 	%rd87, %rd93, 128;
	// inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd86];
	// inline asm
	mov.b32 	 %f607, %r98;
	mov.b32 	 %f608, %r99;
	mov.b32 	 %f609, %r100;
	mov.b32 	 %f610, %r101;
	add.s64 	%rd90, %rd93, 144;
	// inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd89];
	// inline asm
	mov.f32 	%f611, 0f3F800000;
	sub.f32 	%f612, %f611, %f37;
	mul.f32 	%f613, %f37, %f599;
	mul.f32 	%f614, %f37, %f600;
	mul.f32 	%f615, %f37, %f601;
	mul.f32 	%f616, %f37, %f602;
	fma.rn.f32 	%f2240, %f612, %f2240, %f613;
	fma.rn.f32 	%f2241, %f612, %f2241, %f614;
	fma.rn.f32 	%f2242, %f612, %f2242, %f615;
	fma.rn.f32 	%f2243, %f612, %f2243, %f616;
	mul.f32 	%f617, %f37, %f603;
	mul.f32 	%f618, %f37, %f604;
	mul.f32 	%f619, %f37, %f605;
	mul.f32 	%f620, %f37, %f606;
	fma.rn.f32 	%f2244, %f612, %f2244, %f617;
	fma.rn.f32 	%f2245, %f612, %f2245, %f618;
	fma.rn.f32 	%f2246, %f612, %f2246, %f619;
	fma.rn.f32 	%f2247, %f612, %f2247, %f620;
	mul.f32 	%f621, %f37, %f607;
	mul.f32 	%f622, %f37, %f608;
	mul.f32 	%f623, %f37, %f609;
	mul.f32 	%f624, %f37, %f610;
	fma.rn.f32 	%f2248, %f612, %f2248, %f621;
	fma.rn.f32 	%f625, %f612, %f2249, %f622;
	fma.rn.f32 	%f626, %f612, %f2250, %f623;
	fma.rn.f32 	%f627, %f612, %f2251, %f624;
	mov.b32 	 %f628, %r102;
	mov.b32 	 %f629, %r103;
	mov.b32 	 %f630, %r104;
	mov.b32 	 %f631, %r105;
	mul.f32 	%f632, %f37, %f628;
	mul.f32 	%f633, %f37, %f629;
	mul.f32 	%f634, %f37, %f630;
	mul.f32 	%f635, %f37, %f631;
	fma.rn.f32 	%f636, %f612, %f2252, %f632;
	fma.rn.f32 	%f2253, %f612, %f2253, %f633;
	fma.rn.f32 	%f2254, %f612, %f2254, %f634;
	fma.rn.f32 	%f2255, %f612, %f2255, %f635;
	mul.f32 	%f637, %f626, %f626;
	fma.rn.f32 	%f638, %f625, %f625, %f637;
	fma.rn.f32 	%f639, %f627, %f627, %f638;
	fma.rn.f32 	%f640, %f636, %f636, %f639;
	sqrt.rn.f32 	%f641, %f640;
	rcp.rn.f32 	%f642, %f641;
	mul.f32 	%f2249, %f625, %f642;
	mul.f32 	%f2250, %f626, %f642;
	mul.f32 	%f2251, %f627, %f642;
	mul.f32 	%f2252, %f636, %f642;

BB11_12:
	mul.f32 	%f643, %f2250, %f2250;
	fma.rn.f32 	%f644, %f2249, %f2249, %f643;
	fma.rn.f32 	%f645, %f2251, %f2251, %f644;
	fma.rn.f32 	%f646, %f2252, %f2252, %f645;
	rcp.rn.f32 	%f647, %f646;
	mul.f32 	%f648, %f2249, %f647;
	mul.f32 	%f649, %f2250, %f647;
	mul.f32 	%f650, %f2251, %f647;
	mul.f32 	%f651, %f2252, %f647;
	mul.f32 	%f652, %f2249, %f648;
	mul.f32 	%f653, %f2250, %f649;
	mul.f32 	%f654, %f2251, %f650;
	mul.f32 	%f655, %f2249, %f649;
	mul.f32 	%f656, %f2251, %f651;
	mul.f32 	%f657, %f2249, %f650;
	mul.f32 	%f658, %f2250, %f651;
	mul.f32 	%f659, %f2250, %f650;
	mul.f32 	%f660, %f2249, %f651;
	sub.f32 	%f661, %f652, %f653;
	sub.f32 	%f662, %f661, %f654;
	fma.rn.f32 	%f663, %f2252, %f651, %f662;
	sub.f32 	%f664, %f655, %f656;
	add.f32 	%f665, %f664, %f664;
	add.f32 	%f666, %f657, %f658;
	add.f32 	%f667, %f666, %f666;
	add.f32 	%f668, %f655, %f656;
	add.f32 	%f669, %f668, %f668;
	sub.f32 	%f670, %f653, %f652;
	sub.f32 	%f671, %f670, %f654;
	fma.rn.f32 	%f672, %f2252, %f651, %f671;
	sub.f32 	%f673, %f659, %f660;
	add.f32 	%f674, %f673, %f673;
	sub.f32 	%f675, %f657, %f658;
	add.f32 	%f676, %f675, %f675;
	add.f32 	%f677, %f659, %f660;
	add.f32 	%f678, %f677, %f677;
	neg.f32 	%f679, %f652;
	sub.f32 	%f680, %f679, %f653;
	add.f32 	%f681, %f654, %f680;
	fma.rn.f32 	%f682, %f2252, %f651, %f681;
	mul.f32 	%f683, %f2243, %f663;
	fma.rn.f32 	%f684, %f2246, %f665, %f683;
	fma.rn.f32 	%f685, %f2248, %f667, %f684;
	sub.f32 	%f2267, %f2253, %f685;
	mul.f32 	%f686, %f2246, %f672;
	fma.rn.f32 	%f687, %f2243, %f669, %f686;
	fma.rn.f32 	%f688, %f2248, %f674, %f687;
	sub.f32 	%f2263, %f2254, %f688;
	mul.f32 	%f689, %f2246, %f678;
	fma.rn.f32 	%f690, %f2243, %f676, %f689;
	fma.rn.f32 	%f691, %f2248, %f682, %f690;
	sub.f32 	%f2259, %f2255, %f691;
	mul.f32 	%f692, %f2242, %f663;
	fma.rn.f32 	%f693, %f2245, %f665, %f692;
	fma.rn.f32 	%f2266, %f2247, %f667, %f693;
	mul.f32 	%f694, %f2245, %f672;
	fma.rn.f32 	%f695, %f2242, %f669, %f694;
	fma.rn.f32 	%f2262, %f2247, %f674, %f695;
	mul.f32 	%f696, %f2245, %f678;
	fma.rn.f32 	%f697, %f2242, %f676, %f696;
	fma.rn.f32 	%f2258, %f2247, %f682, %f697;
	mul.f32 	%f698, %f2241, %f663;
	fma.rn.f32 	%f2265, %f2244, %f665, %f698;
	mul.f32 	%f699, %f2244, %f672;
	fma.rn.f32 	%f2261, %f2241, %f669, %f699;
	mul.f32 	%f700, %f2244, %f678;
	fma.rn.f32 	%f2257, %f2241, %f676, %f700;
	mul.f32 	%f2264, %f2240, %f663;
	mul.f32 	%f2260, %f2240, %f669;
	mul.f32 	%f2256, %f2240, %f676;

BB11_15:
	mul.f32 	%f738, %f2257, %f2262;
	mul.f32 	%f739, %f2258, %f2261;
	sub.f32 	%f740, %f739, %f738;
	mul.f32 	%f741, %f2264, %f740;
	mul.f32 	%f742, %f2256, %f2262;
	mul.f32 	%f743, %f2258, %f2260;
	sub.f32 	%f744, %f743, %f742;
	mul.f32 	%f745, %f744, %f2265;
	sub.f32 	%f746, %f741, %f745;
	mul.f32 	%f747, %f2256, %f2261;
	mul.f32 	%f748, %f2257, %f2260;
	sub.f32 	%f749, %f748, %f747;
	fma.rn.f32 	%f750, %f749, %f2266, %f746;
	rcp.rn.f32 	%f751, %f750;
	mul.f32 	%f2276, %f740, %f751;
	mul.f32 	%f752, %f2258, %f2265;
	mul.f32 	%f753, %f2257, %f2266;
	sub.f32 	%f754, %f753, %f752;
	mul.f32 	%f2277, %f751, %f754;
	mul.f32 	%f755, %f2261, %f2266;
	mul.f32 	%f756, %f2262, %f2265;
	sub.f32 	%f757, %f756, %f755;
	mul.f32 	%f2278, %f751, %f757;
	sub.f32 	%f758, %f742, %f743;
	mul.f32 	%f2272, %f758, %f751;
	mul.f32 	%f759, %f2256, %f2266;
	mul.f32 	%f760, %f2258, %f2264;
	sub.f32 	%f761, %f760, %f759;
	mul.f32 	%f2273, %f751, %f761;
	mul.f32 	%f762, %f2262, %f2264;
	mul.f32 	%f763, %f2260, %f2266;
	sub.f32 	%f764, %f763, %f762;
	mul.f32 	%f2274, %f751, %f764;
	mul.f32 	%f2268, %f749, %f751;
	mul.f32 	%f765, %f2257, %f2264;
	mul.f32 	%f766, %f2256, %f2265;
	sub.f32 	%f767, %f766, %f765;
	mul.f32 	%f2269, %f767, %f751;
	mul.f32 	%f768, %f2260, %f2265;
	mul.f32 	%f769, %f2261, %f2264;
	sub.f32 	%f770, %f769, %f768;
	mul.f32 	%f2270, %f770, %f751;
	mul.f32 	%f771, %f2267, %f2276;
	neg.f32 	%f772, %f771;
	mul.f32 	%f773, %f2263, %f2277;
	sub.f32 	%f774, %f772, %f773;
	mul.f32 	%f775, %f2259, %f2278;
	sub.f32 	%f2279, %f774, %f775;
	mul.f32 	%f776, %f2267, %f2272;
	neg.f32 	%f777, %f776;
	mul.f32 	%f778, %f2263, %f2273;
	sub.f32 	%f779, %f777, %f778;
	mul.f32 	%f780, %f2259, %f2274;
	sub.f32 	%f2275, %f779, %f780;
	mul.f32 	%f781, %f2267, %f2268;
	neg.f32 	%f782, %f781;
	mul.f32 	%f783, %f2263, %f2269;
	sub.f32 	%f784, %f782, %f783;
	mul.f32 	%f785, %f2259, %f2270;
	sub.f32 	%f2271, %f784, %f785;
	bra.uni 	BB11_16;

BB11_5:
	setp.ne.s32	%p14, %r17, 1;
	mov.f32 	%f2269, %f2268;
	mov.f32 	%f2271, %f2268;
	mov.f32 	%f2272, %f2268;
	mov.f32 	%f2273, %f2270;
	mov.f32 	%f2274, %f2268;
	mov.f32 	%f2275, %f2268;
	mov.f32 	%f2276, %f2270;
	mov.f32 	%f2277, %f2268;
	mov.f32 	%f2278, %f2268;
	mov.f32 	%f2279, %f2268;
	@%p14 bra 	BB11_16;

	// inline asm
	call (%rd22), _optix_get_static_transform_from_handle, (%rd20);
	// inline asm
	add.s64 	%rd264, %rd22, 64;

BB11_8:
	// inline asm
	cvta.to.global.u64 %rd26, %rd264;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r19,%r20,%r21,%r22}, [%rd26];
	// inline asm
	mov.b32 	 %f2276, %r19;
	mov.b32 	 %f2277, %r20;
	mov.b32 	 %f2278, %r21;
	mov.b32 	 %f2279, %r22;
	add.s64 	%rd30, %rd264, 16;
	// inline asm
	cvta.to.global.u64 %rd29, %rd30;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd29];
	// inline asm
	mov.b32 	 %f2272, %r23;
	mov.b32 	 %f2273, %r24;
	mov.b32 	 %f2274, %r25;
	mov.b32 	 %f2275, %r26;
	add.s64 	%rd33, %rd264, 32;
	// inline asm
	cvta.to.global.u64 %rd32, %rd33;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd32];
	// inline asm
	mov.b32 	 %f2268, %r27;
	mov.b32 	 %f2269, %r28;
	mov.b32 	 %f2270, %r29;
	mov.b32 	 %f2271, %r30;

BB11_16:
	setp.eq.s32	%p18, %r425, 0;
	@%p18 bra 	BB11_17;
	bra.uni 	BB11_18;

BB11_17:
	mov.f32 	%f2239, %f2279;
	mov.f32 	%f2238, %f2278;
	mov.f32 	%f2237, %f2277;
	mov.f32 	%f2236, %f2276;
	mov.f32 	%f2235, %f2275;
	mov.f32 	%f2234, %f2274;
	mov.f32 	%f2233, %f2273;
	mov.f32 	%f2232, %f2272;
	mov.f32 	%f2231, %f2271;
	mov.f32 	%f2230, %f2270;
	mov.f32 	%f2229, %f2269;
	mov.f32 	%f2228, %f2268;
	bra.uni 	BB11_19;

BB11_18:
	mul.f32 	%f786, %f2232, %f2277;
	fma.rn.f32 	%f787, %f2236, %f2276, %f786;
	fma.rn.f32 	%f151, %f2228, %f2278, %f787;
	mul.f32 	%f788, %f2233, %f2277;
	fma.rn.f32 	%f789, %f2237, %f2276, %f788;
	fma.rn.f32 	%f152, %f2229, %f2278, %f789;
	mul.f32 	%f790, %f2234, %f2277;
	fma.rn.f32 	%f791, %f2238, %f2276, %f790;
	fma.rn.f32 	%f153, %f2230, %f2278, %f791;
	mul.f32 	%f792, %f2235, %f2277;
	fma.rn.f32 	%f793, %f2239, %f2276, %f792;
	fma.rn.f32 	%f794, %f2231, %f2278, %f793;
	add.f32 	%f154, %f2279, %f794;
	mul.f32 	%f795, %f2232, %f2273;
	fma.rn.f32 	%f796, %f2236, %f2272, %f795;
	fma.rn.f32 	%f155, %f2228, %f2274, %f796;
	mul.f32 	%f797, %f2233, %f2273;
	fma.rn.f32 	%f798, %f2237, %f2272, %f797;
	fma.rn.f32 	%f156, %f2229, %f2274, %f798;
	mul.f32 	%f799, %f2234, %f2273;
	fma.rn.f32 	%f800, %f2238, %f2272, %f799;
	fma.rn.f32 	%f157, %f2230, %f2274, %f800;
	mul.f32 	%f801, %f2235, %f2273;
	fma.rn.f32 	%f802, %f2239, %f2272, %f801;
	fma.rn.f32 	%f803, %f2231, %f2274, %f802;
	add.f32 	%f158, %f2275, %f803;
	mul.f32 	%f804, %f2232, %f2269;
	fma.rn.f32 	%f805, %f2236, %f2268, %f804;
	fma.rn.f32 	%f2228, %f2228, %f2270, %f805;
	mul.f32 	%f806, %f2233, %f2269;
	fma.rn.f32 	%f807, %f2237, %f2268, %f806;
	fma.rn.f32 	%f2229, %f2229, %f2270, %f807;
	mul.f32 	%f808, %f2234, %f2269;
	fma.rn.f32 	%f809, %f2238, %f2268, %f808;
	fma.rn.f32 	%f2230, %f2230, %f2270, %f809;
	mul.f32 	%f810, %f2235, %f2269;
	fma.rn.f32 	%f811, %f2239, %f2268, %f810;
	fma.rn.f32 	%f812, %f2231, %f2270, %f811;
	add.f32 	%f2231, %f2271, %f812;
	mov.f32 	%f2239, %f154;
	mov.f32 	%f2238, %f153;
	mov.f32 	%f2237, %f152;
	mov.f32 	%f2236, %f151;
	mov.f32 	%f2235, %f158;
	mov.f32 	%f2234, %f157;
	mov.f32 	%f2233, %f156;
	mov.f32 	%f2232, %f155;

BB11_19:
	add.s32 	%r425, %r425, 1;
	setp.lt.u32	%p19, %r425, %r14;
	@%p19 bra 	BB11_3;

	mul.f32 	%f813, %f571, %f2236;
	fma.rn.f32 	%f814, %f572, %f2237, %f813;
	fma.rn.f32 	%f815, %f2292, %f2238, %f814;
	add.f32 	%f2294, %f2239, %f815;
	mul.f32 	%f816, %f571, %f2232;
	fma.rn.f32 	%f817, %f572, %f2233, %f816;
	fma.rn.f32 	%f818, %f2292, %f2234, %f817;
	add.f32 	%f2293, %f2235, %f818;
	mul.f32 	%f819, %f571, %f2228;
	fma.rn.f32 	%f820, %f572, %f2229, %f819;
	fma.rn.f32 	%f821, %f2292, %f2230, %f820;
	add.f32 	%f2292, %f2231, %f821;
	bra.uni 	BB11_21;

BB11_1:
	mov.f32 	%f2293, %f572;
	mov.f32 	%f2294, %f571;

BB11_21:
	setp.eq.s32	%p331, %r14, 0;
	// inline asm
	call (%f822), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f823), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f2343), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f825), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r426, 0;
	@%p331 bra 	BB11_22;

BB11_23:
	.pragma "nounroll";
	// inline asm
	call (%rd141), _optix_get_transform_list_handle, (%r426);
	// inline asm
	// inline asm
	call (%r167), _optix_get_transform_type_from_handle, (%rd141);
	// inline asm
	and.b32  	%r168, %r167, -2;
	setp.eq.s32	%p21, %r168, 2;
	@%p21 bra 	BB11_29;
	bra.uni 	BB11_24;

BB11_29:
	setp.eq.s32	%p24, %r167, 2;
	@%p24 bra 	BB11_33;
	bra.uni 	BB11_30;

BB11_33:
	// inline asm
	call (%rd215), _optix_get_matrix_motion_transform_from_handle, (%rd141);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd217, %rd215;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd217];
	// inline asm
	mov.b32	{%rs13, %rs14}, %r258;
	add.s64 	%rd221, %rd215, 16;
	// inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd220];
	// inline asm
	add.s64 	%rd224, %rd215, 32;
	// inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd223];
	// inline asm
	add.s64 	%rd227, %rd215, 48;
	// inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd226];
	// inline asm
	add.s64 	%rd230, %rd215, 64;
	// inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd229];
	// inline asm
	add.s64 	%rd233, %rd215, 80;
	// inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd232];
	// inline asm
	add.s64 	%rd236, %rd215, 96;
	// inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd235];
	// inline asm
	add.s64 	%rd239, %rd215, 112;
	// inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd238];
	// inline asm
	mov.b32 	 %f928, %r259;
	mov.b32 	 %f929, %r260;
	cvt.u32.u16	%r300, %rs13;
	add.s32 	%r301, %r300, -1;
	cvt.rn.f32.s32	%f930, %r301;
	sub.f32 	%f931, %f825, %f928;
	mul.f32 	%f932, %f931, %f930;
	sub.f32 	%f933, %f929, %f928;
	div.rn.f32 	%f934, %f932, %f933;
	min.f32 	%f935, %f930, %f934;
	mov.f32 	%f936, 0f00000000;
	max.f32 	%f937, %f936, %f935;
	cvt.rmi.f32.f32	%f938, %f937;
	cvt.rzi.s32.f32	%r302, %f938;
	cvt.s64.s32	%rd17, %r302;
	mul.wide.s32 	%rd250, %r302, 48;
	add.s64 	%rd242, %rd224, %rd250;
	// inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd241];
	// inline asm
	mov.b32 	 %f2320, %r288;
	mov.b32 	 %f2321, %r289;
	mov.b32 	 %f2322, %r290;
	add.s64 	%rd245, %rd242, 16;
	// inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd244];
	// inline asm
	mov.b32 	 %f2317, %r292;
	mov.b32 	 %f2318, %r293;
	mov.b32 	 %f2319, %r294;
	add.s64 	%rd248, %rd242, 32;
	// inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd247];
	// inline asm
	sub.f32 	%f249, %f937, %f938;
	mov.b32 	 %f2314, %r296;
	mov.b32 	 %f2315, %r297;
	mov.b32 	 %f2316, %r298;
	setp.leu.f32	%p26, %f249, 0f00000000;
	@%p26 bra 	BB11_35;

	mul.lo.s64 	%rd260, %rd17, 48;
	add.s64 	%rd261, %rd215, %rd260;
	add.s64 	%rd252, %rd261, 80;
	// inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd251];
	// inline asm
	mov.b32 	 %f939, %r303;
	mov.b32 	 %f940, %r304;
	mov.b32 	 %f941, %r305;
	add.s64 	%rd255, %rd261, 96;
	// inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd254];
	// inline asm
	mov.b32 	 %f942, %r307;
	mov.b32 	 %f943, %r308;
	mov.b32 	 %f944, %r309;
	add.s64 	%rd258, %rd261, 112;
	// inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd257];
	// inline asm
	mov.f32 	%f945, 0f3F800000;
	sub.f32 	%f946, %f945, %f249;
	mul.f32 	%f947, %f249, %f939;
	mul.f32 	%f948, %f249, %f940;
	mul.f32 	%f949, %f249, %f941;
	fma.rn.f32 	%f2320, %f946, %f2320, %f947;
	fma.rn.f32 	%f2321, %f946, %f2321, %f948;
	fma.rn.f32 	%f2322, %f946, %f2322, %f949;
	mul.f32 	%f950, %f249, %f942;
	mul.f32 	%f951, %f249, %f943;
	mul.f32 	%f952, %f249, %f944;
	fma.rn.f32 	%f2317, %f946, %f2317, %f950;
	fma.rn.f32 	%f2318, %f946, %f2318, %f951;
	fma.rn.f32 	%f2319, %f946, %f2319, %f952;
	mov.b32 	 %f953, %r311;
	mov.b32 	 %f954, %r312;
	mov.b32 	 %f955, %r313;
	mul.f32 	%f956, %f249, %f953;
	mul.f32 	%f957, %f249, %f954;
	mul.f32 	%f958, %f249, %f955;
	fma.rn.f32 	%f2314, %f946, %f2314, %f956;
	fma.rn.f32 	%f2315, %f946, %f2315, %f957;
	fma.rn.f32 	%f2316, %f946, %f2316, %f958;
	bra.uni 	BB11_35;

BB11_24:
	mov.f32 	%f2323, 0f00000000;
	mov.f32 	%f2325, 0f3F800000;
	setp.eq.s32	%p22, %r167, 4;
	@%p22 bra 	BB11_27;
	bra.uni 	BB11_25;

BB11_27:
	// inline asm
	call (%rd265), _optix_get_instance_inverse_transform_from_handle, (%rd141);
	// inline asm
	bra.uni 	BB11_28;

BB11_30:
	// inline asm
	call (%rd156), _optix_get_srt_motion_transform_from_handle, (%rd141);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd158, %rd156;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r181,%r182,%r183,%r184}, [%rd158];
	// inline asm
	mov.b32	{%rs11, %rs12}, %r183;
	add.s64 	%rd162, %rd156, 16;
	// inline asm
	cvta.to.global.u64 %rd161, %rd162;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd161];
	// inline asm
	add.s64 	%rd165, %rd156, 32;
	// inline asm
	cvta.to.global.u64 %rd164, %rd165;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd164];
	// inline asm
	add.s64 	%rd168, %rd156, 48;
	// inline asm
	cvta.to.global.u64 %rd167, %rd168;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd167];
	// inline asm
	add.s64 	%rd171, %rd156, 64;
	// inline asm
	cvta.to.global.u64 %rd170, %rd171;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd170];
	// inline asm
	add.s64 	%rd174, %rd156, 80;
	// inline asm
	cvta.to.global.u64 %rd173, %rd174;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd173];
	// inline asm
	add.s64 	%rd177, %rd156, 96;
	// inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd176];
	// inline asm
	add.s64 	%rd180, %rd156, 112;
	// inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd179];
	// inline asm
	add.s64 	%rd183, %rd156, 128;
	// inline asm
	cvta.to.global.u64 %rd182, %rd183;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd182];
	// inline asm
	add.s64 	%rd186, %rd156, 144;
	// inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd185];
	// inline asm
	mov.b32 	 %f836, %r184;
	mov.b32 	 %f837, %r185;
	cvt.u32.u16	%r237, %rs11;
	add.s32 	%r238, %r237, -1;
	cvt.rn.f32.s32	%f838, %r238;
	sub.f32 	%f839, %f825, %f836;
	mul.f32 	%f840, %f839, %f838;
	sub.f32 	%f841, %f837, %f836;
	div.rn.f32 	%f842, %f840, %f841;
	min.f32 	%f843, %f838, %f842;
	mov.f32 	%f844, 0f00000000;
	max.f32 	%f845, %f844, %f843;
	cvt.rmi.f32.f32	%f846, %f845;
	cvt.rzi.s32.f32	%r239, %f846;
	cvt.s64.s32	%rd15, %r239;
	mul.wide.s32 	%rd200, %r239, 64;
	add.s64 	%rd189, %rd165, %rd200;
	// inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd188];
	// inline asm
	mov.b32 	 %f2304, %r221;
	mov.b32 	 %f2305, %r222;
	mov.b32 	 %f2306, %r223;
	add.s64 	%rd192, %rd189, 16;
	// inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd191];
	// inline asm
	mov.b32 	 %f2307, %r225;
	mov.b32 	 %f2308, %r226;
	mov.b32 	 %f2309, %r228;
	add.s64 	%rd195, %rd189, 32;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd194];
	// inline asm
	sub.f32 	%f209, %f845, %f846;
	mov.b32 	 %f2310, %r230;
	mov.b32 	 %f2311, %r231;
	mov.b32 	 %f2312, %r232;
	add.s64 	%rd198, %rd189, 48;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd197];
	// inline asm
	mov.b32 	 %f2313, %r233;
	setp.leu.f32	%p25, %f209, 0f00000000;
	@%p25 bra 	BB11_32;

	shl.b64 	%rd213, %rd15, 6;
	add.s64 	%rd214, %rd213, %rd156;
	add.s64 	%rd202, %rd214, 96;
	// inline asm
	cvta.to.global.u64 %rd201, %rd202;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd201];
	// inline asm
	mov.b32 	 %f847, %r240;
	mov.b32 	 %f848, %r241;
	mov.b32 	 %f849, %r242;
	add.s64 	%rd205, %rd214, 112;
	// inline asm
	cvta.to.global.u64 %rd204, %rd205;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd204];
	// inline asm
	mov.b32 	 %f850, %r244;
	mov.b32 	 %f851, %r245;
	mov.b32 	 %f852, %r247;
	add.s64 	%rd208, %rd214, 128;
	// inline asm
	cvta.to.global.u64 %rd207, %rd208;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd207];
	// inline asm
	mov.b32 	 %f853, %r249;
	mov.b32 	 %f854, %r250;
	mov.b32 	 %f855, %r251;
	add.s64 	%rd211, %rd214, 144;
	// inline asm
	cvta.to.global.u64 %rd210, %rd211;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd210];
	// inline asm
	mov.f32 	%f856, 0f3F800000;
	sub.f32 	%f857, %f856, %f209;
	mul.f32 	%f858, %f209, %f847;
	mul.f32 	%f859, %f209, %f848;
	mul.f32 	%f860, %f209, %f849;
	fma.rn.f32 	%f2304, %f857, %f2304, %f858;
	fma.rn.f32 	%f2305, %f857, %f2305, %f859;
	fma.rn.f32 	%f2306, %f857, %f2306, %f860;
	mul.f32 	%f861, %f209, %f850;
	mul.f32 	%f862, %f209, %f851;
	mul.f32 	%f863, %f209, %f852;
	fma.rn.f32 	%f2307, %f857, %f2307, %f861;
	fma.rn.f32 	%f2308, %f857, %f2308, %f862;
	fma.rn.f32 	%f2309, %f857, %f2309, %f863;
	mul.f32 	%f864, %f209, %f853;
	mul.f32 	%f865, %f209, %f854;
	mul.f32 	%f866, %f209, %f855;
	fma.rn.f32 	%f867, %f857, %f2310, %f864;
	fma.rn.f32 	%f868, %f857, %f2311, %f865;
	fma.rn.f32 	%f869, %f857, %f2312, %f866;
	mov.b32 	 %f870, %r252;
	mul.f32 	%f871, %f209, %f870;
	fma.rn.f32 	%f872, %f857, %f2313, %f871;
	mul.f32 	%f873, %f868, %f868;
	fma.rn.f32 	%f874, %f867, %f867, %f873;
	fma.rn.f32 	%f875, %f869, %f869, %f874;
	fma.rn.f32 	%f876, %f872, %f872, %f875;
	sqrt.rn.f32 	%f877, %f876;
	rcp.rn.f32 	%f878, %f877;
	mul.f32 	%f2310, %f867, %f878;
	mul.f32 	%f2311, %f868, %f878;
	mul.f32 	%f2312, %f869, %f878;
	mul.f32 	%f2313, %f872, %f878;

BB11_32:
	mul.f32 	%f879, %f2311, %f2311;
	fma.rn.f32 	%f880, %f2310, %f2310, %f879;
	fma.rn.f32 	%f881, %f2312, %f2312, %f880;
	fma.rn.f32 	%f882, %f2313, %f2313, %f881;
	rcp.rn.f32 	%f883, %f882;
	mul.f32 	%f884, %f2310, %f883;
	mul.f32 	%f885, %f2311, %f883;
	mul.f32 	%f886, %f2312, %f883;
	mul.f32 	%f887, %f2313, %f883;
	mul.f32 	%f888, %f2310, %f884;
	mul.f32 	%f889, %f2311, %f885;
	mul.f32 	%f890, %f2312, %f886;
	mul.f32 	%f891, %f2310, %f885;
	mul.f32 	%f892, %f2312, %f887;
	mul.f32 	%f893, %f2310, %f886;
	mul.f32 	%f894, %f2311, %f887;
	mul.f32 	%f895, %f2311, %f886;
	mul.f32 	%f896, %f2310, %f887;
	sub.f32 	%f897, %f888, %f889;
	sub.f32 	%f898, %f897, %f890;
	fma.rn.f32 	%f899, %f2313, %f887, %f898;
	sub.f32 	%f900, %f891, %f892;
	add.f32 	%f901, %f900, %f900;
	add.f32 	%f902, %f893, %f894;
	add.f32 	%f903, %f902, %f902;
	add.f32 	%f904, %f891, %f892;
	add.f32 	%f905, %f904, %f904;
	sub.f32 	%f906, %f889, %f888;
	sub.f32 	%f907, %f906, %f890;
	fma.rn.f32 	%f908, %f2313, %f887, %f907;
	sub.f32 	%f909, %f895, %f896;
	add.f32 	%f910, %f909, %f909;
	sub.f32 	%f911, %f893, %f894;
	add.f32 	%f912, %f911, %f911;
	add.f32 	%f913, %f895, %f896;
	add.f32 	%f914, %f913, %f913;
	neg.f32 	%f915, %f888;
	sub.f32 	%f916, %f915, %f889;
	add.f32 	%f917, %f890, %f916;
	fma.rn.f32 	%f918, %f2313, %f887, %f917;
	mul.f32 	%f919, %f2306, %f899;
	fma.rn.f32 	%f920, %f2308, %f901, %f919;
	fma.rn.f32 	%f2322, %f2309, %f903, %f920;
	mul.f32 	%f921, %f2308, %f908;
	fma.rn.f32 	%f922, %f2306, %f905, %f921;
	fma.rn.f32 	%f2319, %f2309, %f910, %f922;
	mul.f32 	%f923, %f2308, %f914;
	fma.rn.f32 	%f924, %f2306, %f912, %f923;
	fma.rn.f32 	%f2316, %f2309, %f918, %f924;
	mul.f32 	%f925, %f2305, %f899;
	fma.rn.f32 	%f2321, %f2307, %f901, %f925;
	mul.f32 	%f926, %f2307, %f908;
	fma.rn.f32 	%f2318, %f2305, %f905, %f926;
	mul.f32 	%f927, %f2307, %f914;
	fma.rn.f32 	%f2315, %f2305, %f912, %f927;
	mul.f32 	%f2320, %f2304, %f899;
	mul.f32 	%f2317, %f2304, %f905;
	mul.f32 	%f2314, %f2304, %f912;

BB11_35:
	mul.f32 	%f959, %f2315, %f2319;
	mul.f32 	%f960, %f2316, %f2318;
	sub.f32 	%f961, %f960, %f959;
	mul.f32 	%f962, %f2320, %f961;
	mul.f32 	%f963, %f2314, %f2319;
	mul.f32 	%f964, %f2316, %f2317;
	sub.f32 	%f965, %f964, %f963;
	mul.f32 	%f966, %f965, %f2321;
	sub.f32 	%f967, %f962, %f966;
	mul.f32 	%f968, %f2314, %f2318;
	mul.f32 	%f969, %f2315, %f2317;
	sub.f32 	%f970, %f969, %f968;
	fma.rn.f32 	%f971, %f970, %f2322, %f967;
	rcp.rn.f32 	%f972, %f971;
	mul.f32 	%f2329, %f961, %f972;
	mul.f32 	%f973, %f2316, %f2321;
	mul.f32 	%f974, %f2315, %f2322;
	sub.f32 	%f975, %f974, %f973;
	mul.f32 	%f2330, %f972, %f975;
	mul.f32 	%f976, %f2318, %f2322;
	mul.f32 	%f977, %f2319, %f2321;
	sub.f32 	%f978, %f977, %f976;
	mul.f32 	%f2331, %f972, %f978;
	sub.f32 	%f979, %f963, %f964;
	mul.f32 	%f2326, %f979, %f972;
	mul.f32 	%f980, %f2314, %f2322;
	mul.f32 	%f981, %f2316, %f2320;
	sub.f32 	%f982, %f981, %f980;
	mul.f32 	%f2327, %f972, %f982;
	mul.f32 	%f983, %f2319, %f2320;
	mul.f32 	%f984, %f2317, %f2322;
	sub.f32 	%f985, %f984, %f983;
	mul.f32 	%f2328, %f972, %f985;
	mul.f32 	%f2323, %f970, %f972;
	mul.f32 	%f986, %f2315, %f2320;
	mul.f32 	%f987, %f2314, %f2321;
	sub.f32 	%f988, %f987, %f986;
	mul.f32 	%f2324, %f988, %f972;
	mul.f32 	%f989, %f2317, %f2321;
	mul.f32 	%f990, %f2318, %f2320;
	sub.f32 	%f991, %f990, %f989;
	mul.f32 	%f2325, %f991, %f972;
	bra.uni 	BB11_36;

BB11_25:
	setp.ne.s32	%p23, %r167, 1;
	mov.f32 	%f2324, %f2323;
	mov.f32 	%f2326, %f2323;
	mov.f32 	%f2327, %f2325;
	mov.f32 	%f2328, %f2323;
	mov.f32 	%f2329, %f2325;
	mov.f32 	%f2330, %f2323;
	mov.f32 	%f2331, %f2323;
	@%p23 bra 	BB11_36;

	// inline asm
	call (%rd143), _optix_get_static_transform_from_handle, (%rd141);
	// inline asm
	add.s64 	%rd265, %rd143, 64;

BB11_28:
	// inline asm
	cvta.to.global.u64 %rd147, %rd265;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd147];
	// inline asm
	mov.b32 	 %f2329, %r169;
	mov.b32 	 %f2330, %r170;
	mov.b32 	 %f2331, %r171;
	add.s64 	%rd151, %rd265, 16;
	// inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd150];
	// inline asm
	mov.b32 	 %f2326, %r173;
	mov.b32 	 %f2327, %r174;
	mov.b32 	 %f2328, %r175;
	add.s64 	%rd154, %rd265, 32;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd153];
	// inline asm
	mov.b32 	 %f2323, %r177;
	mov.b32 	 %f2324, %r178;
	mov.b32 	 %f2325, %r179;

BB11_36:
	setp.eq.s32	%p27, %r426, 0;
	@%p27 bra 	BB11_37;
	bra.uni 	BB11_38;

BB11_37:
	mov.f32 	%f2303, %f2323;
	mov.f32 	%f2302, %f2324;
	mov.f32 	%f2301, %f2325;
	mov.f32 	%f2300, %f2326;
	mov.f32 	%f2299, %f2327;
	mov.f32 	%f2298, %f2328;
	mov.f32 	%f2297, %f2329;
	mov.f32 	%f2296, %f2330;
	mov.f32 	%f2295, %f2331;
	bra.uni 	BB11_39;

BB11_38:
	mul.f32 	%f992, %f2300, %f2330;
	fma.rn.f32 	%f993, %f2297, %f2329, %f992;
	fma.rn.f32 	%f289, %f2303, %f2331, %f993;
	mul.f32 	%f994, %f2299, %f2330;
	fma.rn.f32 	%f995, %f2296, %f2329, %f994;
	fma.rn.f32 	%f290, %f2302, %f2331, %f995;
	mul.f32 	%f996, %f2298, %f2330;
	fma.rn.f32 	%f997, %f2295, %f2329, %f996;
	fma.rn.f32 	%f291, %f2301, %f2331, %f997;
	mul.f32 	%f998, %f2300, %f2327;
	fma.rn.f32 	%f999, %f2297, %f2326, %f998;
	fma.rn.f32 	%f292, %f2303, %f2328, %f999;
	mul.f32 	%f1000, %f2299, %f2327;
	fma.rn.f32 	%f1001, %f2296, %f2326, %f1000;
	fma.rn.f32 	%f293, %f2302, %f2328, %f1001;
	mul.f32 	%f1002, %f2298, %f2327;
	fma.rn.f32 	%f1003, %f2295, %f2326, %f1002;
	fma.rn.f32 	%f294, %f2301, %f2328, %f1003;
	mul.f32 	%f1004, %f2300, %f2324;
	fma.rn.f32 	%f1005, %f2297, %f2323, %f1004;
	fma.rn.f32 	%f2303, %f2303, %f2325, %f1005;
	mul.f32 	%f1006, %f2299, %f2324;
	fma.rn.f32 	%f1007, %f2296, %f2323, %f1006;
	fma.rn.f32 	%f2302, %f2302, %f2325, %f1007;
	mul.f32 	%f1008, %f2298, %f2324;
	fma.rn.f32 	%f1009, %f2295, %f2323, %f1008;
	fma.rn.f32 	%f2301, %f2301, %f2325, %f1009;
	mov.f32 	%f2300, %f292;
	mov.f32 	%f2299, %f293;
	mov.f32 	%f2298, %f294;
	mov.f32 	%f2297, %f289;
	mov.f32 	%f2296, %f290;
	mov.f32 	%f2295, %f291;

BB11_39:
	add.s32 	%r426, %r426, 1;
	setp.lt.u32	%p28, %r426, %r14;
	@%p28 bra 	BB11_23;

	mul.f32 	%f1010, %f823, %f2296;
	fma.rn.f32 	%f1011, %f822, %f2297, %f1010;
	fma.rn.f32 	%f2341, %f2343, %f2295, %f1011;
	mul.f32 	%f1012, %f823, %f2299;
	fma.rn.f32 	%f1013, %f822, %f2300, %f1012;
	fma.rn.f32 	%f2342, %f2343, %f2298, %f1013;
	mul.f32 	%f1014, %f823, %f2302;
	fma.rn.f32 	%f1015, %f822, %f2303, %f1014;
	fma.rn.f32 	%f2343, %f2343, %f2301, %f1015;
	bra.uni 	BB11_41;

BB11_22:
	mov.f32 	%f2341, %f822;
	mov.f32 	%f2342, %f823;

BB11_41:
	// inline asm
	call (%f1016), _optix_get_ray_tmin, ();
	// inline asm
	// inline asm
	call (%f1017), _optix_get_ray_tmax, ();
	// inline asm
	ld.f32 	%f315, [%rd1+304];
	ld.v2.f32 	{%f1020, %f1021}, [%rd1+288];
	mov.f32 	%f1025, 0f40000000;
	abs.f32 	%f319, %f2341;
	setp.lt.f32	%p29, %f319, 0f00800000;
	mul.f32 	%f1027, %f319, 0f4B800000;
	selp.f32	%f1028, 0fC3170000, 0fC2FE0000, %p29;
	selp.f32	%f1029, %f1027, %f319, %p29;
	mov.b32 	 %r315, %f1029;
	and.b32  	%r316, %r315, 8388607;
	or.b32  	%r317, %r316, 1065353216;
	mov.b32 	 %f1030, %r317;
	shr.u32 	%r318, %r315, 23;
	cvt.rn.f32.u32	%f1031, %r318;
	add.f32 	%f1032, %f1028, %f1031;
	setp.gt.f32	%p30, %f1030, 0f3FB504F3;
	mul.f32 	%f1033, %f1030, 0f3F000000;
	add.f32 	%f1034, %f1032, 0f3F800000;
	selp.f32	%f1035, %f1033, %f1030, %p30;
	selp.f32	%f1036, %f1034, %f1032, %p30;
	add.f32 	%f320, %f1035, 0fBF800000;
	add.f32 	%f1019, %f1035, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1018,%f1019;
	// inline asm
	add.f32 	%f322, %f320, %f320;
	mul.f32 	%f1037, %f1018, %f322;
	mul.f32 	%f1038, %f1037, %f1037;
	mov.f32 	%f1039, 0f3C4CAF63;
	mov.f32 	%f1040, 0f3B18F0FE;
	fma.rn.f32 	%f1041, %f1040, %f1038, %f1039;
	mov.f32 	%f1042, 0f3DAAAABD;
	fma.rn.f32 	%f1043, %f1041, %f1038, %f1042;
	mul.rn.f32 	%f1044, %f1043, %f1038;
	mul.rn.f32 	%f1045, %f1044, %f1037;
	sub.f32 	%f1046, %f320, %f1037;
	neg.f32 	%f1047, %f1037;
	add.f32 	%f1048, %f1046, %f1046;
	fma.rn.f32 	%f1049, %f1047, %f320, %f1048;
	mul.rn.f32 	%f1050, %f1018, %f1049;
	add.f32 	%f1051, %f1045, %f1037;
	sub.f32 	%f1052, %f1037, %f1051;
	add.f32 	%f1053, %f1045, %f1052;
	add.f32 	%f1054, %f1050, %f1053;
	add.f32 	%f1055, %f1051, %f1054;
	sub.f32 	%f1056, %f1051, %f1055;
	add.f32 	%f1057, %f1054, %f1056;
	mov.f32 	%f1058, 0f3F317200;
	mul.rn.f32 	%f323, %f1036, %f1058;
	mov.f32 	%f1059, 0f35BFBE8E;
	mul.rn.f32 	%f324, %f1036, %f1059;
	add.f32 	%f1060, %f323, %f1055;
	sub.f32 	%f1061, %f323, %f1060;
	add.f32 	%f1062, %f1055, %f1061;
	add.f32 	%f1063, %f1057, %f1062;
	add.f32 	%f1064, %f324, %f1063;
	add.f32 	%f1065, %f1060, %f1064;
	sub.f32 	%f1066, %f1060, %f1065;
	add.f32 	%f1067, %f1064, %f1066;
	mul.rn.f32 	%f1068, %f1025, %f1065;
	neg.f32 	%f1069, %f1068;
	fma.rn.f32 	%f1070, %f1025, %f1065, %f1069;
	fma.rn.f32 	%f1071, %f1025, %f1067, %f1070;
	mov.f32 	%f1072, 0f00000000;
	fma.rn.f32 	%f1073, %f1072, %f1065, %f1071;
	add.rn.f32 	%f1074, %f1068, %f1073;
	neg.f32 	%f1075, %f1074;
	add.rn.f32 	%f1076, %f1068, %f1075;
	add.rn.f32 	%f1077, %f1076, %f1073;
	mov.b32 	 %r319, %f1074;
	setp.eq.s32	%p31, %r319, 1118925336;
	add.s32 	%r320, %r319, -1;
	mov.b32 	 %f1078, %r320;
	add.f32 	%f1079, %f1077, 0f37000000;
	selp.f32	%f1080, %f1078, %f1074, %p31;
	selp.f32	%f325, %f1079, %f1077, %p31;
	mul.f32 	%f1081, %f1080, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1082, %f1081;
	mov.f32 	%f1083, 0fBF317200;
	fma.rn.f32 	%f1084, %f1082, %f1083, %f1080;
	mov.f32 	%f1085, 0fB5BFBE8E;
	fma.rn.f32 	%f1086, %f1082, %f1085, %f1084;
	mul.f32 	%f1087, %f1086, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1088, %f1087;
	add.f32 	%f1089, %f1082, 0f00000000;
	ex2.approx.f32 	%f1090, %f1089;
	mul.f32 	%f1091, %f1088, %f1090;
	setp.lt.f32	%p32, %f1080, 0fC2D20000;
	selp.f32	%f1092, 0f00000000, %f1091, %p32;
	setp.gt.f32	%p33, %f1080, 0f42D20000;
	selp.f32	%f2344, 0f7F800000, %f1092, %p33;
	setp.eq.f32	%p34, %f2344, 0f7F800000;
	@%p34 bra 	BB11_43;

	fma.rn.f32 	%f2344, %f2344, %f325, %f2344;

BB11_43:
	mov.f32 	%f2216, 0f3F800000;
	cvt.rzi.f32.f32	%f2215, %f2216;
	add.f32 	%f2214, %f2215, %f2215;
	mov.f32 	%f2213, 0f40000000;
	sub.f32 	%f2212, %f2213, %f2214;
	abs.f32 	%f2211, %f2212;
	setp.lt.f32	%p35, %f2341, 0f00000000;
	setp.eq.f32	%p36, %f2211, 0f3F800000;
	and.pred  	%p1, %p35, %p36;
	mov.b32 	 %r321, %f2344;
	xor.b32  	%r322, %r321, -2147483648;
	mov.b32 	 %f1093, %r322;
	selp.f32	%f2346, %f1093, %f2344, %p1;
	setp.eq.f32	%p37, %f2341, 0f00000000;
	@%p37 bra 	BB11_46;
	bra.uni 	BB11_44;

BB11_46:
	add.f32 	%f1096, %f2341, %f2341;
	selp.f32	%f2346, %f1096, 0f00000000, %p36;
	bra.uni 	BB11_47;

BB11_44:
	setp.geu.f32	%p38, %f2341, 0f00000000;
	@%p38 bra 	BB11_47;

	cvt.rzi.f32.f32	%f1095, %f1025;
	setp.neu.f32	%p39, %f1095, 0f40000000;
	selp.f32	%f2346, 0f7FFFFFFF, %f2346, %p39;

BB11_47:
	abs.f32 	%f2217, %f2341;
	add.f32 	%f1097, %f2217, 0f40000000;
	mov.b32 	 %r8, %f1097;
	setp.lt.s32	%p41, %r8, 2139095040;
	@%p41 bra 	BB11_52;

	abs.f32 	%f2226, %f2341;
	setp.gtu.f32	%p42, %f2226, 0f7F800000;
	@%p42 bra 	BB11_51;
	bra.uni 	BB11_49;

BB11_51:
	add.f32 	%f2346, %f2341, 0f40000000;
	bra.uni 	BB11_52;

BB11_49:
	abs.f32 	%f2227, %f2341;
	setp.neu.f32	%p43, %f2227, 0f7F800000;
	@%p43 bra 	BB11_52;

	selp.f32	%f2346, 0fFF800000, 0f7F800000, %p1;

BB11_52:
	mov.f32 	%f2225, 0fB5BFBE8E;
	mov.f32 	%f2224, 0fBF317200;
	mov.f32 	%f2223, 0f00000000;
	mov.f32 	%f2222, 0f35BFBE8E;
	mov.f32 	%f2221, 0f3F317200;
	mov.f32 	%f2220, 0f3DAAAABD;
	mov.f32 	%f2219, 0f3C4CAF63;
	mov.f32 	%f2218, 0f3B18F0FE;
	setp.eq.f32	%p44, %f2341, 0f3F800000;
	selp.f32	%f336, 0f3F800000, %f2346, %p44;
	abs.f32 	%f337, %f2342;
	setp.lt.f32	%p45, %f337, 0f00800000;
	mul.f32 	%f1100, %f337, 0f4B800000;
	selp.f32	%f1101, 0fC3170000, 0fC2FE0000, %p45;
	selp.f32	%f1102, %f1100, %f337, %p45;
	mov.b32 	 %r323, %f1102;
	and.b32  	%r324, %r323, 8388607;
	or.b32  	%r325, %r324, 1065353216;
	mov.b32 	 %f1103, %r325;
	shr.u32 	%r326, %r323, 23;
	cvt.rn.f32.u32	%f1104, %r326;
	add.f32 	%f1105, %f1101, %f1104;
	setp.gt.f32	%p46, %f1103, 0f3FB504F3;
	mul.f32 	%f1106, %f1103, 0f3F000000;
	add.f32 	%f1107, %f1105, 0f3F800000;
	selp.f32	%f1108, %f1106, %f1103, %p46;
	selp.f32	%f1109, %f1107, %f1105, %p46;
	add.f32 	%f338, %f1108, 0fBF800000;
	add.f32 	%f1099, %f1108, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1098,%f1099;
	// inline asm
	add.f32 	%f340, %f338, %f338;
	mul.f32 	%f1110, %f1098, %f340;
	mul.f32 	%f1111, %f1110, %f1110;
	fma.rn.f32 	%f1114, %f2218, %f1111, %f2219;
	fma.rn.f32 	%f1116, %f1114, %f1111, %f2220;
	mul.rn.f32 	%f1117, %f1116, %f1111;
	mul.rn.f32 	%f1118, %f1117, %f1110;
	sub.f32 	%f1119, %f338, %f1110;
	neg.f32 	%f1120, %f1110;
	add.f32 	%f1121, %f1119, %f1119;
	fma.rn.f32 	%f1122, %f1120, %f338, %f1121;
	mul.rn.f32 	%f1123, %f1098, %f1122;
	add.f32 	%f1124, %f1118, %f1110;
	sub.f32 	%f1125, %f1110, %f1124;
	add.f32 	%f1126, %f1118, %f1125;
	add.f32 	%f1127, %f1123, %f1126;
	add.f32 	%f1128, %f1124, %f1127;
	sub.f32 	%f1129, %f1124, %f1128;
	add.f32 	%f1130, %f1127, %f1129;
	mul.rn.f32 	%f341, %f1109, %f2221;
	mul.rn.f32 	%f342, %f1109, %f2222;
	add.f32 	%f1133, %f341, %f1128;
	sub.f32 	%f1134, %f341, %f1133;
	add.f32 	%f1135, %f1128, %f1134;
	add.f32 	%f1136, %f1130, %f1135;
	add.f32 	%f1137, %f342, %f1136;
	add.f32 	%f1138, %f1133, %f1137;
	sub.f32 	%f1139, %f1133, %f1138;
	add.f32 	%f1140, %f1137, %f1139;
	mul.rn.f32 	%f1142, %f1025, %f1138;
	neg.f32 	%f1143, %f1142;
	fma.rn.f32 	%f1144, %f1025, %f1138, %f1143;
	fma.rn.f32 	%f1145, %f1025, %f1140, %f1144;
	fma.rn.f32 	%f1147, %f2223, %f1138, %f1145;
	add.rn.f32 	%f1148, %f1142, %f1147;
	neg.f32 	%f1149, %f1148;
	add.rn.f32 	%f1150, %f1142, %f1149;
	add.rn.f32 	%f1151, %f1150, %f1147;
	mov.b32 	 %r327, %f1148;
	setp.eq.s32	%p47, %r327, 1118925336;
	add.s32 	%r328, %r327, -1;
	mov.b32 	 %f1152, %r328;
	add.f32 	%f1153, %f1151, 0f37000000;
	selp.f32	%f1154, %f1152, %f1148, %p47;
	selp.f32	%f343, %f1153, %f1151, %p47;
	mul.f32 	%f1155, %f1154, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1156, %f1155;
	fma.rn.f32 	%f1158, %f1156, %f2224, %f1154;
	fma.rn.f32 	%f1160, %f1156, %f2225, %f1158;
	mul.f32 	%f1161, %f1160, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1162, %f1161;
	add.f32 	%f1163, %f1156, 0f00000000;
	ex2.approx.f32 	%f1164, %f1163;
	mul.f32 	%f1165, %f1162, %f1164;
	setp.lt.f32	%p48, %f1154, 0fC2D20000;
	selp.f32	%f1166, 0f00000000, %f1165, %p48;
	setp.gt.f32	%p49, %f1154, 0f42D20000;
	selp.f32	%f2347, 0f7F800000, %f1166, %p49;
	setp.eq.f32	%p50, %f2347, 0f7F800000;
	@%p50 bra 	BB11_54;

	fma.rn.f32 	%f2347, %f2347, %f343, %f2347;

BB11_54:
	setp.lt.f32	%p51, %f2342, 0f00000000;
	and.pred  	%p2, %p51, %p36;
	mov.b32 	 %r329, %f2347;
	xor.b32  	%r330, %r329, -2147483648;
	mov.b32 	 %f1167, %r330;
	selp.f32	%f2349, %f1167, %f2347, %p2;
	setp.eq.f32	%p53, %f2342, 0f00000000;
	@%p53 bra 	BB11_57;
	bra.uni 	BB11_55;

BB11_57:
	add.f32 	%f1170, %f2342, %f2342;
	selp.f32	%f2349, %f1170, 0f00000000, %p36;
	bra.uni 	BB11_58;

BB11_55:
	setp.geu.f32	%p54, %f2342, 0f00000000;
	@%p54 bra 	BB11_58;

	cvt.rzi.f32.f32	%f1169, %f1025;
	setp.neu.f32	%p55, %f1169, 0f40000000;
	selp.f32	%f2349, 0f7FFFFFFF, %f2349, %p55;

BB11_58:
	abs.f32 	%f2198, %f2342;
	add.f32 	%f1171, %f2198, 0f40000000;
	mov.b32 	 %r9, %f1171;
	setp.lt.s32	%p57, %r9, 2139095040;
	@%p57 bra 	BB11_63;

	abs.f32 	%f2207, %f2342;
	setp.gtu.f32	%p58, %f2207, 0f7F800000;
	@%p58 bra 	BB11_62;
	bra.uni 	BB11_60;

BB11_62:
	add.f32 	%f2349, %f2342, 0f40000000;
	bra.uni 	BB11_63;

BB11_60:
	abs.f32 	%f2208, %f2342;
	setp.neu.f32	%p59, %f2208, 0f7F800000;
	@%p59 bra 	BB11_63;

	selp.f32	%f2349, 0fFF800000, 0f7F800000, %p2;

BB11_63:
	mov.f32 	%f2206, 0fB5BFBE8E;
	mov.f32 	%f2205, 0fBF317200;
	mov.f32 	%f2204, 0f00000000;
	mov.f32 	%f2203, 0f35BFBE8E;
	mov.f32 	%f2202, 0f3F317200;
	mov.f32 	%f2201, 0f3DAAAABD;
	mov.f32 	%f2200, 0f3C4CAF63;
	mov.f32 	%f2199, 0f3B18F0FE;
	setp.eq.f32	%p60, %f2342, 0f3F800000;
	selp.f32	%f1174, 0f3F800000, %f2349, %p60;
	add.f32 	%f354, %f336, %f1174;
	add.f32 	%f355, %f2294, %f2294;
	mul.f32 	%f1175, %f355, %f2341;
	add.f32 	%f1176, %f1020, %f1020;
	mul.f32 	%f1177, %f1176, %f2341;
	sub.f32 	%f1178, %f1175, %f1177;
	add.f32 	%f356, %f2293, %f2293;
	fma.rn.f32 	%f1179, %f356, %f2342, %f1178;
	add.f32 	%f1180, %f1021, %f1021;
	mul.f32 	%f1181, %f1180, %f2342;
	sub.f32 	%f357, %f1179, %f1181;
	abs.f32 	%f358, %f2294;
	setp.lt.f32	%p61, %f358, 0f00800000;
	mul.f32 	%f1182, %f358, 0f4B800000;
	selp.f32	%f1183, 0fC3170000, 0fC2FE0000, %p61;
	selp.f32	%f1184, %f1182, %f358, %p61;
	mov.b32 	 %r331, %f1184;
	and.b32  	%r332, %r331, 8388607;
	or.b32  	%r333, %r332, 1065353216;
	mov.b32 	 %f1185, %r333;
	shr.u32 	%r334, %r331, 23;
	cvt.rn.f32.u32	%f1186, %r334;
	add.f32 	%f1187, %f1183, %f1186;
	setp.gt.f32	%p62, %f1185, 0f3FB504F3;
	mul.f32 	%f1188, %f1185, 0f3F000000;
	add.f32 	%f1189, %f1187, 0f3F800000;
	selp.f32	%f1190, %f1188, %f1185, %p62;
	selp.f32	%f1191, %f1189, %f1187, %p62;
	add.f32 	%f359, %f1190, 0fBF800000;
	add.f32 	%f1173, %f1190, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1172,%f1173;
	// inline asm
	add.f32 	%f361, %f359, %f359;
	mul.f32 	%f1192, %f1172, %f361;
	mul.f32 	%f1193, %f1192, %f1192;
	fma.rn.f32 	%f1196, %f2199, %f1193, %f2200;
	fma.rn.f32 	%f1198, %f1196, %f1193, %f2201;
	mul.rn.f32 	%f1199, %f1198, %f1193;
	mul.rn.f32 	%f1200, %f1199, %f1192;
	sub.f32 	%f1201, %f359, %f1192;
	neg.f32 	%f1202, %f1192;
	add.f32 	%f1203, %f1201, %f1201;
	fma.rn.f32 	%f1204, %f1202, %f359, %f1203;
	mul.rn.f32 	%f1205, %f1172, %f1204;
	add.f32 	%f1206, %f1200, %f1192;
	sub.f32 	%f1207, %f1192, %f1206;
	add.f32 	%f1208, %f1200, %f1207;
	add.f32 	%f1209, %f1205, %f1208;
	add.f32 	%f1210, %f1206, %f1209;
	sub.f32 	%f1211, %f1206, %f1210;
	add.f32 	%f1212, %f1209, %f1211;
	mul.rn.f32 	%f362, %f1191, %f2202;
	mul.rn.f32 	%f363, %f1191, %f2203;
	add.f32 	%f1215, %f362, %f1210;
	sub.f32 	%f1216, %f362, %f1215;
	add.f32 	%f1217, %f1210, %f1216;
	add.f32 	%f1218, %f1212, %f1217;
	add.f32 	%f1219, %f363, %f1218;
	add.f32 	%f1220, %f1215, %f1219;
	sub.f32 	%f1221, %f1215, %f1220;
	add.f32 	%f1222, %f1219, %f1221;
	mul.rn.f32 	%f1224, %f1025, %f1220;
	neg.f32 	%f1225, %f1224;
	fma.rn.f32 	%f1226, %f1025, %f1220, %f1225;
	fma.rn.f32 	%f1227, %f1025, %f1222, %f1226;
	fma.rn.f32 	%f1229, %f2204, %f1220, %f1227;
	add.rn.f32 	%f1230, %f1224, %f1229;
	neg.f32 	%f1231, %f1230;
	add.rn.f32 	%f1232, %f1224, %f1231;
	add.rn.f32 	%f1233, %f1232, %f1229;
	mov.b32 	 %r335, %f1230;
	setp.eq.s32	%p63, %r335, 1118925336;
	add.s32 	%r336, %r335, -1;
	mov.b32 	 %f1234, %r336;
	add.f32 	%f1235, %f1233, 0f37000000;
	selp.f32	%f1236, %f1234, %f1230, %p63;
	selp.f32	%f364, %f1235, %f1233, %p63;
	mul.f32 	%f1237, %f1236, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1238, %f1237;
	fma.rn.f32 	%f1240, %f1238, %f2205, %f1236;
	fma.rn.f32 	%f1242, %f1238, %f2206, %f1240;
	mul.f32 	%f1243, %f1242, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1244, %f1243;
	add.f32 	%f1245, %f1238, 0f00000000;
	ex2.approx.f32 	%f1246, %f1245;
	mul.f32 	%f1247, %f1244, %f1246;
	setp.lt.f32	%p64, %f1236, 0fC2D20000;
	selp.f32	%f1248, 0f00000000, %f1247, %p64;
	setp.gt.f32	%p65, %f1236, 0f42D20000;
	selp.f32	%f2350, 0f7F800000, %f1248, %p65;
	setp.eq.f32	%p66, %f2350, 0f7F800000;
	@%p66 bra 	BB11_65;

	fma.rn.f32 	%f2350, %f2350, %f364, %f2350;

BB11_65:
	setp.lt.f32	%p67, %f2294, 0f00000000;
	and.pred  	%p3, %p67, %p36;
	mov.b32 	 %r337, %f2350;
	xor.b32  	%r338, %r337, -2147483648;
	mov.b32 	 %f1249, %r338;
	selp.f32	%f2352, %f1249, %f2350, %p3;
	setp.eq.f32	%p69, %f2294, 0f00000000;
	@%p69 bra 	BB11_68;
	bra.uni 	BB11_66;

BB11_68:
	add.f32 	%f2197, %f2294, %f2294;
	selp.f32	%f2352, %f2197, 0f00000000, %p36;
	bra.uni 	BB11_69;

BB11_66:
	setp.geu.f32	%p70, %f2294, 0f00000000;
	@%p70 bra 	BB11_69;

	cvt.rzi.f32.f32	%f1251, %f1025;
	setp.neu.f32	%p71, %f1251, 0f40000000;
	selp.f32	%f2352, 0f7FFFFFFF, %f2352, %p71;

BB11_69:
	abs.f32 	%f2185, %f2294;
	add.f32 	%f1253, %f2185, 0f40000000;
	mov.b32 	 %r10, %f1253;
	setp.lt.s32	%p73, %r10, 2139095040;
	@%p73 bra 	BB11_74;

	abs.f32 	%f2195, %f2294;
	setp.gtu.f32	%p74, %f2195, 0f7F800000;
	@%p74 bra 	BB11_73;
	bra.uni 	BB11_71;

BB11_73:
	add.f32 	%f2352, %f2294, 0f40000000;
	bra.uni 	BB11_74;

BB11_71:
	abs.f32 	%f2196, %f2294;
	setp.neu.f32	%p75, %f2196, 0f7F800000;
	@%p75 bra 	BB11_74;

	selp.f32	%f2352, 0fFF800000, 0f7F800000, %p3;

BB11_74:
	add.f32 	%f2194, %f2294, %f2294;
	mov.f32 	%f2193, 0fB5BFBE8E;
	mov.f32 	%f2192, 0fBF317200;
	mov.f32 	%f2191, 0f00000000;
	mov.f32 	%f2190, 0f35BFBE8E;
	mov.f32 	%f2189, 0f3F317200;
	mov.f32 	%f2188, 0f3DAAAABD;
	mov.f32 	%f2187, 0f3C4CAF63;
	mov.f32 	%f2186, 0f3B18F0FE;
	setp.eq.f32	%p76, %f2294, 0f3F800000;
	selp.f32	%f1256, 0f3F800000, %f2352, %p76;
	mul.f32 	%f375, %f1020, %f2194;
	sub.f32 	%f376, %f1256, %f375;
	abs.f32 	%f377, %f1020;
	setp.lt.f32	%p77, %f377, 0f00800000;
	mul.f32 	%f1257, %f377, 0f4B800000;
	selp.f32	%f1258, 0fC3170000, 0fC2FE0000, %p77;
	selp.f32	%f1259, %f1257, %f377, %p77;
	mov.b32 	 %r339, %f1259;
	and.b32  	%r340, %r339, 8388607;
	or.b32  	%r341, %r340, 1065353216;
	mov.b32 	 %f1260, %r341;
	shr.u32 	%r342, %r339, 23;
	cvt.rn.f32.u32	%f1261, %r342;
	add.f32 	%f1262, %f1258, %f1261;
	setp.gt.f32	%p78, %f1260, 0f3FB504F3;
	mul.f32 	%f1263, %f1260, 0f3F000000;
	add.f32 	%f1264, %f1262, 0f3F800000;
	selp.f32	%f1265, %f1263, %f1260, %p78;
	selp.f32	%f1266, %f1264, %f1262, %p78;
	add.f32 	%f378, %f1265, 0fBF800000;
	add.f32 	%f1255, %f1265, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1254,%f1255;
	// inline asm
	add.f32 	%f380, %f378, %f378;
	mul.f32 	%f1267, %f1254, %f380;
	mul.f32 	%f1268, %f1267, %f1267;
	fma.rn.f32 	%f1271, %f2186, %f1268, %f2187;
	fma.rn.f32 	%f1273, %f1271, %f1268, %f2188;
	mul.rn.f32 	%f1274, %f1273, %f1268;
	mul.rn.f32 	%f1275, %f1274, %f1267;
	sub.f32 	%f1276, %f378, %f1267;
	neg.f32 	%f1277, %f1267;
	add.f32 	%f1278, %f1276, %f1276;
	fma.rn.f32 	%f1279, %f1277, %f378, %f1278;
	mul.rn.f32 	%f1280, %f1254, %f1279;
	add.f32 	%f1281, %f1275, %f1267;
	sub.f32 	%f1282, %f1267, %f1281;
	add.f32 	%f1283, %f1275, %f1282;
	add.f32 	%f1284, %f1280, %f1283;
	add.f32 	%f1285, %f1281, %f1284;
	sub.f32 	%f1286, %f1281, %f1285;
	add.f32 	%f1287, %f1284, %f1286;
	mul.rn.f32 	%f381, %f1266, %f2189;
	mul.rn.f32 	%f382, %f1266, %f2190;
	add.f32 	%f1290, %f381, %f1285;
	sub.f32 	%f1291, %f381, %f1290;
	add.f32 	%f1292, %f1285, %f1291;
	add.f32 	%f1293, %f1287, %f1292;
	add.f32 	%f1294, %f382, %f1293;
	add.f32 	%f1295, %f1290, %f1294;
	sub.f32 	%f1296, %f1290, %f1295;
	add.f32 	%f1297, %f1294, %f1296;
	mul.rn.f32 	%f1299, %f1025, %f1295;
	neg.f32 	%f1300, %f1299;
	fma.rn.f32 	%f1301, %f1025, %f1295, %f1300;
	fma.rn.f32 	%f1302, %f1025, %f1297, %f1301;
	fma.rn.f32 	%f1304, %f2191, %f1295, %f1302;
	add.rn.f32 	%f1305, %f1299, %f1304;
	neg.f32 	%f1306, %f1305;
	add.rn.f32 	%f1307, %f1299, %f1306;
	add.rn.f32 	%f1308, %f1307, %f1304;
	mov.b32 	 %r343, %f1305;
	setp.eq.s32	%p79, %r343, 1118925336;
	add.s32 	%r344, %r343, -1;
	mov.b32 	 %f1309, %r344;
	add.f32 	%f1310, %f1308, 0f37000000;
	selp.f32	%f1311, %f1309, %f1305, %p79;
	selp.f32	%f383, %f1310, %f1308, %p79;
	mul.f32 	%f1312, %f1311, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1313, %f1312;
	fma.rn.f32 	%f1315, %f1313, %f2192, %f1311;
	fma.rn.f32 	%f1317, %f1313, %f2193, %f1315;
	mul.f32 	%f1318, %f1317, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1319, %f1318;
	add.f32 	%f1320, %f1313, 0f00000000;
	ex2.approx.f32 	%f1321, %f1320;
	mul.f32 	%f1322, %f1319, %f1321;
	setp.lt.f32	%p80, %f1311, 0fC2D20000;
	selp.f32	%f1323, 0f00000000, %f1322, %p80;
	setp.gt.f32	%p81, %f1311, 0f42D20000;
	selp.f32	%f2353, 0f7F800000, %f1323, %p81;
	setp.eq.f32	%p82, %f2353, 0f7F800000;
	@%p82 bra 	BB11_76;

	fma.rn.f32 	%f2353, %f2353, %f383, %f2353;

BB11_76:
	setp.lt.f32	%p83, %f1020, 0f00000000;
	and.pred  	%p4, %p83, %p36;
	mov.b32 	 %r345, %f2353;
	xor.b32  	%r346, %r345, -2147483648;
	mov.b32 	 %f1324, %r346;
	selp.f32	%f2355, %f1324, %f2353, %p4;
	setp.eq.f32	%p85, %f1020, 0f00000000;
	@%p85 bra 	BB11_79;
	bra.uni 	BB11_77;

BB11_79:
	add.f32 	%f2184, %f1020, %f1020;
	selp.f32	%f2355, %f2184, 0f00000000, %p36;
	bra.uni 	BB11_80;

BB11_77:
	setp.geu.f32	%p86, %f1020, 0f00000000;
	@%p86 bra 	BB11_80;

	cvt.rzi.f32.f32	%f1326, %f1025;
	setp.neu.f32	%p87, %f1326, 0f40000000;
	selp.f32	%f2355, 0f7FFFFFFF, %f2355, %p87;

BB11_80:
	abs.f32 	%f2173, %f1020;
	add.f32 	%f1328, %f2173, 0f40000000;
	mov.b32 	 %r11, %f1328;
	setp.lt.s32	%p89, %r11, 2139095040;
	@%p89 bra 	BB11_85;

	abs.f32 	%f2182, %f1020;
	setp.gtu.f32	%p90, %f2182, 0f7F800000;
	@%p90 bra 	BB11_84;
	bra.uni 	BB11_82;

BB11_84:
	add.f32 	%f2355, %f1020, 0f40000000;
	bra.uni 	BB11_85;

BB11_82:
	abs.f32 	%f2183, %f1020;
	setp.neu.f32	%p91, %f2183, 0f7F800000;
	@%p91 bra 	BB11_85;

	selp.f32	%f2355, 0fFF800000, 0f7F800000, %p4;

BB11_85:
	mov.f32 	%f2181, 0fB5BFBE8E;
	mov.f32 	%f2180, 0fBF317200;
	mov.f32 	%f2179, 0f00000000;
	mov.f32 	%f2178, 0f35BFBE8E;
	mov.f32 	%f2177, 0f3F317200;
	mov.f32 	%f2176, 0f3DAAAABD;
	mov.f32 	%f2175, 0f3C4CAF63;
	mov.f32 	%f2174, 0f3B18F0FE;
	setp.eq.f32	%p92, %f1020, 0f3F800000;
	selp.f32	%f1331, 0f3F800000, %f2355, %p92;
	add.f32 	%f394, %f376, %f1331;
	abs.f32 	%f395, %f2293;
	setp.lt.f32	%p93, %f395, 0f00800000;
	mul.f32 	%f1332, %f395, 0f4B800000;
	selp.f32	%f1333, 0fC3170000, 0fC2FE0000, %p93;
	selp.f32	%f1334, %f1332, %f395, %p93;
	mov.b32 	 %r347, %f1334;
	and.b32  	%r348, %r347, 8388607;
	or.b32  	%r349, %r348, 1065353216;
	mov.b32 	 %f1335, %r349;
	shr.u32 	%r350, %r347, 23;
	cvt.rn.f32.u32	%f1336, %r350;
	add.f32 	%f1337, %f1333, %f1336;
	setp.gt.f32	%p94, %f1335, 0f3FB504F3;
	mul.f32 	%f1338, %f1335, 0f3F000000;
	add.f32 	%f1339, %f1337, 0f3F800000;
	selp.f32	%f1340, %f1338, %f1335, %p94;
	selp.f32	%f1341, %f1339, %f1337, %p94;
	add.f32 	%f396, %f1340, 0fBF800000;
	add.f32 	%f1330, %f1340, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1329,%f1330;
	// inline asm
	add.f32 	%f398, %f396, %f396;
	mul.f32 	%f1342, %f1329, %f398;
	mul.f32 	%f1343, %f1342, %f1342;
	fma.rn.f32 	%f1346, %f2174, %f1343, %f2175;
	fma.rn.f32 	%f1348, %f1346, %f1343, %f2176;
	mul.rn.f32 	%f1349, %f1348, %f1343;
	mul.rn.f32 	%f1350, %f1349, %f1342;
	sub.f32 	%f1351, %f396, %f1342;
	neg.f32 	%f1352, %f1342;
	add.f32 	%f1353, %f1351, %f1351;
	fma.rn.f32 	%f1354, %f1352, %f396, %f1353;
	mul.rn.f32 	%f1355, %f1329, %f1354;
	add.f32 	%f1356, %f1350, %f1342;
	sub.f32 	%f1357, %f1342, %f1356;
	add.f32 	%f1358, %f1350, %f1357;
	add.f32 	%f1359, %f1355, %f1358;
	add.f32 	%f1360, %f1356, %f1359;
	sub.f32 	%f1361, %f1356, %f1360;
	add.f32 	%f1362, %f1359, %f1361;
	mul.rn.f32 	%f399, %f1341, %f2177;
	mul.rn.f32 	%f400, %f1341, %f2178;
	add.f32 	%f1365, %f399, %f1360;
	sub.f32 	%f1366, %f399, %f1365;
	add.f32 	%f1367, %f1360, %f1366;
	add.f32 	%f1368, %f1362, %f1367;
	add.f32 	%f1369, %f400, %f1368;
	add.f32 	%f1370, %f1365, %f1369;
	sub.f32 	%f1371, %f1365, %f1370;
	add.f32 	%f1372, %f1369, %f1371;
	mul.rn.f32 	%f1374, %f1025, %f1370;
	neg.f32 	%f1375, %f1374;
	fma.rn.f32 	%f1376, %f1025, %f1370, %f1375;
	fma.rn.f32 	%f1377, %f1025, %f1372, %f1376;
	fma.rn.f32 	%f1379, %f2179, %f1370, %f1377;
	add.rn.f32 	%f1380, %f1374, %f1379;
	neg.f32 	%f1381, %f1380;
	add.rn.f32 	%f1382, %f1374, %f1381;
	add.rn.f32 	%f1383, %f1382, %f1379;
	mov.b32 	 %r351, %f1380;
	setp.eq.s32	%p95, %r351, 1118925336;
	add.s32 	%r352, %r351, -1;
	mov.b32 	 %f1384, %r352;
	add.f32 	%f1385, %f1383, 0f37000000;
	selp.f32	%f1386, %f1384, %f1380, %p95;
	selp.f32	%f401, %f1385, %f1383, %p95;
	mul.f32 	%f1387, %f1386, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1388, %f1387;
	fma.rn.f32 	%f1390, %f1388, %f2180, %f1386;
	fma.rn.f32 	%f1392, %f1388, %f2181, %f1390;
	mul.f32 	%f1393, %f1392, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1394, %f1393;
	add.f32 	%f1395, %f1388, 0f00000000;
	ex2.approx.f32 	%f1396, %f1395;
	mul.f32 	%f1397, %f1394, %f1396;
	setp.lt.f32	%p96, %f1386, 0fC2D20000;
	selp.f32	%f1398, 0f00000000, %f1397, %p96;
	setp.gt.f32	%p97, %f1386, 0f42D20000;
	selp.f32	%f2356, 0f7F800000, %f1398, %p97;
	setp.eq.f32	%p98, %f2356, 0f7F800000;
	@%p98 bra 	BB11_87;

	fma.rn.f32 	%f2356, %f2356, %f401, %f2356;

BB11_87:
	setp.lt.f32	%p99, %f2293, 0f00000000;
	and.pred  	%p5, %p99, %p36;
	mov.b32 	 %r353, %f2356;
	xor.b32  	%r354, %r353, -2147483648;
	mov.b32 	 %f1399, %r354;
	selp.f32	%f2358, %f1399, %f2356, %p5;
	setp.eq.f32	%p101, %f2293, 0f00000000;
	@%p101 bra 	BB11_90;
	bra.uni 	BB11_88;

BB11_90:
	add.f32 	%f2169, %f2293, %f2293;
	selp.f32	%f2358, %f2169, 0f00000000, %p36;
	bra.uni 	BB11_91;

BB11_88:
	setp.geu.f32	%p102, %f2293, 0f00000000;
	@%p102 bra 	BB11_91;

	cvt.rzi.f32.f32	%f1401, %f1025;
	setp.neu.f32	%p103, %f1401, 0f40000000;
	selp.f32	%f2358, 0f7FFFFFFF, %f2358, %p103;

BB11_91:
	abs.f32 	%f2148, %f2293;
	add.f32 	%f1403, %f2148, 0f40000000;
	mov.b32 	 %r12, %f1403;
	setp.lt.s32	%p105, %r12, 2139095040;
	@%p105 bra 	BB11_96;

	abs.f32 	%f2167, %f2293;
	setp.gtu.f32	%p106, %f2167, 0f7F800000;
	@%p106 bra 	BB11_95;
	bra.uni 	BB11_93;

BB11_95:
	add.f32 	%f2358, %f2293, 0f40000000;
	bra.uni 	BB11_96;

BB11_93:
	abs.f32 	%f2168, %f2293;
	setp.neu.f32	%p107, %f2168, 0f7F800000;
	@%p107 bra 	BB11_96;

	selp.f32	%f2358, 0fFF800000, 0f7F800000, %p5;

BB11_96:
	add.f32 	%f2157, %f2293, %f2293;
	mov.f32 	%f2156, 0fB5BFBE8E;
	mov.f32 	%f2155, 0fBF317200;
	mov.f32 	%f2154, 0f00000000;
	mov.f32 	%f2153, 0f35BFBE8E;
	mov.f32 	%f2152, 0f3F317200;
	mov.f32 	%f2151, 0f3DAAAABD;
	mov.f32 	%f2150, 0f3C4CAF63;
	mov.f32 	%f2149, 0f3B18F0FE;
	setp.eq.f32	%p108, %f2293, 0f3F800000;
	selp.f32	%f1406, 0f3F800000, %f2358, %p108;
	add.f32 	%f1407, %f394, %f1406;
	mul.f32 	%f412, %f1021, %f2157;
	sub.f32 	%f413, %f1407, %f412;
	abs.f32 	%f414, %f1021;
	setp.lt.f32	%p109, %f414, 0f00800000;
	mul.f32 	%f1408, %f414, 0f4B800000;
	selp.f32	%f1409, 0fC3170000, 0fC2FE0000, %p109;
	selp.f32	%f1410, %f1408, %f414, %p109;
	mov.b32 	 %r355, %f1410;
	and.b32  	%r356, %r355, 8388607;
	or.b32  	%r357, %r356, 1065353216;
	mov.b32 	 %f1411, %r357;
	shr.u32 	%r358, %r355, 23;
	cvt.rn.f32.u32	%f1412, %r358;
	add.f32 	%f1413, %f1409, %f1412;
	setp.gt.f32	%p110, %f1411, 0f3FB504F3;
	mul.f32 	%f1414, %f1411, 0f3F000000;
	add.f32 	%f1415, %f1413, 0f3F800000;
	selp.f32	%f1416, %f1414, %f1411, %p110;
	selp.f32	%f1417, %f1415, %f1413, %p110;
	add.f32 	%f415, %f1416, 0fBF800000;
	add.f32 	%f1405, %f1416, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1404,%f1405;
	// inline asm
	add.f32 	%f417, %f415, %f415;
	mul.f32 	%f1418, %f1404, %f417;
	mul.f32 	%f1419, %f1418, %f1418;
	fma.rn.f32 	%f1422, %f2149, %f1419, %f2150;
	fma.rn.f32 	%f1424, %f1422, %f1419, %f2151;
	mul.rn.f32 	%f1425, %f1424, %f1419;
	mul.rn.f32 	%f1426, %f1425, %f1418;
	sub.f32 	%f1427, %f415, %f1418;
	neg.f32 	%f1428, %f1418;
	add.f32 	%f1429, %f1427, %f1427;
	fma.rn.f32 	%f1430, %f1428, %f415, %f1429;
	mul.rn.f32 	%f1431, %f1404, %f1430;
	add.f32 	%f1432, %f1426, %f1418;
	sub.f32 	%f1433, %f1418, %f1432;
	add.f32 	%f1434, %f1426, %f1433;
	add.f32 	%f1435, %f1431, %f1434;
	add.f32 	%f1436, %f1432, %f1435;
	sub.f32 	%f1437, %f1432, %f1436;
	add.f32 	%f1438, %f1435, %f1437;
	mul.rn.f32 	%f418, %f1417, %f2152;
	mul.rn.f32 	%f419, %f1417, %f2153;
	add.f32 	%f1441, %f418, %f1436;
	sub.f32 	%f1442, %f418, %f1441;
	add.f32 	%f1443, %f1436, %f1442;
	add.f32 	%f1444, %f1438, %f1443;
	add.f32 	%f1445, %f419, %f1444;
	add.f32 	%f1446, %f1441, %f1445;
	sub.f32 	%f1447, %f1441, %f1446;
	add.f32 	%f1448, %f1445, %f1447;
	mul.rn.f32 	%f1450, %f1025, %f1446;
	neg.f32 	%f1451, %f1450;
	fma.rn.f32 	%f1452, %f1025, %f1446, %f1451;
	fma.rn.f32 	%f1453, %f1025, %f1448, %f1452;
	fma.rn.f32 	%f1455, %f2154, %f1446, %f1453;
	add.rn.f32 	%f1456, %f1450, %f1455;
	neg.f32 	%f1457, %f1456;
	add.rn.f32 	%f1458, %f1450, %f1457;
	add.rn.f32 	%f1459, %f1458, %f1455;
	mov.b32 	 %r359, %f1456;
	setp.eq.s32	%p111, %r359, 1118925336;
	add.s32 	%r360, %r359, -1;
	mov.b32 	 %f1460, %r360;
	add.f32 	%f1461, %f1459, 0f37000000;
	selp.f32	%f1462, %f1460, %f1456, %p111;
	selp.f32	%f420, %f1461, %f1459, %p111;
	mul.f32 	%f1463, %f1462, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1464, %f1463;
	fma.rn.f32 	%f1466, %f1464, %f2155, %f1462;
	fma.rn.f32 	%f1468, %f1464, %f2156, %f1466;
	mul.f32 	%f1469, %f1468, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1470, %f1469;
	add.f32 	%f1471, %f1464, 0f00000000;
	ex2.approx.f32 	%f1472, %f1471;
	mul.f32 	%f1473, %f1470, %f1472;
	setp.lt.f32	%p112, %f1462, 0fC2D20000;
	selp.f32	%f1474, 0f00000000, %f1473, %p112;
	setp.gt.f32	%p113, %f1462, 0f42D20000;
	selp.f32	%f2359, 0f7F800000, %f1474, %p113;
	setp.eq.f32	%p114, %f2359, 0f7F800000;
	@%p114 bra 	BB11_98;

	fma.rn.f32 	%f2359, %f2359, %f420, %f2359;

BB11_98:
	setp.lt.f32	%p115, %f1021, 0f00000000;
	and.pred  	%p6, %p115, %p36;
	mov.b32 	 %r361, %f2359;
	xor.b32  	%r362, %r361, -2147483648;
	mov.b32 	 %f1475, %r362;
	selp.f32	%f2361, %f1475, %f2359, %p6;
	setp.eq.f32	%p117, %f1021, 0f00000000;
	@%p117 bra 	BB11_101;
	bra.uni 	BB11_99;

BB11_101:
	add.f32 	%f2166, %f1021, %f1021;
	selp.f32	%f2361, %f2166, 0f00000000, %p36;
	bra.uni 	BB11_102;

BB11_99:
	setp.geu.f32	%p118, %f1021, 0f00000000;
	@%p118 bra 	BB11_102;

	cvt.rzi.f32.f32	%f1477, %f1025;
	setp.neu.f32	%p119, %f1477, 0f40000000;
	selp.f32	%f2361, 0f7FFFFFFF, %f2361, %p119;

BB11_102:
	abs.f32 	%f2170, %f1021;
	add.f32 	%f1479, %f2170, 0f40000000;
	mov.b32 	 %r13, %f1479;
	setp.lt.s32	%p121, %r13, 2139095040;
	@%p121 bra 	BB11_107;

	abs.f32 	%f2171, %f1021;
	setp.gtu.f32	%p122, %f2171, 0f7F800000;
	@%p122 bra 	BB11_106;
	bra.uni 	BB11_104;

BB11_106:
	add.f32 	%f2361, %f1021, 0f40000000;
	bra.uni 	BB11_107;

BB11_104:
	abs.f32 	%f2172, %f1021;
	setp.neu.f32	%p123, %f2172, 0f7F800000;
	@%p123 bra 	BB11_107;

	selp.f32	%f2361, 0fFF800000, 0f7F800000, %p6;

BB11_107:
	mov.f32 	%f2165, 0fB5BFBE8E;
	mov.f32 	%f2164, 0fBF317200;
	mov.f32 	%f2163, 0f00000000;
	mov.f32 	%f2162, 0f35BFBE8E;
	mov.f32 	%f2161, 0f3F317200;
	mov.f32 	%f2160, 0f3DAAAABD;
	mov.f32 	%f2159, 0f3C4CAF63;
	mov.f32 	%f2158, 0f3B18F0FE;
	setp.eq.f32	%p124, %f1021, 0f3F800000;
	selp.f32	%f1482, 0f3F800000, %f2361, %p124;
	add.f32 	%f431, %f413, %f1482;
	abs.f32 	%f432, %f315;
	setp.lt.f32	%p125, %f432, 0f00800000;
	mul.f32 	%f1483, %f432, 0f4B800000;
	selp.f32	%f1484, 0fC3170000, 0fC2FE0000, %p125;
	selp.f32	%f1485, %f1483, %f432, %p125;
	mov.b32 	 %r363, %f1485;
	and.b32  	%r364, %r363, 8388607;
	or.b32  	%r365, %r364, 1065353216;
	mov.b32 	 %f1486, %r365;
	shr.u32 	%r366, %r363, 23;
	cvt.rn.f32.u32	%f1487, %r366;
	add.f32 	%f1488, %f1484, %f1487;
	setp.gt.f32	%p126, %f1486, 0f3FB504F3;
	mul.f32 	%f1489, %f1486, 0f3F000000;
	add.f32 	%f1490, %f1488, 0f3F800000;
	selp.f32	%f1491, %f1489, %f1486, %p126;
	selp.f32	%f1492, %f1490, %f1488, %p126;
	add.f32 	%f1493, %f1491, 0fBF800000;
	add.f32 	%f1481, %f1491, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1480,%f1481;
	// inline asm
	add.f32 	%f1494, %f1493, %f1493;
	mul.f32 	%f1495, %f1480, %f1494;
	mul.f32 	%f1496, %f1495, %f1495;
	fma.rn.f32 	%f1499, %f2158, %f1496, %f2159;
	fma.rn.f32 	%f1501, %f1499, %f1496, %f2160;
	mul.rn.f32 	%f1502, %f1501, %f1496;
	mul.rn.f32 	%f1503, %f1502, %f1495;
	sub.f32 	%f1504, %f1493, %f1495;
	neg.f32 	%f1505, %f1495;
	add.f32 	%f1506, %f1504, %f1504;
	fma.rn.f32 	%f1507, %f1505, %f1493, %f1506;
	mul.rn.f32 	%f1508, %f1480, %f1507;
	add.f32 	%f1509, %f1503, %f1495;
	sub.f32 	%f1510, %f1495, %f1509;
	add.f32 	%f1511, %f1503, %f1510;
	add.f32 	%f1512, %f1508, %f1511;
	add.f32 	%f1513, %f1509, %f1512;
	sub.f32 	%f1514, %f1509, %f1513;
	add.f32 	%f1515, %f1512, %f1514;
	mul.rn.f32 	%f1517, %f1492, %f2161;
	mul.rn.f32 	%f1519, %f1492, %f2162;
	add.f32 	%f1520, %f1517, %f1513;
	sub.f32 	%f1521, %f1517, %f1520;
	add.f32 	%f1522, %f1513, %f1521;
	add.f32 	%f1523, %f1515, %f1522;
	add.f32 	%f1524, %f1519, %f1523;
	add.f32 	%f1525, %f1520, %f1524;
	sub.f32 	%f1526, %f1520, %f1525;
	add.f32 	%f1527, %f1524, %f1526;
	mul.rn.f32 	%f1529, %f1025, %f1525;
	neg.f32 	%f1530, %f1529;
	fma.rn.f32 	%f1531, %f1025, %f1525, %f1530;
	fma.rn.f32 	%f1532, %f1025, %f1527, %f1531;
	fma.rn.f32 	%f1534, %f2163, %f1525, %f1532;
	add.rn.f32 	%f1535, %f1529, %f1534;
	neg.f32 	%f1536, %f1535;
	add.rn.f32 	%f1537, %f1529, %f1536;
	add.rn.f32 	%f1538, %f1537, %f1534;
	mov.b32 	 %r367, %f1535;
	setp.eq.s32	%p127, %r367, 1118925336;
	add.s32 	%r368, %r367, -1;
	mov.b32 	 %f1539, %r368;
	add.f32 	%f1540, %f1538, 0f37000000;
	selp.f32	%f1541, %f1539, %f1535, %p127;
	selp.f32	%f433, %f1540, %f1538, %p127;
	mul.f32 	%f1542, %f1541, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1543, %f1542;
	fma.rn.f32 	%f1545, %f1543, %f2164, %f1541;
	fma.rn.f32 	%f1547, %f1543, %f2165, %f1545;
	mul.f32 	%f1548, %f1547, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1549, %f1548;
	add.f32 	%f1550, %f1543, 0f00000000;
	ex2.approx.f32 	%f1551, %f1550;
	mul.f32 	%f1552, %f1549, %f1551;
	setp.lt.f32	%p128, %f1541, 0fC2D20000;
	selp.f32	%f1553, 0f00000000, %f1552, %p128;
	setp.gt.f32	%p129, %f1541, 0f42D20000;
	selp.f32	%f2362, 0f7F800000, %f1553, %p129;
	setp.eq.f32	%p130, %f2362, 0f7F800000;
	@%p130 bra 	BB11_109;

	fma.rn.f32 	%f2362, %f2362, %f433, %f2362;

BB11_109:
	setp.lt.f32	%p131, %f315, 0f00000000;
	and.pred  	%p7, %p131, %p36;
	mov.b32 	 %r369, %f2362;
	xor.b32  	%r370, %r369, -2147483648;
	mov.b32 	 %f1554, %r370;
	selp.f32	%f2364, %f1554, %f2362, %p7;
	setp.eq.f32	%p133, %f315, 0f00000000;
	@%p133 bra 	BB11_112;
	bra.uni 	BB11_110;

BB11_112:
	add.f32 	%f1557, %f315, %f315;
	selp.f32	%f2364, %f1557, 0f00000000, %p36;
	bra.uni 	BB11_113;

BB11_110:
	setp.geu.f32	%p134, %f315, 0f00000000;
	@%p134 bra 	BB11_113;

	cvt.rzi.f32.f32	%f1556, %f1025;
	setp.neu.f32	%p135, %f1556, 0f40000000;
	selp.f32	%f2364, 0f7FFFFFFF, %f2364, %p135;

BB11_113:
	abs.f32 	%f2069, %f315;
	add.f32 	%f1558, %f2069, 0f40000000;
	mov.b32 	 %r371, %f1558;
	setp.lt.s32	%p137, %r371, 2139095040;
	@%p137 bra 	BB11_118;

	abs.f32 	%f2146, %f315;
	setp.gtu.f32	%p138, %f2146, 0f7F800000;
	@%p138 bra 	BB11_117;
	bra.uni 	BB11_115;

BB11_117:
	add.f32 	%f2364, %f315, 0f40000000;
	bra.uni 	BB11_118;

BB11_115:
	abs.f32 	%f2147, %f315;
	setp.neu.f32	%p139, %f2147, 0f7F800000;
	@%p139 bra 	BB11_118;

	selp.f32	%f2364, 0fFF800000, 0f7F800000, %p7;

BB11_118:
	setp.eq.f32	%p141, %f315, 0f3F800000;
	selp.f32	%f1560, 0f3F800000, %f2364, %p141;
	sub.f32 	%f444, %f431, %f1560;
	setp.eq.f32	%p142, %f357, 0f00000000;
	setp.eq.f32	%p143, %f354, 0f00000000;
	and.pred  	%p144, %p143, %p142;
	mov.pred 	%p332, -1;
	@%p144 bra 	BB11_122;

	neg.f32 	%f1561, %f444;
	div.rn.f32 	%f2365, %f1561, %f357;
	mul.f32 	%f1562, %f354, 0fC0800000;
	mul.f32 	%f1563, %f1562, %f444;
	fma.rn.f32 	%f446, %f357, %f357, %f1563;
	setp.lt.f32	%p146, %f446, 0f00000000;
	setp.neu.f32	%p147, %f354, 0f00000000;
	and.pred  	%p148, %p146, %p147;
	@%p148 bra 	BB11_120;
	bra.uni 	BB11_121;

BB11_120:
	mov.f32 	%f2366, %f2365;
	bra.uni 	BB11_122;

BB11_121:
	mov.b32 	 %r372, %f357;
	and.b32  	%r373, %r372, -2147483648;
	sqrt.rn.f32 	%f1564, %f446;
	mov.b32 	 %r374, %f1564;
	and.b32  	%r375, %r374, 2147483647;
	or.b32  	%r376, %r375, %r373;
	mov.b32 	 %f1565, %r376;
	add.f32 	%f1566, %f357, %f1565;
	mul.f32 	%f1567, %f1566, 0fBF000000;
	div.rn.f32 	%f1568, %f1567, %f354;
	div.rn.f32 	%f1569, %f444, %f1567;
	min.f32 	%f1570, %f1568, %f1569;
	max.f32 	%f1571, %f1568, %f1569;
	selp.f32	%f2366, %f2365, %f1570, %p143;
	selp.f32	%f2365, %f2365, %f1571, %p143;
	mov.pred 	%p332, 0;

BB11_122:
	ld.v2.f32 	{%f1572, %f1573}, [%rd1+320];
	mov.u16 	%rs25, 0;
	mov.u16 	%rs24, %rs25;
	@%p332 bra 	BB11_126;

	setp.leu.f32	%p151, %f2366, %f1016;
	setp.geu.f32	%p152, %f2366, %f1017;
	or.pred  	%p153, %p151, %p152;
	mov.u16 	%rs24, %rs25;
	@%p153 bra 	BB11_126;

	fma.rn.f32 	%f453, %f2366, %f2343, %f2292;
	setp.ltu.f32	%p154, %f453, %f1572;
	mov.u16 	%rs24, %rs25;
	@%p154 bra 	BB11_126;

	setp.lt.f32	%p155, %f453, %f1573;
	selp.u16	%rs24, 1, 0, %p155;

BB11_126:
	@%p332 bra 	BB11_130;

	setp.leu.f32	%p156, %f2365, %f1016;
	setp.geu.f32	%p157, %f2365, %f1017;
	or.pred  	%p158, %p156, %p157;
	@%p158 bra 	BB11_130;

	fma.rn.f32 	%f454, %f2365, %f2343, %f2292;
	setp.ltu.f32	%p159, %f454, %f1572;
	@%p159 bra 	BB11_130;

	setp.lt.f32	%p160, %f454, %f1573;
	selp.u16	%rs25, 1, 0, %p160;

BB11_130:
	mov.f32 	%f2075, 0fB5BFBE8E;
	mov.f32 	%f2074, 0fBF317200;
	mov.f32 	%f2073, 0f00000000;
	mov.f32 	%f2072, 0f3DAAAABD;
	mov.f32 	%f2071, 0f3C4CAF63;
	mov.f32 	%f2070, 0f3B18F0FE;
	setp.eq.s16	%p161, %rs25, 0;
	selp.f32	%f1576, 0f7F800000, %f2365, %p161;
	setp.eq.s16	%p162, %rs24, 0;
	selp.f32	%f455, %f1576, %f2366, %p162;
	ld.f32 	%f456, [%rd1+308];
	// inline asm
	rcp.approx.ftz.f32 %f1574,%f1019;
	// inline asm
	mul.f32 	%f1577, %f1574, %f322;
	mul.f32 	%f1578, %f1577, %f1577;
	fma.rn.f32 	%f1581, %f2070, %f1578, %f2071;
	fma.rn.f32 	%f1583, %f1581, %f1578, %f2072;
	mul.rn.f32 	%f1584, %f1583, %f1578;
	mul.rn.f32 	%f1585, %f1584, %f1577;
	sub.f32 	%f1586, %f320, %f1577;
	neg.f32 	%f1587, %f1577;
	add.f32 	%f1588, %f1586, %f1586;
	fma.rn.f32 	%f1589, %f1587, %f320, %f1588;
	mul.rn.f32 	%f1590, %f1574, %f1589;
	add.f32 	%f1591, %f1585, %f1577;
	sub.f32 	%f1592, %f1577, %f1591;
	add.f32 	%f1593, %f1585, %f1592;
	add.f32 	%f1594, %f1590, %f1593;
	add.f32 	%f1595, %f1591, %f1594;
	sub.f32 	%f1596, %f1591, %f1595;
	add.f32 	%f1597, %f1594, %f1596;
	add.f32 	%f1598, %f323, %f1595;
	sub.f32 	%f1599, %f323, %f1598;
	add.f32 	%f1600, %f1595, %f1599;
	add.f32 	%f1601, %f1597, %f1600;
	add.f32 	%f1602, %f324, %f1601;
	add.f32 	%f1603, %f1598, %f1602;
	sub.f32 	%f1604, %f1598, %f1603;
	add.f32 	%f1605, %f1602, %f1604;
	mul.rn.f32 	%f1607, %f1025, %f1603;
	neg.f32 	%f1608, %f1607;
	fma.rn.f32 	%f1609, %f1025, %f1603, %f1608;
	fma.rn.f32 	%f1610, %f1025, %f1605, %f1609;
	fma.rn.f32 	%f1612, %f2073, %f1603, %f1610;
	add.rn.f32 	%f1613, %f1607, %f1612;
	neg.f32 	%f1614, %f1613;
	add.rn.f32 	%f1615, %f1607, %f1614;
	add.rn.f32 	%f1616, %f1615, %f1612;
	mov.b32 	 %r377, %f1613;
	setp.eq.s32	%p163, %r377, 1118925336;
	add.s32 	%r378, %r377, -1;
	mov.b32 	 %f1617, %r378;
	add.f32 	%f1618, %f1616, 0f37000000;
	selp.f32	%f1619, %f1617, %f1613, %p163;
	selp.f32	%f457, %f1618, %f1616, %p163;
	mul.f32 	%f1620, %f1619, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1621, %f1620;
	fma.rn.f32 	%f1623, %f1621, %f2074, %f1619;
	fma.rn.f32 	%f1625, %f1621, %f2075, %f1623;
	mul.f32 	%f1626, %f1625, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1627, %f1626;
	add.f32 	%f1628, %f1621, 0f00000000;
	ex2.approx.f32 	%f1629, %f1628;
	mul.f32 	%f1630, %f1627, %f1629;
	setp.lt.f32	%p164, %f1619, 0fC2D20000;
	selp.f32	%f1631, 0f00000000, %f1630, %p164;
	setp.gt.f32	%p165, %f1619, 0f42D20000;
	selp.f32	%f2367, 0f7F800000, %f1631, %p165;
	setp.eq.f32	%p166, %f2367, 0f7F800000;
	@%p166 bra 	BB11_132;

	fma.rn.f32 	%f2367, %f2367, %f457, %f2367;

BB11_132:
	setp.lt.f32	%p307, %f2341, 0f00000000;
	and.pred  	%p306, %p307, %p36;
	setp.eq.f32	%p288, %f2341, 0f00000000;
	mov.b32 	 %r379, %f2367;
	xor.b32  	%r380, %r379, -2147483648;
	mov.b32 	 %f1632, %r380;
	selp.f32	%f2369, %f1632, %f2367, %p306;
	@%p288 bra 	BB11_135;
	bra.uni 	BB11_133;

BB11_135:
	add.f32 	%f1635, %f2341, %f2341;
	selp.f32	%f2369, %f1635, 0f00000000, %p36;
	bra.uni 	BB11_136;

BB11_133:
	setp.geu.f32	%p168, %f2341, 0f00000000;
	@%p168 bra 	BB11_136;

	cvt.rzi.f32.f32	%f1634, %f1025;
	setp.neu.f32	%p169, %f1634, 0f40000000;
	selp.f32	%f2369, 0f7FFFFFFF, %f2369, %p169;

BB11_136:
	abs.f32 	%f2077, %f2341;
	add.f32 	%f2076, %f2077, 0f40000000;
	mov.b32 	 %r417, %f2076;
	setp.lt.s32	%p289, %r417, 2139095040;
	@%p289 bra 	BB11_141;

	abs.f32 	%f2144, %f2341;
	setp.gtu.f32	%p172, %f2144, 0f7F800000;
	@%p172 bra 	BB11_140;
	bra.uni 	BB11_138;

BB11_140:
	add.f32 	%f2369, %f2341, 0f40000000;
	bra.uni 	BB11_141;

BB11_138:
	abs.f32 	%f2145, %f2341;
	setp.neu.f32	%p173, %f2145, 0f7F800000;
	@%p173 bra 	BB11_141;

	setp.lt.f32	%p321, %f2341, 0f00000000;
	and.pred  	%p320, %p321, %p36;
	selp.f32	%f2369, 0fFF800000, 0f7F800000, %p320;

BB11_141:
	setp.eq.f32	%p290, %f2341, 0f3F800000;
	mov.f32 	%f2083, 0fB5BFBE8E;
	mov.f32 	%f2082, 0fBF317200;
	mov.f32 	%f2081, 0f00000000;
	mov.f32 	%f2080, 0f3DAAAABD;
	mov.f32 	%f2079, 0f3C4CAF63;
	mov.f32 	%f2078, 0f3B18F0FE;
	selp.f32	%f468, 0f3F800000, %f2369, %p290;
	// inline asm
	rcp.approx.ftz.f32 %f1636,%f1099;
	// inline asm
	mul.f32 	%f1638, %f1636, %f340;
	mul.f32 	%f1639, %f1638, %f1638;
	fma.rn.f32 	%f1642, %f2078, %f1639, %f2079;
	fma.rn.f32 	%f1644, %f1642, %f1639, %f2080;
	mul.rn.f32 	%f1645, %f1644, %f1639;
	mul.rn.f32 	%f1646, %f1645, %f1638;
	sub.f32 	%f1647, %f338, %f1638;
	neg.f32 	%f1648, %f1638;
	add.f32 	%f1649, %f1647, %f1647;
	fma.rn.f32 	%f1650, %f1648, %f338, %f1649;
	mul.rn.f32 	%f1651, %f1636, %f1650;
	add.f32 	%f1652, %f1646, %f1638;
	sub.f32 	%f1653, %f1638, %f1652;
	add.f32 	%f1654, %f1646, %f1653;
	add.f32 	%f1655, %f1651, %f1654;
	add.f32 	%f1656, %f1652, %f1655;
	sub.f32 	%f1657, %f1652, %f1656;
	add.f32 	%f1658, %f1655, %f1657;
	add.f32 	%f1659, %f341, %f1656;
	sub.f32 	%f1660, %f341, %f1659;
	add.f32 	%f1661, %f1656, %f1660;
	add.f32 	%f1662, %f1658, %f1661;
	add.f32 	%f1663, %f342, %f1662;
	add.f32 	%f1664, %f1659, %f1663;
	sub.f32 	%f1665, %f1659, %f1664;
	add.f32 	%f1666, %f1663, %f1665;
	mul.rn.f32 	%f1668, %f1025, %f1664;
	neg.f32 	%f1669, %f1668;
	fma.rn.f32 	%f1670, %f1025, %f1664, %f1669;
	fma.rn.f32 	%f1671, %f1025, %f1666, %f1670;
	fma.rn.f32 	%f1673, %f2081, %f1664, %f1671;
	add.rn.f32 	%f1674, %f1668, %f1673;
	neg.f32 	%f1675, %f1674;
	add.rn.f32 	%f1676, %f1668, %f1675;
	add.rn.f32 	%f1677, %f1676, %f1673;
	mov.b32 	 %r381, %f1674;
	setp.eq.s32	%p175, %r381, 1118925336;
	add.s32 	%r382, %r381, -1;
	mov.b32 	 %f1678, %r382;
	add.f32 	%f1679, %f1677, 0f37000000;
	selp.f32	%f1680, %f1678, %f1674, %p175;
	selp.f32	%f469, %f1679, %f1677, %p175;
	mul.f32 	%f1681, %f1680, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1682, %f1681;
	fma.rn.f32 	%f1684, %f1682, %f2082, %f1680;
	fma.rn.f32 	%f1686, %f1682, %f2083, %f1684;
	mul.f32 	%f1687, %f1686, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1688, %f1687;
	add.f32 	%f1689, %f1682, 0f00000000;
	ex2.approx.f32 	%f1690, %f1689;
	mul.f32 	%f1691, %f1688, %f1690;
	setp.lt.f32	%p176, %f1680, 0fC2D20000;
	selp.f32	%f1692, 0f00000000, %f1691, %p176;
	setp.gt.f32	%p177, %f1680, 0f42D20000;
	selp.f32	%f2370, 0f7F800000, %f1692, %p177;
	setp.eq.f32	%p178, %f2370, 0f7F800000;
	@%p178 bra 	BB11_143;

	fma.rn.f32 	%f2370, %f2370, %f469, %f2370;

BB11_143:
	setp.lt.f32	%p309, %f2342, 0f00000000;
	and.pred  	%p308, %p309, %p36;
	setp.eq.f32	%p291, %f2342, 0f00000000;
	mov.b32 	 %r383, %f2370;
	xor.b32  	%r384, %r383, -2147483648;
	mov.b32 	 %f1693, %r384;
	selp.f32	%f2372, %f1693, %f2370, %p308;
	@%p291 bra 	BB11_146;
	bra.uni 	BB11_144;

BB11_146:
	add.f32 	%f1696, %f2342, %f2342;
	selp.f32	%f2372, %f1696, 0f00000000, %p36;
	bra.uni 	BB11_147;

BB11_144:
	setp.geu.f32	%p180, %f2342, 0f00000000;
	@%p180 bra 	BB11_147;

	cvt.rzi.f32.f32	%f1695, %f1025;
	setp.neu.f32	%p181, %f1695, 0f40000000;
	selp.f32	%f2372, 0f7FFFFFFF, %f2372, %p181;

BB11_147:
	abs.f32 	%f2085, %f2342;
	add.f32 	%f2084, %f2085, 0f40000000;
	mov.b32 	 %r418, %f2084;
	setp.lt.s32	%p292, %r418, 2139095040;
	@%p292 bra 	BB11_152;

	abs.f32 	%f2142, %f2342;
	setp.gtu.f32	%p184, %f2142, 0f7F800000;
	@%p184 bra 	BB11_151;
	bra.uni 	BB11_149;

BB11_151:
	add.f32 	%f2372, %f2342, 0f40000000;
	bra.uni 	BB11_152;

BB11_149:
	abs.f32 	%f2143, %f2342;
	setp.neu.f32	%p185, %f2143, 0f7F800000;
	@%p185 bra 	BB11_152;

	setp.lt.f32	%p319, %f2342, 0f00000000;
	and.pred  	%p318, %p319, %p36;
	selp.f32	%f2372, 0fFF800000, 0f7F800000, %p318;

BB11_152:
	setp.eq.f32	%p293, %f2342, 0f3F800000;
	mov.f32 	%f2091, 0fB5BFBE8E;
	mov.f32 	%f2090, 0fBF317200;
	mov.f32 	%f2089, 0f00000000;
	mov.f32 	%f2088, 0f3DAAAABD;
	mov.f32 	%f2087, 0f3C4CAF63;
	mov.f32 	%f2086, 0f3B18F0FE;
	selp.f32	%f1699, 0f3F800000, %f2372, %p293;
	add.f32 	%f480, %f468, %f1699;
	// inline asm
	rcp.approx.ftz.f32 %f1697,%f1173;
	// inline asm
	mul.f32 	%f1700, %f1697, %f361;
	mul.f32 	%f1701, %f1700, %f1700;
	fma.rn.f32 	%f1704, %f2086, %f1701, %f2087;
	fma.rn.f32 	%f1706, %f1704, %f1701, %f2088;
	mul.rn.f32 	%f1707, %f1706, %f1701;
	mul.rn.f32 	%f1708, %f1707, %f1700;
	sub.f32 	%f1709, %f359, %f1700;
	neg.f32 	%f1710, %f1700;
	add.f32 	%f1711, %f1709, %f1709;
	fma.rn.f32 	%f1712, %f1710, %f359, %f1711;
	mul.rn.f32 	%f1713, %f1697, %f1712;
	add.f32 	%f1714, %f1708, %f1700;
	sub.f32 	%f1715, %f1700, %f1714;
	add.f32 	%f1716, %f1708, %f1715;
	add.f32 	%f1717, %f1713, %f1716;
	add.f32 	%f1718, %f1714, %f1717;
	sub.f32 	%f1719, %f1714, %f1718;
	add.f32 	%f1720, %f1717, %f1719;
	add.f32 	%f1721, %f362, %f1718;
	sub.f32 	%f1722, %f362, %f1721;
	add.f32 	%f1723, %f1718, %f1722;
	add.f32 	%f1724, %f1720, %f1723;
	add.f32 	%f1725, %f363, %f1724;
	add.f32 	%f1726, %f1721, %f1725;
	sub.f32 	%f1727, %f1721, %f1726;
	add.f32 	%f1728, %f1725, %f1727;
	mul.rn.f32 	%f1730, %f1025, %f1726;
	neg.f32 	%f1731, %f1730;
	fma.rn.f32 	%f1732, %f1025, %f1726, %f1731;
	fma.rn.f32 	%f1733, %f1025, %f1728, %f1732;
	fma.rn.f32 	%f1735, %f2089, %f1726, %f1733;
	add.rn.f32 	%f1736, %f1730, %f1735;
	neg.f32 	%f1737, %f1736;
	add.rn.f32 	%f1738, %f1730, %f1737;
	add.rn.f32 	%f1739, %f1738, %f1735;
	mov.b32 	 %r385, %f1736;
	setp.eq.s32	%p187, %r385, 1118925336;
	add.s32 	%r386, %r385, -1;
	mov.b32 	 %f1740, %r386;
	add.f32 	%f1741, %f1739, 0f37000000;
	selp.f32	%f1742, %f1740, %f1736, %p187;
	selp.f32	%f481, %f1741, %f1739, %p187;
	mul.f32 	%f1743, %f1742, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1744, %f1743;
	fma.rn.f32 	%f1746, %f1744, %f2090, %f1742;
	fma.rn.f32 	%f1748, %f1744, %f2091, %f1746;
	mul.f32 	%f1749, %f1748, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1750, %f1749;
	add.f32 	%f1751, %f1744, 0f00000000;
	ex2.approx.f32 	%f1752, %f1751;
	mul.f32 	%f1753, %f1750, %f1752;
	setp.lt.f32	%p188, %f1742, 0fC2D20000;
	selp.f32	%f1754, 0f00000000, %f1753, %p188;
	setp.gt.f32	%p189, %f1742, 0f42D20000;
	selp.f32	%f2373, 0f7F800000, %f1754, %p189;
	setp.eq.f32	%p190, %f2373, 0f7F800000;
	@%p190 bra 	BB11_154;

	fma.rn.f32 	%f2373, %f2373, %f481, %f2373;

BB11_154:
	setp.lt.f32	%p311, %f2294, 0f00000000;
	and.pred  	%p310, %p311, %p36;
	setp.eq.f32	%p294, %f2294, 0f00000000;
	mov.b32 	 %r387, %f2373;
	xor.b32  	%r388, %r387, -2147483648;
	mov.b32 	 %f1755, %r388;
	selp.f32	%f2375, %f1755, %f2373, %p310;
	@%p294 bra 	BB11_157;
	bra.uni 	BB11_155;

BB11_157:
	add.f32 	%f2141, %f2294, %f2294;
	selp.f32	%f2375, %f2141, 0f00000000, %p36;
	bra.uni 	BB11_158;

BB11_155:
	setp.geu.f32	%p192, %f2294, 0f00000000;
	@%p192 bra 	BB11_158;

	cvt.rzi.f32.f32	%f1757, %f1025;
	setp.neu.f32	%p193, %f1757, 0f40000000;
	selp.f32	%f2375, 0f7FFFFFFF, %f2375, %p193;

BB11_158:
	abs.f32 	%f2093, %f2294;
	add.f32 	%f2092, %f2093, 0f40000000;
	mov.b32 	 %r419, %f2092;
	setp.lt.s32	%p295, %r419, 2139095040;
	@%p295 bra 	BB11_163;

	abs.f32 	%f2139, %f2294;
	setp.gtu.f32	%p196, %f2139, 0f7F800000;
	@%p196 bra 	BB11_162;
	bra.uni 	BB11_160;

BB11_162:
	add.f32 	%f2375, %f2294, 0f40000000;
	bra.uni 	BB11_163;

BB11_160:
	abs.f32 	%f2140, %f2294;
	setp.neu.f32	%p197, %f2140, 0f7F800000;
	@%p197 bra 	BB11_163;

	setp.lt.f32	%p317, %f2294, 0f00000000;
	and.pred  	%p316, %p317, %p36;
	selp.f32	%f2375, 0fFF800000, 0f7F800000, %p316;

BB11_163:
	add.f32 	%f2101, %f2294, %f2294;
	mul.f32 	%f2100, %f1020, %f2101;
	setp.eq.f32	%p296, %f2294, 0f3F800000;
	mov.f32 	%f2099, 0fB5BFBE8E;
	mov.f32 	%f2098, 0fBF317200;
	mov.f32 	%f2097, 0f00000000;
	mov.f32 	%f2096, 0f3DAAAABD;
	mov.f32 	%f2095, 0f3C4CAF63;
	mov.f32 	%f2094, 0f3B18F0FE;
	selp.f32	%f1761, 0f3F800000, %f2375, %p296;
	sub.f32 	%f492, %f1761, %f2100;
	// inline asm
	rcp.approx.ftz.f32 %f1759,%f1255;
	// inline asm
	mul.f32 	%f1762, %f1759, %f380;
	mul.f32 	%f1763, %f1762, %f1762;
	fma.rn.f32 	%f1766, %f2094, %f1763, %f2095;
	fma.rn.f32 	%f1768, %f1766, %f1763, %f2096;
	mul.rn.f32 	%f1769, %f1768, %f1763;
	mul.rn.f32 	%f1770, %f1769, %f1762;
	sub.f32 	%f1771, %f378, %f1762;
	neg.f32 	%f1772, %f1762;
	add.f32 	%f1773, %f1771, %f1771;
	fma.rn.f32 	%f1774, %f1772, %f378, %f1773;
	mul.rn.f32 	%f1775, %f1759, %f1774;
	add.f32 	%f1776, %f1770, %f1762;
	sub.f32 	%f1777, %f1762, %f1776;
	add.f32 	%f1778, %f1770, %f1777;
	add.f32 	%f1779, %f1775, %f1778;
	add.f32 	%f1780, %f1776, %f1779;
	sub.f32 	%f1781, %f1776, %f1780;
	add.f32 	%f1782, %f1779, %f1781;
	add.f32 	%f1783, %f381, %f1780;
	sub.f32 	%f1784, %f381, %f1783;
	add.f32 	%f1785, %f1780, %f1784;
	add.f32 	%f1786, %f1782, %f1785;
	add.f32 	%f1787, %f382, %f1786;
	add.f32 	%f1788, %f1783, %f1787;
	sub.f32 	%f1789, %f1783, %f1788;
	add.f32 	%f1790, %f1787, %f1789;
	mul.rn.f32 	%f1792, %f1025, %f1788;
	neg.f32 	%f1793, %f1792;
	fma.rn.f32 	%f1794, %f1025, %f1788, %f1793;
	fma.rn.f32 	%f1795, %f1025, %f1790, %f1794;
	fma.rn.f32 	%f1797, %f2097, %f1788, %f1795;
	add.rn.f32 	%f1798, %f1792, %f1797;
	neg.f32 	%f1799, %f1798;
	add.rn.f32 	%f1800, %f1792, %f1799;
	add.rn.f32 	%f1801, %f1800, %f1797;
	mov.b32 	 %r389, %f1798;
	setp.eq.s32	%p199, %r389, 1118925336;
	add.s32 	%r390, %r389, -1;
	mov.b32 	 %f1802, %r390;
	add.f32 	%f1803, %f1801, 0f37000000;
	selp.f32	%f1804, %f1802, %f1798, %p199;
	selp.f32	%f493, %f1803, %f1801, %p199;
	mul.f32 	%f1805, %f1804, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1806, %f1805;
	fma.rn.f32 	%f1808, %f1806, %f2098, %f1804;
	fma.rn.f32 	%f1810, %f1806, %f2099, %f1808;
	mul.f32 	%f1811, %f1810, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1812, %f1811;
	add.f32 	%f1813, %f1806, 0f00000000;
	ex2.approx.f32 	%f1814, %f1813;
	mul.f32 	%f1815, %f1812, %f1814;
	setp.lt.f32	%p200, %f1804, 0fC2D20000;
	selp.f32	%f1816, 0f00000000, %f1815, %p200;
	setp.gt.f32	%p201, %f1804, 0f42D20000;
	selp.f32	%f2376, 0f7F800000, %f1816, %p201;
	setp.eq.f32	%p202, %f2376, 0f7F800000;
	@%p202 bra 	BB11_165;

	fma.rn.f32 	%f2376, %f2376, %f493, %f2376;

BB11_165:
	setp.lt.f32	%p313, %f1020, 0f00000000;
	and.pred  	%p312, %p313, %p36;
	setp.eq.f32	%p297, %f1020, 0f00000000;
	mov.b32 	 %r391, %f2376;
	xor.b32  	%r392, %r391, -2147483648;
	mov.b32 	 %f1817, %r392;
	selp.f32	%f2378, %f1817, %f2376, %p312;
	@%p297 bra 	BB11_168;
	bra.uni 	BB11_166;

BB11_168:
	add.f32 	%f2138, %f1020, %f1020;
	selp.f32	%f2378, %f2138, 0f00000000, %p36;
	bra.uni 	BB11_169;

BB11_166:
	setp.geu.f32	%p204, %f1020, 0f00000000;
	@%p204 bra 	BB11_169;

	cvt.rzi.f32.f32	%f1819, %f1025;
	setp.neu.f32	%p205, %f1819, 0f40000000;
	selp.f32	%f2378, 0f7FFFFFFF, %f2378, %p205;

BB11_169:
	abs.f32 	%f2103, %f1020;
	add.f32 	%f2102, %f2103, 0f40000000;
	mov.b32 	 %r420, %f2102;
	setp.lt.s32	%p298, %r420, 2139095040;
	@%p298 bra 	BB11_174;

	abs.f32 	%f2136, %f1020;
	setp.gtu.f32	%p208, %f2136, 0f7F800000;
	@%p208 bra 	BB11_173;
	bra.uni 	BB11_171;

BB11_173:
	add.f32 	%f2378, %f1020, 0f40000000;
	bra.uni 	BB11_174;

BB11_171:
	abs.f32 	%f2137, %f1020;
	setp.neu.f32	%p209, %f2137, 0f7F800000;
	@%p209 bra 	BB11_174;

	setp.lt.f32	%p315, %f1020, 0f00000000;
	and.pred  	%p314, %p315, %p36;
	selp.f32	%f2378, 0fFF800000, 0f7F800000, %p314;

BB11_174:
	setp.eq.f32	%p299, %f1020, 0f3F800000;
	mov.f32 	%f2109, 0fB5BFBE8E;
	mov.f32 	%f2108, 0fBF317200;
	mov.f32 	%f2107, 0f00000000;
	mov.f32 	%f2106, 0f3DAAAABD;
	mov.f32 	%f2105, 0f3C4CAF63;
	mov.f32 	%f2104, 0f3B18F0FE;
	selp.f32	%f1823, 0f3F800000, %f2378, %p299;
	add.f32 	%f504, %f492, %f1823;
	// inline asm
	rcp.approx.ftz.f32 %f1821,%f1330;
	// inline asm
	mul.f32 	%f1824, %f1821, %f398;
	mul.f32 	%f1825, %f1824, %f1824;
	fma.rn.f32 	%f1828, %f2104, %f1825, %f2105;
	fma.rn.f32 	%f1830, %f1828, %f1825, %f2106;
	mul.rn.f32 	%f1831, %f1830, %f1825;
	mul.rn.f32 	%f1832, %f1831, %f1824;
	sub.f32 	%f1833, %f396, %f1824;
	neg.f32 	%f1834, %f1824;
	add.f32 	%f1835, %f1833, %f1833;
	fma.rn.f32 	%f1836, %f1834, %f396, %f1835;
	mul.rn.f32 	%f1837, %f1821, %f1836;
	add.f32 	%f1838, %f1832, %f1824;
	sub.f32 	%f1839, %f1824, %f1838;
	add.f32 	%f1840, %f1832, %f1839;
	add.f32 	%f1841, %f1837, %f1840;
	add.f32 	%f1842, %f1838, %f1841;
	sub.f32 	%f1843, %f1838, %f1842;
	add.f32 	%f1844, %f1841, %f1843;
	add.f32 	%f1845, %f399, %f1842;
	sub.f32 	%f1846, %f399, %f1845;
	add.f32 	%f1847, %f1842, %f1846;
	add.f32 	%f1848, %f1844, %f1847;
	add.f32 	%f1849, %f400, %f1848;
	add.f32 	%f1850, %f1845, %f1849;
	sub.f32 	%f1851, %f1845, %f1850;
	add.f32 	%f1852, %f1849, %f1851;
	mul.rn.f32 	%f1854, %f1025, %f1850;
	neg.f32 	%f1855, %f1854;
	fma.rn.f32 	%f1856, %f1025, %f1850, %f1855;
	fma.rn.f32 	%f1857, %f1025, %f1852, %f1856;
	fma.rn.f32 	%f1859, %f2107, %f1850, %f1857;
	add.rn.f32 	%f1860, %f1854, %f1859;
	neg.f32 	%f1861, %f1860;
	add.rn.f32 	%f1862, %f1854, %f1861;
	add.rn.f32 	%f1863, %f1862, %f1859;
	mov.b32 	 %r393, %f1860;
	setp.eq.s32	%p211, %r393, 1118925336;
	add.s32 	%r394, %r393, -1;
	mov.b32 	 %f1864, %r394;
	add.f32 	%f1865, %f1863, 0f37000000;
	selp.f32	%f1866, %f1864, %f1860, %p211;
	selp.f32	%f505, %f1865, %f1863, %p211;
	mul.f32 	%f1867, %f1866, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1868, %f1867;
	fma.rn.f32 	%f1870, %f1868, %f2108, %f1866;
	fma.rn.f32 	%f1872, %f1868, %f2109, %f1870;
	mul.f32 	%f1873, %f1872, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1874, %f1873;
	add.f32 	%f1875, %f1868, 0f00000000;
	ex2.approx.f32 	%f1876, %f1875;
	mul.f32 	%f1877, %f1874, %f1876;
	setp.lt.f32	%p212, %f1866, 0fC2D20000;
	selp.f32	%f1878, 0f00000000, %f1877, %p212;
	setp.gt.f32	%p213, %f1866, 0f42D20000;
	selp.f32	%f2379, 0f7F800000, %f1878, %p213;
	setp.eq.f32	%p214, %f2379, 0f7F800000;
	@%p214 bra 	BB11_176;

	fma.rn.f32 	%f2379, %f2379, %f505, %f2379;

BB11_176:
	setp.lt.f32	%p323, %f2293, 0f00000000;
	and.pred  	%p322, %p323, %p36;
	setp.eq.f32	%p300, %f2293, 0f00000000;
	mov.b32 	 %r395, %f2379;
	xor.b32  	%r396, %r395, -2147483648;
	mov.b32 	 %f1879, %r396;
	selp.f32	%f2381, %f1879, %f2379, %p322;
	@%p300 bra 	BB11_179;
	bra.uni 	BB11_177;

BB11_179:
	add.f32 	%f2135, %f2293, %f2293;
	selp.f32	%f2381, %f2135, 0f00000000, %p36;
	bra.uni 	BB11_180;

BB11_177:
	setp.geu.f32	%p216, %f2293, 0f00000000;
	@%p216 bra 	BB11_180;

	cvt.rzi.f32.f32	%f1881, %f1025;
	setp.neu.f32	%p217, %f1881, 0f40000000;
	selp.f32	%f2381, 0f7FFFFFFF, %f2381, %p217;

BB11_180:
	abs.f32 	%f2111, %f2293;
	add.f32 	%f2110, %f2111, 0f40000000;
	mov.b32 	 %r421, %f2110;
	setp.lt.s32	%p301, %r421, 2139095040;
	@%p301 bra 	BB11_185;

	abs.f32 	%f2133, %f2293;
	setp.gtu.f32	%p220, %f2133, 0f7F800000;
	@%p220 bra 	BB11_184;
	bra.uni 	BB11_182;

BB11_184:
	add.f32 	%f2381, %f2293, 0f40000000;
	bra.uni 	BB11_185;

BB11_182:
	abs.f32 	%f2134, %f2293;
	setp.neu.f32	%p221, %f2134, 0f7F800000;
	@%p221 bra 	BB11_185;

	setp.lt.f32	%p325, %f2293, 0f00000000;
	and.pred  	%p324, %p325, %p36;
	selp.f32	%f2381, 0fFF800000, 0f7F800000, %p324;

BB11_185:
	add.f32 	%f2119, %f2293, %f2293;
	mul.f32 	%f2118, %f1021, %f2119;
	setp.eq.f32	%p302, %f2293, 0f3F800000;
	mov.f32 	%f2117, 0fB5BFBE8E;
	mov.f32 	%f2116, 0fBF317200;
	mov.f32 	%f2115, 0f00000000;
	mov.f32 	%f2114, 0f3DAAAABD;
	mov.f32 	%f2113, 0f3C4CAF63;
	mov.f32 	%f2112, 0f3B18F0FE;
	selp.f32	%f1885, 0f3F800000, %f2381, %p302;
	add.f32 	%f1886, %f504, %f1885;
	sub.f32 	%f516, %f1886, %f2118;
	// inline asm
	rcp.approx.ftz.f32 %f1883,%f1405;
	// inline asm
	mul.f32 	%f1887, %f1883, %f417;
	mul.f32 	%f1888, %f1887, %f1887;
	fma.rn.f32 	%f1891, %f2112, %f1888, %f2113;
	fma.rn.f32 	%f1893, %f1891, %f1888, %f2114;
	mul.rn.f32 	%f1894, %f1893, %f1888;
	mul.rn.f32 	%f1895, %f1894, %f1887;
	sub.f32 	%f1896, %f415, %f1887;
	neg.f32 	%f1897, %f1887;
	add.f32 	%f1898, %f1896, %f1896;
	fma.rn.f32 	%f1899, %f1897, %f415, %f1898;
	mul.rn.f32 	%f1900, %f1883, %f1899;
	add.f32 	%f1901, %f1895, %f1887;
	sub.f32 	%f1902, %f1887, %f1901;
	add.f32 	%f1903, %f1895, %f1902;
	add.f32 	%f1904, %f1900, %f1903;
	add.f32 	%f1905, %f1901, %f1904;
	sub.f32 	%f1906, %f1901, %f1905;
	add.f32 	%f1907, %f1904, %f1906;
	add.f32 	%f1908, %f418, %f1905;
	sub.f32 	%f1909, %f418, %f1908;
	add.f32 	%f1910, %f1905, %f1909;
	add.f32 	%f1911, %f1907, %f1910;
	add.f32 	%f1912, %f419, %f1911;
	add.f32 	%f1913, %f1908, %f1912;
	sub.f32 	%f1914, %f1908, %f1913;
	add.f32 	%f1915, %f1912, %f1914;
	mul.rn.f32 	%f1917, %f1025, %f1913;
	neg.f32 	%f1918, %f1917;
	fma.rn.f32 	%f1919, %f1025, %f1913, %f1918;
	fma.rn.f32 	%f1920, %f1025, %f1915, %f1919;
	fma.rn.f32 	%f1922, %f2115, %f1913, %f1920;
	add.rn.f32 	%f1923, %f1917, %f1922;
	neg.f32 	%f1924, %f1923;
	add.rn.f32 	%f1925, %f1917, %f1924;
	add.rn.f32 	%f1926, %f1925, %f1922;
	mov.b32 	 %r397, %f1923;
	setp.eq.s32	%p223, %r397, 1118925336;
	add.s32 	%r398, %r397, -1;
	mov.b32 	 %f1927, %r398;
	add.f32 	%f1928, %f1926, 0f37000000;
	selp.f32	%f1929, %f1927, %f1923, %p223;
	selp.f32	%f517, %f1928, %f1926, %p223;
	mul.f32 	%f1930, %f1929, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1931, %f1930;
	fma.rn.f32 	%f1933, %f1931, %f2116, %f1929;
	fma.rn.f32 	%f1935, %f1931, %f2117, %f1933;
	mul.f32 	%f1936, %f1935, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f1937, %f1936;
	add.f32 	%f1938, %f1931, 0f00000000;
	ex2.approx.f32 	%f1939, %f1938;
	mul.f32 	%f1940, %f1937, %f1939;
	setp.lt.f32	%p224, %f1929, 0fC2D20000;
	selp.f32	%f1941, 0f00000000, %f1940, %p224;
	setp.gt.f32	%p225, %f1929, 0f42D20000;
	selp.f32	%f2382, 0f7F800000, %f1941, %p225;
	setp.eq.f32	%p226, %f2382, 0f7F800000;
	@%p226 bra 	BB11_187;

	fma.rn.f32 	%f2382, %f2382, %f517, %f2382;

BB11_187:
	setp.lt.f32	%p327, %f1021, 0f00000000;
	and.pred  	%p326, %p327, %p36;
	setp.eq.f32	%p303, %f1021, 0f00000000;
	mov.b32 	 %r399, %f2382;
	xor.b32  	%r400, %r399, -2147483648;
	mov.b32 	 %f1942, %r400;
	selp.f32	%f2384, %f1942, %f2382, %p326;
	@%p303 bra 	BB11_190;
	bra.uni 	BB11_188;

BB11_190:
	add.f32 	%f2132, %f1021, %f1021;
	selp.f32	%f2384, %f2132, 0f00000000, %p36;
	bra.uni 	BB11_191;

BB11_188:
	setp.geu.f32	%p228, %f1021, 0f00000000;
	@%p228 bra 	BB11_191;

	cvt.rzi.f32.f32	%f1944, %f1025;
	setp.neu.f32	%p229, %f1944, 0f40000000;
	selp.f32	%f2384, 0f7FFFFFFF, %f2384, %p229;

BB11_191:
	abs.f32 	%f2121, %f1021;
	add.f32 	%f2120, %f2121, 0f40000000;
	mov.b32 	 %r422, %f2120;
	setp.lt.s32	%p304, %r422, 2139095040;
	@%p304 bra 	BB11_196;

	abs.f32 	%f2130, %f1021;
	setp.gtu.f32	%p232, %f2130, 0f7F800000;
	@%p232 bra 	BB11_195;
	bra.uni 	BB11_193;

BB11_195:
	add.f32 	%f2384, %f1021, 0f40000000;
	bra.uni 	BB11_196;

BB11_193:
	abs.f32 	%f2131, %f1021;
	setp.neu.f32	%p233, %f2131, 0f7F800000;
	@%p233 bra 	BB11_196;

	setp.lt.f32	%p330, %f1021, 0f00000000;
	and.pred  	%p329, %p330, %p36;
	selp.f32	%f2384, 0fFF800000, 0f7F800000, %p329;

BB11_196:
	setp.eq.f32	%p305, %f1021, 0f3F800000;
	mov.f32 	%f2129, 0fB5BFBE8E;
	mov.f32 	%f2128, 0fBF317200;
	mov.f32 	%f2127, 0f00000000;
	mov.f32 	%f2126, 0f35BFBE8E;
	mov.f32 	%f2125, 0f3F317200;
	mov.f32 	%f2124, 0f3DAAAABD;
	mov.f32 	%f2123, 0f3C4CAF63;
	mov.f32 	%f2122, 0f3B18F0FE;
	selp.f32	%f1948, 0f3F800000, %f2384, %p305;
	add.f32 	%f528, %f516, %f1948;
	abs.f32 	%f529, %f456;
	setp.lt.f32	%p235, %f529, 0f00800000;
	mul.f32 	%f1949, %f529, 0f4B800000;
	selp.f32	%f1950, 0fC3170000, 0fC2FE0000, %p235;
	selp.f32	%f1951, %f1949, %f529, %p235;
	mov.b32 	 %r401, %f1951;
	and.b32  	%r402, %r401, 8388607;
	or.b32  	%r403, %r402, 1065353216;
	mov.b32 	 %f1952, %r403;
	shr.u32 	%r404, %r401, 23;
	cvt.rn.f32.u32	%f1953, %r404;
	add.f32 	%f1954, %f1950, %f1953;
	setp.gt.f32	%p236, %f1952, 0f3FB504F3;
	mul.f32 	%f1955, %f1952, 0f3F000000;
	add.f32 	%f1956, %f1954, 0f3F800000;
	selp.f32	%f1957, %f1955, %f1952, %p236;
	selp.f32	%f1958, %f1956, %f1954, %p236;
	add.f32 	%f1959, %f1957, 0fBF800000;
	add.f32 	%f1947, %f1957, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1946,%f1947;
	// inline asm
	add.f32 	%f1960, %f1959, %f1959;
	mul.f32 	%f1961, %f1946, %f1960;
	mul.f32 	%f1962, %f1961, %f1961;
	fma.rn.f32 	%f1965, %f2122, %f1962, %f2123;
	fma.rn.f32 	%f1967, %f1965, %f1962, %f2124;
	mul.rn.f32 	%f1968, %f1967, %f1962;
	mul.rn.f32 	%f1969, %f1968, %f1961;
	sub.f32 	%f1970, %f1959, %f1961;
	neg.f32 	%f1971, %f1961;
	add.f32 	%f1972, %f1970, %f1970;
	fma.rn.f32 	%f1973, %f1971, %f1959, %f1972;
	mul.rn.f32 	%f1974, %f1946, %f1973;
	add.f32 	%f1975, %f1969, %f1961;
	sub.f32 	%f1976, %f1961, %f1975;
	add.f32 	%f1977, %f1969, %f1976;
	add.f32 	%f1978, %f1974, %f1977;
	add.f32 	%f1979, %f1975, %f1978;
	sub.f32 	%f1980, %f1975, %f1979;
	add.f32 	%f1981, %f1978, %f1980;
	mul.rn.f32 	%f1983, %f1958, %f2125;
	mul.rn.f32 	%f1985, %f1958, %f2126;
	add.f32 	%f1986, %f1983, %f1979;
	sub.f32 	%f1987, %f1983, %f1986;
	add.f32 	%f1988, %f1979, %f1987;
	add.f32 	%f1989, %f1981, %f1988;
	add.f32 	%f1990, %f1985, %f1989;
	add.f32 	%f1991, %f1986, %f1990;
	sub.f32 	%f1992, %f1986, %f1991;
	add.f32 	%f1993, %f1990, %f1992;
	mul.rn.f32 	%f1995, %f1025, %f1991;
	neg.f32 	%f1996, %f1995;
	fma.rn.f32 	%f1997, %f1025, %f1991, %f1996;
	fma.rn.f32 	%f1998, %f1025, %f1993, %f1997;
	fma.rn.f32 	%f2000, %f2127, %f1991, %f1998;
	add.rn.f32 	%f2001, %f1995, %f2000;
	neg.f32 	%f2002, %f2001;
	add.rn.f32 	%f2003, %f1995, %f2002;
	add.rn.f32 	%f2004, %f2003, %f2000;
	mov.b32 	 %r405, %f2001;
	setp.eq.s32	%p237, %r405, 1118925336;
	add.s32 	%r406, %r405, -1;
	mov.b32 	 %f2005, %r406;
	add.f32 	%f2006, %f2004, 0f37000000;
	selp.f32	%f2007, %f2005, %f2001, %p237;
	selp.f32	%f530, %f2006, %f2004, %p237;
	mul.f32 	%f2008, %f2007, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f2009, %f2008;
	fma.rn.f32 	%f2011, %f2009, %f2128, %f2007;
	fma.rn.f32 	%f2013, %f2009, %f2129, %f2011;
	mul.f32 	%f2014, %f2013, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f2015, %f2014;
	add.f32 	%f2016, %f2009, 0f00000000;
	ex2.approx.f32 	%f2017, %f2016;
	mul.f32 	%f2018, %f2015, %f2017;
	setp.lt.f32	%p238, %f2007, 0fC2D20000;
	selp.f32	%f2019, 0f00000000, %f2018, %p238;
	setp.gt.f32	%p239, %f2007, 0f42D20000;
	selp.f32	%f2385, 0f7F800000, %f2019, %p239;
	setp.eq.f32	%p240, %f2385, 0f7F800000;
	@%p240 bra 	BB11_198;

	fma.rn.f32 	%f2385, %f2385, %f530, %f2385;

BB11_198:
	setp.lt.f32	%p241, %f456, 0f00000000;
	and.pred  	%p9, %p241, %p36;
	mov.b32 	 %r407, %f2385;
	xor.b32  	%r408, %r407, -2147483648;
	mov.b32 	 %f2020, %r408;
	selp.f32	%f2387, %f2020, %f2385, %p9;
	setp.eq.f32	%p243, %f456, 0f00000000;
	@%p243 bra 	BB11_201;
	bra.uni 	BB11_199;

BB11_201:
	add.f32 	%f2023, %f456, %f456;
	selp.f32	%f2387, %f2023, 0f00000000, %p36;
	bra.uni 	BB11_202;

BB11_199:
	setp.geu.f32	%p244, %f456, 0f00000000;
	@%p244 bra 	BB11_202;

	cvt.rzi.f32.f32	%f2022, %f1025;
	setp.neu.f32	%p245, %f2022, 0f40000000;
	selp.f32	%f2387, 0f7FFFFFFF, %f2387, %p245;

BB11_202:
	add.f32 	%f2024, %f529, 0f40000000;
	mov.b32 	 %r409, %f2024;
	setp.lt.s32	%p247, %r409, 2139095040;
	@%p247 bra 	BB11_207;

	setp.gtu.f32	%p248, %f529, 0f7F800000;
	@%p248 bra 	BB11_206;
	bra.uni 	BB11_204;

BB11_206:
	add.f32 	%f2387, %f456, 0f40000000;
	bra.uni 	BB11_207;

BB11_204:
	setp.neu.f32	%p249, %f529, 0f7F800000;
	@%p249 bra 	BB11_207;

	selp.f32	%f2387, 0fFF800000, 0f7F800000, %p9;

BB11_207:
	setp.eq.f32	%p328, %f357, 0f00000000;
	setp.eq.f32	%p251, %f456, 0f3F800000;
	selp.f32	%f2026, 0f3F800000, %f2387, %p251;
	sub.f32 	%f541, %f528, %f2026;
	setp.eq.f32	%p252, %f480, 0f00000000;
	and.pred  	%p254, %p252, %p328;
	mov.pred 	%p333, -1;
	@%p254 bra 	BB11_211;

	neg.f32 	%f2027, %f541;
	div.rn.f32 	%f2388, %f2027, %f357;
	mul.f32 	%f2028, %f480, 0fC0800000;
	mul.f32 	%f2029, %f2028, %f541;
	fma.rn.f32 	%f543, %f357, %f357, %f2029;
	setp.lt.f32	%p256, %f543, 0f00000000;
	setp.neu.f32	%p257, %f480, 0f00000000;
	and.pred  	%p258, %p256, %p257;
	@%p258 bra 	BB11_209;
	bra.uni 	BB11_210;

BB11_209:
	mov.f32 	%f2389, %f2388;
	bra.uni 	BB11_211;

BB11_210:
	mov.b32 	 %r410, %f357;
	and.b32  	%r411, %r410, -2147483648;
	sqrt.rn.f32 	%f2030, %f543;
	mov.b32 	 %r412, %f2030;
	and.b32  	%r413, %r412, 2147483647;
	or.b32  	%r414, %r413, %r411;
	mov.b32 	 %f2031, %r414;
	add.f32 	%f2032, %f357, %f2031;
	mul.f32 	%f2033, %f2032, 0fBF000000;
	div.rn.f32 	%f2034, %f2033, %f480;
	div.rn.f32 	%f2035, %f541, %f2033;
	min.f32 	%f2036, %f2034, %f2035;
	max.f32 	%f2037, %f2034, %f2035;
	selp.f32	%f2389, %f2388, %f2036, %p252;
	selp.f32	%f2388, %f2388, %f2037, %p252;
	mov.pred 	%p333, 0;

BB11_211:
	mov.u16 	%rs26, 0;
	@%p333 bra 	BB11_215;

	setp.leu.f32	%p261, %f2389, %f1016;
	setp.geu.f32	%p262, %f2389, %f1017;
	or.pred  	%p263, %p261, %p262;
	@%p263 bra 	BB11_215;

	fma.rn.f32 	%f548, %f2389, %f2343, %f2292;
	setp.ltu.f32	%p264, %f548, %f1572;
	@%p264 bra 	BB11_215;

	setp.lt.f32	%p265, %f548, %f1573;
	selp.u16	%rs26, 1, 0, %p265;

BB11_215:
	mov.f32 	%f2394, 0f7F800000;
	mov.f32 	%f2390, %f2394;
	@%p333 bra 	BB11_219;

	setp.leu.f32	%p266, %f2388, %f1016;
	setp.geu.f32	%p267, %f2388, %f1017;
	or.pred  	%p268, %p266, %p267;
	mov.f32 	%f2390, %f2394;
	@%p268 bra 	BB11_219;

	fma.rn.f32 	%f549, %f2388, %f2343, %f2292;
	setp.ltu.f32	%p269, %f549, %f1572;
	mov.f32 	%f2390, %f2394;
	@%p269 bra 	BB11_219;

	setp.lt.f32	%p270, %f549, %f1573;
	selp.f32	%f2390, %f2388, 0f7F800000, %p270;

BB11_219:
	setp.eq.s16	%p271, %rs26, 0;
	selp.f32	%f552, %f2390, %f2389, %p271;
	add.f32 	%f553, %f1020, 0f00000000;
	add.f32 	%f554, %f1021, 0f00000000;
	ld.f32 	%f555, [%rd1+296];
	add.f32 	%f556, %f555, 0f00000000;
	setp.eq.f32	%p272, %f2343, 0f00000000;
	mov.f32 	%f2391, %f2394;
	@%p272 bra 	BB11_221;

	sub.f32 	%f2042, %f556, %f2292;
	div.rn.f32 	%f2391, %f2042, %f2343;

BB11_221:
	setp.gtu.f32	%p273, %f2391, %f1017;
	setp.ltu.f32	%p274, %f2391, %f1016;
	or.pred  	%p275, %p274, %p273;
	selp.f32	%f559, 0f7F800000, %f2391, %p275;
	fma.rn.f32 	%f2044, %f559, %f2341, %f2294;
	fma.rn.f32 	%f2045, %f559, %f2342, %f2293;
	fma.rn.f32 	%f2046, %f559, %f2343, %f2292;
	sub.f32 	%f2047, %f553, %f2044;
	sub.f32 	%f2048, %f554, %f2045;
	sub.f32 	%f2049, %f556, %f2046;
	mul.f32 	%f2050, %f2047, %f2047;
	fma.rn.f32 	%f2051, %f2048, %f2048, %f2050;
	fma.rn.f32 	%f2052, %f2049, %f2049, %f2051;
	sqrt.rn.f32 	%f560, %f2052;
	setp.ltu.f32	%p276, %f560, %f315;
	mov.f32 	%f2392, %f2394;
	@%p276 bra 	BB11_223;

	setp.le.f32	%p277, %f560, %f456;
	selp.f32	%f2392, %f559, 0f7F800000, %p277;

BB11_223:
	ld.f32 	%f2054, [%rd1+316];
	add.f32 	%f563, %f555, %f2054;
	mov.f32 	%f2393, %f2394;
	@%p272 bra 	BB11_225;

	sub.f32 	%f2055, %f563, %f2292;
	div.rn.f32 	%f2393, %f2055, %f2343;

BB11_225:
	setp.gtu.f32	%p279, %f2393, %f1017;
	setp.ltu.f32	%p280, %f2393, %f1016;
	or.pred  	%p281, %p280, %p279;
	selp.f32	%f566, 0f7F800000, %f2393, %p281;
	fma.rn.f32 	%f2057, %f566, %f2341, %f2294;
	fma.rn.f32 	%f2058, %f566, %f2342, %f2293;
	fma.rn.f32 	%f2059, %f566, %f2343, %f2292;
	sub.f32 	%f2060, %f553, %f2057;
	sub.f32 	%f2061, %f554, %f2058;
	sub.f32 	%f2062, %f563, %f2059;
	mul.f32 	%f2063, %f2060, %f2060;
	fma.rn.f32 	%f2064, %f2061, %f2061, %f2063;
	fma.rn.f32 	%f2065, %f2062, %f2062, %f2064;
	sqrt.rn.f32 	%f567, %f2065;
	setp.ltu.f32	%p282, %f567, %f315;
	@%p282 bra 	BB11_227;

	setp.le.f32	%p283, %f567, %f456;
	selp.f32	%f2394, %f566, 0f7F800000, %p283;

BB11_227:
	setp.lt.f32	%p284, %f455, %f552;
	selp.f32	%f2066, %f455, %f552, %p284;
	setp.geu.f32	%p285, %f2066, %f2392;
	selp.f32	%f2067, %f2392, %f2066, %p285;
	setp.geu.f32	%p286, %f2067, %f2394;
	selp.f32	%f570, %f2394, %f2067, %p286;
	setp.eq.f32	%p287, %f570, 0f7F800000;
	@%p287 bra 	BB11_229;

	mov.u32 	%r416, 254;
	// inline asm
	call (%r415), _optix_report_intersection_0, (%f570, %r416);
	// inline asm

BB11_229:
	ret;
}

	// .globl	__closesthit__cylhollow
.visible .entry __closesthit__cylhollow(

)
{
	.reg .pred 	%p<55>;
	.reg .b16 	%rs<18>;
	.reg .f32 	%f<1924>;
	.reg .b32 	%r<635>;
	.reg .b64 	%rd<647>;


	// inline asm
	call (%r19), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r20), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r22), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r23), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r24), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r25, %r24, %r20, %r23;
	mad.lo.s32 	%r1, %r25, %r19, %r22;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	@%p1 bra 	BB12_2;

	cvta.to.global.u64 	%rd46, %rd1;
	cvt.u64.u32	%rd47, %r1;
	add.s64 	%rd48, %rd46, %rd47;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd48], %rs1;
	bra.uni 	BB12_112;

BB12_2:
	// inline asm
	call (%rd49), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	ld.u64 	%rd3, [%rd49+8];
	// inline asm
	call (%f667), _optix_get_world_ray_origin_x, ();
	// inline asm
	// inline asm
	call (%f668), _optix_get_world_ray_origin_y, ();
	// inline asm
	// inline asm
	call (%f1723), _optix_get_world_ray_origin_z, ();
	// inline asm
	// inline asm
	call (%r26), _optix_get_transform_list_size, ();
	// inline asm
	setp.eq.s32	%p2, %r26, 0;
	@%p2 bra 	BB12_3;

	mov.u32 	%r631, 0;
	// inline asm
	call (%f670), _optix_get_ray_time, ();
	// inline asm

BB12_5:
	.pragma "nounroll";
	// inline asm
	call (%rd50), _optix_get_transform_list_handle, (%r631);
	// inline asm
	// inline asm
	call (%r29), _optix_get_transform_type_from_handle, (%rd50);
	// inline asm
	and.b32  	%r30, %r29, -2;
	setp.eq.s32	%p3, %r30, 2;
	@%p3 bra 	BB12_11;
	bra.uni 	BB12_6;

BB12_11:
	setp.eq.s32	%p6, %r29, 2;
	@%p6 bra 	BB12_15;
	bra.uni 	BB12_12;

BB12_15:
	// inline asm
	call (%rd124), _optix_get_matrix_motion_transform_from_handle, (%rd50);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd126, %rd124;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd126];
	// inline asm
	mov.b32	{%rs4, %rs5}, %r120;
	add.s64 	%rd130, %rd124, 16;
	// inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd129];
	// inline asm
	add.s64 	%rd133, %rd124, 32;
	// inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd132];
	// inline asm
	add.s64 	%rd136, %rd124, 48;
	// inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd135];
	// inline asm
	add.s64 	%rd139, %rd124, 64;
	// inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd138];
	// inline asm
	add.s64 	%rd142, %rd124, 80;
	// inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd141];
	// inline asm
	add.s64 	%rd145, %rd124, 96;
	// inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd144];
	// inline asm
	add.s64 	%rd148, %rd124, 112;
	// inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r146,%r147,%r148,%r149}, [%rd147];
	// inline asm
	mov.b32 	 %f797, %r121;
	mov.b32 	 %f798, %r122;
	cvt.u32.u16	%r162, %rs4;
	add.s32 	%r163, %r162, -1;
	cvt.rn.f32.s32	%f799, %r163;
	sub.f32 	%f800, %f670, %f797;
	mul.f32 	%f801, %f800, %f799;
	sub.f32 	%f802, %f798, %f797;
	div.rn.f32 	%f803, %f801, %f802;
	min.f32 	%f804, %f799, %f803;
	mov.f32 	%f805, 0f00000000;
	max.f32 	%f806, %f805, %f804;
	cvt.rmi.f32.f32	%f807, %f806;
	cvt.rzi.s32.f32	%r164, %f807;
	mul.wide.s32 	%rd159, %r164, 48;
	add.s64 	%rd151, %rd133, %rd159;
	// inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r150,%r151,%r152,%r153}, [%rd150];
	// inline asm
	mov.b32 	 %f1690, %r150;
	mov.b32 	 %f1689, %r151;
	mov.b32 	 %f1688, %r152;
	mov.b32 	 %f1687, %r153;
	add.s64 	%rd154, %rd151, 16;
	// inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r154,%r155,%r156,%r157}, [%rd153];
	// inline asm
	mov.b32 	 %f1694, %r154;
	mov.b32 	 %f1693, %r155;
	mov.b32 	 %f1692, %r156;
	mov.b32 	 %f1691, %r157;
	add.s64 	%rd157, %rd151, 32;
	// inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r158,%r159,%r160,%r161}, [%rd156];
	// inline asm
	sub.f32 	%f98, %f806, %f807;
	mov.b32 	 %f1698, %r158;
	mov.b32 	 %f1697, %r159;
	mov.b32 	 %f1696, %r160;
	mov.b32 	 %f1695, %r161;
	setp.leu.f32	%p8, %f98, 0f00000000;
	@%p8 bra 	BB12_17;

	cvt.rmi.f32.f32	%f1658, %f806;
	cvt.rzi.s32.f32	%r630, %f1658;
	cvt.s64.s32	%rd642, %r630;
	mul.lo.s64 	%rd169, %rd642, 48;
	add.s64 	%rd170, %rd124, %rd169;
	add.s64 	%rd161, %rd170, 80;
	// inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd160];
	// inline asm
	mov.b32 	 %f808, %r165;
	mov.b32 	 %f809, %r166;
	mov.b32 	 %f810, %r167;
	mov.b32 	 %f811, %r168;
	add.s64 	%rd164, %rd170, 96;
	// inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd163];
	// inline asm
	mov.b32 	 %f812, %r169;
	mov.b32 	 %f813, %r170;
	mov.b32 	 %f814, %r171;
	mov.b32 	 %f815, %r172;
	add.s64 	%rd167, %rd170, 112;
	// inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd166];
	// inline asm
	mov.f32 	%f816, 0f3F800000;
	sub.f32 	%f817, %f816, %f98;
	mul.f32 	%f818, %f98, %f808;
	mul.f32 	%f819, %f98, %f809;
	mul.f32 	%f820, %f98, %f810;
	mul.f32 	%f821, %f98, %f811;
	fma.rn.f32 	%f1690, %f817, %f1690, %f818;
	fma.rn.f32 	%f1689, %f817, %f1689, %f819;
	fma.rn.f32 	%f1688, %f817, %f1688, %f820;
	fma.rn.f32 	%f1687, %f817, %f1687, %f821;
	mul.f32 	%f822, %f98, %f812;
	mul.f32 	%f823, %f98, %f813;
	mul.f32 	%f824, %f98, %f814;
	mul.f32 	%f825, %f98, %f815;
	fma.rn.f32 	%f1694, %f817, %f1694, %f822;
	fma.rn.f32 	%f1693, %f817, %f1693, %f823;
	fma.rn.f32 	%f1692, %f817, %f1692, %f824;
	fma.rn.f32 	%f1691, %f817, %f1691, %f825;
	mov.b32 	 %f826, %r173;
	mov.b32 	 %f827, %r174;
	mov.b32 	 %f828, %r175;
	mov.b32 	 %f829, %r176;
	mul.f32 	%f830, %f98, %f826;
	mul.f32 	%f831, %f98, %f827;
	mul.f32 	%f832, %f98, %f828;
	mul.f32 	%f833, %f98, %f829;
	fma.rn.f32 	%f1698, %f817, %f1698, %f830;
	fma.rn.f32 	%f1697, %f817, %f1697, %f831;
	fma.rn.f32 	%f1696, %f817, %f1696, %f832;
	fma.rn.f32 	%f1695, %f817, %f1695, %f833;
	bra.uni 	BB12_17;

BB12_6:
	mov.f32 	%f1699, 0f00000000;
	mov.f32 	%f1702, 0f3F800000;
	setp.eq.s32	%p4, %r29, 4;
	@%p4 bra 	BB12_9;
	bra.uni 	BB12_7;

BB12_9:
	// inline asm
	call (%rd643), _optix_get_instance_inverse_transform_from_handle, (%rd50);
	// inline asm
	bra.uni 	BB12_10;

BB12_12:
	// inline asm
	call (%rd65), _optix_get_srt_motion_transform_from_handle, (%rd50);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd67, %rd65;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd67];
	// inline asm
	mov.b32	{%rs2, %rs3}, %r45;
	add.s64 	%rd71, %rd65, 16;
	// inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd70];
	// inline asm
	add.s64 	%rd74, %rd65, 32;
	// inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd73];
	// inline asm
	add.s64 	%rd77, %rd65, 48;
	// inline asm
	cvta.to.global.u64 %rd76, %rd77;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd76];
	// inline asm
	add.s64 	%rd80, %rd65, 64;
	// inline asm
	cvta.to.global.u64 %rd79, %rd80;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd79];
	// inline asm
	add.s64 	%rd83, %rd65, 80;
	// inline asm
	cvta.to.global.u64 %rd82, %rd83;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd82];
	// inline asm
	add.s64 	%rd86, %rd65, 96;
	// inline asm
	cvta.to.global.u64 %rd85, %rd86;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd85];
	// inline asm
	add.s64 	%rd89, %rd65, 112;
	// inline asm
	cvta.to.global.u64 %rd88, %rd89;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd88];
	// inline asm
	add.s64 	%rd92, %rd65, 128;
	// inline asm
	cvta.to.global.u64 %rd91, %rd92;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd91];
	// inline asm
	add.s64 	%rd95, %rd65, 144;
	// inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd94];
	// inline asm
	mov.b32 	 %f684, %r46;
	mov.b32 	 %f685, %r47;
	cvt.u32.u16	%r99, %rs2;
	add.s32 	%r100, %r99, -1;
	cvt.rn.f32.s32	%f686, %r100;
	sub.f32 	%f687, %f670, %f684;
	mul.f32 	%f688, %f687, %f686;
	sub.f32 	%f689, %f685, %f684;
	div.rn.f32 	%f690, %f688, %f689;
	min.f32 	%f691, %f686, %f690;
	mov.f32 	%f692, 0f00000000;
	max.f32 	%f693, %f692, %f691;
	cvt.rmi.f32.f32	%f694, %f693;
	cvt.rzi.s32.f32	%r101, %f694;
	mul.wide.s32 	%rd109, %r101, 64;
	add.s64 	%rd98, %rd74, %rd109;
	// inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r83,%r84,%r85,%r86}, [%rd97];
	// inline asm
	mov.b32 	 %f1671, %r83;
	mov.b32 	 %f1672, %r84;
	mov.b32 	 %f1673, %r85;
	mov.b32 	 %f1674, %r86;
	add.s64 	%rd101, %rd98, 16;
	// inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r87,%r88,%r89,%r90}, [%rd100];
	// inline asm
	mov.b32 	 %f1675, %r87;
	mov.b32 	 %f1676, %r88;
	mov.b32 	 %f1677, %r89;
	mov.b32 	 %f1678, %r90;
	add.s64 	%rd104, %rd98, 32;
	// inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r91,%r92,%r93,%r94}, [%rd103];
	// inline asm
	sub.f32 	%f37, %f693, %f694;
	mov.b32 	 %f1679, %r91;
	mov.b32 	 %f1680, %r92;
	mov.b32 	 %f1681, %r93;
	mov.b32 	 %f1682, %r94;
	add.s64 	%rd107, %rd98, 48;
	// inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r95,%r96,%r97,%r98}, [%rd106];
	// inline asm
	mov.b32 	 %f1683, %r95;
	mov.b32 	 %f1684, %r96;
	mov.b32 	 %f1685, %r97;
	mov.b32 	 %f1686, %r98;
	setp.leu.f32	%p7, %f37, 0f00000000;
	@%p7 bra 	BB12_14;

	cvt.rmi.f32.f32	%f1657, %f693;
	cvt.rzi.s32.f32	%r629, %f1657;
	cvt.s64.s32	%rd641, %r629;
	shl.b64 	%rd122, %rd641, 6;
	add.s64 	%rd123, %rd122, %rd65;
	add.s64 	%rd111, %rd123, 96;
	// inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd110];
	// inline asm
	mov.b32 	 %f695, %r102;
	mov.b32 	 %f696, %r103;
	mov.b32 	 %f697, %r104;
	mov.b32 	 %f698, %r105;
	add.s64 	%rd114, %rd123, 112;
	// inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd113];
	// inline asm
	mov.b32 	 %f699, %r106;
	mov.b32 	 %f700, %r107;
	mov.b32 	 %f701, %r108;
	mov.b32 	 %f702, %r109;
	add.s64 	%rd117, %rd123, 128;
	// inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd116];
	// inline asm
	mov.b32 	 %f703, %r110;
	mov.b32 	 %f704, %r111;
	mov.b32 	 %f705, %r112;
	mov.b32 	 %f706, %r113;
	add.s64 	%rd120, %rd123, 144;
	// inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd119];
	// inline asm
	mov.f32 	%f707, 0f3F800000;
	sub.f32 	%f708, %f707, %f37;
	mul.f32 	%f709, %f37, %f695;
	mul.f32 	%f710, %f37, %f696;
	mul.f32 	%f711, %f37, %f697;
	mul.f32 	%f712, %f37, %f698;
	fma.rn.f32 	%f1671, %f708, %f1671, %f709;
	fma.rn.f32 	%f1672, %f708, %f1672, %f710;
	fma.rn.f32 	%f1673, %f708, %f1673, %f711;
	fma.rn.f32 	%f1674, %f708, %f1674, %f712;
	mul.f32 	%f713, %f37, %f699;
	mul.f32 	%f714, %f37, %f700;
	mul.f32 	%f715, %f37, %f701;
	mul.f32 	%f716, %f37, %f702;
	fma.rn.f32 	%f1675, %f708, %f1675, %f713;
	fma.rn.f32 	%f1676, %f708, %f1676, %f714;
	fma.rn.f32 	%f1677, %f708, %f1677, %f715;
	fma.rn.f32 	%f1678, %f708, %f1678, %f716;
	mul.f32 	%f717, %f37, %f703;
	mul.f32 	%f718, %f37, %f704;
	mul.f32 	%f719, %f37, %f705;
	mul.f32 	%f720, %f37, %f706;
	fma.rn.f32 	%f1679, %f708, %f1679, %f717;
	fma.rn.f32 	%f721, %f708, %f1680, %f718;
	fma.rn.f32 	%f722, %f708, %f1681, %f719;
	fma.rn.f32 	%f723, %f708, %f1682, %f720;
	mov.b32 	 %f724, %r114;
	mov.b32 	 %f725, %r115;
	mov.b32 	 %f726, %r116;
	mov.b32 	 %f727, %r117;
	mul.f32 	%f728, %f37, %f724;
	mul.f32 	%f729, %f37, %f725;
	mul.f32 	%f730, %f37, %f726;
	mul.f32 	%f731, %f37, %f727;
	fma.rn.f32 	%f732, %f708, %f1683, %f728;
	fma.rn.f32 	%f1684, %f708, %f1684, %f729;
	fma.rn.f32 	%f1685, %f708, %f1685, %f730;
	fma.rn.f32 	%f1686, %f708, %f1686, %f731;
	mul.f32 	%f733, %f722, %f722;
	fma.rn.f32 	%f734, %f721, %f721, %f733;
	fma.rn.f32 	%f735, %f723, %f723, %f734;
	fma.rn.f32 	%f736, %f732, %f732, %f735;
	sqrt.rn.f32 	%f737, %f736;
	rcp.rn.f32 	%f738, %f737;
	mul.f32 	%f1680, %f721, %f738;
	mul.f32 	%f1681, %f722, %f738;
	mul.f32 	%f1682, %f723, %f738;
	mul.f32 	%f1683, %f732, %f738;

BB12_14:
	mul.f32 	%f739, %f1681, %f1681;
	fma.rn.f32 	%f740, %f1680, %f1680, %f739;
	fma.rn.f32 	%f741, %f1682, %f1682, %f740;
	fma.rn.f32 	%f742, %f1683, %f1683, %f741;
	rcp.rn.f32 	%f743, %f742;
	mul.f32 	%f744, %f1680, %f743;
	mul.f32 	%f745, %f1681, %f743;
	mul.f32 	%f746, %f1682, %f743;
	mul.f32 	%f747, %f1683, %f743;
	mul.f32 	%f748, %f1680, %f744;
	mul.f32 	%f749, %f1681, %f745;
	mul.f32 	%f750, %f1682, %f746;
	mul.f32 	%f751, %f1680, %f745;
	mul.f32 	%f752, %f1682, %f747;
	mul.f32 	%f753, %f1680, %f746;
	mul.f32 	%f754, %f1681, %f747;
	mul.f32 	%f755, %f1681, %f746;
	mul.f32 	%f756, %f1680, %f747;
	sub.f32 	%f757, %f748, %f749;
	sub.f32 	%f758, %f757, %f750;
	fma.rn.f32 	%f759, %f1683, %f747, %f758;
	sub.f32 	%f760, %f751, %f752;
	add.f32 	%f761, %f760, %f760;
	add.f32 	%f762, %f753, %f754;
	add.f32 	%f763, %f762, %f762;
	add.f32 	%f764, %f751, %f752;
	add.f32 	%f765, %f764, %f764;
	sub.f32 	%f766, %f749, %f748;
	sub.f32 	%f767, %f766, %f750;
	fma.rn.f32 	%f768, %f1683, %f747, %f767;
	sub.f32 	%f769, %f755, %f756;
	add.f32 	%f770, %f769, %f769;
	sub.f32 	%f771, %f753, %f754;
	add.f32 	%f772, %f771, %f771;
	add.f32 	%f773, %f755, %f756;
	add.f32 	%f774, %f773, %f773;
	neg.f32 	%f775, %f748;
	sub.f32 	%f776, %f775, %f749;
	add.f32 	%f777, %f750, %f776;
	fma.rn.f32 	%f778, %f1683, %f747, %f777;
	mul.f32 	%f779, %f1674, %f759;
	fma.rn.f32 	%f780, %f1677, %f761, %f779;
	fma.rn.f32 	%f781, %f1679, %f763, %f780;
	sub.f32 	%f1687, %f1684, %f781;
	mul.f32 	%f782, %f1677, %f768;
	fma.rn.f32 	%f783, %f1674, %f765, %f782;
	fma.rn.f32 	%f784, %f1679, %f770, %f783;
	sub.f32 	%f1691, %f1685, %f784;
	mul.f32 	%f785, %f1677, %f774;
	fma.rn.f32 	%f786, %f1674, %f772, %f785;
	fma.rn.f32 	%f787, %f1679, %f778, %f786;
	sub.f32 	%f1695, %f1686, %f787;
	mul.f32 	%f788, %f1673, %f759;
	fma.rn.f32 	%f789, %f1676, %f761, %f788;
	fma.rn.f32 	%f1688, %f1678, %f763, %f789;
	mul.f32 	%f790, %f1676, %f768;
	fma.rn.f32 	%f791, %f1673, %f765, %f790;
	fma.rn.f32 	%f1692, %f1678, %f770, %f791;
	mul.f32 	%f792, %f1676, %f774;
	fma.rn.f32 	%f793, %f1673, %f772, %f792;
	fma.rn.f32 	%f1696, %f1678, %f778, %f793;
	mul.f32 	%f794, %f1672, %f759;
	fma.rn.f32 	%f1689, %f1675, %f761, %f794;
	mul.f32 	%f795, %f1675, %f768;
	fma.rn.f32 	%f1693, %f1672, %f765, %f795;
	mul.f32 	%f796, %f1675, %f774;
	fma.rn.f32 	%f1697, %f1672, %f772, %f796;
	mul.f32 	%f1690, %f1671, %f759;
	mul.f32 	%f1694, %f1671, %f765;
	mul.f32 	%f1698, %f1671, %f772;

BB12_17:
	mul.f32 	%f834, %f1692, %f1697;
	mul.f32 	%f835, %f1693, %f1696;
	sub.f32 	%f836, %f835, %f834;
	mul.f32 	%f837, %f1690, %f836;
	mul.f32 	%f838, %f1692, %f1698;
	mul.f32 	%f839, %f1694, %f1696;
	sub.f32 	%f840, %f839, %f838;
	mul.f32 	%f841, %f1689, %f840;
	sub.f32 	%f842, %f837, %f841;
	mul.f32 	%f843, %f1693, %f1698;
	mul.f32 	%f844, %f1694, %f1697;
	sub.f32 	%f845, %f844, %f843;
	fma.rn.f32 	%f846, %f1688, %f845, %f842;
	rcp.rn.f32 	%f847, %f846;
	mul.f32 	%f1702, %f847, %f836;
	mul.f32 	%f848, %f1689, %f1696;
	mul.f32 	%f849, %f1688, %f1697;
	sub.f32 	%f850, %f849, %f848;
	mul.f32 	%f1701, %f847, %f850;
	mul.f32 	%f851, %f1688, %f1693;
	mul.f32 	%f852, %f1689, %f1692;
	sub.f32 	%f853, %f852, %f851;
	mul.f32 	%f1700, %f853, %f847;
	sub.f32 	%f854, %f838, %f839;
	mul.f32 	%f1706, %f847, %f854;
	mul.f32 	%f855, %f1688, %f1698;
	mul.f32 	%f856, %f1690, %f1696;
	sub.f32 	%f857, %f856, %f855;
	mul.f32 	%f1705, %f847, %f857;
	mul.f32 	%f858, %f1690, %f1692;
	mul.f32 	%f859, %f1688, %f1694;
	sub.f32 	%f860, %f859, %f858;
	mul.f32 	%f1704, %f860, %f847;
	mul.f32 	%f1710, %f847, %f845;
	mul.f32 	%f861, %f1690, %f1697;
	mul.f32 	%f862, %f1689, %f1698;
	sub.f32 	%f863, %f862, %f861;
	mul.f32 	%f1709, %f847, %f863;
	mul.f32 	%f864, %f1689, %f1694;
	mul.f32 	%f865, %f1690, %f1693;
	sub.f32 	%f866, %f865, %f864;
	mul.f32 	%f1708, %f866, %f847;
	mul.f32 	%f867, %f1687, %f1702;
	neg.f32 	%f868, %f867;
	mul.f32 	%f869, %f1691, %f1701;
	sub.f32 	%f870, %f868, %f869;
	mul.f32 	%f871, %f1695, %f1700;
	sub.f32 	%f1699, %f870, %f871;
	mul.f32 	%f872, %f1687, %f1706;
	neg.f32 	%f873, %f872;
	mul.f32 	%f874, %f1691, %f1705;
	sub.f32 	%f875, %f873, %f874;
	mul.f32 	%f876, %f1695, %f1704;
	sub.f32 	%f1703, %f875, %f876;
	mul.f32 	%f877, %f1687, %f1710;
	neg.f32 	%f878, %f877;
	mul.f32 	%f879, %f1691, %f1709;
	sub.f32 	%f880, %f878, %f879;
	mul.f32 	%f881, %f1695, %f1708;
	sub.f32 	%f1707, %f880, %f881;
	bra.uni 	BB12_18;

BB12_7:
	setp.ne.s32	%p5, %r29, 1;
	mov.f32 	%f1700, %f1699;
	mov.f32 	%f1701, %f1699;
	mov.f32 	%f1703, %f1699;
	mov.f32 	%f1704, %f1699;
	mov.f32 	%f1705, %f1702;
	mov.f32 	%f1706, %f1699;
	mov.f32 	%f1707, %f1699;
	mov.f32 	%f1708, %f1702;
	mov.f32 	%f1709, %f1699;
	mov.f32 	%f1710, %f1699;
	@%p5 bra 	BB12_18;

	// inline asm
	call (%rd52), _optix_get_static_transform_from_handle, (%rd50);
	// inline asm
	add.s64 	%rd643, %rd52, 64;

BB12_10:
	// inline asm
	cvta.to.global.u64 %rd56, %rd643;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd56];
	// inline asm
	mov.b32 	 %f1702, %r31;
	mov.b32 	 %f1701, %r32;
	mov.b32 	 %f1700, %r33;
	mov.b32 	 %f1699, %r34;
	add.s64 	%rd60, %rd643, 16;
	// inline asm
	cvta.to.global.u64 %rd59, %rd60;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd59];
	// inline asm
	mov.b32 	 %f1706, %r35;
	mov.b32 	 %f1705, %r36;
	mov.b32 	 %f1704, %r37;
	mov.b32 	 %f1703, %r38;
	add.s64 	%rd63, %rd643, 32;
	// inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd62];
	// inline asm
	mov.b32 	 %f1710, %r39;
	mov.b32 	 %f1709, %r40;
	mov.b32 	 %f1708, %r41;
	mov.b32 	 %f1707, %r42;

BB12_18:
	setp.eq.s32	%p9, %r631, 0;
	@%p9 bra 	BB12_19;
	bra.uni 	BB12_20;

BB12_19:
	mov.f32 	%f1670, %f1699;
	mov.f32 	%f1669, %f1700;
	mov.f32 	%f1668, %f1701;
	mov.f32 	%f1667, %f1702;
	mov.f32 	%f1666, %f1703;
	mov.f32 	%f1665, %f1704;
	mov.f32 	%f1664, %f1705;
	mov.f32 	%f1663, %f1706;
	mov.f32 	%f1662, %f1707;
	mov.f32 	%f1661, %f1708;
	mov.f32 	%f1660, %f1709;
	mov.f32 	%f1659, %f1710;
	bra.uni 	BB12_21;

BB12_20:
	mul.f32 	%f882, %f1667, %f1702;
	fma.rn.f32 	%f883, %f1663, %f1701, %f882;
	fma.rn.f32 	%f151, %f1659, %f1700, %f883;
	mul.f32 	%f884, %f1668, %f1702;
	fma.rn.f32 	%f885, %f1664, %f1701, %f884;
	fma.rn.f32 	%f152, %f1660, %f1700, %f885;
	mul.f32 	%f886, %f1669, %f1702;
	fma.rn.f32 	%f887, %f1665, %f1701, %f886;
	fma.rn.f32 	%f153, %f1661, %f1700, %f887;
	mul.f32 	%f888, %f1670, %f1702;
	fma.rn.f32 	%f889, %f1666, %f1701, %f888;
	fma.rn.f32 	%f890, %f1662, %f1700, %f889;
	add.f32 	%f154, %f1699, %f890;
	mul.f32 	%f891, %f1667, %f1706;
	fma.rn.f32 	%f892, %f1663, %f1705, %f891;
	fma.rn.f32 	%f155, %f1659, %f1704, %f892;
	mul.f32 	%f893, %f1668, %f1706;
	fma.rn.f32 	%f894, %f1664, %f1705, %f893;
	fma.rn.f32 	%f156, %f1660, %f1704, %f894;
	mul.f32 	%f895, %f1669, %f1706;
	fma.rn.f32 	%f896, %f1665, %f1705, %f895;
	fma.rn.f32 	%f157, %f1661, %f1704, %f896;
	mul.f32 	%f897, %f1670, %f1706;
	fma.rn.f32 	%f898, %f1666, %f1705, %f897;
	fma.rn.f32 	%f899, %f1662, %f1704, %f898;
	add.f32 	%f158, %f1703, %f899;
	mul.f32 	%f900, %f1667, %f1710;
	fma.rn.f32 	%f901, %f1663, %f1709, %f900;
	fma.rn.f32 	%f1659, %f1659, %f1708, %f901;
	mul.f32 	%f902, %f1668, %f1710;
	fma.rn.f32 	%f903, %f1664, %f1709, %f902;
	fma.rn.f32 	%f1660, %f1660, %f1708, %f903;
	mul.f32 	%f904, %f1669, %f1710;
	fma.rn.f32 	%f905, %f1665, %f1709, %f904;
	fma.rn.f32 	%f1661, %f1661, %f1708, %f905;
	mul.f32 	%f906, %f1670, %f1710;
	fma.rn.f32 	%f907, %f1666, %f1709, %f906;
	fma.rn.f32 	%f908, %f1662, %f1708, %f907;
	add.f32 	%f1662, %f1707, %f908;
	mov.f32 	%f1670, %f154;
	mov.f32 	%f1669, %f153;
	mov.f32 	%f1668, %f152;
	mov.f32 	%f1667, %f151;
	mov.f32 	%f1666, %f158;
	mov.f32 	%f1665, %f157;
	mov.f32 	%f1664, %f156;
	mov.f32 	%f1663, %f155;

BB12_21:
	add.s32 	%r631, %r631, 1;
	setp.lt.u32	%p10, %r631, %r26;
	@%p10 bra 	BB12_5;

	mul.f32 	%f909, %f667, %f1667;
	fma.rn.f32 	%f910, %f668, %f1668, %f909;
	fma.rn.f32 	%f911, %f1723, %f1669, %f910;
	add.f32 	%f1725, %f1670, %f911;
	mul.f32 	%f912, %f667, %f1663;
	fma.rn.f32 	%f913, %f668, %f1664, %f912;
	fma.rn.f32 	%f914, %f1723, %f1665, %f913;
	add.f32 	%f1724, %f1666, %f914;
	mul.f32 	%f915, %f667, %f1659;
	fma.rn.f32 	%f916, %f668, %f1660, %f915;
	fma.rn.f32 	%f917, %f1723, %f1661, %f916;
	add.f32 	%f1723, %f1662, %f917;
	bra.uni 	BB12_23;

BB12_3:
	mov.f32 	%f1724, %f668;
	mov.f32 	%f1725, %f667;

BB12_23:
	// inline asm
	call (%f918), _optix_get_world_ray_direction_x, ();
	// inline asm
	// inline asm
	call (%f919), _optix_get_world_ray_direction_y, ();
	// inline asm
	// inline asm
	call (%f1774), _optix_get_world_ray_direction_z, ();
	// inline asm
	// inline asm
	call (%f921), _optix_get_ray_time, ();
	// inline asm
	mov.u32 	%r632, 0;
	@%p2 bra 	BB12_24;

BB12_25:
	.pragma "nounroll";
	// inline asm
	call (%rd171), _optix_get_transform_list_handle, (%r632);
	// inline asm
	// inline asm
	call (%r179), _optix_get_transform_type_from_handle, (%rd171);
	// inline asm
	and.b32  	%r180, %r179, -2;
	setp.eq.s32	%p12, %r180, 2;
	@%p12 bra 	BB12_31;
	bra.uni 	BB12_26;

BB12_31:
	setp.eq.s32	%p15, %r179, 2;
	@%p15 bra 	BB12_35;
	bra.uni 	BB12_32;

BB12_35:
	// inline asm
	call (%rd245), _optix_get_matrix_motion_transform_from_handle, (%rd171);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd247, %rd245;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd247];
	// inline asm
	mov.b32	{%rs8, %rs9}, %r270;
	add.s64 	%rd251, %rd245, 16;
	// inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd250];
	// inline asm
	add.s64 	%rd254, %rd245, 32;
	// inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd253];
	// inline asm
	add.s64 	%rd257, %rd245, 48;
	// inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd256];
	// inline asm
	add.s64 	%rd260, %rd245, 64;
	// inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd259];
	// inline asm
	add.s64 	%rd263, %rd245, 80;
	// inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd262];
	// inline asm
	add.s64 	%rd266, %rd245, 96;
	// inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd265];
	// inline asm
	add.s64 	%rd269, %rd245, 112;
	// inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd268];
	// inline asm
	mov.b32 	 %f1024, %r271;
	mov.b32 	 %f1025, %r272;
	cvt.u32.u16	%r312, %rs8;
	add.s32 	%r313, %r312, -1;
	cvt.rn.f32.s32	%f1026, %r313;
	sub.f32 	%f1027, %f921, %f1024;
	mul.f32 	%f1028, %f1027, %f1026;
	sub.f32 	%f1029, %f1025, %f1024;
	div.rn.f32 	%f1030, %f1028, %f1029;
	min.f32 	%f1031, %f1026, %f1030;
	mov.f32 	%f1032, 0f00000000;
	max.f32 	%f1033, %f1032, %f1031;
	cvt.rmi.f32.f32	%f1034, %f1033;
	cvt.rzi.s32.f32	%r314, %f1034;
	cvt.s64.s32	%rd19, %r314;
	mul.wide.s32 	%rd280, %r314, 48;
	add.s64 	%rd272, %rd254, %rd280;
	// inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r300,%r301,%r302,%r303}, [%rd271];
	// inline asm
	mov.b32 	 %f1751, %r300;
	mov.b32 	 %f1752, %r301;
	mov.b32 	 %f1753, %r302;
	add.s64 	%rd275, %rd272, 16;
	// inline asm
	cvta.to.global.u64 %rd274, %rd275;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r304,%r305,%r306,%r307}, [%rd274];
	// inline asm
	mov.b32 	 %f1748, %r304;
	mov.b32 	 %f1749, %r305;
	mov.b32 	 %f1750, %r306;
	add.s64 	%rd278, %rd272, 32;
	// inline asm
	cvta.to.global.u64 %rd277, %rd278;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r308,%r309,%r310,%r311}, [%rd277];
	// inline asm
	sub.f32 	%f249, %f1033, %f1034;
	mov.b32 	 %f1745, %r308;
	mov.b32 	 %f1746, %r309;
	mov.b32 	 %f1747, %r310;
	setp.leu.f32	%p17, %f249, 0f00000000;
	@%p17 bra 	BB12_37;

	mul.lo.s64 	%rd290, %rd19, 48;
	add.s64 	%rd291, %rd245, %rd290;
	add.s64 	%rd282, %rd291, 80;
	// inline asm
	cvta.to.global.u64 %rd281, %rd282;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd281];
	// inline asm
	mov.b32 	 %f1035, %r315;
	mov.b32 	 %f1036, %r316;
	mov.b32 	 %f1037, %r317;
	add.s64 	%rd285, %rd291, 96;
	// inline asm
	cvta.to.global.u64 %rd284, %rd285;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd284];
	// inline asm
	mov.b32 	 %f1038, %r319;
	mov.b32 	 %f1039, %r320;
	mov.b32 	 %f1040, %r321;
	add.s64 	%rd288, %rd291, 112;
	// inline asm
	cvta.to.global.u64 %rd287, %rd288;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r323,%r324,%r325,%r326}, [%rd287];
	// inline asm
	mov.f32 	%f1041, 0f3F800000;
	sub.f32 	%f1042, %f1041, %f249;
	mul.f32 	%f1043, %f249, %f1035;
	mul.f32 	%f1044, %f249, %f1036;
	mul.f32 	%f1045, %f249, %f1037;
	fma.rn.f32 	%f1751, %f1042, %f1751, %f1043;
	fma.rn.f32 	%f1752, %f1042, %f1752, %f1044;
	fma.rn.f32 	%f1753, %f1042, %f1753, %f1045;
	mul.f32 	%f1046, %f249, %f1038;
	mul.f32 	%f1047, %f249, %f1039;
	mul.f32 	%f1048, %f249, %f1040;
	fma.rn.f32 	%f1748, %f1042, %f1748, %f1046;
	fma.rn.f32 	%f1749, %f1042, %f1749, %f1047;
	fma.rn.f32 	%f1750, %f1042, %f1750, %f1048;
	mov.b32 	 %f1049, %r323;
	mov.b32 	 %f1050, %r324;
	mov.b32 	 %f1051, %r325;
	mul.f32 	%f1052, %f249, %f1049;
	mul.f32 	%f1053, %f249, %f1050;
	mul.f32 	%f1054, %f249, %f1051;
	fma.rn.f32 	%f1745, %f1042, %f1745, %f1052;
	fma.rn.f32 	%f1746, %f1042, %f1746, %f1053;
	fma.rn.f32 	%f1747, %f1042, %f1747, %f1054;
	bra.uni 	BB12_37;

BB12_26:
	mov.f32 	%f1754, 0f00000000;
	mov.f32 	%f1756, 0f3F800000;
	setp.eq.s32	%p13, %r179, 4;
	@%p13 bra 	BB12_29;
	bra.uni 	BB12_27;

BB12_29:
	// inline asm
	call (%rd644), _optix_get_instance_inverse_transform_from_handle, (%rd171);
	// inline asm
	bra.uni 	BB12_30;

BB12_32:
	// inline asm
	call (%rd186), _optix_get_srt_motion_transform_from_handle, (%rd171);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd188, %rd186;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd188];
	// inline asm
	mov.b32	{%rs6, %rs7}, %r195;
	add.s64 	%rd192, %rd186, 16;
	// inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd191];
	// inline asm
	add.s64 	%rd195, %rd186, 32;
	// inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd194];
	// inline asm
	add.s64 	%rd198, %rd186, 48;
	// inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd197];
	// inline asm
	add.s64 	%rd201, %rd186, 64;
	// inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd200];
	// inline asm
	add.s64 	%rd204, %rd186, 80;
	// inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd203];
	// inline asm
	add.s64 	%rd207, %rd186, 96;
	// inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd206];
	// inline asm
	add.s64 	%rd210, %rd186, 112;
	// inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd209];
	// inline asm
	add.s64 	%rd213, %rd186, 128;
	// inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd212];
	// inline asm
	add.s64 	%rd216, %rd186, 144;
	// inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd215];
	// inline asm
	mov.b32 	 %f932, %r196;
	mov.b32 	 %f933, %r197;
	cvt.u32.u16	%r249, %rs6;
	add.s32 	%r250, %r249, -1;
	cvt.rn.f32.s32	%f934, %r250;
	sub.f32 	%f935, %f921, %f932;
	mul.f32 	%f936, %f935, %f934;
	sub.f32 	%f937, %f933, %f932;
	div.rn.f32 	%f938, %f936, %f937;
	min.f32 	%f939, %f934, %f938;
	mov.f32 	%f940, 0f00000000;
	max.f32 	%f941, %f940, %f939;
	cvt.rmi.f32.f32	%f942, %f941;
	cvt.rzi.s32.f32	%r251, %f942;
	cvt.s64.s32	%rd17, %r251;
	mul.wide.s32 	%rd230, %r251, 64;
	add.s64 	%rd219, %rd195, %rd230;
	// inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd218];
	// inline asm
	mov.b32 	 %f1735, %r233;
	mov.b32 	 %f1736, %r234;
	mov.b32 	 %f1737, %r235;
	add.s64 	%rd222, %rd219, 16;
	// inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r237,%r238,%r239,%r240}, [%rd221];
	// inline asm
	mov.b32 	 %f1738, %r237;
	mov.b32 	 %f1739, %r238;
	mov.b32 	 %f1740, %r240;
	add.s64 	%rd225, %rd219, 32;
	// inline asm
	cvta.to.global.u64 %rd224, %rd225;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r241,%r242,%r243,%r244}, [%rd224];
	// inline asm
	sub.f32 	%f209, %f941, %f942;
	mov.b32 	 %f1741, %r242;
	mov.b32 	 %f1742, %r243;
	mov.b32 	 %f1743, %r244;
	add.s64 	%rd228, %rd219, 48;
	// inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r245,%r246,%r247,%r248}, [%rd227];
	// inline asm
	mov.b32 	 %f1744, %r245;
	setp.leu.f32	%p16, %f209, 0f00000000;
	@%p16 bra 	BB12_34;

	shl.b64 	%rd243, %rd17, 6;
	add.s64 	%rd244, %rd243, %rd186;
	add.s64 	%rd232, %rd244, 96;
	// inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd231];
	// inline asm
	mov.b32 	 %f943, %r252;
	mov.b32 	 %f944, %r253;
	mov.b32 	 %f945, %r254;
	add.s64 	%rd235, %rd244, 112;
	// inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd234];
	// inline asm
	mov.b32 	 %f946, %r256;
	mov.b32 	 %f947, %r257;
	mov.b32 	 %f948, %r259;
	add.s64 	%rd238, %rd244, 128;
	// inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd237];
	// inline asm
	mov.b32 	 %f949, %r261;
	mov.b32 	 %f950, %r262;
	mov.b32 	 %f951, %r263;
	add.s64 	%rd241, %rd244, 144;
	// inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd240];
	// inline asm
	mov.f32 	%f952, 0f3F800000;
	sub.f32 	%f953, %f952, %f209;
	mul.f32 	%f954, %f209, %f943;
	mul.f32 	%f955, %f209, %f944;
	mul.f32 	%f956, %f209, %f945;
	fma.rn.f32 	%f1735, %f953, %f1735, %f954;
	fma.rn.f32 	%f1736, %f953, %f1736, %f955;
	fma.rn.f32 	%f1737, %f953, %f1737, %f956;
	mul.f32 	%f957, %f209, %f946;
	mul.f32 	%f958, %f209, %f947;
	mul.f32 	%f959, %f209, %f948;
	fma.rn.f32 	%f1738, %f953, %f1738, %f957;
	fma.rn.f32 	%f1739, %f953, %f1739, %f958;
	fma.rn.f32 	%f1740, %f953, %f1740, %f959;
	mul.f32 	%f960, %f209, %f949;
	mul.f32 	%f961, %f209, %f950;
	mul.f32 	%f962, %f209, %f951;
	fma.rn.f32 	%f963, %f953, %f1741, %f960;
	fma.rn.f32 	%f964, %f953, %f1742, %f961;
	fma.rn.f32 	%f965, %f953, %f1743, %f962;
	mov.b32 	 %f966, %r264;
	mul.f32 	%f967, %f209, %f966;
	fma.rn.f32 	%f968, %f953, %f1744, %f967;
	mul.f32 	%f969, %f964, %f964;
	fma.rn.f32 	%f970, %f963, %f963, %f969;
	fma.rn.f32 	%f971, %f965, %f965, %f970;
	fma.rn.f32 	%f972, %f968, %f968, %f971;
	sqrt.rn.f32 	%f973, %f972;
	rcp.rn.f32 	%f974, %f973;
	mul.f32 	%f1741, %f963, %f974;
	mul.f32 	%f1742, %f964, %f974;
	mul.f32 	%f1743, %f965, %f974;
	mul.f32 	%f1744, %f968, %f974;

BB12_34:
	mul.f32 	%f975, %f1742, %f1742;
	fma.rn.f32 	%f976, %f1741, %f1741, %f975;
	fma.rn.f32 	%f977, %f1743, %f1743, %f976;
	fma.rn.f32 	%f978, %f1744, %f1744, %f977;
	rcp.rn.f32 	%f979, %f978;
	mul.f32 	%f980, %f1741, %f979;
	mul.f32 	%f981, %f1742, %f979;
	mul.f32 	%f982, %f1743, %f979;
	mul.f32 	%f983, %f1744, %f979;
	mul.f32 	%f984, %f1741, %f980;
	mul.f32 	%f985, %f1742, %f981;
	mul.f32 	%f986, %f1743, %f982;
	mul.f32 	%f987, %f1741, %f981;
	mul.f32 	%f988, %f1743, %f983;
	mul.f32 	%f989, %f1741, %f982;
	mul.f32 	%f990, %f1742, %f983;
	mul.f32 	%f991, %f1742, %f982;
	mul.f32 	%f992, %f1741, %f983;
	sub.f32 	%f993, %f984, %f985;
	sub.f32 	%f994, %f993, %f986;
	fma.rn.f32 	%f995, %f1744, %f983, %f994;
	sub.f32 	%f996, %f987, %f988;
	add.f32 	%f997, %f996, %f996;
	add.f32 	%f998, %f989, %f990;
	add.f32 	%f999, %f998, %f998;
	add.f32 	%f1000, %f987, %f988;
	add.f32 	%f1001, %f1000, %f1000;
	sub.f32 	%f1002, %f985, %f984;
	sub.f32 	%f1003, %f1002, %f986;
	fma.rn.f32 	%f1004, %f1744, %f983, %f1003;
	sub.f32 	%f1005, %f991, %f992;
	add.f32 	%f1006, %f1005, %f1005;
	sub.f32 	%f1007, %f989, %f990;
	add.f32 	%f1008, %f1007, %f1007;
	add.f32 	%f1009, %f991, %f992;
	add.f32 	%f1010, %f1009, %f1009;
	neg.f32 	%f1011, %f984;
	sub.f32 	%f1012, %f1011, %f985;
	add.f32 	%f1013, %f986, %f1012;
	fma.rn.f32 	%f1014, %f1744, %f983, %f1013;
	mul.f32 	%f1015, %f1737, %f995;
	fma.rn.f32 	%f1016, %f1739, %f997, %f1015;
	fma.rn.f32 	%f1753, %f1740, %f999, %f1016;
	mul.f32 	%f1017, %f1739, %f1004;
	fma.rn.f32 	%f1018, %f1737, %f1001, %f1017;
	fma.rn.f32 	%f1750, %f1740, %f1006, %f1018;
	mul.f32 	%f1019, %f1739, %f1010;
	fma.rn.f32 	%f1020, %f1737, %f1008, %f1019;
	fma.rn.f32 	%f1747, %f1740, %f1014, %f1020;
	mul.f32 	%f1021, %f1736, %f995;
	fma.rn.f32 	%f1752, %f1738, %f997, %f1021;
	mul.f32 	%f1022, %f1738, %f1004;
	fma.rn.f32 	%f1749, %f1736, %f1001, %f1022;
	mul.f32 	%f1023, %f1738, %f1010;
	fma.rn.f32 	%f1746, %f1736, %f1008, %f1023;
	mul.f32 	%f1751, %f1735, %f995;
	mul.f32 	%f1748, %f1735, %f1001;
	mul.f32 	%f1745, %f1735, %f1008;

BB12_37:
	mul.f32 	%f1055, %f1746, %f1750;
	mul.f32 	%f1056, %f1747, %f1749;
	sub.f32 	%f1057, %f1056, %f1055;
	mul.f32 	%f1058, %f1751, %f1057;
	mul.f32 	%f1059, %f1745, %f1750;
	mul.f32 	%f1060, %f1747, %f1748;
	sub.f32 	%f1061, %f1060, %f1059;
	mul.f32 	%f1062, %f1061, %f1752;
	sub.f32 	%f1063, %f1058, %f1062;
	mul.f32 	%f1064, %f1745, %f1749;
	mul.f32 	%f1065, %f1746, %f1748;
	sub.f32 	%f1066, %f1065, %f1064;
	fma.rn.f32 	%f1067, %f1066, %f1753, %f1063;
	rcp.rn.f32 	%f1068, %f1067;
	mul.f32 	%f1760, %f1057, %f1068;
	mul.f32 	%f1069, %f1747, %f1752;
	mul.f32 	%f1070, %f1746, %f1753;
	sub.f32 	%f1071, %f1070, %f1069;
	mul.f32 	%f1761, %f1068, %f1071;
	mul.f32 	%f1072, %f1749, %f1753;
	mul.f32 	%f1073, %f1750, %f1752;
	sub.f32 	%f1074, %f1073, %f1072;
	mul.f32 	%f1762, %f1068, %f1074;
	sub.f32 	%f1075, %f1059, %f1060;
	mul.f32 	%f1757, %f1075, %f1068;
	mul.f32 	%f1076, %f1745, %f1753;
	mul.f32 	%f1077, %f1747, %f1751;
	sub.f32 	%f1078, %f1077, %f1076;
	mul.f32 	%f1758, %f1068, %f1078;
	mul.f32 	%f1079, %f1750, %f1751;
	mul.f32 	%f1080, %f1748, %f1753;
	sub.f32 	%f1081, %f1080, %f1079;
	mul.f32 	%f1759, %f1068, %f1081;
	mul.f32 	%f1754, %f1066, %f1068;
	mul.f32 	%f1082, %f1746, %f1751;
	mul.f32 	%f1083, %f1745, %f1752;
	sub.f32 	%f1084, %f1083, %f1082;
	mul.f32 	%f1755, %f1084, %f1068;
	mul.f32 	%f1085, %f1748, %f1752;
	mul.f32 	%f1086, %f1749, %f1751;
	sub.f32 	%f1087, %f1086, %f1085;
	mul.f32 	%f1756, %f1087, %f1068;
	bra.uni 	BB12_38;

BB12_27:
	setp.ne.s32	%p14, %r179, 1;
	mov.f32 	%f1755, %f1754;
	mov.f32 	%f1757, %f1754;
	mov.f32 	%f1758, %f1756;
	mov.f32 	%f1759, %f1754;
	mov.f32 	%f1760, %f1756;
	mov.f32 	%f1761, %f1754;
	mov.f32 	%f1762, %f1754;
	@%p14 bra 	BB12_38;

	// inline asm
	call (%rd173), _optix_get_static_transform_from_handle, (%rd171);
	// inline asm
	add.s64 	%rd644, %rd173, 64;

BB12_30:
	// inline asm
	cvta.to.global.u64 %rd177, %rd644;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r181,%r182,%r183,%r184}, [%rd177];
	// inline asm
	mov.b32 	 %f1760, %r181;
	mov.b32 	 %f1761, %r182;
	mov.b32 	 %f1762, %r183;
	add.s64 	%rd181, %rd644, 16;
	// inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd180];
	// inline asm
	mov.b32 	 %f1757, %r185;
	mov.b32 	 %f1758, %r186;
	mov.b32 	 %f1759, %r187;
	add.s64 	%rd184, %rd644, 32;
	// inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd183];
	// inline asm
	mov.b32 	 %f1754, %r189;
	mov.b32 	 %f1755, %r190;
	mov.b32 	 %f1756, %r191;

BB12_38:
	setp.eq.s32	%p18, %r632, 0;
	@%p18 bra 	BB12_39;
	bra.uni 	BB12_40;

BB12_39:
	mov.f32 	%f1734, %f1754;
	mov.f32 	%f1733, %f1755;
	mov.f32 	%f1732, %f1756;
	mov.f32 	%f1731, %f1757;
	mov.f32 	%f1730, %f1758;
	mov.f32 	%f1729, %f1759;
	mov.f32 	%f1728, %f1760;
	mov.f32 	%f1727, %f1761;
	mov.f32 	%f1726, %f1762;
	bra.uni 	BB12_41;

BB12_40:
	mul.f32 	%f1088, %f1731, %f1761;
	fma.rn.f32 	%f1089, %f1728, %f1760, %f1088;
	fma.rn.f32 	%f289, %f1734, %f1762, %f1089;
	mul.f32 	%f1090, %f1730, %f1761;
	fma.rn.f32 	%f1091, %f1727, %f1760, %f1090;
	fma.rn.f32 	%f290, %f1733, %f1762, %f1091;
	mul.f32 	%f1092, %f1729, %f1761;
	fma.rn.f32 	%f1093, %f1726, %f1760, %f1092;
	fma.rn.f32 	%f291, %f1732, %f1762, %f1093;
	mul.f32 	%f1094, %f1731, %f1758;
	fma.rn.f32 	%f1095, %f1728, %f1757, %f1094;
	fma.rn.f32 	%f292, %f1734, %f1759, %f1095;
	mul.f32 	%f1096, %f1730, %f1758;
	fma.rn.f32 	%f1097, %f1727, %f1757, %f1096;
	fma.rn.f32 	%f293, %f1733, %f1759, %f1097;
	mul.f32 	%f1098, %f1729, %f1758;
	fma.rn.f32 	%f1099, %f1726, %f1757, %f1098;
	fma.rn.f32 	%f294, %f1732, %f1759, %f1099;
	mul.f32 	%f1100, %f1731, %f1755;
	fma.rn.f32 	%f1101, %f1728, %f1754, %f1100;
	fma.rn.f32 	%f1734, %f1734, %f1756, %f1101;
	mul.f32 	%f1102, %f1730, %f1755;
	fma.rn.f32 	%f1103, %f1727, %f1754, %f1102;
	fma.rn.f32 	%f1733, %f1733, %f1756, %f1103;
	mul.f32 	%f1104, %f1729, %f1755;
	fma.rn.f32 	%f1105, %f1726, %f1754, %f1104;
	fma.rn.f32 	%f1732, %f1732, %f1756, %f1105;
	mov.f32 	%f1731, %f292;
	mov.f32 	%f1730, %f293;
	mov.f32 	%f1729, %f294;
	mov.f32 	%f1728, %f289;
	mov.f32 	%f1727, %f290;
	mov.f32 	%f1726, %f291;

BB12_41:
	add.s32 	%r632, %r632, 1;
	setp.lt.u32	%p19, %r632, %r26;
	@%p19 bra 	BB12_25;

	mul.f32 	%f1106, %f919, %f1727;
	fma.rn.f32 	%f1107, %f918, %f1728, %f1106;
	fma.rn.f32 	%f1772, %f1774, %f1726, %f1107;
	mul.f32 	%f1108, %f919, %f1730;
	fma.rn.f32 	%f1109, %f918, %f1731, %f1108;
	fma.rn.f32 	%f1773, %f1774, %f1729, %f1109;
	mul.f32 	%f1110, %f919, %f1733;
	fma.rn.f32 	%f1111, %f918, %f1734, %f1110;
	fma.rn.f32 	%f1774, %f1774, %f1732, %f1111;
	bra.uni 	BB12_43;

BB12_24:
	mov.f32 	%f1772, %f918;
	mov.f32 	%f1773, %f919;

BB12_43:
	// inline asm
	call (%f1113), _optix_get_ray_tmax, ();
	// inline asm
	fma.rn.f32 	%f1923, %f1113, %f1774, %f1723;
	ld.f32 	%f315, [%rd3+320];
	setp.eq.f32	%p20, %f1923, %f315;
	@%p20 bra 	BB12_48;

	ld.f32 	%f1114, [%rd3+324];
	setp.eq.f32	%p21, %f1923, %f1114;
	@%p21 bra 	BB12_48;
	bra.uni 	BB12_45;

BB12_48:
	mov.f32 	%f1144, 0f00000000;
	fma.rn.f32 	%f326, %f1144, %f1144, %f1144;
	@%p20 bra 	BB12_50;
	bra.uni 	BB12_49;

BB12_50:
	mov.f32 	%f1149, 0fBF800000;
	fma.rn.f32 	%f1150, %f1149, %f1149, %f326;
	sqrt.rn.f32 	%f1151, %f1150;
	div.rn.f32 	%f1775, %f1144, %f1151;
	div.rn.f32 	%f1777, %f1149, %f1151;
	bra.uni 	BB12_51;

BB12_49:
	mov.f32 	%f1145, 0f3F800000;
	fma.rn.f32 	%f1146, %f1145, %f1145, %f326;
	sqrt.rn.f32 	%f1147, %f1146;
	div.rn.f32 	%f1775, %f1144, %f1147;
	rcp.rn.f32 	%f1777, %f1147;

BB12_51:
	mov.f32 	%f1776, %f1775;

BB12_52:
	fma.rn.f32 	%f1921, %f1113, %f1772, %f1725;
	fma.rn.f32 	%f1922, %f1113, %f1773, %f1724;
	ld.u64 	%rd21, [%rd49];
	ld.const.u64 	%rd292, [params+344];
	cvta.to.global.u64 	%rd293, %rd292;
	cvt.u64.u32	%rd22, %r1;
	mul.wide.u32 	%rd294, %r1, 4;
	add.s64 	%rd23, %rd293, %rd294;
	ld.global.u32 	%r9, [%rd23];
	setp.eq.s32	%p24, %r9, 0;
	mov.f32 	%f1909, 0f00000000;
	@%p24 bra 	BB12_53;

	// inline asm
	call (%r327), _optix_read_instance_id, ();
	// inline asm
	setp.ge.u32	%p25, %r327, %r9;
	@%p25 bra 	BB12_53;

	mov.f32 	%f1843, 0f00000000;
	mov.f32 	%f1844, 0f3F800000;
	mov.f32 	%f1781, %f1844;
	mov.f32 	%f1780, %f1843;
	mov.f32 	%f1779, %f1843;
	mov.f32 	%f1778, %f1843;
	mov.f32 	%f1785, %f1843;
	mov.f32 	%f1784, %f1844;
	mov.f32 	%f1783, %f1843;
	mov.f32 	%f1782, %f1843;
	mov.f32 	%f1789, %f1843;
	mov.f32 	%f1788, %f1843;
	mov.f32 	%f1787, %f1844;
	mov.f32 	%f1786, %f1843;
	@%p2 bra 	BB12_73;

	add.s32 	%r633, %r26, -1;
	setp.lt.s32	%p27, %r633, 0;
	@%p27 bra 	BB12_73;

BB12_57:
	.pragma "nounroll";
	// inline asm
	call (%rd295), _optix_get_transform_list_handle, (%r633);
	// inline asm
	// inline asm
	call (%r329), _optix_get_transform_type_from_handle, (%rd295);
	// inline asm
	and.b32  	%r330, %r329, -2;
	setp.eq.s32	%p28, %r330, 2;
	@%p28 bra 	BB12_63;
	bra.uni 	BB12_58;

BB12_63:
	setp.eq.s32	%p31, %r329, 2;
	@%p31 bra 	BB12_67;
	bra.uni 	BB12_64;

BB12_67:
	// inline asm
	call (%rd369), _optix_get_matrix_motion_transform_from_handle, (%rd295);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd371, %rd369;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r418,%r419,%r420,%r421}, [%rd371];
	// inline asm
	mov.b32	{%rs12, %rs13}, %r420;
	add.s64 	%rd375, %rd369, 16;
	// inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r422,%r423,%r424,%r425}, [%rd374];
	// inline asm
	add.s64 	%rd378, %rd369, 32;
	// inline asm
	cvta.to.global.u64 %rd377, %rd378;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd377];
	// inline asm
	add.s64 	%rd381, %rd369, 48;
	// inline asm
	cvta.to.global.u64 %rd380, %rd381;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd380];
	// inline asm
	add.s64 	%rd384, %rd369, 64;
	// inline asm
	cvta.to.global.u64 %rd383, %rd384;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd383];
	// inline asm
	add.s64 	%rd387, %rd369, 80;
	// inline asm
	cvta.to.global.u64 %rd386, %rd387;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd386];
	// inline asm
	add.s64 	%rd390, %rd369, 96;
	// inline asm
	cvta.to.global.u64 %rd389, %rd390;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd389];
	// inline asm
	add.s64 	%rd393, %rd369, 112;
	// inline asm
	cvta.to.global.u64 %rd392, %rd393;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd392];
	// inline asm
	mov.b32 	 %f1303, %r421;
	mov.b32 	 %f1304, %r422;
	cvt.u32.u16	%r462, %rs12;
	add.s32 	%r463, %r462, -1;
	cvt.rn.f32.s32	%f1305, %r463;
	sub.f32 	%f1306, %f921, %f1303;
	mul.f32 	%f1307, %f1306, %f1305;
	sub.f32 	%f1308, %f1304, %f1303;
	div.rn.f32 	%f1309, %f1307, %f1308;
	min.f32 	%f1310, %f1305, %f1309;
	mov.f32 	%f1311, 0f00000000;
	max.f32 	%f1312, %f1311, %f1310;
	cvt.rmi.f32.f32	%f1313, %f1312;
	cvt.rzi.s32.f32	%r464, %f1313;
	cvt.s64.s32	%rd31, %r464;
	mul.wide.s32 	%rd404, %r464, 48;
	add.s64 	%rd396, %rd378, %rd404;
	// inline asm
	cvta.to.global.u64 %rd395, %rd396;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd395];
	// inline asm
	mov.b32 	 %f1814, %r450;
	mov.b32 	 %f1815, %r451;
	mov.b32 	 %f1816, %r452;
	mov.b32 	 %f1817, %r453;
	add.s64 	%rd399, %rd396, 16;
	// inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd398];
	// inline asm
	mov.b32 	 %f1810, %r454;
	mov.b32 	 %f1811, %r455;
	mov.b32 	 %f1812, %r456;
	mov.b32 	 %f1813, %r457;
	add.s64 	%rd402, %rd396, 32;
	// inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd401];
	// inline asm
	sub.f32 	%f429, %f1312, %f1313;
	mov.b32 	 %f1806, %r458;
	mov.b32 	 %f1807, %r459;
	mov.b32 	 %f1808, %r460;
	mov.b32 	 %f1809, %r461;
	setp.leu.f32	%p33, %f429, 0f00000000;
	@%p33 bra 	BB12_69;

	mul.lo.s64 	%rd414, %rd31, 48;
	add.s64 	%rd415, %rd369, %rd414;
	add.s64 	%rd406, %rd415, 80;
	// inline asm
	cvta.to.global.u64 %rd405, %rd406;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r465,%r466,%r467,%r468}, [%rd405];
	// inline asm
	mov.b32 	 %f1314, %r465;
	mov.b32 	 %f1315, %r466;
	mov.b32 	 %f1316, %r467;
	mov.b32 	 %f1317, %r468;
	add.s64 	%rd409, %rd415, 96;
	// inline asm
	cvta.to.global.u64 %rd408, %rd409;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r469,%r470,%r471,%r472}, [%rd408];
	// inline asm
	mov.b32 	 %f1318, %r469;
	mov.b32 	 %f1319, %r470;
	mov.b32 	 %f1320, %r471;
	mov.b32 	 %f1321, %r472;
	add.s64 	%rd412, %rd415, 112;
	// inline asm
	cvta.to.global.u64 %rd411, %rd412;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r473,%r474,%r475,%r476}, [%rd411];
	// inline asm
	mov.f32 	%f1322, 0f3F800000;
	sub.f32 	%f1323, %f1322, %f429;
	mul.f32 	%f1324, %f429, %f1314;
	mul.f32 	%f1325, %f429, %f1315;
	mul.f32 	%f1326, %f429, %f1316;
	mul.f32 	%f1327, %f429, %f1317;
	fma.rn.f32 	%f1814, %f1323, %f1814, %f1324;
	fma.rn.f32 	%f1815, %f1323, %f1815, %f1325;
	fma.rn.f32 	%f1816, %f1323, %f1816, %f1326;
	fma.rn.f32 	%f1817, %f1323, %f1817, %f1327;
	mul.f32 	%f1328, %f429, %f1318;
	mul.f32 	%f1329, %f429, %f1319;
	mul.f32 	%f1330, %f429, %f1320;
	mul.f32 	%f1331, %f429, %f1321;
	fma.rn.f32 	%f1810, %f1323, %f1810, %f1328;
	fma.rn.f32 	%f1811, %f1323, %f1811, %f1329;
	fma.rn.f32 	%f1812, %f1323, %f1812, %f1330;
	fma.rn.f32 	%f1813, %f1323, %f1813, %f1331;
	mov.b32 	 %f1332, %r473;
	mov.b32 	 %f1333, %r474;
	mov.b32 	 %f1334, %r475;
	mov.b32 	 %f1335, %r476;
	mul.f32 	%f1336, %f429, %f1332;
	mul.f32 	%f1337, %f429, %f1333;
	mul.f32 	%f1338, %f429, %f1334;
	mul.f32 	%f1339, %f429, %f1335;
	fma.rn.f32 	%f1806, %f1323, %f1806, %f1336;
	fma.rn.f32 	%f1807, %f1323, %f1807, %f1337;
	fma.rn.f32 	%f1808, %f1323, %f1808, %f1338;
	fma.rn.f32 	%f1809, %f1323, %f1809, %f1339;
	bra.uni 	BB12_69;

BB12_58:
	mov.f32 	%f1806, 0f00000000;
	mov.f32 	%f1808, 0f3F800000;
	setp.eq.s32	%p29, %r329, 4;
	@%p29 bra 	BB12_61;
	bra.uni 	BB12_59;

BB12_61:
	// inline asm
	call (%rd645), _optix_get_instance_transform_from_handle, (%rd295);
	// inline asm
	bra.uni 	BB12_62;

BB12_64:
	// inline asm
	call (%rd310), _optix_get_srt_motion_transform_from_handle, (%rd295);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd312, %rd310;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r343,%r344,%r345,%r346}, [%rd312];
	// inline asm
	mov.b32	{%rs10, %rs11}, %r345;
	add.s64 	%rd316, %rd310, 16;
	// inline asm
	cvta.to.global.u64 %rd315, %rd316;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r347,%r348,%r349,%r350}, [%rd315];
	// inline asm
	add.s64 	%rd319, %rd310, 32;
	// inline asm
	cvta.to.global.u64 %rd318, %rd319;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r351,%r352,%r353,%r354}, [%rd318];
	// inline asm
	add.s64 	%rd322, %rd310, 48;
	// inline asm
	cvta.to.global.u64 %rd321, %rd322;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd321];
	// inline asm
	add.s64 	%rd325, %rd310, 64;
	// inline asm
	cvta.to.global.u64 %rd324, %rd325;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd324];
	// inline asm
	add.s64 	%rd328, %rd310, 80;
	// inline asm
	cvta.to.global.u64 %rd327, %rd328;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd327];
	// inline asm
	add.s64 	%rd331, %rd310, 96;
	// inline asm
	cvta.to.global.u64 %rd330, %rd331;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd330];
	// inline asm
	add.s64 	%rd334, %rd310, 112;
	// inline asm
	cvta.to.global.u64 %rd333, %rd334;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd333];
	// inline asm
	add.s64 	%rd337, %rd310, 128;
	// inline asm
	cvta.to.global.u64 %rd336, %rd337;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd336];
	// inline asm
	add.s64 	%rd340, %rd310, 144;
	// inline asm
	cvta.to.global.u64 %rd339, %rd340;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd339];
	// inline asm
	mov.b32 	 %f1190, %r346;
	mov.b32 	 %f1191, %r347;
	cvt.u32.u16	%r399, %rs10;
	add.s32 	%r400, %r399, -1;
	cvt.rn.f32.s32	%f1192, %r400;
	sub.f32 	%f1193, %f921, %f1190;
	mul.f32 	%f1194, %f1193, %f1192;
	sub.f32 	%f1195, %f1191, %f1190;
	div.rn.f32 	%f1196, %f1194, %f1195;
	min.f32 	%f1197, %f1192, %f1196;
	mov.f32 	%f1198, 0f00000000;
	max.f32 	%f1199, %f1198, %f1197;
	cvt.rmi.f32.f32	%f1200, %f1199;
	cvt.rzi.s32.f32	%r401, %f1200;
	cvt.s64.s32	%rd29, %r401;
	mul.wide.s32 	%rd354, %r401, 64;
	add.s64 	%rd343, %rd319, %rd354;
	// inline asm
	cvta.to.global.u64 %rd342, %rd343;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd342];
	// inline asm
	mov.b32 	 %f1790, %r383;
	mov.b32 	 %f1791, %r384;
	mov.b32 	 %f1792, %r385;
	mov.b32 	 %f1793, %r386;
	add.s64 	%rd346, %rd343, 16;
	// inline asm
	cvta.to.global.u64 %rd345, %rd346;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd345];
	// inline asm
	mov.b32 	 %f1794, %r387;
	mov.b32 	 %f1795, %r388;
	mov.b32 	 %f1796, %r389;
	mov.b32 	 %f1797, %r390;
	add.s64 	%rd349, %rd343, 32;
	// inline asm
	cvta.to.global.u64 %rd348, %rd349;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd348];
	// inline asm
	sub.f32 	%f368, %f1199, %f1200;
	mov.b32 	 %f1798, %r391;
	mov.b32 	 %f1799, %r392;
	mov.b32 	 %f1800, %r393;
	mov.b32 	 %f1801, %r394;
	add.s64 	%rd352, %rd343, 48;
	// inline asm
	cvta.to.global.u64 %rd351, %rd352;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd351];
	// inline asm
	mov.b32 	 %f1802, %r395;
	mov.b32 	 %f1803, %r396;
	mov.b32 	 %f1804, %r397;
	mov.b32 	 %f1805, %r398;
	setp.leu.f32	%p32, %f368, 0f00000000;
	@%p32 bra 	BB12_66;

	shl.b64 	%rd367, %rd29, 6;
	add.s64 	%rd368, %rd367, %rd310;
	add.s64 	%rd356, %rd368, 96;
	// inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r402,%r403,%r404,%r405}, [%rd355];
	// inline asm
	mov.b32 	 %f1201, %r402;
	mov.b32 	 %f1202, %r403;
	mov.b32 	 %f1203, %r404;
	mov.b32 	 %f1204, %r405;
	add.s64 	%rd359, %rd368, 112;
	// inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r406,%r407,%r408,%r409}, [%rd358];
	// inline asm
	mov.b32 	 %f1205, %r406;
	mov.b32 	 %f1206, %r407;
	mov.b32 	 %f1207, %r408;
	mov.b32 	 %f1208, %r409;
	add.s64 	%rd362, %rd368, 128;
	// inline asm
	cvta.to.global.u64 %rd361, %rd362;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r410,%r411,%r412,%r413}, [%rd361];
	// inline asm
	mov.b32 	 %f1209, %r410;
	mov.b32 	 %f1210, %r411;
	mov.b32 	 %f1211, %r412;
	mov.b32 	 %f1212, %r413;
	add.s64 	%rd365, %rd368, 144;
	// inline asm
	cvta.to.global.u64 %rd364, %rd365;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r414,%r415,%r416,%r417}, [%rd364];
	// inline asm
	mov.f32 	%f1213, 0f3F800000;
	sub.f32 	%f1214, %f1213, %f368;
	mul.f32 	%f1215, %f368, %f1201;
	mul.f32 	%f1216, %f368, %f1202;
	mul.f32 	%f1217, %f368, %f1203;
	mul.f32 	%f1218, %f368, %f1204;
	fma.rn.f32 	%f1790, %f1214, %f1790, %f1215;
	fma.rn.f32 	%f1791, %f1214, %f1791, %f1216;
	fma.rn.f32 	%f1792, %f1214, %f1792, %f1217;
	fma.rn.f32 	%f1793, %f1214, %f1793, %f1218;
	mul.f32 	%f1219, %f368, %f1205;
	mul.f32 	%f1220, %f368, %f1206;
	mul.f32 	%f1221, %f368, %f1207;
	mul.f32 	%f1222, %f368, %f1208;
	fma.rn.f32 	%f1794, %f1214, %f1794, %f1219;
	fma.rn.f32 	%f1795, %f1214, %f1795, %f1220;
	fma.rn.f32 	%f1796, %f1214, %f1796, %f1221;
	fma.rn.f32 	%f1797, %f1214, %f1797, %f1222;
	mul.f32 	%f1223, %f368, %f1209;
	mul.f32 	%f1224, %f368, %f1210;
	mul.f32 	%f1225, %f368, %f1211;
	mul.f32 	%f1226, %f368, %f1212;
	fma.rn.f32 	%f1798, %f1214, %f1798, %f1223;
	fma.rn.f32 	%f1227, %f1214, %f1799, %f1224;
	fma.rn.f32 	%f1228, %f1214, %f1800, %f1225;
	fma.rn.f32 	%f1229, %f1214, %f1801, %f1226;
	mov.b32 	 %f1230, %r414;
	mov.b32 	 %f1231, %r415;
	mov.b32 	 %f1232, %r416;
	mov.b32 	 %f1233, %r417;
	mul.f32 	%f1234, %f368, %f1230;
	mul.f32 	%f1235, %f368, %f1231;
	mul.f32 	%f1236, %f368, %f1232;
	mul.f32 	%f1237, %f368, %f1233;
	fma.rn.f32 	%f1238, %f1214, %f1802, %f1234;
	fma.rn.f32 	%f1803, %f1214, %f1803, %f1235;
	fma.rn.f32 	%f1804, %f1214, %f1804, %f1236;
	fma.rn.f32 	%f1805, %f1214, %f1805, %f1237;
	mul.f32 	%f1239, %f1228, %f1228;
	fma.rn.f32 	%f1240, %f1227, %f1227, %f1239;
	fma.rn.f32 	%f1241, %f1229, %f1229, %f1240;
	fma.rn.f32 	%f1242, %f1238, %f1238, %f1241;
	sqrt.rn.f32 	%f1243, %f1242;
	rcp.rn.f32 	%f1244, %f1243;
	mul.f32 	%f1799, %f1227, %f1244;
	mul.f32 	%f1800, %f1228, %f1244;
	mul.f32 	%f1801, %f1229, %f1244;
	mul.f32 	%f1802, %f1238, %f1244;

BB12_66:
	mul.f32 	%f1245, %f1800, %f1800;
	fma.rn.f32 	%f1246, %f1799, %f1799, %f1245;
	fma.rn.f32 	%f1247, %f1801, %f1801, %f1246;
	fma.rn.f32 	%f1248, %f1802, %f1802, %f1247;
	rcp.rn.f32 	%f1249, %f1248;
	mul.f32 	%f1250, %f1799, %f1249;
	mul.f32 	%f1251, %f1800, %f1249;
	mul.f32 	%f1252, %f1801, %f1249;
	mul.f32 	%f1253, %f1802, %f1249;
	mul.f32 	%f1254, %f1799, %f1250;
	mul.f32 	%f1255, %f1800, %f1251;
	mul.f32 	%f1256, %f1801, %f1252;
	mul.f32 	%f1257, %f1799, %f1251;
	mul.f32 	%f1258, %f1801, %f1253;
	mul.f32 	%f1259, %f1799, %f1252;
	mul.f32 	%f1260, %f1800, %f1253;
	mul.f32 	%f1261, %f1800, %f1252;
	mul.f32 	%f1262, %f1799, %f1253;
	sub.f32 	%f1263, %f1254, %f1255;
	sub.f32 	%f1264, %f1263, %f1256;
	fma.rn.f32 	%f1265, %f1802, %f1253, %f1264;
	sub.f32 	%f1266, %f1257, %f1258;
	add.f32 	%f1267, %f1266, %f1266;
	add.f32 	%f1268, %f1259, %f1260;
	add.f32 	%f1269, %f1268, %f1268;
	add.f32 	%f1270, %f1257, %f1258;
	add.f32 	%f1271, %f1270, %f1270;
	sub.f32 	%f1272, %f1255, %f1254;
	sub.f32 	%f1273, %f1272, %f1256;
	fma.rn.f32 	%f1274, %f1802, %f1253, %f1273;
	sub.f32 	%f1275, %f1261, %f1262;
	add.f32 	%f1276, %f1275, %f1275;
	sub.f32 	%f1277, %f1259, %f1260;
	add.f32 	%f1278, %f1277, %f1277;
	add.f32 	%f1279, %f1261, %f1262;
	add.f32 	%f1280, %f1279, %f1279;
	neg.f32 	%f1281, %f1254;
	sub.f32 	%f1282, %f1281, %f1255;
	add.f32 	%f1283, %f1256, %f1282;
	fma.rn.f32 	%f1284, %f1802, %f1253, %f1283;
	mul.f32 	%f1285, %f1793, %f1265;
	fma.rn.f32 	%f1286, %f1796, %f1267, %f1285;
	fma.rn.f32 	%f1287, %f1798, %f1269, %f1286;
	sub.f32 	%f1817, %f1803, %f1287;
	mul.f32 	%f1288, %f1796, %f1274;
	fma.rn.f32 	%f1289, %f1793, %f1271, %f1288;
	fma.rn.f32 	%f1290, %f1798, %f1276, %f1289;
	sub.f32 	%f1813, %f1804, %f1290;
	mul.f32 	%f1291, %f1796, %f1280;
	fma.rn.f32 	%f1292, %f1793, %f1278, %f1291;
	fma.rn.f32 	%f1293, %f1798, %f1284, %f1292;
	sub.f32 	%f1809, %f1805, %f1293;
	mul.f32 	%f1294, %f1792, %f1265;
	fma.rn.f32 	%f1295, %f1795, %f1267, %f1294;
	fma.rn.f32 	%f1816, %f1797, %f1269, %f1295;
	mul.f32 	%f1296, %f1795, %f1274;
	fma.rn.f32 	%f1297, %f1792, %f1271, %f1296;
	fma.rn.f32 	%f1812, %f1797, %f1276, %f1297;
	mul.f32 	%f1298, %f1795, %f1280;
	fma.rn.f32 	%f1299, %f1792, %f1278, %f1298;
	fma.rn.f32 	%f1808, %f1797, %f1284, %f1299;
	mul.f32 	%f1300, %f1791, %f1265;
	fma.rn.f32 	%f1815, %f1794, %f1267, %f1300;
	mul.f32 	%f1301, %f1794, %f1274;
	fma.rn.f32 	%f1811, %f1791, %f1271, %f1301;
	mul.f32 	%f1302, %f1794, %f1280;
	fma.rn.f32 	%f1807, %f1791, %f1278, %f1302;
	mul.f32 	%f1814, %f1790, %f1265;
	mul.f32 	%f1810, %f1790, %f1271;
	mul.f32 	%f1806, %f1790, %f1278;
	bra.uni 	BB12_69;

BB12_59:
	setp.ne.s32	%p30, %r329, 1;
	mov.f32 	%f1807, %f1806;
	mov.f32 	%f1809, %f1806;
	mov.f32 	%f1810, %f1806;
	mov.f32 	%f1811, %f1808;
	mov.f32 	%f1812, %f1806;
	mov.f32 	%f1813, %f1806;
	mov.f32 	%f1814, %f1808;
	mov.f32 	%f1815, %f1806;
	mov.f32 	%f1816, %f1806;
	mov.f32 	%f1817, %f1806;
	@%p30 bra 	BB12_69;

	// inline asm
	call (%rd297), _optix_get_static_transform_from_handle, (%rd295);
	// inline asm
	add.s64 	%rd645, %rd297, 16;

BB12_62:
	// inline asm
	cvta.to.global.u64 %rd301, %rd645;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r331,%r332,%r333,%r334}, [%rd301];
	// inline asm
	mov.b32 	 %f1814, %r331;
	mov.b32 	 %f1815, %r332;
	mov.b32 	 %f1816, %r333;
	mov.b32 	 %f1817, %r334;
	add.s64 	%rd305, %rd645, 16;
	// inline asm
	cvta.to.global.u64 %rd304, %rd305;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r335,%r336,%r337,%r338}, [%rd304];
	// inline asm
	mov.b32 	 %f1810, %r335;
	mov.b32 	 %f1811, %r336;
	mov.b32 	 %f1812, %r337;
	mov.b32 	 %f1813, %r338;
	add.s64 	%rd308, %rd645, 32;
	// inline asm
	cvta.to.global.u64 %rd307, %rd308;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r339,%r340,%r341,%r342}, [%rd307];
	// inline asm
	mov.b32 	 %f1806, %r339;
	mov.b32 	 %f1807, %r340;
	mov.b32 	 %f1808, %r341;
	mov.b32 	 %f1809, %r342;

BB12_69:
	add.s32 	%r14, %r633, 1;
	setp.eq.s32	%p34, %r14, %r26;
	@%p34 bra 	BB12_70;
	bra.uni 	BB12_71;

BB12_70:
	mov.f32 	%f1789, %f1806;
	mov.f32 	%f1788, %f1807;
	mov.f32 	%f1787, %f1808;
	mov.f32 	%f1786, %f1809;
	mov.f32 	%f1785, %f1810;
	mov.f32 	%f1784, %f1811;
	mov.f32 	%f1783, %f1812;
	mov.f32 	%f1782, %f1813;
	mov.f32 	%f1781, %f1814;
	mov.f32 	%f1780, %f1815;
	mov.f32 	%f1779, %f1816;
	mov.f32 	%f1778, %f1817;
	bra.uni 	BB12_72;

BB12_71:
	mul.f32 	%f1340, %f1785, %f1815;
	fma.rn.f32 	%f1341, %f1781, %f1814, %f1340;
	fma.rn.f32 	%f458, %f1789, %f1816, %f1341;
	mul.f32 	%f1342, %f1784, %f1815;
	fma.rn.f32 	%f1343, %f1780, %f1814, %f1342;
	fma.rn.f32 	%f459, %f1788, %f1816, %f1343;
	mul.f32 	%f1344, %f1783, %f1815;
	fma.rn.f32 	%f1345, %f1779, %f1814, %f1344;
	fma.rn.f32 	%f460, %f1787, %f1816, %f1345;
	mul.f32 	%f1346, %f1782, %f1815;
	fma.rn.f32 	%f1347, %f1778, %f1814, %f1346;
	fma.rn.f32 	%f1348, %f1786, %f1816, %f1347;
	add.f32 	%f461, %f1817, %f1348;
	mul.f32 	%f1349, %f1785, %f1811;
	fma.rn.f32 	%f1350, %f1781, %f1810, %f1349;
	fma.rn.f32 	%f462, %f1789, %f1812, %f1350;
	mul.f32 	%f1351, %f1784, %f1811;
	fma.rn.f32 	%f1352, %f1780, %f1810, %f1351;
	fma.rn.f32 	%f463, %f1788, %f1812, %f1352;
	mul.f32 	%f1353, %f1783, %f1811;
	fma.rn.f32 	%f1354, %f1779, %f1810, %f1353;
	fma.rn.f32 	%f464, %f1787, %f1812, %f1354;
	mul.f32 	%f1355, %f1782, %f1811;
	fma.rn.f32 	%f1356, %f1778, %f1810, %f1355;
	fma.rn.f32 	%f1357, %f1786, %f1812, %f1356;
	add.f32 	%f465, %f1813, %f1357;
	mul.f32 	%f1358, %f1785, %f1807;
	fma.rn.f32 	%f1359, %f1781, %f1806, %f1358;
	fma.rn.f32 	%f1789, %f1789, %f1808, %f1359;
	mul.f32 	%f1360, %f1784, %f1807;
	fma.rn.f32 	%f1361, %f1780, %f1806, %f1360;
	fma.rn.f32 	%f1788, %f1788, %f1808, %f1361;
	mul.f32 	%f1362, %f1783, %f1807;
	fma.rn.f32 	%f1363, %f1779, %f1806, %f1362;
	fma.rn.f32 	%f1787, %f1787, %f1808, %f1363;
	mul.f32 	%f1364, %f1782, %f1807;
	fma.rn.f32 	%f1365, %f1778, %f1806, %f1364;
	fma.rn.f32 	%f1366, %f1786, %f1808, %f1365;
	add.f32 	%f1786, %f1809, %f1366;
	mov.f32 	%f1785, %f462;
	mov.f32 	%f1784, %f463;
	mov.f32 	%f1783, %f464;
	mov.f32 	%f1782, %f465;
	mov.f32 	%f1781, %f458;
	mov.f32 	%f1780, %f459;
	mov.f32 	%f1779, %f460;
	mov.f32 	%f1778, %f461;

BB12_72:
	add.s32 	%r633, %r14, -2;
	setp.gt.s32	%p35, %r633, -1;
	@%p35 bra 	BB12_57;

BB12_73:
	mov.u32 	%r634, 0;
	mov.f32 	%f1842, %f1843;
	mov.f32 	%f1847, %f1843;
	mov.f32 	%f1846, %f1844;
	mov.f32 	%f1845, %f1843;
	mov.f32 	%f1850, %f1843;
	mov.f32 	%f1849, %f1843;
	mov.f32 	%f1848, %f1844;
	@%p2 bra 	BB12_91;

BB12_74:
	.pragma "nounroll";
	// inline asm
	call (%rd416), _optix_get_transform_list_handle, (%r634);
	// inline asm
	// inline asm
	call (%r479), _optix_get_transform_type_from_handle, (%rd416);
	// inline asm
	and.b32  	%r480, %r479, -2;
	setp.eq.s32	%p37, %r480, 2;
	@%p37 bra 	BB12_80;
	bra.uni 	BB12_75;

BB12_80:
	setp.eq.s32	%p40, %r479, 2;
	@%p40 bra 	BB12_84;
	bra.uni 	BB12_81;

BB12_84:
	// inline asm
	call (%rd490), _optix_get_matrix_motion_transform_from_handle, (%rd416);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd492, %rd490;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd492];
	// inline asm
	mov.b32	{%rs16, %rs17}, %r570;
	add.s64 	%rd496, %rd490, 16;
	// inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd495];
	// inline asm
	add.s64 	%rd499, %rd490, 32;
	// inline asm
	cvta.to.global.u64 %rd498, %rd499;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd498];
	// inline asm
	add.s64 	%rd502, %rd490, 48;
	// inline asm
	cvta.to.global.u64 %rd501, %rd502;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd501];
	// inline asm
	add.s64 	%rd505, %rd490, 64;
	// inline asm
	cvta.to.global.u64 %rd504, %rd505;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd504];
	// inline asm
	add.s64 	%rd508, %rd490, 80;
	// inline asm
	cvta.to.global.u64 %rd507, %rd508;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd507];
	// inline asm
	add.s64 	%rd511, %rd490, 96;
	// inline asm
	cvta.to.global.u64 %rd510, %rd511;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd510];
	// inline asm
	add.s64 	%rd514, %rd490, 112;
	// inline asm
	cvta.to.global.u64 %rd513, %rd514;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd513];
	// inline asm
	mov.b32 	 %f1478, %r571;
	mov.b32 	 %f1479, %r572;
	cvt.u32.u16	%r612, %rs16;
	add.s32 	%r613, %r612, -1;
	cvt.rn.f32.s32	%f1480, %r613;
	sub.f32 	%f1481, %f921, %f1478;
	mul.f32 	%f1482, %f1481, %f1480;
	sub.f32 	%f1483, %f1479, %f1478;
	div.rn.f32 	%f1484, %f1482, %f1483;
	min.f32 	%f1485, %f1480, %f1484;
	mov.f32 	%f1486, 0f00000000;
	max.f32 	%f1487, %f1486, %f1485;
	cvt.rmi.f32.f32	%f1488, %f1487;
	cvt.rzi.s32.f32	%r614, %f1488;
	cvt.s64.s32	%rd39, %r614;
	mul.wide.s32 	%rd525, %r614, 48;
	add.s64 	%rd517, %rd499, %rd525;
	// inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd516];
	// inline asm
	mov.b32 	 %f1867, %r600;
	mov.b32 	 %f1868, %r601;
	mov.b32 	 %f1869, %r602;
	add.s64 	%rd520, %rd517, 16;
	// inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd519];
	// inline asm
	mov.b32 	 %f1864, %r604;
	mov.b32 	 %f1865, %r605;
	mov.b32 	 %f1866, %r606;
	add.s64 	%rd523, %rd517, 32;
	// inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd522];
	// inline asm
	sub.f32 	%f558, %f1487, %f1488;
	mov.b32 	 %f1861, %r608;
	mov.b32 	 %f1862, %r609;
	mov.b32 	 %f1863, %r610;
	setp.leu.f32	%p42, %f558, 0f00000000;
	@%p42 bra 	BB12_86;

	mul.lo.s64 	%rd535, %rd39, 48;
	add.s64 	%rd536, %rd490, %rd535;
	add.s64 	%rd527, %rd536, 80;
	// inline asm
	cvta.to.global.u64 %rd526, %rd527;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r615,%r616,%r617,%r618}, [%rd526];
	// inline asm
	mov.b32 	 %f1489, %r615;
	mov.b32 	 %f1490, %r616;
	mov.b32 	 %f1491, %r617;
	add.s64 	%rd530, %rd536, 96;
	// inline asm
	cvta.to.global.u64 %rd529, %rd530;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r619,%r620,%r621,%r622}, [%rd529];
	// inline asm
	mov.b32 	 %f1492, %r619;
	mov.b32 	 %f1493, %r620;
	mov.b32 	 %f1494, %r621;
	add.s64 	%rd533, %rd536, 112;
	// inline asm
	cvta.to.global.u64 %rd532, %rd533;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r623,%r624,%r625,%r626}, [%rd532];
	// inline asm
	mov.f32 	%f1495, 0f3F800000;
	sub.f32 	%f1496, %f1495, %f558;
	mul.f32 	%f1497, %f558, %f1489;
	mul.f32 	%f1498, %f558, %f1490;
	mul.f32 	%f1499, %f558, %f1491;
	fma.rn.f32 	%f1867, %f1496, %f1867, %f1497;
	fma.rn.f32 	%f1868, %f1496, %f1868, %f1498;
	fma.rn.f32 	%f1869, %f1496, %f1869, %f1499;
	mul.f32 	%f1500, %f558, %f1492;
	mul.f32 	%f1501, %f558, %f1493;
	mul.f32 	%f1502, %f558, %f1494;
	fma.rn.f32 	%f1864, %f1496, %f1864, %f1500;
	fma.rn.f32 	%f1865, %f1496, %f1865, %f1501;
	fma.rn.f32 	%f1866, %f1496, %f1866, %f1502;
	mov.b32 	 %f1503, %r623;
	mov.b32 	 %f1504, %r624;
	mov.b32 	 %f1505, %r625;
	mul.f32 	%f1506, %f558, %f1503;
	mul.f32 	%f1507, %f558, %f1504;
	mul.f32 	%f1508, %f558, %f1505;
	fma.rn.f32 	%f1861, %f1496, %f1861, %f1506;
	fma.rn.f32 	%f1862, %f1496, %f1862, %f1507;
	fma.rn.f32 	%f1863, %f1496, %f1863, %f1508;
	bra.uni 	BB12_86;

BB12_75:
	mov.f32 	%f1870, 0f00000000;
	mov.f32 	%f1872, 0f3F800000;
	setp.eq.s32	%p38, %r479, 4;
	@%p38 bra 	BB12_78;
	bra.uni 	BB12_76;

BB12_78:
	// inline asm
	call (%rd646), _optix_get_instance_inverse_transform_from_handle, (%rd416);
	// inline asm
	bra.uni 	BB12_79;

BB12_81:
	// inline asm
	call (%rd431), _optix_get_srt_motion_transform_from_handle, (%rd416);
	// inline asm
	// inline asm
	cvta.to.global.u64 %rd433, %rd431;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r493,%r494,%r495,%r496}, [%rd433];
	// inline asm
	mov.b32	{%rs14, %rs15}, %r495;
	add.s64 	%rd437, %rd431, 16;
	// inline asm
	cvta.to.global.u64 %rd436, %rd437;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd436];
	// inline asm
	add.s64 	%rd440, %rd431, 32;
	// inline asm
	cvta.to.global.u64 %rd439, %rd440;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd439];
	// inline asm
	add.s64 	%rd443, %rd431, 48;
	// inline asm
	cvta.to.global.u64 %rd442, %rd443;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd442];
	// inline asm
	add.s64 	%rd446, %rd431, 64;
	// inline asm
	cvta.to.global.u64 %rd445, %rd446;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd445];
	// inline asm
	add.s64 	%rd449, %rd431, 80;
	// inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd448];
	// inline asm
	add.s64 	%rd452, %rd431, 96;
	// inline asm
	cvta.to.global.u64 %rd451, %rd452;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd451];
	// inline asm
	add.s64 	%rd455, %rd431, 112;
	// inline asm
	cvta.to.global.u64 %rd454, %rd455;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd454];
	// inline asm
	add.s64 	%rd458, %rd431, 128;
	// inline asm
	cvta.to.global.u64 %rd457, %rd458;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd457];
	// inline asm
	add.s64 	%rd461, %rd431, 144;
	// inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd460];
	// inline asm
	mov.b32 	 %f1386, %r496;
	mov.b32 	 %f1387, %r497;
	cvt.u32.u16	%r549, %rs14;
	add.s32 	%r550, %r549, -1;
	cvt.rn.f32.s32	%f1388, %r550;
	sub.f32 	%f1389, %f921, %f1386;
	mul.f32 	%f1390, %f1389, %f1388;
	sub.f32 	%f1391, %f1387, %f1386;
	div.rn.f32 	%f1392, %f1390, %f1391;
	min.f32 	%f1393, %f1388, %f1392;
	mov.f32 	%f1394, 0f00000000;
	max.f32 	%f1395, %f1394, %f1393;
	cvt.rmi.f32.f32	%f1396, %f1395;
	cvt.rzi.s32.f32	%r551, %f1396;
	cvt.s64.s32	%rd37, %r551;
	mul.wide.s32 	%rd475, %r551, 64;
	add.s64 	%rd464, %rd440, %rd475;
	// inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd463];
	// inline asm
	mov.b32 	 %f1851, %r533;
	mov.b32 	 %f1852, %r534;
	mov.b32 	 %f1853, %r535;
	add.s64 	%rd467, %rd464, 16;
	// inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd466];
	// inline asm
	mov.b32 	 %f1854, %r537;
	mov.b32 	 %f1855, %r538;
	mov.b32 	 %f1856, %r540;
	add.s64 	%rd470, %rd464, 32;
	// inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd469];
	// inline asm
	sub.f32 	%f518, %f1395, %f1396;
	mov.b32 	 %f1857, %r542;
	mov.b32 	 %f1858, %r543;
	mov.b32 	 %f1859, %r544;
	add.s64 	%rd473, %rd464, 48;
	// inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd472];
	// inline asm
	mov.b32 	 %f1860, %r545;
	setp.leu.f32	%p41, %f518, 0f00000000;
	@%p41 bra 	BB12_83;

	shl.b64 	%rd488, %rd37, 6;
	add.s64 	%rd489, %rd488, %rd431;
	add.s64 	%rd477, %rd489, 96;
	// inline asm
	cvta.to.global.u64 %rd476, %rd477;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r552,%r553,%r554,%r555}, [%rd476];
	// inline asm
	mov.b32 	 %f1397, %r552;
	mov.b32 	 %f1398, %r553;
	mov.b32 	 %f1399, %r554;
	add.s64 	%rd480, %rd489, 112;
	// inline asm
	cvta.to.global.u64 %rd479, %rd480;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r556,%r557,%r558,%r559}, [%rd479];
	// inline asm
	mov.b32 	 %f1400, %r556;
	mov.b32 	 %f1401, %r557;
	mov.b32 	 %f1402, %r559;
	add.s64 	%rd483, %rd489, 128;
	// inline asm
	cvta.to.global.u64 %rd482, %rd483;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r560,%r561,%r562,%r563}, [%rd482];
	// inline asm
	mov.b32 	 %f1403, %r561;
	mov.b32 	 %f1404, %r562;
	mov.b32 	 %f1405, %r563;
	add.s64 	%rd486, %rd489, 144;
	// inline asm
	cvta.to.global.u64 %rd485, %rd486;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r564,%r565,%r566,%r567}, [%rd485];
	// inline asm
	mov.f32 	%f1406, 0f3F800000;
	sub.f32 	%f1407, %f1406, %f518;
	mul.f32 	%f1408, %f518, %f1397;
	mul.f32 	%f1409, %f518, %f1398;
	mul.f32 	%f1410, %f518, %f1399;
	fma.rn.f32 	%f1851, %f1407, %f1851, %f1408;
	fma.rn.f32 	%f1852, %f1407, %f1852, %f1409;
	fma.rn.f32 	%f1853, %f1407, %f1853, %f1410;
	mul.f32 	%f1411, %f518, %f1400;
	mul.f32 	%f1412, %f518, %f1401;
	mul.f32 	%f1413, %f518, %f1402;
	fma.rn.f32 	%f1854, %f1407, %f1854, %f1411;
	fma.rn.f32 	%f1855, %f1407, %f1855, %f1412;
	fma.rn.f32 	%f1856, %f1407, %f1856, %f1413;
	mul.f32 	%f1414, %f518, %f1403;
	mul.f32 	%f1415, %f518, %f1404;
	mul.f32 	%f1416, %f518, %f1405;
	fma.rn.f32 	%f1417, %f1407, %f1857, %f1414;
	fma.rn.f32 	%f1418, %f1407, %f1858, %f1415;
	fma.rn.f32 	%f1419, %f1407, %f1859, %f1416;
	mov.b32 	 %f1420, %r564;
	mul.f32 	%f1421, %f518, %f1420;
	fma.rn.f32 	%f1422, %f1407, %f1860, %f1421;
	mul.f32 	%f1423, %f1418, %f1418;
	fma.rn.f32 	%f1424, %f1417, %f1417, %f1423;
	fma.rn.f32 	%f1425, %f1419, %f1419, %f1424;
	fma.rn.f32 	%f1426, %f1422, %f1422, %f1425;
	sqrt.rn.f32 	%f1427, %f1426;
	rcp.rn.f32 	%f1428, %f1427;
	mul.f32 	%f1857, %f1417, %f1428;
	mul.f32 	%f1858, %f1418, %f1428;
	mul.f32 	%f1859, %f1419, %f1428;
	mul.f32 	%f1860, %f1422, %f1428;

BB12_83:
	mul.f32 	%f1429, %f1858, %f1858;
	fma.rn.f32 	%f1430, %f1857, %f1857, %f1429;
	fma.rn.f32 	%f1431, %f1859, %f1859, %f1430;
	fma.rn.f32 	%f1432, %f1860, %f1860, %f1431;
	rcp.rn.f32 	%f1433, %f1432;
	mul.f32 	%f1434, %f1857, %f1433;
	mul.f32 	%f1435, %f1858, %f1433;
	mul.f32 	%f1436, %f1859, %f1433;
	mul.f32 	%f1437, %f1860, %f1433;
	mul.f32 	%f1438, %f1857, %f1434;
	mul.f32 	%f1439, %f1858, %f1435;
	mul.f32 	%f1440, %f1859, %f1436;
	mul.f32 	%f1441, %f1857, %f1435;
	mul.f32 	%f1442, %f1859, %f1437;
	mul.f32 	%f1443, %f1857, %f1436;
	mul.f32 	%f1444, %f1858, %f1437;
	mul.f32 	%f1445, %f1858, %f1436;
	mul.f32 	%f1446, %f1857, %f1437;
	sub.f32 	%f1447, %f1438, %f1439;
	sub.f32 	%f1448, %f1447, %f1440;
	fma.rn.f32 	%f1449, %f1860, %f1437, %f1448;
	sub.f32 	%f1450, %f1441, %f1442;
	add.f32 	%f1451, %f1450, %f1450;
	add.f32 	%f1452, %f1443, %f1444;
	add.f32 	%f1453, %f1452, %f1452;
	add.f32 	%f1454, %f1441, %f1442;
	add.f32 	%f1455, %f1454, %f1454;
	sub.f32 	%f1456, %f1439, %f1438;
	sub.f32 	%f1457, %f1456, %f1440;
	fma.rn.f32 	%f1458, %f1860, %f1437, %f1457;
	sub.f32 	%f1459, %f1445, %f1446;
	add.f32 	%f1460, %f1459, %f1459;
	sub.f32 	%f1461, %f1443, %f1444;
	add.f32 	%f1462, %f1461, %f1461;
	add.f32 	%f1463, %f1445, %f1446;
	add.f32 	%f1464, %f1463, %f1463;
	neg.f32 	%f1465, %f1438;
	sub.f32 	%f1466, %f1465, %f1439;
	add.f32 	%f1467, %f1440, %f1466;
	fma.rn.f32 	%f1468, %f1860, %f1437, %f1467;
	mul.f32 	%f1469, %f1853, %f1449;
	fma.rn.f32 	%f1470, %f1855, %f1451, %f1469;
	fma.rn.f32 	%f1869, %f1856, %f1453, %f1470;
	mul.f32 	%f1471, %f1855, %f1458;
	fma.rn.f32 	%f1472, %f1853, %f1455, %f1471;
	fma.rn.f32 	%f1866, %f1856, %f1460, %f1472;
	mul.f32 	%f1473, %f1855, %f1464;
	fma.rn.f32 	%f1474, %f1853, %f1462, %f1473;
	fma.rn.f32 	%f1863, %f1856, %f1468, %f1474;
	mul.f32 	%f1475, %f1852, %f1449;
	fma.rn.f32 	%f1868, %f1854, %f1451, %f1475;
	mul.f32 	%f1476, %f1854, %f1458;
	fma.rn.f32 	%f1865, %f1852, %f1455, %f1476;
	mul.f32 	%f1477, %f1854, %f1464;
	fma.rn.f32 	%f1862, %f1852, %f1462, %f1477;
	mul.f32 	%f1867, %f1851, %f1449;
	mul.f32 	%f1864, %f1851, %f1455;
	mul.f32 	%f1861, %f1851, %f1462;

BB12_86:
	mul.f32 	%f1509, %f1862, %f1866;
	mul.f32 	%f1510, %f1863, %f1865;
	sub.f32 	%f1511, %f1510, %f1509;
	mul.f32 	%f1512, %f1867, %f1511;
	mul.f32 	%f1513, %f1861, %f1866;
	mul.f32 	%f1514, %f1863, %f1864;
	sub.f32 	%f1515, %f1514, %f1513;
	mul.f32 	%f1516, %f1515, %f1868;
	sub.f32 	%f1517, %f1512, %f1516;
	mul.f32 	%f1518, %f1861, %f1865;
	mul.f32 	%f1519, %f1862, %f1864;
	sub.f32 	%f1520, %f1519, %f1518;
	fma.rn.f32 	%f1521, %f1520, %f1869, %f1517;
	rcp.rn.f32 	%f1522, %f1521;
	mul.f32 	%f1876, %f1511, %f1522;
	mul.f32 	%f1523, %f1863, %f1868;
	mul.f32 	%f1524, %f1862, %f1869;
	sub.f32 	%f1525, %f1524, %f1523;
	mul.f32 	%f1877, %f1522, %f1525;
	mul.f32 	%f1526, %f1865, %f1869;
	mul.f32 	%f1527, %f1866, %f1868;
	sub.f32 	%f1528, %f1527, %f1526;
	mul.f32 	%f1878, %f1522, %f1528;
	sub.f32 	%f1529, %f1513, %f1514;
	mul.f32 	%f1873, %f1529, %f1522;
	mul.f32 	%f1530, %f1861, %f1869;
	mul.f32 	%f1531, %f1863, %f1867;
	sub.f32 	%f1532, %f1531, %f1530;
	mul.f32 	%f1874, %f1522, %f1532;
	mul.f32 	%f1533, %f1866, %f1867;
	mul.f32 	%f1534, %f1864, %f1869;
	sub.f32 	%f1535, %f1534, %f1533;
	mul.f32 	%f1875, %f1522, %f1535;
	mul.f32 	%f1870, %f1520, %f1522;
	mul.f32 	%f1536, %f1862, %f1867;
	mul.f32 	%f1537, %f1861, %f1868;
	sub.f32 	%f1538, %f1537, %f1536;
	mul.f32 	%f1871, %f1538, %f1522;
	mul.f32 	%f1539, %f1864, %f1868;
	mul.f32 	%f1540, %f1865, %f1867;
	sub.f32 	%f1541, %f1540, %f1539;
	mul.f32 	%f1872, %f1541, %f1522;
	bra.uni 	BB12_87;

BB12_76:
	setp.ne.s32	%p39, %r479, 1;
	mov.f32 	%f1871, %f1870;
	mov.f32 	%f1873, %f1870;
	mov.f32 	%f1874, %f1872;
	mov.f32 	%f1875, %f1870;
	mov.f32 	%f1876, %f1872;
	mov.f32 	%f1877, %f1870;
	mov.f32 	%f1878, %f1870;
	@%p39 bra 	BB12_87;

	// inline asm
	call (%rd418), _optix_get_static_transform_from_handle, (%rd416);
	// inline asm
	add.s64 	%rd646, %rd418, 64;

BB12_79:
	// inline asm
	cvta.to.global.u64 %rd422, %rd646;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r481,%r482,%r483,%r484}, [%rd422];
	// inline asm
	mov.b32 	 %f1876, %r481;
	mov.b32 	 %f1877, %r482;
	mov.b32 	 %f1878, %r483;
	add.s64 	%rd426, %rd646, 16;
	// inline asm
	cvta.to.global.u64 %rd425, %rd426;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r485,%r486,%r487,%r488}, [%rd425];
	// inline asm
	mov.b32 	 %f1873, %r485;
	mov.b32 	 %f1874, %r486;
	mov.b32 	 %f1875, %r487;
	add.s64 	%rd429, %rd646, 32;
	// inline asm
	cvta.to.global.u64 %rd428, %rd429;
	// inline asm
	// inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd428];
	// inline asm
	mov.b32 	 %f1870, %r489;
	mov.b32 	 %f1871, %r490;
	mov.b32 	 %f1872, %r491;

BB12_87:
	setp.eq.s32	%p43, %r634, 0;
	@%p43 bra 	BB12_88;
	bra.uni 	BB12_89;

BB12_88:
	mov.f32 	%f1850, %f1870;
	mov.f32 	%f1849, %f1871;
	mov.f32 	%f1848, %f1872;
	mov.f32 	%f1847, %f1873;
	mov.f32 	%f1846, %f1874;
	mov.f32 	%f1845, %f1875;
	mov.f32 	%f1844, %f1876;
	mov.f32 	%f1843, %f1877;
	mov.f32 	%f1842, %f1878;
	bra.uni 	BB12_90;

BB12_89:
	mul.f32 	%f1542, %f1847, %f1877;
	fma.rn.f32 	%f1543, %f1844, %f1876, %f1542;
	fma.rn.f32 	%f598, %f1850, %f1878, %f1543;
	mul.f32 	%f1544, %f1846, %f1877;
	fma.rn.f32 	%f1545, %f1843, %f1876, %f1544;
	fma.rn.f32 	%f599, %f1849, %f1878, %f1545;
	mul.f32 	%f1546, %f1845, %f1877;
	fma.rn.f32 	%f1547, %f1842, %f1876, %f1546;
	fma.rn.f32 	%f600, %f1848, %f1878, %f1547;
	mul.f32 	%f1548, %f1847, %f1874;
	fma.rn.f32 	%f1549, %f1844, %f1873, %f1548;
	fma.rn.f32 	%f601, %f1850, %f1875, %f1549;
	mul.f32 	%f1550, %f1846, %f1874;
	fma.rn.f32 	%f1551, %f1843, %f1873, %f1550;
	fma.rn.f32 	%f602, %f1849, %f1875, %f1551;
	mul.f32 	%f1552, %f1845, %f1874;
	fma.rn.f32 	%f1553, %f1842, %f1873, %f1552;
	fma.rn.f32 	%f603, %f1848, %f1875, %f1553;
	mul.f32 	%f1554, %f1847, %f1871;
	fma.rn.f32 	%f1555, %f1844, %f1870, %f1554;
	fma.rn.f32 	%f1850, %f1850, %f1872, %f1555;
	mul.f32 	%f1556, %f1846, %f1871;
	fma.rn.f32 	%f1557, %f1843, %f1870, %f1556;
	fma.rn.f32 	%f1849, %f1849, %f1872, %f1557;
	mul.f32 	%f1558, %f1845, %f1871;
	fma.rn.f32 	%f1559, %f1842, %f1870, %f1558;
	fma.rn.f32 	%f1848, %f1848, %f1872, %f1559;
	mov.f32 	%f1847, %f601;
	mov.f32 	%f1846, %f602;
	mov.f32 	%f1845, %f603;
	mov.f32 	%f1844, %f598;
	mov.f32 	%f1843, %f599;
	mov.f32 	%f1842, %f600;

BB12_90:
	add.s32 	%r634, %r634, 1;
	setp.lt.u32	%p44, %r634, %r26;
	@%p44 bra 	BB12_74;

BB12_91:
	fma.rn.f32 	%f1560, %f1921, %f1781, %f1778;
	fma.rn.f32 	%f1561, %f1922, %f1780, %f1560;
	fma.rn.f32 	%f1562, %f1921, %f1785, %f1782;
	fma.rn.f32 	%f1563, %f1922, %f1784, %f1562;
	fma.rn.f32 	%f1564, %f1921, %f1789, %f1786;
	fma.rn.f32 	%f1565, %f1922, %f1788, %f1564;
	fma.rn.f32 	%f1921, %f1923, %f1779, %f1561;
	fma.rn.f32 	%f1922, %f1923, %f1783, %f1563;
	fma.rn.f32 	%f1923, %f1923, %f1787, %f1565;
	ld.const.u64 	%rd537, [params+112];
	setp.eq.s64	%p45, %rd537, 0;
	mov.f32 	%f1915, %f1775;
	mov.f32 	%f1916, %f1776;
	mov.f32 	%f1917, %f1777;
	@%p45 bra 	BB12_93;

	mul.f32 	%f1566, %f1775, %f1844;
	fma.rn.f32 	%f1567, %f1776, %f1847, %f1566;
	mul.f32 	%f1568, %f1775, %f1843;
	fma.rn.f32 	%f1569, %f1776, %f1846, %f1568;
	mul.f32 	%f1570, %f1775, %f1842;
	fma.rn.f32 	%f1571, %f1776, %f1845, %f1570;
	fma.rn.f32 	%f1572, %f1777, %f1850, %f1567;
	fma.rn.f32 	%f1573, %f1777, %f1849, %f1569;
	fma.rn.f32 	%f1574, %f1777, %f1848, %f1571;
	mul.f32 	%f1575, %f1572, %f1572;
	fma.rn.f32 	%f1576, %f1573, %f1573, %f1575;
	fma.rn.f32 	%f1577, %f1574, %f1574, %f1576;
	sqrt.rn.f32 	%f1578, %f1577;
	div.rn.f32 	%f1915, %f1572, %f1578;
	div.rn.f32 	%f1916, %f1573, %f1578;
	div.rn.f32 	%f1917, %f1574, %f1578;

BB12_93:
	ld.const.u64 	%rd538, [params+136];
	setp.eq.s64	%p46, %rd538, 0;
	@%p46 bra 	BB12_95;

	mul.f32 	%f1579, %f1775, %f1844;
	fma.rn.f32 	%f1580, %f1776, %f1847, %f1579;
	mul.f32 	%f1581, %f1775, %f1843;
	fma.rn.f32 	%f1582, %f1776, %f1846, %f1581;
	mul.f32 	%f1583, %f1775, %f1842;
	fma.rn.f32 	%f1584, %f1776, %f1845, %f1583;
	fma.rn.f32 	%f1585, %f1777, %f1850, %f1580;
	fma.rn.f32 	%f1586, %f1777, %f1849, %f1582;
	fma.rn.f32 	%f1587, %f1777, %f1848, %f1584;
	mul.f32 	%f1588, %f1585, %f1585;
	fma.rn.f32 	%f1589, %f1586, %f1586, %f1588;
	fma.rn.f32 	%f1590, %f1587, %f1587, %f1589;
	sqrt.rn.f32 	%f1591, %f1590;
	div.rn.f32 	%f1775, %f1585, %f1591;
	div.rn.f32 	%f1776, %f1586, %f1591;
	div.rn.f32 	%f1777, %f1587, %f1591;

BB12_95:
	ld.const.u64 	%rd539, [params+184];
	setp.eq.s64	%p47, %rd539, 0;
	mov.f32 	%f1909, 0f00000000;
	mov.f32 	%f1912, %f1909;
	mov.f32 	%f1913, %f1909;
	mov.f32 	%f1914, %f1909;
	@%p47 bra 	BB12_97;

	mul.f32 	%f1595, %f1781, 0f00000000;
	mov.f32 	%f1596, 0f00000000;
	fma.rn.f32 	%f1597, %f1596, %f1780, %f1595;
	mul.f32 	%f1598, %f1785, 0f00000000;
	fma.rn.f32 	%f1599, %f1596, %f1784, %f1598;
	mul.f32 	%f1600, %f1789, 0f00000000;
	fma.rn.f32 	%f1601, %f1596, %f1788, %f1600;
	fma.rn.f32 	%f1912, %f1596, %f1779, %f1597;
	fma.rn.f32 	%f1913, %f1596, %f1783, %f1599;
	fma.rn.f32 	%f1914, %f1596, %f1787, %f1601;

BB12_97:
	ld.const.u64 	%rd540, [params+280];
	ld.const.u64 	%rd541, [params+232];
	or.b64  	%rd542, %rd540, %rd541;
	setp.eq.s64	%p48, %rd542, 0;
	mov.f32 	%f1910, %f1909;
	mov.f32 	%f1911, %f1909;
	@%p48 bra 	BB12_99;

	mul.f32 	%f1605, %f1775, %f1781;
	fma.rn.f32 	%f1606, %f1776, %f1785, %f1605;
	mul.f32 	%f1607, %f1775, %f1780;
	fma.rn.f32 	%f1608, %f1776, %f1784, %f1607;
	mul.f32 	%f1609, %f1775, %f1779;
	fma.rn.f32 	%f1610, %f1776, %f1783, %f1609;
	fma.rn.f32 	%f1611, %f1777, %f1789, %f1606;
	fma.rn.f32 	%f1612, %f1777, %f1788, %f1608;
	fma.rn.f32 	%f1613, %f1777, %f1787, %f1610;
	mul.f32 	%f1614, %f1611, %f1611;
	fma.rn.f32 	%f1615, %f1612, %f1612, %f1614;
	fma.rn.f32 	%f1616, %f1613, %f1613, %f1615;
	sqrt.rn.f32 	%f1617, %f1616;
	div.rn.f32 	%f1618, %f1611, %f1617;
	div.rn.f32 	%f1619, %f1612, %f1617;
	div.rn.f32 	%f1620, %f1613, %f1617;
	mul.f32 	%f1621, %f1618, %f1844;
	mul.f32 	%f1622, %f1618, %f1843;
	mul.f32 	%f1623, %f1618, %f1842;
	fma.rn.f32 	%f1624, %f1619, %f1847, %f1621;
	fma.rn.f32 	%f1625, %f1619, %f1846, %f1622;
	fma.rn.f32 	%f1626, %f1619, %f1845, %f1623;
	fma.rn.f32 	%f1627, %f1620, %f1850, %f1624;
	fma.rn.f32 	%f1628, %f1620, %f1849, %f1625;
	fma.rn.f32 	%f1629, %f1620, %f1848, %f1626;
	mul.f32 	%f1630, %f1627, %f1627;
	fma.rn.f32 	%f1631, %f1628, %f1628, %f1630;
	fma.rn.f32 	%f1632, %f1629, %f1629, %f1631;
	sqrt.rn.f32 	%f1633, %f1632;
	rcp.rn.f32 	%f1634, %f1633;
	mul.f32 	%f1635, %f1634, %f1627;
	mul.f32 	%f1636, %f1634, %f1628;
	mul.f32 	%f1637, %f1634, %f1629;
	mul.f32 	%f1638, %f1844, 0f00000000;
	mov.f32 	%f1639, 0f00000000;
	fma.rn.f32 	%f1640, %f1639, %f1847, %f1638;
	mul.f32 	%f1641, %f1843, 0f00000000;
	fma.rn.f32 	%f1642, %f1639, %f1846, %f1641;
	mul.f32 	%f1643, %f1842, 0f00000000;
	fma.rn.f32 	%f1644, %f1639, %f1845, %f1643;
	fma.rn.f32 	%f1645, %f1639, %f1850, %f1640;
	fma.rn.f32 	%f1646, %f1639, %f1849, %f1642;
	fma.rn.f32 	%f1647, %f1639, %f1848, %f1644;
	mul.f32 	%f1648, %f1645, %f1634;
	mul.f32 	%f1649, %f1646, %f1634;
	mul.f32 	%f1650, %f1647, %f1634;
	mul.f32 	%f1651, %f1635, %f1648;
	fma.rn.f32 	%f1652, %f1636, %f1649, %f1651;
	fma.rn.f32 	%f1653, %f1637, %f1650, %f1652;
	mul.f32 	%f1654, %f1635, %f1653;
	mul.f32 	%f1655, %f1636, %f1653;
	mul.f32 	%f1656, %f1637, %f1653;
	sub.f32 	%f1909, %f1648, %f1654;
	sub.f32 	%f1910, %f1649, %f1655;
	sub.f32 	%f1911, %f1650, %f1656;

BB12_99:
	st.global.u32 	[%rd23], %r327;
	bra.uni 	BB12_100;

BB12_53:
	mov.f32 	%f1910, %f1909;
	mov.f32 	%f1911, %f1909;
	mov.f32 	%f1912, %f1909;
	mov.f32 	%f1913, %f1909;
	mov.f32 	%f1914, %f1909;
	mov.f32 	%f1915, %f1775;
	mov.f32 	%f1916, %f1776;
	mov.f32 	%f1917, %f1777;

BB12_100:
	ld.const.u64 	%rd543, [params+328];
	cvta.to.global.u64 	%rd544, %rd543;
	shl.b64 	%rd545, %rd22, 3;
	add.s64 	%rd546, %rd544, %rd545;
	st.global.u64 	[%rd546], %rd21;
	ld.const.u64 	%rd547, [params+336];
	cvta.to.global.u64 	%rd548, %rd547;
	shl.b64 	%rd549, %rd22, 2;
	add.s64 	%rd550, %rd548, %rd549;
	mov.u32 	%r627, 0;
	st.global.u32 	[%rd550], %r627;
	ld.const.u64 	%rd551, [params+160];
	cvta.to.global.u64 	%rd552, %rd551;
	add.s64 	%rd553, %rd552, %rd549;
	st.global.f32 	[%rd553], %f1921;
	ld.const.u64 	%rd554, [params+168];
	cvta.to.global.u64 	%rd555, %rd554;
	add.s64 	%rd556, %rd555, %rd549;
	st.global.f32 	[%rd556], %f1922;
	ld.const.u64 	%rd557, [params+176];
	cvta.to.global.u64 	%rd558, %rd557;
	add.s64 	%rd559, %rd558, %rd549;
	st.global.f32 	[%rd559], %f1923;
	ld.const.u64 	%rd560, [params+72];
	cvta.to.global.u64 	%rd561, %rd560;
	add.s64 	%rd562, %rd561, %rd549;
	st.global.f32 	[%rd562], %f1113;
	ld.const.u64 	%rd40, [params+96];
	setp.eq.s64	%p49, %rd40, 0;
	@%p49 bra 	BB12_102;

	cvta.to.global.u64 	%rd563, %rd40;
	add.s64 	%rd565, %rd563, %rd549;
	st.global.u32 	[%rd565], %r627;
	ld.const.u64 	%rd566, [params+104];
	cvta.to.global.u64 	%rd567, %rd566;
	add.s64 	%rd568, %rd567, %rd549;
	st.global.u32 	[%rd568], %r627;

BB12_102:
	ld.const.u64 	%rd41, [params+112];
	setp.eq.s64	%p50, %rd41, 0;
	@%p50 bra 	BB12_104;

	cvta.to.global.u64 	%rd569, %rd41;
	add.s64 	%rd571, %rd569, %rd549;
	st.global.f32 	[%rd571], %f1915;
	ld.const.u64 	%rd572, [params+120];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd549;
	st.global.f32 	[%rd574], %f1916;
	ld.const.u64 	%rd575, [params+128];
	cvta.to.global.u64 	%rd576, %rd575;
	add.s64 	%rd577, %rd576, %rd549;
	st.global.f32 	[%rd577], %f1917;

BB12_104:
	ld.const.u64 	%rd42, [params+136];
	setp.eq.s64	%p51, %rd42, 0;
	@%p51 bra 	BB12_106;

	cvta.to.global.u64 	%rd578, %rd42;
	add.s64 	%rd580, %rd578, %rd549;
	st.global.f32 	[%rd580], %f1775;
	ld.const.u64 	%rd581, [params+144];
	cvta.to.global.u64 	%rd582, %rd581;
	add.s64 	%rd583, %rd582, %rd549;
	st.global.f32 	[%rd583], %f1776;
	ld.const.u64 	%rd584, [params+152];
	cvta.to.global.u64 	%rd585, %rd584;
	add.s64 	%rd586, %rd585, %rd549;
	st.global.f32 	[%rd586], %f1777;

BB12_106:
	ld.const.u64 	%rd43, [params+184];
	setp.eq.s64	%p52, %rd43, 0;
	@%p52 bra 	BB12_108;

	cvta.to.global.u64 	%rd587, %rd43;
	add.s64 	%rd589, %rd587, %rd549;
	st.global.f32 	[%rd589], %f1912;
	ld.const.u64 	%rd590, [params+192];
	cvta.to.global.u64 	%rd591, %rd590;
	add.s64 	%rd592, %rd591, %rd549;
	st.global.f32 	[%rd592], %f1913;
	ld.const.u64 	%rd593, [params+200];
	cvta.to.global.u64 	%rd594, %rd593;
	add.s64 	%rd595, %rd594, %rd549;
	st.global.f32 	[%rd595], %f1914;
	ld.const.u64 	%rd596, [params+208];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd549;
	st.global.f32 	[%rd598], %f1912;
	ld.const.u64 	%rd599, [params+216];
	cvta.to.global.u64 	%rd600, %rd599;
	add.s64 	%rd601, %rd600, %rd549;
	st.global.f32 	[%rd601], %f1913;
	ld.const.u64 	%rd602, [params+224];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd549;
	st.global.f32 	[%rd604], %f1914;

BB12_108:
	ld.const.u64 	%rd44, [params+232];
	setp.eq.s64	%p53, %rd44, 0;
	@%p53 bra 	BB12_110;

	cvta.to.global.u64 	%rd605, %rd44;
	add.s64 	%rd607, %rd605, %rd549;
	st.global.f32 	[%rd607], %f1909;
	ld.const.u64 	%rd608, [params+240];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd549;
	st.global.f32 	[%rd610], %f1910;
	ld.const.u64 	%rd611, [params+248];
	cvta.to.global.u64 	%rd612, %rd611;
	add.s64 	%rd613, %rd612, %rd549;
	st.global.f32 	[%rd613], %f1911;
	ld.const.u64 	%rd614, [params+256];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd549;
	st.global.f32 	[%rd616], %f1909;
	ld.const.u64 	%rd617, [params+264];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd549;
	st.global.f32 	[%rd619], %f1910;
	ld.const.u64 	%rd620, [params+272];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd549;
	st.global.f32 	[%rd622], %f1911;

BB12_110:
	ld.const.u64 	%rd45, [params+280];
	setp.eq.s64	%p54, %rd45, 0;
	@%p54 bra 	BB12_112;

	cvta.to.global.u64 	%rd623, %rd45;
	add.s64 	%rd625, %rd623, %rd549;
	st.global.f32 	[%rd625], %f1909;
	ld.const.u64 	%rd626, [params+288];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd549;
	st.global.f32 	[%rd628], %f1910;
	ld.const.u64 	%rd629, [params+296];
	cvta.to.global.u64 	%rd630, %rd629;
	add.s64 	%rd631, %rd630, %rd549;
	st.global.f32 	[%rd631], %f1911;
	ld.const.u64 	%rd632, [params+304];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd549;
	st.global.f32 	[%rd634], %f1909;
	ld.const.u64 	%rd635, [params+312];
	cvta.to.global.u64 	%rd636, %rd635;
	add.s64 	%rd637, %rd636, %rd549;
	st.global.f32 	[%rd637], %f1910;
	ld.const.u64 	%rd638, [params+320];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd549;
	st.global.f32 	[%rd640], %f1911;

BB12_112:
	ret;

BB12_45:
	fma.rn.f32 	%f1115, %f1113, %f1772, %f1725;
	ld.v4.f32 	{%f1116, %f1117, %f1118, %f1119}, [%rd3+288];
	sub.f32 	%f316, %f1115, %f1116;
	fma.rn.f32 	%f1121, %f1113, %f1773, %f1724;
	sub.f32 	%f317, %f1121, %f1117;
	sub.f32 	%f1124, %f1923, %f1118;
	mul.f32 	%f1125, %f1124, 0f00000000;
	mul.f32 	%f1126, %f316, %f316;
	fma.rn.f32 	%f318, %f317, %f317, %f1126;
	fma.rn.f32 	%f1127, %f1125, %f1125, %f318;
	sqrt.rn.f32 	%f1128, %f1127;
	ld.v4.f32 	{%f1129, %f1130, %f1131, %f1132}, [%rd3+304];
	fma.rn.f32 	%f1135, %f1131, 0f3F000000, %f1129;
	setp.gt.f32	%p22, %f1128, %f1135;
	mul.f32 	%f319, %f1125, 0f00000000;
	@%p22 bra 	BB12_47;
	bra.uni 	BB12_46;

BB12_47:
	fma.rn.f32 	%f1142, %f319, %f319, %f318;
	sqrt.rn.f32 	%f1143, %f1142;
	div.rn.f32 	%f1775, %f316, %f1143;
	div.rn.f32 	%f1776, %f317, %f1143;
	div.rn.f32 	%f1777, %f319, %f1143;
	bra.uni 	BB12_52;

BB12_46:
	neg.f32 	%f1136, %f316;
	neg.f32 	%f1138, %f317;
	fma.rn.f32 	%f1139, %f1138, %f1138, %f1126;
	fma.rn.f32 	%f1140, %f319, %f319, %f1139;
	sqrt.rn.f32 	%f1141, %f1140;
	div.rn.f32 	%f1775, %f1136, %f1141;
	div.rn.f32 	%f1776, %f1138, %f1141;
	div.rn.f32 	%f1777, %f319, %f1141;
	bra.uni 	BB12_52;
}

	// .globl	__raygen__rg
.visible .entry __raygen__rg(

)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<44>;


	// inline asm
	call (%r1), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r4), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r5), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r6), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r7, %r6, %r2, %r5;
	mad.lo.s32 	%r8, %r7, %r1, %r4;
	ld.const.u64 	%rd3, [params+8];
	cvta.to.global.u64 	%rd4, %rd3;
	cvt.u64.u32	%rd1, %r8;
	mul.wide.u32 	%rd5, %r8, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f1, [%rd6];
	ld.const.u64 	%rd7, [params+16];
	cvta.to.global.u64 	%rd8, %rd7;
	add.s64 	%rd9, %rd8, %rd5;
	ld.global.f32 	%f2, [%rd9];
	ld.const.u64 	%rd10, [params+24];
	cvta.to.global.u64 	%rd11, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.f32 	%f3, [%rd12];
	ld.const.u64 	%rd13, [params+32];
	cvta.to.global.u64 	%rd14, %rd13;
	add.s64 	%rd15, %rd14, %rd5;
	ld.global.f32 	%f4, [%rd15];
	ld.const.u64 	%rd16, [params+40];
	cvta.to.global.u64 	%rd17, %rd16;
	add.s64 	%rd18, %rd17, %rd5;
	ld.global.f32 	%f5, [%rd18];
	ld.const.u64 	%rd19, [params+48];
	cvta.to.global.u64 	%rd20, %rd19;
	add.s64 	%rd21, %rd20, %rd5;
	ld.global.f32 	%f6, [%rd21];
	ld.const.u64 	%rd22, [params+56];
	cvta.to.global.u64 	%rd23, %rd22;
	add.s64 	%rd24, %rd23, %rd5;
	ld.global.f32 	%f7, [%rd24];
	ld.const.u64 	%rd25, [params+64];
	cvta.to.global.u64 	%rd26, %rd25;
	add.s64 	%rd27, %rd26, %rd5;
	ld.global.f32 	%f9, [%rd27];
	setp.eq.f32	%p1, %f9, 0f7F800000;
	selp.f32	%f8, 0f7F7FFFFF, %f9, %p1;
	ld.const.u64 	%rd2, [params+352];
	setp.eq.s64	%p2, %rd2, 0;
	ld.const.u64 	%rd28, [params];
	cvta.to.global.u64 	%rd29, %rd28;
	add.s64 	%rd30, %rd29, %rd1;
	ld.global.u8 	%rs1, [%rd30];
	@%p2 bra 	BB13_4;

	setp.eq.s16	%p3, %rs1, 0;
	@%p3 bra 	BB13_3;

	ld.const.u64 	%rd31, [params+360];
	mov.u32 	%r10, 4;
	mov.u32 	%r12, 1;
	mov.u32 	%r13, 0;
	mov.f32 	%f18, 0f00000000;
	// inline asm
	call _optix_trace_0, (%rd31, %f1, %f2, %f3, %f4, %f5, %f6, %f7, %f8, %f18, %r12, %r10, %r13, %r12, %r13);
	// inline asm
	bra.uni 	BB13_7;

BB13_4:
	setp.eq.s16	%p4, %rs1, 0;
	@%p4 bra 	BB13_6;

	ld.const.u64 	%rd34, [params+360];
	mov.u32 	%r17, 1;
	mov.u32 	%r18, 0;
	mov.f32 	%f27, 0f00000000;
	// inline asm
	call _optix_trace_0, (%rd34, %f1, %f2, %f3, %f4, %f5, %f6, %f7, %f8, %f27, %r17, %r18, %r18, %r17, %r18);
	// inline asm
	bra.uni 	BB13_7;

BB13_3:
	cvta.to.global.u64 	%rd32, %rd2;
	add.s64 	%rd33, %rd32, %rd1;
	mov.u16 	%rs3, 0;
	st.global.u8 	[%rd33], %rs3;
	bra.uni 	BB13_7;

BB13_6:
	ld.const.u64 	%rd35, [params+328];
	cvta.to.global.u64 	%rd36, %rd35;
	shl.b64 	%rd37, %rd1, 3;
	add.s64 	%rd38, %rd36, %rd37;
	mov.u64 	%rd39, 0;
	st.global.u64 	[%rd38], %rd39;
	ld.const.u64 	%rd40, [params+72];
	cvta.to.global.u64 	%rd41, %rd40;
	shl.b64 	%rd42, %rd1, 2;
	add.s64 	%rd43, %rd41, %rd42;
	mov.u32 	%r19, 2139095040;
	st.global.u32 	[%rd43], %r19;

BB13_7:
	ret;
}

	// .globl	__miss__ms
.visible .entry __miss__ms(

)
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<14>;


	// inline asm
	call (%r1), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_launch_dimension_y, ();
	// inline asm
	// inline asm
	call (%r4), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r5), _optix_get_launch_index_y, ();
	// inline asm
	// inline asm
	call (%r6), _optix_get_launch_index_z, ();
	// inline asm
	mad.lo.s32 	%r7, %r6, %r2, %r5;
	mad.lo.s32 	%r8, %r7, %r1, %r4;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64	%p1, %rd1, 0;
	cvt.u64.u32	%rd2, %r8;
	@%p1 bra 	BB14_2;

	cvta.to.global.u64 	%rd3, %rd1;
	add.s64 	%rd4, %rd3, %rd2;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd4], %rs1;
	bra.uni 	BB14_3;

BB14_2:
	ld.const.u64 	%rd5, [params+328];
	cvta.to.global.u64 	%rd6, %rd5;
	shl.b64 	%rd7, %rd2, 3;
	add.s64 	%rd8, %rd6, %rd7;
	mov.u64 	%rd9, 0;
	st.global.u64 	[%rd8], %rd9;
	ld.const.u64 	%rd10, [params+72];
	cvta.to.global.u64 	%rd11, %rd10;
	shl.b64 	%rd12, %rd2, 2;
	add.s64 	%rd13, %rd11, %rd12;
	mov.u32 	%r9, 2139095040;
	st.global.u32 	[%rd13], %r9;

BB14_3:
	ret;
}

	// .globl	__exception__err
.visible .entry __exception__err(

)
{
	.local .align 16 .b8 	__local_depot15[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<9>;


	mov.u64 	%SPL, __local_depot15;
	cvta.local.u64 	%SP, %SPL;
	// inline asm
	call (%r1), _optix_get_exception_code, ();
	// inline asm
	mul.wide.s32 	%rd1, %r1, 16;
	mov.u64 	%rd2, exceptions;
	add.s64 	%rd3, %rd2, %rd1;
	ld.const.u64 	%rd4, [%rd3+8];
	add.u64 	%rd5, %SP, 0;
	add.u64 	%rd6, %SPL, 0;
	st.local.u32 	[%rd6], %r1;
	st.local.u64 	[%rd6+8], %rd4;
	mov.u64 	%rd7, $str6;
	cvta.global.u64 	%rd8, %rd7;
	// Callseq Start 25
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd8;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r2, [retval0+0];
	
	//{
	}// Callseq End 25
	ret;
}

.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<138>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd12;
	}
	shr.u32 	%r51, %r50, 20;
	setp.ne.s32	%p1, %r51, 0;
	@%p1 bra 	BB16_2;

	mul.f64 	%fd13, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd13;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd13;
	}
	shr.u32 	%r16, %r50, 20;
	add.s32 	%r51, %r16, -54;

BB16_2:
	add.s32 	%r52, %r51, -1023;
	and.b32  	%r17, %r50, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd135, {%r49, %r18};
	setp.lt.u32	%p2, %r18, 1073127583;
	@%p2 bra 	BB16_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd135;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd135, {%r19, %r21};
	add.s32 	%r52, %r51, -1022;

BB16_4:
	add.f64 	%fd14, %fd135, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd15, %fd14;
	neg.f64 	%fd16, %fd14;
	mov.f64 	%fd17, 0d3FF0000000000000;
	fma.rn.f64 	%fd18, %fd16, %fd15, %fd17;
	fma.rn.f64 	%fd19, %fd18, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd15, %fd15;
	add.f64 	%fd21, %fd135, 0dBFF0000000000000;
	mul.f64 	%fd22, %fd21, %fd20;
	fma.rn.f64 	%fd23, %fd21, %fd20, %fd22;
	mul.f64 	%fd24, %fd23, %fd23;
	mov.f64 	%fd25, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd26, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F6249249242B910;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F89999999999DFB;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	sub.f64 	%fd38, %fd21, %fd23;
	add.f64 	%fd39, %fd38, %fd38;
	neg.f64 	%fd40, %fd23;
	fma.rn.f64 	%fd41, %fd40, %fd21, %fd39;
	mul.f64 	%fd42, %fd20, %fd41;
	fma.rn.f64 	%fd43, %fd24, %fd37, 0d3FB5555555555555;
	mov.f64 	%fd44, 0d3FB5555555555555;
	sub.f64 	%fd45, %fd44, %fd43;
	fma.rn.f64 	%fd46, %fd24, %fd37, %fd45;
	add.f64 	%fd47, %fd46, 0d0000000000000000;
	add.f64 	%fd48, %fd47, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd49, %fd43, %fd48;
	sub.f64 	%fd50, %fd43, %fd49;
	add.f64 	%fd51, %fd48, %fd50;
	mul.rn.f64 	%fd52, %fd23, %fd23;
	neg.f64 	%fd53, %fd52;
	fma.rn.f64 	%fd54, %fd23, %fd23, %fd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd42;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd42;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd55, {%r22, %r24};
	fma.rn.f64 	%fd56, %fd23, %fd55, %fd54;
	mul.rn.f64 	%fd57, %fd52, %fd23;
	neg.f64 	%fd58, %fd57;
	fma.rn.f64 	%fd59, %fd52, %fd23, %fd58;
	fma.rn.f64 	%fd60, %fd52, %fd42, %fd59;
	fma.rn.f64 	%fd61, %fd56, %fd23, %fd60;
	mul.rn.f64 	%fd62, %fd49, %fd57;
	neg.f64 	%fd63, %fd62;
	fma.rn.f64 	%fd64, %fd49, %fd57, %fd63;
	fma.rn.f64 	%fd65, %fd49, %fd61, %fd64;
	fma.rn.f64 	%fd66, %fd51, %fd57, %fd65;
	add.f64 	%fd67, %fd62, %fd66;
	sub.f64 	%fd68, %fd62, %fd67;
	add.f64 	%fd69, %fd66, %fd68;
	add.f64 	%fd70, %fd23, %fd67;
	sub.f64 	%fd71, %fd23, %fd70;
	add.f64 	%fd72, %fd67, %fd71;
	add.f64 	%fd73, %fd69, %fd72;
	add.f64 	%fd74, %fd42, %fd73;
	add.f64 	%fd75, %fd70, %fd74;
	sub.f64 	%fd76, %fd70, %fd75;
	add.f64 	%fd77, %fd74, %fd76;
	xor.b32  	%r25, %r52, -2147483648;
	mov.u32 	%r26, -2147483648;
	mov.u32 	%r27, 1127219200;
	mov.b64 	%fd78, {%r25, %r27};
	mov.b64 	%fd79, {%r26, %r27};
	sub.f64 	%fd80, %fd78, %fd79;
	mov.f64 	%fd81, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd82, %fd80, %fd81, %fd75;
	neg.f64 	%fd83, %fd80;
	fma.rn.f64 	%fd84, %fd83, %fd81, %fd82;
	sub.f64 	%fd85, %fd84, %fd75;
	sub.f64 	%fd86, %fd77, %fd85;
	mov.f64 	%fd87, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd88, %fd80, %fd87, %fd86;
	add.f64 	%fd89, %fd82, %fd88;
	sub.f64 	%fd90, %fd82, %fd89;
	add.f64 	%fd91, %fd88, %fd90;
	mov.f64 	%fd92, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd92;
	}
	add.s32 	%r29, %r28, %r28;
	setp.gt.u32	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd92;
	}
	mov.b64 	%fd93, {%r32, %r31};
	mul.rn.f64 	%fd94, %fd89, %fd93;
	neg.f64 	%fd95, %fd94;
	fma.rn.f64 	%fd96, %fd89, %fd93, %fd95;
	fma.rn.f64 	%fd97, %fd91, %fd93, %fd96;
	add.f64 	%fd4, %fd94, %fd97;
	sub.f64 	%fd98, %fd94, %fd4;
	add.f64 	%fd5, %fd97, %fd98;
	mov.f64 	%fd99, 0d4338000000000000;
	mov.f64 	%fd100, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd101, %fd4, %fd100, %fd99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd101;
	}
	mov.f64 	%fd102, 0dC338000000000000;
	add.rn.f64 	%fd103, %fd101, %fd102;
	mov.f64 	%fd104, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd105, %fd103, %fd104, %fd4;
	mov.f64 	%fd106, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd107, %fd103, %fd106, %fd105;
	mov.f64 	%fd108, 0d3E928AF3FCA213EA;
	mov.f64 	%fd109, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd110, %fd109, %fd107, %fd108;
	mov.f64 	%fd111, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd112, %fd110, %fd107, %fd111;
	mov.f64 	%fd113, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd114, %fd112, %fd107, %fd113;
	mov.f64 	%fd115, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd116, %fd114, %fd107, %fd115;
	mov.f64 	%fd117, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd118, %fd116, %fd107, %fd117;
	mov.f64 	%fd119, 0d3F81111111122322;
	fma.rn.f64 	%fd120, %fd118, %fd107, %fd119;
	mov.f64 	%fd121, 0d3FA55555555502A1;
	fma.rn.f64 	%fd122, %fd120, %fd107, %fd121;
	mov.f64 	%fd123, 0d3FC5555555555511;
	fma.rn.f64 	%fd124, %fd122, %fd107, %fd123;
	mov.f64 	%fd125, 0d3FE000000000000B;
	fma.rn.f64 	%fd126, %fd124, %fd107, %fd125;
	fma.rn.f64 	%fd127, %fd126, %fd107, %fd17;
	fma.rn.f64 	%fd128, %fd127, %fd107, %fd17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd128;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd136, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	 %f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB16_7;

	setp.lt.f64	%p5, %fd4, 0d0000000000000000;
	add.f64 	%fd129, %fd4, 0d7FF0000000000000;
	selp.f64	%fd136, 0d0000000000000000, %fd129, %p5;
	setp.geu.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB16_7;

	mov.f64 	%fd134, 0d4338000000000000;
	mov.f64 	%fd133, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd132, %fd4, %fd133, %fd134;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd132;
	}
	shr.u32 	%r36, %r48, 31;
	add.s32 	%r37, %r48, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, %r15;
	mov.b64 	%fd130, {%r14, %r40};
	sub.s32 	%r41, %r48, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd131, {%r44, %r43};
	mul.f64 	%fd136, %fd130, %fd131;

BB16_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd136;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.ne.s32	%p7, %r46, 2146435072;
	@%p7 bra 	BB16_9;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd136;
	}
	setp.eq.s32	%p8, %r47, 0;
	@%p8 bra 	BB16_10;

BB16_9:
	fma.rn.f64 	%fd136, %fd136, %fd5, %fd136;

BB16_10:
	st.param.f64	[func_retval0+0], %fd136;
	ret;
}


